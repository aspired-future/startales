{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Monorepo and Project Scaffolding",
        "description": "Initialize local-first monorepo with client and server workspaces, TypeScript configs, linting, testing, and runtime env management.",
        "details": "- Structure:\n  - repo root: pnpm workspaces; packages: server (Node/TS), ui_frontend (React/TS), shared (types, schemas), scripts (CLIs), content (packs)\n- Tooling:\n  - Node 20+, pnpm, TypeScript strict, ESLint+Prettier, Jest+ts-jest, Playwright for E2E\n  - Env: dotenv-safe for local-only, no remote telemetry by default\n- Folder map:\n  - src/server: LLM orchestration, missions, rules, memory, persistence, realtime, images, scheduling, video (flagged)\n  - src/ui_frontend: voice capture, HUD, campaign browser, schedule editor, captions\n  - framework_docs/ (from repo)\n- Scripts: dev (concurrently server+client), build, test, e2e, lint, typecheck\n- Git hooks: pre-commit lint-staged; commitlint conventional commits\n- Security: .env.local in .gitignore; example env file with placeholders; keyring location documented\n- Accessibility baseline: eslint-plugin-jsx-a11y\n- Vite for UI; ts-node/tsx for server dev\n- CRDT lib placeholder (Automerge/Yjs) added as dep for later tasks",
        "testStrategy": "- CI runs lint, typecheck, unit tests on push\n- Playwright scaffold test opens app shell and loads WebSocket handshake stub\n- Verify no external network calls during startup (mock global fetch and assert none)\n- Ensure workspace build succeeds end-to-end with pnpm -r build",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for monorepo scaffolding (TC001â€“TC006)",
            "description": "Author repository-level tests that codify the core acceptance criteria before any implementation. Cover workspace layout, scripts, TypeScript strictness, linting/formatting, unit/e2e test runners, environment isolation, and absence of external telemetry on startup.",
            "dependencies": [],
            "details": "- Create a temporary sandbox (e.g., scripts/scaffold-tests/setupSandbox.ts) to run CLI scaffolding and assertions.\n- Write Jest tests (root-level) for:\n  - TC001: pnpm -r build succeeds for all workspaces and produces expected dist outputs.\n  - TC002: Workspace graph contains server, ui_frontend, shared, scripts, content with correct package.json config (name, private, type, main/module, scripts).\n  - TC003: TypeScript strict mode enabled across root and packages (tsc --noEmit) and fails on an intentional ts error fixture.\n  - TC004: ESLint + Prettier configured; lint-staged and commitlint configured; pre-commit hook triggers lint on staged files.\n  - TC005: Jest + ts-jest runs unit tests in server and shared; Playwright scaffold can launch dev server and open app shell.\n  - TC006: Startup makes no external network calls: mock global.fetch and node dns/http/https to assert no outbound during dev bootstrap.\n- Write a Playwright spec (e2e/app-smoke.spec.ts) that:\n  - Boots the dev servers via a test harness, visits http://localhost:5173, asserts app shell renders and a WebSocket handshake stub is attempted and intercepted.\n- Add minimal fixtures to assert directory presence and env files exist with placeholders. Do not implement scaffolding yet; tests should fail initially.",
            "status": "pending",
            "testStrategy": "Run tests locally: pnpm i; pnpm test; pnpm e2e. Ensure CI job (temporary GitHub Actions in .github/workflows/ci.yml) runs lint, typecheck, unit, and e2e in the sandbox."
          },
          {
            "id": 2,
            "title": "Initialize pnpm workspaces and root configuration",
            "description": "Create the monorepo root with pnpm workspaces, shared engines/pnpm version, base scripts, gitignore, editorconfig, and Node tool versions.",
            "dependencies": [],
            "details": "- Initialize repo: git init.\n- Add package.json at root:\n  - private: true, packageManager: \"pnpm@9.x\", engines: { node: \">=20\" }.\n  - workspaces: [\"packages/*\", \"framework_docs\"].\n  - scripts: dev, build, test, e2e, lint, typecheck, format, prepare (husky install).\n- Add pnpm-workspace.yaml specifying packages/* and excluding framework_docs from publishing.\n- Add .gitignore covering node_modules, dist, coverage, .env.local, .env.*, playwright/.cache.\n- Add .editorconfig with standard settings.\n- Add README with monorepo overview and local-first principles.\n- Commit and run tests from 1; fix workspace discovery failures until TC002 workspace presence checks pass.",
            "status": "pending",
            "testStrategy": "Run TC002 partial checks to ensure workspaces resolve. Ensure pnpm -r list shows no packages yet but workspace config loads."
          },
          {
            "id": 3,
            "title": "Scaffold shared package (types and schemas)",
            "description": "Create packages/shared with strict TS config, Jest setup, and initial Zod schema placeholders shared across server and UI.",
            "dependencies": [],
            "details": "- Create packages/shared/package.json with name \"@app/shared\", type: module, main: dist/index.js, types: dist/index.d.ts, files: [\"dist\"], sideEffects: false.\n- Add src/index.ts exporting placeholder zod schemas (e.g., MessageEnvelope, Channel, EnvConfig) and shared types.\n- Add tsconfig.json extending root base with \"strict\": true, composite: true, declaration: true, moduleResolution: bundler, module: ESNext, target: ES2022.\n- Add jest.config.ts with ts-jest preset and transforms for ESM.\n- Add basic unit tests verifying schema parse and type inferences (TC005 unit coverage for shared).\n- Add build script: tsup or tsc build; prefer tsc for simplicity: \"build\": \"tsc -b\".\n- Run tests; ensure TC003 strict mode and TC005 shared unit tests pass.",
            "status": "pending",
            "testStrategy": "pnpm --filter @app/shared test; pnpm -r typecheck; verify emitted d.ts and noImplicitAny violations."
          },
          {
            "id": 4,
            "title": "Scaffold server workspace (Node/TS with tsx dev)",
            "description": "Create packages/server with Node 20+ TypeScript, tsx for dev, ts-jest for unit tests, dotenv-safe for local-only env, and baseline runtime.",
            "dependencies": [],
            "details": "- packages/server/package.json: name \"@app/server\", type module, main dist/index.js, scripts: dev: \"tsx src/index.ts\", build: \"tsc -b\", test: jest, lint, typecheck.\n- Add dependencies: dotenv, dotenv-safe, zod; devDeps: tsx, ts-jest, jest, @types/jest, ts-node (if needed), typescript.\n- tsconfig.json extends root, sets NodeNext moduleResolution, strict, outDir dist, rootDir src, skipLibCheck false.\n- src/index.ts: load env via dotenv-safe (require .env.local and .env.example), initialize minimal HTTP server with no outbound calls, log structured startup.\n- src/config/env.ts: zod-validated env loader; export getEnv() used by index.\n- Add jest config and sample unit tests for env validation and startup without external calls (mock http/https/fetch) to satisfy TC006.\n- Document .env.example placeholders and ensure .env.local is gitignored per security baseline.\n- Run tests; ensure TC006 passes for server.",
            "status": "pending",
            "testStrategy": "Isolate network modules with jest.mock; assert that startup completes without any http/https requests; assert process.env is validated."
          },
          {
            "id": 5,
            "title": "Scaffold UI workspace with Vite React TypeScript",
            "description": "Create packages/ui_frontend using Vite React TS template, Playwright config, eslint-plugin-jsx-a11y, and strict TypeScript.",
            "dependencies": [],
            "details": "- Initialize Vite app into packages/ui_frontend (no telemetry): pnpm create vite . --template react-ts (run in that dir) and remove analytics.\n- package.json: name \"@app/ui_frontend\", scripts: dev: \"vite\", build: \"tsc -b && vite build\", preview, test (jest for unit), e2e (playwright).\n- Add Playwright config with devServer that runs vite on port 5173; add a smoke spec loading the app shell and intercepting WS handshake stub (TC005 e2e).\n- Add eslint-plugin-jsx-a11y and configure rules; add basic App shell with accessible landmarks and keyboard nav baseline.\n- TypeScript strict: enable in tsconfig.app.json; set moduleResolution bundler.\n- Add a unit test for a small component and a11y attributes.\n- Run e2e and unit tests; ensure TC005 part (UI) passes.",
            "status": "pending",
            "testStrategy": "Run pnpm --filter @app/ui_frontend e2e headed and headless; assert title, role=main present; intercept WS URL with Playwright route."
          },
          {
            "id": 6,
            "title": "Root TypeScript project references and strict config",
            "description": "Establish root tsconfig with project references and strictness propagated to all workspaces, enabling tsc -b across repo.",
            "dependencies": [],
            "details": "- Root tsconfig.base.json: compilerOptions strict true, noUncheckedIndexedAccess true, exactOptionalPropertyTypes true, noImplicitOverride true, incremental true.\n- Root tsconfig.json: references to ./packages/shared, ./packages/server, ./packages/ui_frontend where applicable; set exclude for node_modules and dist.\n- Ensure each package tsconfig references shared where imported.\n- Run tsc -b -v at root; fix path aliases if used (via tsconfig paths) and ensure builds to dist.\n- Update root scripts: \"typecheck\": \"tsc -b --pretty false\"; \"build\": \"pnpm -r build\".\n- Run tests; TC003 and TC001 build now should be achievable.",
            "status": "pending",
            "testStrategy": "Run pnpm typecheck; intentionally add a failing type in a throwaway test to verify CI fails; remove after verification."
          },
          {
            "id": 7,
            "title": "ESLint, Prettier, and a11y linting baseline",
            "description": "Configure ESLint with TypeScript, import/order, monorepo-aware overrides, Prettier integration, and jsx-a11y for UI.",
            "dependencies": [],
            "details": "- Add .eslintrc.cjs at root with parser @typescript-eslint, plugins: @typescript-eslint, import, unused-imports, jsx-a11y (scoped to UI), jest.\n- Add eslint-configs per workspace via overrides: server (node, commonjs globals), ui (browser, react), shared (lib rules).\n- Add .prettierrc with standard formatting; setup lint-staged to run eslint --fix and prettier --write on staged files.\n- Add scripts: lint, format in root and packages; ensure pnpm -r lint works.\n- Add minimal violations to ensure rules work, then fix them.\n- Ensure TC004 passes including pre-commit hook behavior.",
            "status": "pending",
            "testStrategy": "Run eslint on changed files via lint-staged simulation; commit a change to confirm pre-commit hook runs and blocks on errors."
          },
          {
            "id": 8,
            "title": "Husky, lint-staged, and commitlint hooks",
            "description": "Install and configure Git hooks: pre-commit for lint-staged and commit-msg for conventional commits with commitlint.",
            "dependencies": [],
            "details": "- Install husky, lint-staged, @commitlint/config-conventional, @commitlint/cli.\n- Add prepare script to root package.json and run pnpm prepare to generate .husky/.\n- Create .husky/pre-commit with: pnpm lint-staged.\n- Configure lint-staged in package.json or .lintstagedrc to run eslint and prettier on staged ts/tsx/json/yaml.\n- Create .husky/commit-msg with: pnpm commitlint --edit \"$1\".\n- Add commitlint.config.cjs extending @commitlint/config-conventional.\n- Verify TC004 hook behavior.",
            "status": "pending",
            "testStrategy": "Attempt a non-conforming commit message; expect failure. Attempt conforming message; expect success. Ensure staged lint fixes are applied."
          },
          {
            "id": 9,
            "title": "Jest configuration across monorepo",
            "description": "Unify Jest config to support ESM TypeScript in all packages with ts-jest, coverage reports, and isolated test envs.",
            "dependencies": [],
            "details": "- Create jest.preset.ts at root exporting common config: preset ts-jest, testEnvironment node/jsdom by package, extensionsToTreatAsEsm, transform for ts with useESM, moduleNameMapper for TS paths.\n- Update each package jest.config.ts to extend from root preset.\n- Add coverage thresholds and collectCoverageFrom per package.\n- Ensure server and shared unit tests run; for UI, keep component tests minimal if Playwright covers UI e2e.\n- Run tests; confirm TC005 unit test coverage across packages.",
            "status": "pending",
            "testStrategy": "pnpm -r test with --coverage; verify that ESM interop works and no Babel needed."
          },
          {
            "id": 10,
            "title": "Playwright e2e setup and devServer orchestration",
            "description": "Finalize Playwright project with devServer orchestration to spin up both server and UI concurrently for e2e smoke.",
            "dependencies": [],
            "details": "- In e2e/playwright.config.ts at root, define projects: ui. Configure webServer to start: pnpm --filter @app/server dev and pnpm --filter @app/ui_frontend dev via a wrapper script using concurrently or a custom node launcher.\n- Implement scripts/dev.ts in repo root to spawn both processes, wait for ports (server e.g., 4000, UI 5173), and expose readiness.\n- Add Playwright route interception to stub WS handshake to localhost without touching network.\n- Ensure TC005 end-to-end smoke passes reliably in CI.",
            "status": "pending",
            "testStrategy": "Run pnpm e2e locally and in CI; add retry and timeout settings; capture traces on failure."
          },
          {
            "id": 11,
            "title": "Runtime environment management with dotenv-safe",
            "description": "Standardize environment variable management, examples, and documentation; enforce local-only defaults and no telemetry.",
            "dependencies": [],
            "details": "- Create .env.example at repo root with placeholders and comments for all required variables for server and UI (prefixed VITE_ for UI if needed). Include OFFLINE=true default.\n- Ensure .env.local is in .gitignore and referenced in docs.\n- Update server env loader to respect OFFLINE flag and explicitly deny outbound by default (but do not implement network guard policy yet; just set flags).\n- Document keyring location expectations (future tasks) and environment conventions in README.\n- Update tests to check presence of example env and that startup honors OFFLINE in logs (no network).",
            "status": "pending",
            "testStrategy": "Run server startup under OFFLINE=true and assert logs reflect offline mode; ensure TC006 remains passing."
          },
          {
            "id": 12,
            "title": "Dev, build, test, e2e, lint, typecheck scripts wiring",
            "description": "Wire root and per-package scripts and concurrently-based dev script to run server+client together.",
            "dependencies": [],
            "details": "- Add root scripts:\n  - dev: \"node scripts/dev.js\" (or ts-node/tsx if TypeScript) to run both workspaces.\n  - build: \"pnpm -r build\".\n  - test: \"pnpm -r test\".\n  - e2e: \"playwright test\".\n  - lint: \"pnpm -r lint\"; format: \"pnpm -r format\"; typecheck: \"tsc -b\".\n- Ensure package-level scripts align and dev servers bind to non-conflicting ports.\n- Validate TC001: pnpm -r build passes and produces outputs for server and shared; UI build produces dist.\n- Ensure CI uses these scripts.",
            "status": "pending",
            "testStrategy": "Run pnpm build and verify artifacts; run pnpm dev and access UI; ensure e2e passes."
          },
          {
            "id": 13,
            "title": "CI pipeline: lint, typecheck, unit, and e2e on push",
            "description": "Add GitHub Actions workflow to run lint, typecheck, unit tests, and Playwright e2e on pushes/PRs; cache pnpm and Playwright browsers.",
            "dependencies": [],
            "details": "- .github/workflows/ci.yml:\n  - Use actions/setup-node@v4 with Node 20.x; setup pnpm; cache pnpm store.\n  - Jobs: lint+typecheck, unit, e2e with matrix for OS if needed (start with ubuntu-latest).\n  - Install Playwright browsers with npx playwright install --with-deps.\n  - Artifacts: upload playwright traces on failure and coverage reports.\n- Gate merges by requiring CI pass (docs; optional branch protection).",
            "status": "pending",
            "testStrategy": "Open a PR to trigger CI; ensure all TC001â€“TC006 checks run and are green."
          },
          {
            "id": 14,
            "title": "Security and git hygiene baselines",
            "description": "Ensure sensitive files are ignored, add CODEOWNERS, basic security policy, and configure minimal access boundaries.",
            "dependencies": [],
            "details": "- Verify .gitignore covers .env.local and any keys; add .env.* patterns as needed.\n- Add SECURITY.md and CONTRIBUTING.md describing local-first, no telemetry defaults.\n- Add CODEOWNERS to declare ownership for packages/server, packages/ui_frontend, packages/shared, scripts, content.\n- Add npmrc/pnpm config to avoid sending telemetry if any and lock registry to npmjs.\n- Add a simple script to scan for accidental keys in commits using a regex pre-commit optional step.",
            "status": "pending",
            "testStrategy": "Run a simulated commit containing a dummy API key and confirm the scanner flags it; verify TC006 still passes."
          },
          {
            "id": 15,
            "title": "Content and scripts workspaces scaffolding",
            "description": "Create packages/content and packages/scripts workspaces with minimal structure and testing harness.",
            "dependencies": [],
            "details": "- packages/content: package.json name \"@app/content\", type module; src/ with placeholder pack JSON and loader types referencing @app/shared.\n- packages/scripts: package.json name \"@app/scripts\", bin entries for future CLIs; tsconfig; jest config; sample CLI that prints workspace graph safely (no network).\n- Add unit tests for scripts CLI and content schema validation.\n- Ensure build and tests integrate into pnpm -r build/test.",
            "status": "pending",
            "testStrategy": "Run pnpm --filter @app/scripts test and build; ensure TC001 still green."
          },
          {
            "id": 16,
            "title": "CRDT library placeholder dependencies",
            "description": "Add CRDT dependency placeholders (Automerge/Yjs) without implementation; verify build integrity and tree-shaking.",
            "dependencies": [],
            "details": "- Add dependencies to shared or server where appropriate as optionalDependencies to avoid inflating builds prematurely.\n- Provide minimal type exports that wrap these libs behind an interface stub (no runtime usage yet).\n- Ensure optional import paths are type-safe but not executed in dev smoke.\n- Document future integration points in shared README.",
            "status": "pending",
            "testStrategy": "Run pnpm -r build to confirm no bundling issues; ensure e2e smoke unaffected."
          },
          {
            "id": 17,
            "title": "Finalize folder map and docs import",
            "description": "Lay out src/server subfolders (llm orchestration, missions, rules, memory, persistence, realtime, images, scheduling, video-flagged) and src/ui_frontend features (voice capture, HUD, campaign browser, schedule editor, captions), plus framework_docs/.",
            "dependencies": [],
            "details": "- Create empty folder structure with README.md in each domain describing purpose and boundaries.\n- Add index.ts placeholders exporting nothing to keep TS project references valid.\n- Add a feature flag for video areas in server and UI (simple boolean in env types) and ensure excluded from builds when false.\n- Ensure imports do not create circular deps.\n- Import existing framework_docs/ if provided and exclude from build.",
            "status": "pending",
            "testStrategy": "Run pnpm typecheck to ensure no stray imports; run pnpm -r build; ensure TC001 remains green."
          },
          {
            "id": 18,
            "title": "Verification sweep and harden tests (TC001â€“TC006)",
            "description": "Run and harden all tests, improve flake resistance, and ensure acceptance criteria fully met before closing task.",
            "dependencies": [],
            "details": "- Stabilize Playwright devServer startup with wait-on and retry.\n- Ensure no external network calls by stubbing DNS lookups and setting env OFFLINE in e2e.\n- Validate pnpm -r build works from a clean clone; test incremental builds.\n- Ensure lint-staged and commitlint enforce policies consistently.\n- Update docs with setup steps and troubleshooting.",
            "status": "pending",
            "testStrategy": "Cold CI run in a fresh environment; collect traces; run tests twice to detect flakes; ensure all TC001â€“TC006 pass consistently."
          }
        ]
      },
      {
        "id": 2,
        "title": "Local SQLite and Vector Index Setup",
        "description": "Implement local-first persistence with SQLite and pluggable vector index (FAISS or SQLite-VSS), schema migrations, and access layer.",
        "details": "- Use better-sqlite3 for sync local db; drizzle-orm or Kysely for typed queries\n- Vector: prefer sqlite-vss (if available for platform) with fallback FAISS via node bindings; abstraction interface VectorIndex with namespaces campaign:<id>, player:<id>\n- Migrations: drizzle-kit or Knex; seed script for dev\n- Tables: players, characters, campaigns, sessions, world_states, events, memories, missions, mission_progress, inventory, items, images, videos (featureFlag), llm_messages, settings, schedules\n- Indices: events(session_id, seq), memories(namespace, ts), images(hash/style), schedules(campaign_id, next_fire_at)\n- Snapshots table for periodic snapshots\n- Local asset cache dirs: cache/images, cache/video, logs/\n- Encryption at rest for provider keys: OS keychain via keytar; settings table stores key ids not secrets",
        "testStrategy": "- Unit tests: CRUD for core tables, migrations up/down idempotency\n- Vector tests: insert/query cosine similarity, namespace isolation\n- Performance smoke: simple benchmark ensures typical inserts >2k/s, vector query <50ms on small set\n- Verify keys never stored in plaintext in DB by scanning settings table",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and write tests first (DB + Vector + Security + Perf)",
            "description": "Create a comprehensive test suite that encodes the core acceptance criteria for local-first persistence, migrations, vector index behavior (sqlite-vss and FAISS fallback), access layer, encryption-at-rest via keytar, and basic performance smoke checks. No production code beyond test scaffolding should be implemented here.",
            "dependencies": [],
            "details": "â€¢ Set up test harness with Node.js + TypeScript: vitest/jest, ts-node/ts-jest, and a temporary filesystem sandbox per test.\nâ€¢ Define TC IDs and coverage mapping:\n  - TC001: Migrations up/down idempotency and versioning.\n  - TC002: CRUD for core tables (players, campaigns, sessions, events, memories) covering inserts, updates, deletes, and queries with indices.\n  - TC003: Vector index insert and cosine similarity search returns expected order; validate namespace isolation (campaign:<id>, player:<id>).\n  - TC004: Fallback from sqlite-vss to FAISS when vss extension unavailable.\n  - TC005: Keys are not stored in plaintext in DB; settings table stores key IDs only; keytar used for secret retrieval.\n  - TC006: Seed script populates dev data deterministically and re-runnable without duplication.\n  - TC007: Indices exist and are used (events(session_id, seq), memories(namespace, ts), images(hash, style), schedules(campaign_id, next_fire_at)).\n  - TC008: Snapshots table creation and periodic write/read integrity.\n  - TC009: Performance smoke: typical inserts >2000 rows/s; vector top-k query <50ms on small set.\n  - TC010: Feature flag toggles videos table creation and access layer exposure.\nâ€¢ Create fixtures for sample entities and small vector sets.\nâ€¢ Provide mock/shim for keytar in tests to simulate OS keychain.\nâ€¢ Stub FAISS bindings with simple in-memory vector store behind the same interface for unit tests if native module is not available in CI.\nâ€¢ Set up test database paths in a temp directory; ensure cleanup.\nâ€¢ Do not implement production modules; write tests that reference planned module contracts and interfaces.",
            "status": "pending",
            "testStrategy": "Run the test suite; all tests expected to fail initially (red). Ensure CI runs on push and PR."
          },
          {
            "id": 2,
            "title": "Project scaffolding and package setup",
            "description": "Initialize packages, TypeScript config, testing framework, scripts, and environment scaffolding for local-first SQLite and vector index development.",
            "dependencies": [
              "2.1"
            ],
            "details": "â€¢ Add dependencies: better-sqlite3, drizzle-orm or kysely (choose one), drizzle-kit or knex, keytar, zod, dotenv, fast-glob, and optionally sqlite-vss package/loader; add FAISS node bindings dependency (optional peer) and a lightweight fallback dev stub.\nâ€¢ Add dev dependencies: vitest/jest, ts-node/tsx, types for node, eslint, prettier, tsup/tsc build.\nâ€¢ Configure tsconfig for ES2020 target and NodeNext module resolution.\nâ€¢ Add NPM scripts: test, test:watch, db:migrate, db:seed, db:reset, build, lint, typecheck, perf:smoke.\nâ€¢ Create environment loader: .env schema with DB_FILE, FEATURE_VIDEOS, VSS_EXTENSION_PATH, FAISS_ENABLED, APP_ENV.\nâ€¢ Provide platform notes for loading sqlite-vss (dlopen) and FAISS optional load.",
            "status": "pending",
            "testStrategy": "Run test suite; ensure it executes and fails only on unimplemented features, not on environment issues."
          },
          {
            "id": 3,
            "title": "Database connection and lifecycle module (better-sqlite3)",
            "description": "Implement a robust SQLite connection factory using better-sqlite3 with safe open, WAL mode, PRAGMA defaults, and a standardized path layout for local-first storage.",
            "dependencies": [
              "2.2"
            ],
            "details": "â€¢ Implement db/connection.ts: create or open DB at DB_FILE; set PRAGMAs: journal_mode=WAL, synchronous=NORMAL, foreign_keys=ON, cache_size=-20000, temp_store=MEMORY; busy_timeout=5000.\nâ€¢ Ensure directories exist: ./cache/images, ./cache/video, ./logs.\nâ€¢ Expose a singleton getDb() and a withTransaction<T>(fn) helper using db.transaction.\nâ€¢ Implement graceful shutdown hook; close DB on process exit.\nâ€¢ Export a lightweight query interface if using better-sqlite3 prepared statements.\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "Unit tests: open/close DB, PRAGMAs set, WAL file appears after write, concurrent prepared statements work. Map to TC002 partial infra."
          },
          {
            "id": 4,
            "title": "Schema definition with ORM and migrations baseline",
            "description": "Define schemas for all required tables and generate initial migration files using drizzle-orm (or Kysely) with drizzle-kit (or Knex).",
            "dependencies": [
              "2.3"
            ],
            "details": "â€¢ Choose ORM: drizzle-orm recommended for typed queries; set up schema folder with table definitions for: players, characters, campaigns, sessions, world_states, events, memories, missions, mission_progress, inventory, items, images, videos (featureFlag), llm_messages, settings, schedules, snapshots.\nâ€¢ Define indices:\n  - events: composite index (session_id, seq).\n  - memories: (namespace, ts).\n  - images: (hash), (style) or composite depending on query plan.\n  - schedules: (campaign_id, next_fire_at).\nâ€¢ Add foreign keys and ON DELETE/UPDATE behaviors; add created_at/updated_at defaults.\nâ€¢ Implement conditional DDL for videos table controlled by FEATURE_VIDEOS env at migration time.\nâ€¢ Generate initial migration SQL and a migration runner script (db/migrate.ts) with up/down and idempotency guards.\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC001 (idempotent up/down), TC007 (indices exist), and part of TC010 (videos flag) should pass."
          },
          {
            "id": 5,
            "title": "Seed script for development data",
            "description": "Create a repeatable, idempotent seed script to populate core entities and sample data for development and tests.",
            "dependencies": [
              "2.4"
            ],
            "details": "â€¢ Implement db/seed.ts: insert sample players, campaigns, sessions, items, and minimal vectors for memories.\nâ€¢ Use upsert patterns (INSERT ... ON CONFLICT DO UPDATE/NOTHING) keyed by stable IDs to ensure re-runnable seeds.\nâ€¢ Provide small deterministic corpus for vector tests (fixed random seed, small embeddings arrays).\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC006 should pass; verify rows count stable across repeated seeding; ensure referential integrity."
          },
          {
            "id": 6,
            "title": "VectorIndex interface and adapter contracts",
            "description": "Design a pluggable VectorIndex TypeScript interface with namespace support and define contracts for sqlite-vss and FAISS adapters.",
            "dependencies": [
              "2.4"
            ],
            "details": "â€¢ Define types in vector/index.ts:\n  - interface VectorIndex { init(): Promise<void>|void; upsert(vecs: {id:string, namespace:string, embedding:number[], metadata?:Record<string,any>}[]): Promise<void>; delete(ids: string[], namespace: string): Promise<void>; query(opts:{namespace:string, embedding:number[], topK:number, filter?:Record<string,any>, metric?:'cosine'|'l2'}): Promise<{id:string, score:number, metadata?:Record<string,any>}[]>; purgeNamespace(namespace:string): Promise<void>; close(): Promise<void>|void }\nâ€¢ Enforce namespace forms: campaign:<id>, player:<id> via zod refinements.\nâ€¢ Define error classes and feature detection helpers for sqlite-vss availability and FAISS bindings.\nâ€¢ Run tests and make them pass for interface existence and validation utilities.",
            "status": "pending",
            "testStrategy": "Unit tests validate input schemas, namespace regex, and adapter selection logic stubs."
          },
          {
            "id": 7,
            "title": "SQLite-VSS adapter implementation",
            "description": "Implement VectorIndex using sqlite-vss extension when available, with table creation, indexing, and cosine similarity queries per namespace.",
            "dependencies": [
              "2.6",
              "2.3",
              "2.4"
            ],
            "details": "â€¢ Load sqlite-vss extension via db.loadExtension(VSS_EXTENSION_PATH) or compile-time bundled load; guard per-platform.\nâ€¢ Create vss embeddings table: vss_embeddings(dim INTEGER, namespace TEXT, id TEXT PRIMARY KEY, embedding BLOB, metadata JSON, created_at/updated_at). Create a VSS index over embedding; store embeddings as FLOAT32 array in BLOB.\nâ€¢ Implement upsert: use replace/insert with parameter binding; maintain updated_at.\nâ€¢ Implement query: compute topK via vss_search using cosine distance; translate to similarity score (1 - distance if needed). Apply namespace filter and optional metadata JSON filter via JSON_EXTRACT.\nâ€¢ Implement delete and purgeNamespace.\nâ€¢ Ensure transactions for batch upserts.\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC003 (sqlite-vss path) and TC004 partial (availability detection) pass on environments with extension."
          },
          {
            "id": 8,
            "title": "FAISS adapter implementation (fallback)",
            "description": "Implement FAISS-based VectorIndex adapter loaded optionally via node bindings, used when sqlite-vss is unavailable.",
            "dependencies": [
              "2.6"
            ],
            "details": "â€¢ Attempt to import FAISS; if unavailable, provide a minimal in-memory cosine index fallback for dev to satisfy tests.\nâ€¢ Implement index management: maintain per-namespace index (IndexFlatIP or L2 as configured). Persist index shards to files under ./cache/vector/<namespace>.faiss when possible; else memory-only with warning.\nâ€¢ Implement upsert by re-building or adding vectors; delete by re-indexing namespace excluding IDs; maintain an aux mapping {id->position, metadata} in JSON file per namespace.\nâ€¢ Implement query with topK; return scores normalized to cosine similarity.\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC004 (fallback works) and TC003 (namespace isolation and similarity order) pass with FAISS or in-memory fallback."
          },
          {
            "id": 9,
            "title": "Vector adapter selection and factory",
            "description": "Implement a factory that selects sqlite-vss when available, else FAISS adapter, exposing a single VectorIndex instance.",
            "dependencies": [
              "2.7",
              "2.8"
            ],
            "details": "â€¢ Implement vector/factory.ts: detect sqlite-vss by trying to load extension or probing PRAGMA module_list; if successful, return SQLiteVSS adapter, else try FAISS; if both fail, throw descriptive error with remediation.\nâ€¢ Ensure init() sets up necessary tables or files; ensure close() cleans up handles.\nâ€¢ Integrate with env flags to force a particular backend for testing.\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC004 should fully pass across environments; add unit tests for forced selection via env."
          },
          {
            "id": 10,
            "title": "Access layer (repositories) with typed queries",
            "description": "Implement repositories for core tables using the ORM: CRUD operations, common queries, and transaction-safe methods.",
            "dependencies": [
              "2.4",
              "2.3"
            ],
            "details": "â€¢ Implement repositories: PlayersRepo, CampaignsRepo, SessionsRepo, EventsRepo, MemoriesRepo, ItemsRepo, InventoryRepo, MissionsRepo, MissionProgressRepo, WorldStatesRepo, ImagesRepo, LlmMessagesRepo, SettingsRepo, SchedulesRepo, SnapshotsRepo.\nâ€¢ Provide methods: create/get/update/delete, list by foreign key, and domain-specific methods (e.g., EventsRepo.appendEvent(sessionId, seq, payload) enforcing seq index; MemoriesRepo.listByNamespace with ts ordering; SchedulesRepo.nextDue(campaignId)).\nâ€¢ Use prepared statements or ORM queries; ensure consistent error handling and result typing.\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC002 and TC007 should pass for CRUD and indexed queries."
          },
          {
            "id": 11,
            "title": "Security: key management via keytar and settings indirection",
            "description": "Store provider secrets in OS keychain using keytar; persist only key IDs in settings; add helper to set/get/delete secrets safely.",
            "dependencies": [
              "2.10"
            ],
            "details": "â€¢ Implement security/secrets.ts with functions: saveSecret(id, value), getSecret(id), deleteSecret(id). Use keytar with service name from env/app name.\nâ€¢ Implement SettingsRepo helpers: setProviderKey(provider, keyId), getProviderKeyId(provider). Ensure no plaintext keys stored in DB; add validation checks scanning settings rows for secret-like content.\nâ€¢ Provide migration safeguard ensuring settings columns are string ids, not secret blobs.\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC005 passes, including scanning DB to ensure no secrets present."
          },
          {
            "id": 12,
            "title": "Snapshots table and periodic snapshot writer",
            "description": "Add snapshotting support to persist periodic world state and session metadata for recovery and audits.",
            "dependencies": [
              "2.10"
            ],
            "details": "â€¢ Confirm snapshots schema (id, scope, ref_id, ts, payload JSON, hash) and indices on (scope, ref_id, ts DESC).\nâ€¢ Implement snapshots service: takeSnapshot(scope, refId, payload) computes content hash, stores row; listSnapshots(scope, refId, limit); getLatest.\nâ€¢ Integrate with withTransaction and repositories where appropriate.\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC008 passes with write/read integrity and hash validation."
          },
          {
            "id": 13,
            "title": "Feature flagged videos table and repository",
            "description": "Conditionally expose videos repository and DDL based on FEATURE_VIDEOS flag without breaking other modules.",
            "dependencies": [
              "2.4",
              "2.10"
            ],
            "details": "â€¢ Ensure migrations respect FEATURE_VIDEOS at runtime; add guard that if disabled, VideosRepo throws a controlled error on use.\nâ€¢ If enabled, implement CRUD and indexing per schema; store files in cache/video directory with hashed filenames.\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC010 passes for both enabled and disabled states."
          },
          {
            "id": 14,
            "title": "Integration: vector memory flows with repositories",
            "description": "Wire the VectorIndex with MemoriesRepo to support write/query operations with strict namespace handling.",
            "dependencies": [
              "2.9",
              "2.10"
            ],
            "details": "â€¢ Implement memoryService with methods: writeMemory(namespace, text, embedding, metadata), retrieve(namespace, embedding, topK, filter), delete(ids, namespace), promote hooks (stub for Task 12).\nâ€¢ Ensure transactional write: insert memory row then upsert embedding; on failure, rollback.\nâ€¢ Validate namespace format before execution.\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "Covers TC003 end-to-end with repo + vector query; add integration test using seed corpus."
          },
          {
            "id": 15,
            "title": "Performance smoke tests and tuning",
            "description": "Implement automated performance smoke benchmarks for inserts and vector queries; tune PRAGMAs and batch sizes to meet targets.",
            "dependencies": [
              "2.14"
            ],
            "details": "â€¢ Implement perf tests: bulk insert 10k events using prepared statements and transactions; capture rows/s; assert >2000 rows/s on typical dev machine.\nâ€¢ Vector query perf: index 1k embeddings and run topK=5 cosine query; assert <50ms median for warm cache.\nâ€¢ Tune: batch upserts (500-1000), PRAGMAs set earlier, WAL checkpointing as needed.\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC009 passes; report metrics in test output for observability."
          },
          {
            "id": 16,
            "title": "Tooling: DB reset, migration verify, and lint rules",
            "description": "Add utility scripts to reset DB, verify migration integrity, and enforce SQL/ORM lint rules.",
            "dependencies": [
              "2.4"
            ],
            "details": "â€¢ db:reset script drops DB file, runs migrations up, and runs seed.\nâ€¢ db:verify script runs down/up cycle in a temp DB and checks schema checksum to ensure idempotency.\nâ€¢ ESLint rules for no raw secrets in code; forbid direct INSERT into settings.secret columns (not present) via custom lint pattern.\nâ€¢ Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "Re-run TC001 and TC006 in a fresh environment; ensure pass."
          },
          {
            "id": 17,
            "title": "Documentation and examples",
            "description": "Provide README and example snippets for developers to use the access layer and vector index correctly.",
            "dependencies": [
              "2.14",
              "2.11",
              "2.13"
            ],
            "details": "â€¢ Add docs explaining environment variables, how to run migrations and seed, how vector backend is selected, and how to store secrets with keytar.\nâ€¢ Provide example scripts: examples/demo-seed-and-query.ts demonstrating end-to-end insert and retrieval across namespaces.\nâ€¢ Ensure examples run under CI as part of tests.",
            "status": "pending",
            "testStrategy": "Run examples in CI; basic assertions that outputs contain expected IDs and scores."
          }
        ]
      },
      {
        "id": 3,
        "title": "Realtime WebSocket Gateway",
        "description": "Create WebSocket server for multiplayer messaging, presence, and pub/sub channels underpinning voice/text synchronization.",
        "details": "- Library: ws or uWebSockets.js; Node/TS\n- Auth: local session token per client (simple dev auth); campaign+session scoping\n- Channels: 1:1, room/proximity, team/line, party/alliance topics; server enforces membership\n- Message types: join, leave, voice-meta, caption, action, ticker-update, crdt-sync\n- Backpressure and retries with exponential backoff; heartbeat pings; reconnect tokens\n- Serialize with zod schemas in shared package for strict validation\n- Rate limit per connection; structured logs to logs/",
        "testStrategy": "- Integration tests with superwstest/ws mocking multiple clients joining/leaving\n- TC002 mapping: verify channel membership and audio routing metadata distribution\n- Chaos test: drop packets, ensure reconnect restores subscriptions\n- Performance: sustain 100 concurrent clients locally without error",
        "priority": "high",
        "dependencies": [
          1,
          2
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for WebSocket gateway (unit + integration)",
            "description": "Before implementation, author a comprehensive test suite capturing the core acceptance criteria for the realtime gateway covering connection lifecycle, auth, channel membership enforcement, message routing per type, rate limiting, backpressure handling, heartbeat/reconnect, and basic performance envelopes.",
            "dependencies": [],
            "details": "Create tests in packages/server/src/realtime/__tests__ with Jest + ts-jest and superwstest or ws test utilities. Add:\n- Unit tests for validators (zod schemas), rate limiter, backoff utility, token parsing, and channel authorization rules.\n- Integration tests spinning up an ephemeral ws server on a random port with multiple simulated clients using ws or superwstest.\n- Tag relevant cases with IDs TC002 (channel membership and audio metadata routing) and reserve TC010â€“TC014 for lifecycle, resilience, and rate-limit cases.",
            "status": "pending",
            "testStrategy": "- Unit: zod schema validation for message types join, leave, voice-meta, caption, action, ticker-update, crdt-sync. Expect parse success/failure on fixtures (TC010).\n- Unit: rate limiter blocks excess messages per connection with reset window (TC011).\n- Unit: exponential backoff function yields expected sequence with jitter (TC012).\n- Integration: auth requiredâ€”unauthorized handshake rejected; authorized connects succeed (TC013).\n- Integration: channel membership enforcedâ€”publish blocked if not a member; allowed after join; distribution only to members (TC002).\n- Integration: presence events broadcast join/leave to relevant channels (TC014).\n- Integration: heartbeatâ€”server pings, client must pong; idle disconnect; reconnect token restores subscriptions (TC015).\n- Integration: backpressureâ€”server buffers capped; slow consumer triggers pause/drop policy with signal; retries with backoff from client harness (TC016).\n- Integration: sustain 100 concurrent local clients for 30s without error and with <1% message loss for best-effort channels (TC017)."
          },
          {
            "id": 2,
            "title": "Scaffold realtime server module and configuration",
            "description": "Create the realtime WebSocket gateway package structure, environment config, and process bootstrap to run tests.",
            "dependencies": [
              "3.1"
            ],
            "details": "In packages/server/src/realtime: add index.ts (server entry), server.ts (gateway class), config.ts (env: PORT, RATE_LIMIT, HEARTBEAT_MS, BACKPRESSURE_LIMIT, RECONNECT_TTL, DEV_AUTH), logs/ directory for structured logs. Use ws or uWebSockets.js; start with ws for portability. Wire pnpm scripts: server:dev, server:test. Ensure Jest spins ephemeral server for integration tests.",
            "status": "pending",
            "testStrategy": "Run all tests from 3.1 and ensure the harness boots a server per test and tears down cleanly."
          },
          {
            "id": 3,
            "title": "Implement Zod schemas and shared message types",
            "description": "Define strict Zod schemas for all message types and envelopes in the shared package; export TS types for server and client.",
            "dependencies": [
              "3.1",
              "3.2"
            ],
            "details": "In packages/shared/src/realtime/schemas.ts define: Envelope {type, ts, sessionId, campaignId, channel?, payload}, and payload schemas for join, leave, voice-meta, caption, action, ticker-update, crdt-sync. Add parse/serialize helpers and discriminated unions. Version messages with v field for forward compatibility. Include error schema for server errors.",
            "status": "pending",
            "testStrategy": "Run unit tests from 3.1 TC010 validating success/failure paths and round-trip serialization."
          },
          {
            "id": 4,
            "title": "Authentication and scoping middleware",
            "description": "Implement connection authentication using local session tokens and enforce campaign+session scoping for each client.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.3"
            ],
            "details": "On connection upgrade, parse token from query/header; validate format and map to {userId, campaignId, sessionId, roles} via a dev in-memory verifier. Attach auth context to ws. Reject unauthenticated with close code 4001. Maintain a connection registry keyed by sessionId/userId. Ensure all incoming messages are checked against the connection's campaign/session scope.",
            "status": "pending",
            "testStrategy": "Run TC013 integration: unauthorized rejected, authorized succeeds; unit test token parsing including malformed tokens."
          },
          {
            "id": 5,
            "title": "Channel model and membership enforcement",
            "description": "Add server-side channel registry for 1:1, room/proximity, team/line, party/alliance topics with membership rules.",
            "dependencies": [
              "3.1",
              "3.4"
            ],
            "details": "Design ChannelId type {kind, key} where kind âˆˆ {direct, room, team, party}. Implement membership service: direct = {a,b}; room/proximity based on session state map; team and party via role/team assignments. Provide join/leave handlers updating membership and presence state. Enforce on publish: block if not a member. Maintain indexes: channel->connections and connection->channels.",
            "status": "pending",
            "testStrategy": "Run TC002: attempts to publish without membership fail; after join, messages fan out only to members; presence events sent on join/leave."
          },
          {
            "id": 6,
            "title": "Message routing and handlers per type",
            "description": "Implement dispatch loop validating messages with zod and routing to appropriate channels with structured logs.",
            "dependencies": [
              "3.1",
              "3.3",
              "3.5"
            ],
            "details": "On message, parse Envelope with zod; reject invalid with error envelope. Route: voice-meta and caption to channel members; action to channel or targeted users; ticker-update broadcast to session scope; crdt-sync enqueue to CRDT module hook (stub for Task 20). Add tracing context (requestId) in logs. Prevent echo to sender when not desired.",
            "status": "pending",
            "testStrategy": "Extend TC002 and add cases for each type to ensure correct targeting and schema validation errors."
          },
          {
            "id": 7,
            "title": "Heartbeat, idle detection, and reconnect tokens",
            "description": "Add pings at configured interval, close idle connections, and implement reconnect tokens to restore subscriptions.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.4",
              "3.5",
              "3.6"
            ],
            "details": "Implement server ping loop; mark connection alive on pong; if missed N pings, close with 4002. On close, persist a reconnect token mapping to prior subscriptions and presence for RECONNECT_TTL in memory. On reconnect with token and same auth, restore channel memberships and emit presence restored events.",
            "status": "pending",
            "testStrategy": "Run TC015: simulate dropped client; verify disconnect then reconnect with token restores subscriptions and presence notifications."
          },
          {
            "id": 8,
            "title": "Backpressure control and send queue",
            "description": "Implement per-connection buffered send queues with size caps and policies for slow consumers.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.6"
            ],
            "details": "Wrap ws.send with a queue. If socket bufferedAmount exceeds BACKPRESSURE_LIMIT or queue length exceeds limit, apply policy: drop oldest non-critical messages (e.g., voice-meta, ticker-update) marked best-effort; retain critical (join/leave, action, crdt-sync). Expose metrics. Notify sender of drops via control messages.",
            "status": "pending",
            "testStrategy": "Run TC016: create artificial slow consumer; assert queue caps are enforced and best-effort drops occur with notifications; ensure no process crash."
          },
          {
            "id": 9,
            "title": "Client retry strategy and exponential backoff utilities",
            "description": "Provide a reusable backoff utility and document client-side retry expectations; include server hints in close reasons.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.7",
              "3.8"
            ],
            "details": "Implement backoff.ts with base, cap, jitter. Include recommended retry-after hints in close frames for 4002/overload conditions. Provide sample client harness in tests using the utility to validate retries and eventual reconnect with token.",
            "status": "pending",
            "testStrategy": "Run TC012 for utility sequence; integration verifies retries escalate and reconnect succeeds without storming the server."
          },
          {
            "id": 10,
            "title": "Per-connection rate limiting",
            "description": "Add token-bucket or leaky-bucket rate limiting per connection with burst allowance and penalty close on abuse.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.6"
            ],
            "details": "Implement a token bucket with configurable tokens/sec and burst. Apply per incoming message before parsing heavy payloads. On exceed, send error envelope and optionally temporarily mute or close with 4003 on sustained abuse. Exempt heartbeat pings/pongs.",
            "status": "pending",
            "testStrategy": "Run TC011: flood messages and assert throttling kicks in, errors returned, and optional close on persistent violation."
          },
          {
            "id": 11,
            "title": "Structured logging and diagnostics",
            "description": "Produce structured JSON logs for key events to logs/ with rotation hooks and redaction of sensitive fields.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.4",
              "3.6"
            ],
            "details": "Use pino or winston to log events: connect, auth, join/leave, publish, drops, rate-limit, heartbeat, errors. Include fields: ts, level, connId, userId, sessionId, channelId, event, metrics. Redact tokens. Configure test logger to memory to assert log entries in tests.",
            "status": "pending",
            "testStrategy": "Add assertions in existing integration tests to verify presence of required log fields for representative flows."
          },
          {
            "id": 12,
            "title": "Integration with CRDT sync hook (Task 20 preparation)",
            "description": "Provide a typed hook for crdt-sync messages so Task 20 can plug in Yjs/Automerge syncing without changing the gateway.",
            "dependencies": [
              "3.1",
              "3.3",
              "3.6"
            ],
            "details": "Define CrdtSyncAdapter interface in shared: onMessage(connCtx, payload), getDocsForSession(sessionId), and broadcast helper. In server, on crdt-sync route to adapter if present; otherwise acknowledge with stub response. Guard permissions via roles from auth context.",
            "status": "pending",
            "testStrategy": "Integration test sends crdt-sync; verify adapter stub invoked and messages contained within session scope; permission denied when role missing."
          },
          {
            "id": 13,
            "title": "Presence service and roster queries",
            "description": "Maintain presence state per session/channel and support roster queries and updates on join/leave.",
            "dependencies": [
              "3.1",
              "3.5",
              "3.6"
            ],
            "details": "Track online users and their channels; on join/leave, send presence events to relevant members. Add a query message type or action to request roster snapshot for a channel which returns list of userIds and metadata.",
            "status": "pending",
            "testStrategy": "Extend TC014: verify presence roster updates across joins/leaves and that roster query returns accurate membership."
          },
          {
            "id": 14,
            "title": "Performance and load test scaffold (100 clients)",
            "description": "Add a local load test to spin up 100 ws clients, join channels, and exchange messages for 30s to validate stability.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.5",
              "3.6",
              "3.7",
              "3.8",
              "3.10",
              "3.11"
            ],
            "details": "Create scripts/perf/realtime.load.test.ts using Jest with increased timeout. Launch 100 clients with staggered connects and randomized publishes within rate limits. Collect metrics: connect success, message throughput, error count, dropped messages percentage.",
            "status": "pending",
            "testStrategy": "Run TC017: assert zero crashes, >95% delivery for reliable messages, and best-effort within acceptable loss; max memory within threshold."
          },
          {
            "id": 15,
            "title": "Security hardening and close codes",
            "description": "Standardize WebSocket close codes and sanitize inputs; guard against oversized frames and JSON bombs.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.6",
              "3.10"
            ],
            "details": "Configure ws maxPayload. Validate message size before parse. Define close codes: 4000 generic, 4001 auth, 4002 idle, 4003 rate limit, 4004 membership, 4005 schema. Strip unknown fields in zod. Deny unknown message types.",
            "status": "pending",
            "testStrategy": "Integration tests sending oversized or malformed frames should be rejected with appropriate close/error envelopes; fuzz a few random payloads."
          },
          {
            "id": 16,
            "title": "Admin and observability endpoints (dev)",
            "description": "Expose dev-only HTTP endpoints to inspect sessions, channels, and metrics for debugging.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.5",
              "3.11"
            ],
            "details": "Attach a minimal HTTP server to expose /health, /metrics (Prom-like counters for connections, messages, drops), /sessions/:id, /channels/:id members. Guard behind DEV_AUTH and not enabled in production.",
            "status": "pending",
            "testStrategy": "Integration test fetches endpoints while gateway runs; verify JSON structure and that metrics increase during test traffic."
          },
          {
            "id": 17,
            "title": "Sample client harness and docs",
            "description": "Provide a TypeScript sample client demonstrating auth, join, publish, heartbeat handling, and reconnect workflow.",
            "dependencies": [
              "3.1",
              "3.3",
              "3.4",
              "3.7",
              "3.9"
            ],
            "details": "In scripts/clients/sample-client.ts implement flows using the shared schemas and backoff utility. Document configuration and how to run load tests and integration tests in README within realtime folder.",
            "status": "pending",
            "testStrategy": "Manual run during CI or as part of integration tests to ensure interoperability; verify it can reconnect and restore channels."
          }
        ]
      },
      {
        "id": 4,
        "title": "React UI Shell and Campaign Browser",
        "description": "Implement UI shell with campaign list/create/clone/archive and basic session lobby.",
        "details": "- React + Vite; state with Zustand or Redux Toolkit; React Router\n- Views: Campaigns (list/create/clone/archive), Sessions (list/join), Settings (providers), Assets viewer (images cache)\n- Use accessible components; keyboard nav; color contrast tokens\n- API routes: /campaigns CRUD/clone/archive\n- Localized strings scaffold; dark/light themes\n- Display isolation indicators per campaign",
        "testStrategy": "- Playwright: create campaign, clone, archive; verify isolation in UI\n- Accessibility: axe-core scan passes for pages\n- Snapshot tests for key components",
        "priority": "high",
        "dependencies": [
          1,
          3,
          2
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and write initial tests (TDD scaffolding)",
            "description": "Create test plans and implement the first round of unit, integration, and accessibility/UI tests that encode the core acceptance criteria for the UI shell, campaign browser (list/create/clone/archive), sessions lobby (list/join), settings, and assets viewer. Establish testing utilities and fixtures.",
            "dependencies": [],
            "details": "â€¢ Document acceptance criteria mapped to verification IDs: TC001 (UI shell nav), TC003 (Campaign list CRUD/clone/archive), TC004 (Session join flow), TC005 (Settings providers persistence), TC006 (Assets viewer loads and caches images), TC007 (Accessibility axe checks), TC008 (Dark/Light theme switch), TC009 (Isolation indicator display), TC010 (i18n string rendering). \nâ€¢ Set up testing stack: Vitest + React Testing Library for unit/component tests; Playwright for E2E; axe-core/axe-playwright for accessibility; MSW for API mocking; Storybook optional for snapshots. \nâ€¢ Create base test utilities: renderWithProviders (Router + Zustand/Redux store + Theme + I18n), mock server handlers for /campaigns CRUD/clone/archive and /sessions, i18n test config with en locale. \nâ€¢ Author initial tests (failing by design): \n  - Unit: NavBar renders links and keyboard focus order (TC001). \n  - Component: CampaignList renders items from API and supports pagination/filter basics (TC003). \n  - Component: CampaignForm validates required fields (TC003). \n  - Integration: Createâ†’Cloneâ†’Archive happy path via UI using Playwright with MSW (TC003). \n  - Integration: Session list and Join button route to session lobby (TC004). \n  - Accessibility: axe passes for Campaigns, Sessions, Settings, Assets pages (TC007). \n  - Theming: toggling theme updates tokens and contrast snapshots (TC008). \n  - i18n: strings come from locale files; fallback works (TC010). \n  - Isolation indicator: per-campaign badge visible and labeled (TC009).",
            "status": "pending",
            "testStrategy": "Run: vitest for unit/component; playwright test for E2E; axe scans within tests. Ensure all tests fail initially to drive implementation."
          },
          {
            "id": 2,
            "title": "Project setup: Vite React app, routing, state, testing and tooling",
            "description": "Initialize React + Vite project, configure TypeScript, React Router, state management (Zustand or Redux Toolkit), testing frameworks, linting, formatting, and CI workflows.",
            "dependencies": [
              "4.1"
            ],
            "details": "â€¢ Create Vite React TS app; add React Router v6+. \nâ€¢ Choose state: Redux Toolkit (RTK) with RTK Query or Zustand. Prefer RTK for API caching and normalized lists. \nâ€¢ Install packages: react-router-dom, @reduxjs/toolkit, react-redux or zustand; vitest, @testing-library/react, @testing-library/user-event, msw, playwright, axe-core, @axe-core/playwright, i18next, react-i18next, i18next-browser-languagedetector, tailwind or CSS variables for tokens. \nâ€¢ Configure Vitest setup file to include RTL and i18n. \nâ€¢ Configure MSW service worker and test server. \nâ€¢ Set up Playwright project with MSW integration or test server mocks, CI scripts, and npm scripts: test, test:e2e, test:a11y, lint, format. \nâ€¢ Add absolute import aliases. \nâ€¢ Add GitHub Actions workflow to run unit and Playwright tests. \nâ€¢ Run tests from 4.1 and verify they execute (still failing by design).",
            "status": "pending",
            "testStrategy": "Run all tests; ensure environment resolves and reporters show failures. Fix only environment/test runner issues, keep feature tests failing."
          },
          {
            "id": 3,
            "title": "UI shell layout, routing structure, and accessible navigation",
            "description": "Implement the application shell: header, sidebar/top-nav, main content area, skip links, focus management, and React Router routes for Campaigns, Sessions, Settings, Assets.",
            "dependencies": [
              "4.1",
              "4.2"
            ],
            "details": "â€¢ Create Layout components: AppShell (Header with app title and theme toggle; Nav with links to Campaigns, Sessions, Settings, Assets), Main with landmark roles. \nâ€¢ Add skip-to-content link, aria-current on active nav links, keyboard navigable menu, and focus ring styles. \nâ€¢ Define routes: /campaigns, /campaigns/new, /campaigns/:id, /sessions, /settings, /assets. \nâ€¢ Implement basic placeholders for pages with test IDs and i18n keys. \nâ€¢ Ensure color contrast tokens applied to shell. \nâ€¢ Run tests from 4.1 and make TC001 pass; keep others pending.",
            "status": "pending",
            "testStrategy": "Unit/component tests for NavBar rendering and keyboard nav; axe check on shell; routing tests using MemoryRouter."
          },
          {
            "id": 4,
            "title": "Theming system: dark/light tokens and contrast",
            "description": "Add theme provider with dark/light mode, CSS variables tokens, and accessible color contrast compliance.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "â€¢ Define design tokens as CSS variables (colors, spacing, typography) with data-theme attribute on html. \nâ€¢ Implement ThemeContext or use CSS prefers-color-scheme with toggle persisted to localStorage. \nâ€¢ Ensure minimum contrast ratios (4.5:1 body text); adjust palette accordingly. \nâ€¢ Update AppShell to use tokens. \nâ€¢ Run tests to satisfy TC008 and axe color contrast snapshots.",
            "status": "pending",
            "testStrategy": "Unit test for theme toggle state; visual snapshot tests for key components in both themes; axe contrast rules."
          },
          {
            "id": 5,
            "title": "i18n scaffold and localized strings",
            "description": "Set up i18next with language detector, resource bundles for en (and placeholder for others), and translation hooks across shell and pages.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "â€¢ Initialize i18next with react-i18next provider; create locales/en/common.json with all UI strings keys. \nâ€¢ Wire t() into AppShell, page titles, buttons, forms, empty states, and validation messages. \nâ€¢ Add language switcher in Settings page (scaffold). \nâ€¢ Run tests to satisfy TC010.",
            "status": "pending",
            "testStrategy": "Unit tests rendering strings via keys; snapshot comparing translated text; ensure fallback works when key missing."
          },
          {
            "id": 6,
            "title": "API client layer and state slices for campaigns and sessions",
            "description": "Implement API client with fetch wrappers, error handling, and RTK Query or Zustand selectors for campaigns and sessions endpoints.",
            "dependencies": [
              "4.1",
              "4.2"
            ],
            "details": "â€¢ Create api/base with fetchJson, error normalization, retry policy for idempotent GETs. \nâ€¢ Define types: Campaign, CampaignInput, Session, SessionJoinPayload. \nâ€¢ Implement endpoints: /campaigns (GET list, POST create), /campaigns/:id (GET, PUT), /campaigns/:id/clone (POST), /campaigns/:id/archive (POST or PATCH), /sessions (GET), /sessions/:id/join (POST). \nâ€¢ If using RTK Query: createApi with endpoints and cache tags; otherwise build Zustand store with async actions and status flags. \nâ€¢ Integrate MSW handlers mirroring server routes for tests and dev. \nâ€¢ Run tests and ensure service hooks/stores are testable.",
            "status": "pending",
            "testStrategy": "Unit tests for API functions with MSW mocking: happy path and error cases; ensure correct payloads and state updates."
          },
          {
            "id": 7,
            "title": "Campaigns page: list with accessible actions and isolation indicators",
            "description": "Build Campaigns list UI: fetch and render campaigns, show per-campaign isolation indicator, and provide actions (create, clone, archive) with confirmation modals.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.6"
            ],
            "details": "â€¢ Implement CampaignList component: table or list with columns Name, Updated, Status, Isolation badge (e.g., shield icon with aria-label including campaign ID), Actions menu. \nâ€¢ Keyboard-accessible action buttons; proper aria-labels. \nâ€¢ Empty state with Create button. \nâ€¢ Wire to API state for loading/error/empty. \nâ€¢ Ensure isolation indicator visible and testable (data-testid). \nâ€¢ Run tests to satisfy parts of TC003 and TC009.",
            "status": "pending",
            "testStrategy": "Component tests rendering list from MSW; axe checks; verify isolation badge content; snapshot in dark/light."
          },
          {
            "id": 8,
            "title": "Campaign create/clone/archive flows",
            "description": "Implement modal or page for creating campaigns, clone flow from selected campaign, and archive action with confirmation and optimistic updates.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.6",
              "4.7"
            ],
            "details": "â€¢ Create CampaignForm with fields: name (required), description (optional), provider preset selection (optional). \nâ€¢ Create route /campaigns/new with form validation and submit to POST /campaigns. \nâ€¢ Implement Clone action: opens dialog prefilled from source; POST /campaigns/:id/clone; navigate to detail or back to list. \nâ€¢ Implement Archive action: confirmation dialog; POST/PATCH archive; show archived status and hide from default view if needed. \nâ€¢ Toast notifications for success/error via ARIA live region. \nâ€¢ Run tests to make remaining TC003 pass (unit form validation + Playwright createâ†’cloneâ†’archive).",
            "status": "pending",
            "testStrategy": "RTL tests for validation errors; integration tests for full flow; axe on dialogs."
          },
          {
            "id": 9,
            "title": "Sessions lobby: list and join",
            "description": "Create Sessions page that lists active sessions per campaign context and supports joining a session with proper routing and state.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.6"
            ],
            "details": "â€¢ Implement SessionsList fetching /sessions with campaign filter (if applicable). \nâ€¢ Display session name, participants, status; keyboard navigable list. \nâ€¢ Join button triggers POST /sessions/:id/join, then navigate to /sessions/:id (basic lobby placeholder). \nâ€¢ Handle errors and loading states with ARIA live. \nâ€¢ Run tests to satisfy TC004.",
            "status": "pending",
            "testStrategy": "Component tests with MSW: list and join; Playwright test navigating and verifying lobby route; axe checks."
          },
          {
            "id": 10,
            "title": "Settings view: provider configuration and preferences",
            "description": "Implement Settings page for provider selections and user preferences including theme and language.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.4",
              "4.5"
            ],
            "details": "â€¢ Sections: Providers (placeholder controls), Appearance (theme toggle), Language (i18n switch). \nâ€¢ Persist selections to localStorage or state store; reflect changes immediately. \nâ€¢ Ensure controls accessible with labels and descriptions. \nâ€¢ Run tests to validate persistence and UI updates (TC005, TC008, TC010).",
            "status": "pending",
            "testStrategy": "Unit tests for persistence and immediate application; axe scan on Settings."
          },
          {
            "id": 11,
            "title": "Assets viewer: images list with caching indicators",
            "description": "Create Assets page to browse images with basic client-side caching indicators and lazy loading.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "â€¢ Implement grid/list of images from mock endpoint; use IntersectionObserver to lazy load. \nâ€¢ Show cache state badge (e.g., from a simple in-memory or IndexedDB cache) and loading skeletons. \nâ€¢ Keyboard navigation and focus management for thumbnails; alt text from metadata. \nâ€¢ Run tests to satisfy TC006 and accessibility.",
            "status": "pending",
            "testStrategy": "Component tests verifying cache hits after second load; Playwright scroll/lazy-load; axe scan."
          },
          {
            "id": 12,
            "title": "Accessibility pass and keyboard navigation enhancements",
            "description": "Ensure WCAG-focused fixes across pages: roles, labels, focus traps in dialogs, skip links, and tab order.",
            "dependencies": [
              "4.1",
              "4.3",
              "4.7",
              "4.8",
              "4.9",
              "4.10",
              "4.11"
            ],
            "details": "â€¢ Validate landmarks and headings hierarchy. \nâ€¢ Ensure dialog traps and escape to close; ARIA labels for all interactive elements. \nâ€¢ Improve tab order and visible focus states. \nâ€¢ Re-run axe on all pages and fix violations. \nâ€¢ Run tests to satisfy TC007 comprehensively.",
            "status": "pending",
            "testStrategy": "Automated axe tests + manual keyboard-only walkthroughs; snapshots after fixes."
          },
          {
            "id": 13,
            "title": "Isolation indicator consistency and campaign context propagation",
            "description": "Standardize how campaign isolation indicators are displayed and ensure campaign_id context is propagated to Sessions and Assets views.",
            "dependencies": [
              "4.1",
              "4.6",
              "4.7",
              "4.9",
              "4.11"
            ],
            "details": "â€¢ Create CampaignContext provider carrying current campaign_id when navigating from Campaigns. \nâ€¢ Ensure Sessions and Assets read campaign_id and reflect isolation badge and scoping hints. \nâ€¢ Add breadcrumb with campaign label and isolation icon. \nâ€¢ Run tests to reaffirm TC009 across pages.",
            "status": "pending",
            "testStrategy": "Component/integration tests verifying context propagation and indicator presence on child routes."
          },
          {
            "id": 14,
            "title": "Error boundaries and loading states",
            "description": "Add error boundaries around route segments and graceful loading skeletons for data fetches.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.6"
            ],
            "details": "â€¢ Implement ErrorBoundary components per route with retry buttons and accessible error messages. \nâ€¢ Add Suspense-like loading placeholders/skeletons for lists and forms. \nâ€¢ Wire API errors to user-friendly toasts and ARIA live regions. \nâ€¢ Update tests expecting stable error handling.",
            "status": "pending",
            "testStrategy": "Unit tests for ErrorBoundary catching thrown errors; component tests for retry behavior; axe checks for alerts."
          },
          {
            "id": 15,
            "title": "Snapshots and visual regression for key components",
            "description": "Add snapshot tests for NavBar, CampaignList, CampaignForm, SessionsList in both themes and locale.",
            "dependencies": [
              "4.1",
              "4.4",
              "4.5",
              "4.7",
              "4.8",
              "4.9"
            ],
            "details": "â€¢ Create deterministic renders with mocked dates and data. \nâ€¢ Generate snapshots per theme (light/dark) and locale (en). \nâ€¢ Integrate into CI and gate on changes. \nâ€¢ Ensure no flakiness.",
            "status": "pending",
            "testStrategy": "Vitest snapshot tests; optional Playwright visual diffs for pages."
          },
          {
            "id": 16,
            "title": "Finalize Playwright E2E flows for campaigns and sessions",
            "description": "Harden E2E scenarios for create/clone/archive and join session; add retries and network idle waits with MSW to reduce flakiness.",
            "dependencies": [
              "4.1",
              "4.7",
              "4.8",
              "4.9"
            ],
            "details": "â€¢ Write comprehensive specs: \n  - Campaigns: create new, clone, archive; verify list updates and isolation badges (TC003, TC009). \n  - Sessions: join and navigate to lobby; verify breadcrumb and context (TC004). \nâ€¢ Add axe scans within flows to validate TC007. \nâ€¢ Tag tests with TC IDs in titles.",
            "status": "pending",
            "testStrategy": "Playwright headed and headless runs; CI parallelism; record traces on failure."
          },
          {
            "id": 17,
            "title": "Documentation and developer experience polish",
            "description": "Provide README instructions, scripts, and Storybook (optional) for components; ensure contributors can run tests and develop efficiently.",
            "dependencies": [
              "4.2",
              "4.3",
              "4.6",
              "4.7",
              "4.8",
              "4.9",
              "4.10",
              "4.11",
              "4.12",
              "4.16"
            ],
            "details": "â€¢ Update README with setup, scripts, environment, and testing instructions. \nâ€¢ Add component stories for key UI pieces with accessibility notes. \nâ€¢ Provide example .env and MSW handlers docs. \nâ€¢ Ensure pre-commit hooks for lint/test run.",
            "status": "pending",
            "testStrategy": "Manual validation following README; ensure newcomer can clone, install, run tests, and open app."
          }
        ]
      },
      {
        "id": 5,
        "title": "Provider Adapter Framework (LLM/STT/TTS/Image/Video/Embeddings)",
        "description": "Design provider-agnostic adapter interfaces selectable at runtime, with registry and config UI.",
        "details": "- Define interfaces in shared: LLMAdapter, STTAdapter, TTSAdapter, ImageGenAdapter, VideoGenAdapter (flag), EmbeddingsAdapter\n- Adapter capabilities describe models, cost, token limits, streaming support\n- Registry loads adapters via config; hot-switch per campaign/session\n- Initial implementations (MVP):\n  - LLM: OpenAI-compatible, local Ollama; STT: Vosk/Whisper local; TTS: Coqui XTTS or system; Image: Stable Diffusion (Automatic1111 or ComfyUI HTTP); Embeddings: text-embedding via local model\n  - Video placeholder adapter disabled by flag\n- A/B harness scaffold: route % traffic or paired eval; capture latency/tokens to llm_messages",
        "testStrategy": "- Unit tests ensure each adapter conforms to interface and error handling\n- TC011â€“TC013 partial: conformance checks and metrics capture\n- Config UI allows switching providers; persistence in settings without storing raw keys",
        "priority": "high",
        "dependencies": [
          2,
          4
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and unit/integration tests (TC011â€“TC013, UI config switching)",
            "description": "Before implementation, author test suites that define core acceptance criteria for the provider-agnostic adapter framework, registry selection, runtime hot-switching, capability metadata, metrics capture, and config UI switching. Include at least: unit tests for each adapter interface conformance and error handling, integration tests for registry loading and hot-switch per campaign/session, and a UI test for provider switching persistence without storing raw API keys.",
            "dependencies": [],
            "details": "Create test plan mapping: TC011 â€“ adapter conformance and capability reporting; TC012 â€“ metrics capture (latency/tokens) into llm_messages; TC013 â€“ runtime switching via registry/config. Add a UI test case for switching providers and persisting selection. Set up test scaffolding in repo: - shared/tests/adapters/*.spec.ts for interface conformance. - services/registry/*.spec.ts for registry resolution and hot-switch. - db/tests/llm_messages_metrics.spec.ts for metrics capture. - webapp/e2e/config-provider-switch.spec.ts for UI switching. Stub provider mocks for: OpenAI-compatible LLM, Ollama LLM, Whisper local STT, Vosk STT, Coqui XTTS TTS, system TTS, Stable Diffusion (A1111/ComfyUI HTTP), local embeddings. Define fixtures for campaign/session contexts. Define redaction expectations for secrets. Do not implement framework yet; tests should initially fail.",
            "status": "pending",
            "testStrategy": "Use Jest/Vitest for unit/integration, Playwright/Cypress for UI. Create mocks for network calls. Seed sqlite/test DB for llm_messages. Verify: - Each adapter implements required methods and capability descriptors. - Consistent error mapping across adapters. - Registry loads adapters from config and supports per-campaign and per-session overrides. - Hot-switching does not require process restart. - A/B harness routes by percentage and paired eval mode. - Metrics recorded with latency and token counts. - Config UI switching persists provider keys via secrets manager reference, not raw key."
          },
          {
            "id": 2,
            "title": "Define shared adapter interfaces and capability descriptors",
            "description": "Implement TypeScript interfaces in shared module: LLMAdapter, STTAdapter, TTSAdapter, ImageGenAdapter, VideoGenAdapter (gated by feature flag), EmbeddingsAdapter. Include standardized request/response shapes, streaming support, and capability descriptors for models, token/context limits, cost, and features.",
            "dependencies": [
              "5.1"
            ],
            "details": "In packages/shared/adapters/: define base types. Common: AdapterId, ProviderName, Capability { models: string[], cost: { inputPer1K?: number; outputPer1K?: number; unit?: 'tokens'|'sec'|'image' }, maxTokens?: number, contextWindow?: number, streaming?: boolean, languages?: string[], notes?: string }. Add result/error types and standardized error codes (AdapterErrorCode: 'RATE_LIMIT'|'AUTH'|'UNAVAILABLE'|'TIMEOUT'|'VALIDATION'|'UNKNOWN'). - LLMAdapter: methods: chat(options: { messages: ChatMessage[]; model?: string; temperature?: number; maxTokens?: number; stream?: boolean; tools?: ToolDef[] }): Promise<LLMResult> | AsyncIterable<LLMDelta>; embed(texts: string[]): Promise<number[][]> optional? keep separate in EmbeddingsAdapter per spec. - STTAdapter: transcribe(input: AudioInput, options?): Promise<STTResult>; supports streaming? add streamTranscribe(inputStream, options?): AsyncIterable<STTDelta>. - TTSAdapter: synthesize(input: { text: string; voiceId?: string; rate?: number; volume?: number; format?: 'wav'|'mp3' }, options?): Promise<TTSResult>; streamSynthesize? AsyncIterable<AudioChunk & Timestamps?>. - ImageGenAdapter: generate(input: { prompt: string; negativePrompt?: string; width?: number; height?: number; style?: Record<string, any>; seed?: number }, options?): Promise<ImageResult>; getStatus?(id): Promise<ImageStatus>. - VideoGenAdapter: behind feature flag; define interface similar to Image with disabled default implementation. - EmbeddingsAdapter: embed(texts: string[], options?): Promise<{ vectors: number[][]; model: string }>. Export Capability descriptors in each adapter via getCapabilities(): Promise<Capability>. Include type guards and zod schemas for validation.",
            "status": "pending",
            "testStrategy": "Run tests from 5.1. Ensure type conformance tests compile and fail until implementations; then update tests to import interfaces and validate shape using runtime zod schemas. Verify capability schemas validation and error code enums."
          },
          {
            "id": 3,
            "title": "Implement adapter error normalization and metrics hooks",
            "description": "Create shared error normalization utility and metrics hook contracts used by all adapters to map provider-specific errors to standardized codes and to capture latency, token counts, and payload sizes.",
            "dependencies": [
              "5.1",
              "5.2"
            ],
            "details": "Add packages/shared/adapters/errors.ts with AdapterError extends Error { code: AdapterErrorCode; provider?: string; raw?: unknown; httpStatus?: number }. Provide normalizeError(provider, rawError): AdapterError with mappings for common HTTP codes/timeouts. Add metrics interface: AdapterMetricsSink { onRequestStart(ctx), onRequestEnd(ctx, metrics), onRequestError(ctx, err) }. Define Metrics types: { latencyMs, inputTokens?, outputTokens?, bytesIn?, bytesOut?, model }. Implement default no-op sink and allow dependency injection via adapter constructors. Provide helper timers and token estimation hooks for OpenAI/Ollama models using encoding libs when exact not available.",
            "status": "pending",
            "testStrategy": "Unit tests assert mapping of simulated provider errors to AdapterError codes (TC011/TC012). Verify metrics hooks invoked and capture latency; assert token estimation fallback triggers when providers don't return counts."
          },
          {
            "id": 4,
            "title": "Build Adapter Registry with runtime selection and hot-switching",
            "description": "Implement a registry that loads adapter instances from configuration, supports per-campaign and per-session overrides, and allows hot-switching without restart.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3"
            ],
            "details": "Create packages/core/registry/AdapterRegistry.ts. Expose: register(type: 'llm'|'stt'|'tts'|'image'|'video'|'embeddings', id: string, factory: (cfg, deps)=>Adapter); get(type, context: { campaignId?: string; sessionId?: string }): Adapter; list(type): AdapterInfo[]. Load config from settings service (Task 2/4 deps) with schema: providers: { llm: { default: 'openai', perCampaign: { [id]: 'ollama' }, perSession: { [id]: 'openai' } }, ... } and providerConfigs: { openai: { apiKeyRef: 'secret://openai' , baseUrl? }, ollama: { host }, ... }. Implement watcher on config changes to recreate instances lazily. Support hot-switch by context: registry resolves provider id by session override > campaign override > default. Ensure secrets resolved via secrets manager refs (no raw keys kept).",
            "status": "pending",
            "testStrategy": "Integration tests from 5.1 should now pass for registry resolution and hot-switch (TC013). Add additional tests for config change triggering provider replacement between calls without process restart."
          },
          {
            "id": 5,
            "title": "MVP LLM adapters: OpenAI-compatible and local Ollama",
            "description": "Implement two LLMAdapter providers: OpenAI-compatible (chat/completions APIs) and Ollama local. Support streaming and token metrics capture.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "Create packages/providers/llm/openaiAdapter.ts supporting baseUrl override and model listing via /models when available. Streaming via SSE chunks -> AsyncIterable<LLMDelta>. Capture input/output tokens from response if present; else estimate. Implement tool/function call mapping. Create packages/providers/llm/ollamaAdapter.ts using ollama HTTP API (/api/chat, /api/generate) with stream support; map responses to LLMResult/LLMDelta. Provide getCapabilities() with models, contextWindow if known, streaming true, cost unknown or zero for local. Use metrics sink injection and error normalization.",
            "status": "pending",
            "testStrategy": "Unit tests per adapter: conformance, streaming emits deltas, errors normalized (TC011). Integration: registry returns correct adapter by config, A/B routing harness scaffolding can call both and capture metrics (TC012/TC013)."
          },
          {
            "id": 6,
            "title": "MVP STT adapters: Whisper local and Vosk",
            "description": "Implement STTAdapter providers for local Whisper and Vosk engines, with optional streaming if supported, unified timestamps output when available.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "Implement providers/stt/whisperLocalAdapter.ts wrapping local whisper CLI/server; providers/stt/voskAdapter.ts wrapping Vosk model via node binding or HTTP microservice. Normalize outputs to STTResult { text, words?: [{ start, end, word }], language? }. Support streamTranscribe when engine supports partials. Integrate error normalization and metrics (latency).",
            "status": "pending",
            "testStrategy": "Unit tests: adapter conformance, error paths, timestamp presence/absence handled. Integration: registry selection and switching. Performance smoke test optional."
          },
          {
            "id": 7,
            "title": "MVP TTS adapters: Coqui XTTS and System TTS",
            "description": "Implement TTSAdapter providers for Coqui XTTS (local/server) and a basic System TTS fallback. Provide optional timestamp/captions when available.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "providers/tts/coquiXttsAdapter.ts: call local XTTS server; support voiceId; streamSynthesize if API supports chunks; map viseme/phoneme timestamps if available. providers/tts/systemAdapter.ts: use OS TTS or simple offline engine; no timestamps by default. Both emit audio format metadata and integrate metrics.",
            "status": "pending",
            "testStrategy": "Unit: conformance, voice params mapping, error normalization. Integration: registry switching; verify absence of timestamps triggers documented fallback behavior."
          },
          {
            "id": 8,
            "title": "MVP Image generation adapters: Stable Diffusion (A1111 and ComfyUI HTTP)",
            "description": "Implement ImageGenAdapter providers for Stable Diffusion via Automatic1111 and ComfyUI HTTP APIs, with job status polling and seed/style controls.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "providers/image/sdA1111Adapter.ts calling /sdapi/v1/txt2img/img2img; handle negative prompts, width/height, seed, steps. providers/image/comfyUiAdapter.ts building graph payload; submit, poll status, retrieve image. Normalize outputs to ImageResult { id, images: [Buffer|assetRef], seed?, metadata }. Add getStatus(id) for long jobs. Integrate metrics and error normalization.",
            "status": "pending",
            "testStrategy": "Unit: payload building and parameter mapping; error cases. Integration: registry selection; ensure long-running job status works. These adapters will be used by Task 8 tests (TC003)."
          },
          {
            "id": 9,
            "title": "MVP Embeddings adapter: local model",
            "description": "Implement EmbeddingsAdapter for a local text-embedding model (e.g., sentence-transformers or llama.cpp embeddings), returning float vectors and model name.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "providers/embeddings/localAdapter.ts: wrap local service or on-device library; batch inputs; return consistent vector length; include model id in result. Add capability descriptor with cost=0 and supported languages.",
            "status": "pending",
            "testStrategy": "Unit: vector length consistency, batching, error normalization. Integration: registry selection."
          },
          {
            "id": 10,
            "title": "Feature-flagged VideoGenAdapter placeholder",
            "description": "Create a disabled-by-default VideoGenAdapter placeholder behind a feature flag, returning a clear NotEnabled error on invocation.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "Define FeatureFlag 'video.gen.enabled'. Implement providers/video/placeholderAdapter.ts that implements interface but throws AdapterError{ code:'UNAVAILABLE', message:'Video generation disabled by feature flag' }. Register only when flag true; otherwise registry returns placeholder for clarity.",
            "status": "pending",
            "testStrategy": "Unit: when flag off, calls throw UNAVAILABLE; when flag on with placeholder, ensure methods exist. Registry test: type 'video' returns placeholder."
          },
          {
            "id": 11,
            "title": "A/B harness scaffold and paired evaluation",
            "description": "Implement routing harness to send a percentage of traffic to alternate provider or perform paired evaluations, capturing metrics and persisting to llm_messages.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4",
              "5.5"
            ],
            "details": "Create core/ab/AbHarness.ts supporting modes: percentageSplit{ controlId, variantId, percent }, pairedEval{ aId, bId }. For percentage, randomly route per request using stable hash of session to meet target percent. For paired, call both adapters, store both outputs with linkage id. Integrate metrics sink to write latency/token counts into db.llm_messages with columns: request_id, provider_id, latency_ms, input_tokens, output_tokens, mode, paired_group_id. Provide API to configure per campaign/session.",
            "status": "pending",
            "testStrategy": "Integration tests (TC012/TC013): verify distribution within tolerance over N requests; paired eval stores two records linked by group id; metrics captured. Property tests for stable routing by session hash."
          },
          {
            "id": 12,
            "title": "Config UI for provider selection and secret references",
            "description": "Build a settings UI to switch providers per capability type (LLM/STT/TTS/Image/Embeddings), with per-campaign and per-session overrides. Persist selections using secret references instead of raw keys.",
            "dependencies": [
              "5.1",
              "5.4"
            ],
            "details": "In webapp: Add Settings > Providers page. Components: ProviderTypeSelector, ProviderList (from registry list()), ProviderConfigForm (fields depend on provider schema), OverrideScopes (global/campaign/session). Persist via settings API: provider selection and providerConfigs with secretRef fields (secret://...). Implement validation UI to test connection without revealing secrets. Ensure hot-switch reflected immediately by querying registry on apply.",
            "status": "pending",
            "testStrategy": "E2E UI test from 5.1 validates that switching providers updates active adapter and persists across reload; secrets are not exposed in DOM or network logs. Integration test asserts registry picks overrides after UI save."
          },
          {
            "id": 13,
            "title": "llm_messages metrics persistence and schema updates",
            "description": "Extend database schema and data-access layer to store latency and token metrics for LLM calls; provide generic metrics write for other adapters where applicable.",
            "dependencies": [
              "5.1",
              "5.3"
            ],
            "details": "Migrate db: alter llm_messages add columns: provider_id, model, latency_ms, input_tokens, output_tokens, bytes_in, bytes_out, mode, paired_group_id, created_at. Add DAO functions logLLMCallMetrics(ctx, data). Wire metrics sink default implementation to call DAO when type='llm'. Prepare views or queries for analytics.",
            "status": "pending",
            "testStrategy": "Unit tests (TC012): inserting and reading metrics; migration reversible; DAO validates constraints. Integration: verify entries appear after LLM calls via adapters and A/B harness."
          },
          {
            "id": 14,
            "title": "Security: secrets handling and redaction",
            "description": "Implement secrets manager references and ensure no raw API keys are persisted in settings, logs, or metrics. Add redaction utilities.",
            "dependencies": [
              "5.1",
              "5.4",
              "5.12"
            ],
            "details": "Create secrets module to resolve secret:// refs at runtime from OS keyring/env/VAULT. Inject resolved keys into adapter factories only in-memory. Implement redact(obj) utility to filter keys matching patterns (apiKey, token, Authorization) from logs and errors. Add interceptors to strip secrets from error.raw. Update config UI to only store secretRef strings.",
            "status": "pending",
            "testStrategy": "Unit: secrets resolution mock; verify no raw secret stored in settings DB; log snapshot tests confirm redaction. E2E: change secret, confirm adapters continue to work after refresh."
          },
          {
            "id": 15,
            "title": "Documentation and developer guide",
            "description": "Document adapter interfaces, registry usage, adding new providers, error codes, metrics, A/B harness, and config UI operations.",
            "dependencies": [
              "5.2",
              "5.4",
              "5.5",
              "5.6",
              "5.7",
              "5.8",
              "5.9",
              "5.10",
              "5.11",
              "5.12",
              "5.13",
              "5.14"
            ],
            "details": "Create docs in /docs/adapters/: overview, architecture diagrams, code samples, step-by-step guide to build a new adapter, capability descriptor reference, registry config examples, secrets handling, and troubleshooting. Add ADR for choosing Adapter pattern and registry design.",
            "status": "pending",
            "testStrategy": "Doc linting, example code snippets compiled in CI. Optional link checks."
          }
        ]
      },
      {
        "id": 6,
        "title": "Voice Capture, VAD, STT Pipeline with Captions and Diarization",
        "description": "Implement client voice capture with VAD, push-to-talk fallback, streaming STT, captions rendering, and speaker diarization.",
        "details": "- Web Audio API + MediaStream; VAD via webrtcvad-wasm; PTT UI toggle\n- Stream opus/pcm chunks over WebSocket to server; server forwards to STT adapter\n- Diarization: simple client-side speaker tagging by connection id; optional pyannote server bridge later\n- Captions: render per speaker with timestamps; adjustable rate/volume controls; accessibility semantics\n- Latency target: STT < 800 ms median; use partial hypotheses streaming",
        "testStrategy": "- TC001: join/voice/action: verify transcript and captions visible in multi-client session\n- Measure end-to-end latency with synthetic audio and assert median <800ms locally\n- Packet loss simulation to ensure graceful degradation",
        "priority": "high",
        "dependencies": [
          3,
          5,
          4
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for voiceâ†’captions pipeline (unit + integration)",
            "description": "Write automated tests that codify the core acceptance criteria: capture mic audio, VAD-driven start/stop with push-to-talk fallback, stream to STT over WebSocket, receive partial/final transcripts, render captions per speaker with timestamps, and basic diarization tags. Include latency and packet loss scenarios.",
            "dependencies": [],
            "details": "Create a test plan and scaffolding before implementation.\n- Unit tests:\n  - TC001-U1: VAD state machine transitions (silenceâ†’speechâ†’silence) with synthetic PCM frames.\n  - TC001-U2: Audio chunker frames at configured size (e.g., 20 ms or 100 ms) and encodes PCM/Opus correctly.\n  - TC001-U3: STT adapter client merges partial hypotheses into stable final transcripts.\n  - TC001-U4: Caption formatting includes timestamps and speaker tag.\n  - TC001-U5: PTT toggle enforces capture-on-hold behavior and bypasses VAD.\n- Integration/UI tests:\n  - TC001-I1 (maps to TC001): Two simulated clients join a session via WS gateway, stream synthetic audio, verify captions appear for both with correct speaker tags and ordering.\n  - TC001-I2: Latency measurement harness injects prerecorded audio and asserts median end-to-end STT latency under 800 ms locally.\n  - TC001-I3: Packet loss simulator drops 5â€“10% WS frames; verify graceful degradation (no crash, captions may have gaps but UI stable).\nArtifacts: test utilities to synthesize sinewave/speech-like PCM; a mock STT server emitting partial/final hypotheses; DOM testing for captions region with ARIA roles.",
            "status": "pending",
            "testStrategy": "Implement with Jest/Vitest + Playwright. Provide a WS mock server, a fake STT adapter, and a clock/HRTime probe for latency. Ensure tests run headless and record metrics."
          },
          {
            "id": 2,
            "title": "Audio capture module with Web Audio API and permissions",
            "description": "Implement microphone capture using MediaDevices.getUserMedia and Web Audio API, exposing a readable stream of mono PCM frames with configurable sample rate and frame size.",
            "dependencies": [
              "6.1"
            ],
            "details": "Build an AudioCapture class:\n- Request mic: navigator.mediaDevices.getUserMedia({ audio: { channelCount: 1, echoCancellation: false, noiseSuppression: false, autoGainControl: false, sampleRate: 16000 } }).\n- Use AudioWorklet (preferred) or ScriptProcessor fallback to pull Float32 audio.\n- Resample to 16 kHz mono if necessary (polyphase or linear with anti-aliasing).\n- Convert Float32 [-1,1] to 16-bit PCM Int16Array frames of N ms (start with 20 ms frames; allow config up to 100 ms for efficiency/latency tradeoff).\n- Expose events: onStart, onStop, onFrame(Int16Array, timestamp).\n- Handle permission errors and device changes; provide start/stop/dispose methods.\n- Disable AGC/noise suppression per provider best practices.",
            "status": "pending",
            "testStrategy": "Run tests from 6.1; add unit tests to validate resampler correctness (RMS/energy preserved within tolerance), frame sizing, and error handling. Mock getUserMedia and AudioWorklet."
          },
          {
            "id": 3,
            "title": "Voice Activity Detection (VAD) integration with webrtcvad-wasm",
            "description": "Wire up VAD to gate audio frames into speech segments with configurable aggressiveness and hangover time, emitting start/stop speech events.",
            "dependencies": [
              "6.1",
              "6.2"
            ],
            "details": "Implement VADController:\n- Load webrtcvad-wasm module; initialize with mode (0â€“3) aggressiveness.\n- Feed 10/20/30 ms 16 kHz PCM frames as required by WebRTC VAD.\n- Maintain ring buffer to smooth decisions; parameters: pre-roll (e.g., 200 ms), hangover (e.g., 300 ms).\n- Emit events: onSpeechStart, onSpeechEnd, onSpeechFrame.\n- Provide thresholds to avoid choppy toggling; expose metrics (speech ratio, decisions/sec).",
            "status": "pending",
            "testStrategy": "Unit tests (from 6.1 TC001-U1) with synthetic voiced/unvoiced signals; verify transitions and pre-roll/hangover behavior. Property tests to ensure decisions deterministic."
          },
          {
            "id": 4,
            "title": "Push-to-talk (PTT) UI and control flow",
            "description": "Create a UI toggle/button to enable push-to-talk, bypassing VAD when pressed/held and muting capture when released, with full keyboard accessibility.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3"
            ],
            "details": "Implement a PTTButton component:\n- States: idle, pressed, locked (toggle mode), disabled.\n- Keyboard: Space/Enter to press/hold; toggle via T; ARIA role='button', aria-pressed.\n- Integrate with capture pipeline: when PTT active, forward frames regardless of VAD; when inactive, rely on VAD.\n- Visual feedback (recording indicator) and tooltip. Persist user preference for VAD/PTT mode.\n- Debounce to avoid flapping on quick taps.",
            "status": "pending",
            "testStrategy": "UI tests: simulate keyboard/mouse; verify state changes and that frames are forwarded while held. Map to TC001-U5 and TC001-I1 checks for accessibility attributes."
          },
          {
            "id": 5,
            "title": "Opus/PCM framing and WebSocket client streaming",
            "description": "Implement audio chunker and WS client to send PCM or Opus-encoded frames to server with metadata for session and speaker.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3",
              "6.4"
            ],
            "details": "Build StreamSender:\n- Config: encoding=PCM16 or Opus; frameDurationMs (20/40/60/100); maxBufferedFrames; reconnect/backoff.\n- For Opus, integrate encoder (e.g., opus-recorder/opus-media-recorder or wasm opus) at 16 kHz mono, bitrate ~16â€“24 kbps, complexity tuned for latency.\n- Package messages: { type: 'audio-chunk', ts, seq, encoding, sampleRate, speakerId, sessionId, channelId, payload }.\n- Handle backpressure: if WS bufferedAmount exceeds threshold, drop or downsample per policy and mark with loss hints.\n- Heartbeat pings and resume with seq continuity; include reconnect token.\n- Security: do not include PII; use session token from Task 3 auth.",
            "status": "pending",
            "testStrategy": "Unit tests: encode/decode sanity, framing correctness, seq monotonicity, backpressure behavior. Integration: echo server validates schema and ordering; packet loss injection for TC001-I3."
          },
          {
            "id": 6,
            "title": "STT adapter client with partial/final hypothesis handling",
            "description": "Implement client-side STT stream handler that receives partial and final transcripts from the server and assembles utterances with timestamps.",
            "dependencies": [
              "6.1",
              "6.5"
            ],
            "details": "STTClient:\n- WS message types: stt-partial, stt-final, stt-error; include seq, speakerId, startTs, endTs, text, confidence.\n- Maintain per-speaker utterance buffer: update partial text in place; finalize on stt-final.\n- Emit events: onPartial(utterance), onFinal(utterance), onError.\n- Track timings for latency: first-partial latency, final latency.\n- Handle out-of-order messages via seq; merge corrections.\n- Configurable provider hints (languageCode, punctuation, interimResults=true).",
            "status": "pending",
            "testStrategy": "Unit tests (TC001-U3): merging logic, corrections, and event emission. Integration: with mock STT server producing partials/finals; record latency for TC001-I2."
          },
          {
            "id": 7,
            "title": "Client-side diarization tagging by connection/session",
            "description": "Assign a stable speakerId per client connection and attach it to audio and caption events; prepare hook for future server-side diarization bridge.",
            "dependencies": [
              "6.1",
              "6.5"
            ],
            "details": "Implement SpeakerTagger:\n- Derive speakerId from WS connection id or assigned session user id from gateway.\n- Provide map of speakerIdâ†’displayName/color; persist locally.\n- Attach speakerId to outgoing audio chunks and consume on incoming captions.\n- Define interface for optional server diarization (pyannote) later: accept speaker change events and remap segments post-hoc.",
            "status": "pending",
            "testStrategy": "Unit: verify stable speakerId across reconnects using reconnect token; ensure mapping applied to messages. Integration (TC001-I1): two clients produce distinct speaker tags."
          },
          {
            "id": 8,
            "title": "Captions rendering component with accessibility semantics",
            "description": "Render streaming captions per speaker with timestamps, interim updates, and ARIA-compliant semantics and controls for rate/volume.",
            "dependencies": [
              "6.1",
              "6.6",
              "6.7"
            ],
            "details": "Implement CaptionsPanel:\n- Regions per speaker with color tokens; show partial text updating in place; finalize into scrollback with startâ€“end timestamps.\n- Keyboard navigable; ARIA live region='polite' for partials; role='log' for history.\n- Controls: caption visibility toggle, adjustable TTS speech rate/volume sliders tied to settings; WCAG AA contrast tokens.\n- Virtualized list for performance; time formatting; copy/export transcript.",
            "status": "pending",
            "testStrategy": "UI tests: verify live updates, finalization, keyboard focus order, ARIA roles. Integration (TC001-I1): captions visible in multi-client session and per-speaker segregation."
          },
          {
            "id": 9,
            "title": "Latency optimization and measurement hooks",
            "description": "Implement measurement probes and tune frame sizes, buffering, and encoder settings to achieve <800 ms median STT partial latency locally.",
            "dependencies": [
              "6.1",
              "6.5",
              "6.6",
              "6.8"
            ],
            "details": "Add high-resolution timers around pipeline stages: captureâ†’chunkâ†’sendâ†’serverâ†’partialâ†’render. Expose metrics to console/overlay. Tune defaults: 20â€“40 ms frame size, immediate send on frame, Nagle disabled, Opus lookahead minimized, interimResults enabled. Provide config to trade efficiency vs latency.",
            "status": "pending",
            "testStrategy": "Run TC001-I2: feed synthetic audio, record latencies, assert median under 800 ms. Regression test to fail if exceeded."
          },
          {
            "id": 10,
            "title": "Packet loss tolerance and reconnection handling",
            "description": "Ensure graceful behavior under dropped audio or STT messages with retries/backoff and UI resilience.",
            "dependencies": [
              "6.1",
              "6.5",
              "6.6",
              "6.8"
            ],
            "details": "Implement loss handling:\n- Audio chunks include seq; gaps are tolerated and flagged.\n- Partial timeout fallback: if partials stall, finalize best-effort segment.\n- Reconnect WS with exponential backoff; resubscribe to channels; restore speaker mapping.\n- UI shows subtle loss indicator but continues rendering.\n- Backpressure policy: drop oldest non-sent frames when buffer high.",
            "status": "pending",
            "testStrategy": "Execute TC001-I3 with 5â€“10% drop; verify no crashes, reconnect works, captions continue. Unit tests for backoff schedule and timeout finalization."
          },
          {
            "id": 11,
            "title": "Server gateway interop and schema validation",
            "description": "Validate integration with Realtime WebSocket Gateway schemas and message types, using shared zod schemas for strict validation.",
            "dependencies": [
              "6.1",
              "6.5"
            ],
            "details": "Import shared schema package; validate outbound audio-chunk and inbound stt-* messages. Ensure channel scoping (room/team/etc.) obeys membership. Include rate limiting hints and heartbeat compatibility. Map to Task 3 message types: voice-meta, caption, action as needed.",
            "status": "pending",
            "testStrategy": "Integration tests with gateway test harness (from Task 3): multi-client join/leave, audio routing metadata distribution per TC002 mapping, and schema conformance."
          },
          {
            "id": 12,
            "title": "Settings persistence and controls (rate/volume, caption toggle)",
            "description": "Persist user preferences for captions visibility, speech rate, and volume locally and apply on load.",
            "dependencies": [
              "6.1",
              "6.8"
            ],
            "details": "Implement SettingsStore (localStorage/indexedDB): keys for captionsEnabled, speechRate, speechVolume, PTT/VAD mode. Provide hooks/context to read/write. Ensure defaults sane and synced to UI controls.",
            "status": "pending",
            "testStrategy": "Unit/UI tests: change settings, reload app, confirm persistence and application. Axe checks for controls accessibility."
          },
          {
            "id": 13,
            "title": "Security, privacy, and consent prompts for recording",
            "description": "Add explicit user consent UI for recording and transmitting audio; ensure no PII in telemetry and secure handling of media streams.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.5"
            ],
            "details": "Consent modal/banner before first capture with clear language; store consent flag. Redact PII in logs; avoid storing raw audio locally. Use secure WS (wss) and session tokens. Provide quick mic mute control and indicator.",
            "status": "pending",
            "testStrategy": "UI tests: consent required before capture begins; verify logs contain no audio payloads or PII. Negative tests: decline consent prevents capture."
          },
          {
            "id": 14,
            "title": "Optional server-side diarization bridge hook (pyannote-ready)",
            "description": "Prepare client to accept server diarization segments and remap displayed speakers post-hoc without breaking UX.",
            "dependencies": [
              "6.1",
              "6.6",
              "6.7",
              "6.8"
            ],
            "details": "Define WS message type 'diarization-update' with segments [{start,end,speakerLabel,confidence}]. Implement reconciler to reassign captions in time ranges; maintain mapping and update colors/labels smoothly. Conflict resolution: client tag vs server diarization preference toggle.",
            "status": "pending",
            "testStrategy": "Integration test: feed diarization updates after initial captions; verify UI remaps segments and preserves ordering without flicker."
          },
          {
            "id": 15,
            "title": "End-to-end scenario tests and documentation",
            "description": "Finalize E2E tests covering common flows and document setup, configs, and troubleshooting for the pipeline.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3",
              "6.4",
              "6.5",
              "6.6",
              "6.7",
              "6.8",
              "6.9",
              "6.10",
              "6.11",
              "6.12",
              "6.13",
              "6.14"
            ],
            "details": "Add Playwright E2E covering: VAD-only session, PTT session, multi-client captions, reconnect scenario, settings persistence, and diarization updates. Write README with architecture diagram, configuration options (frame size, encoding), and performance tuning tips.",
            "status": "pending",
            "testStrategy": "Run full suite including TC001, latency goal, and packet loss. Ensure green before marking task complete."
          }
        ]
      },
      {
        "id": 7,
        "title": "TTS Synthesis per NPC with Controls",
        "description": "Add TTS playback per speaker/NPC with adjustable rate/volume and caption sync.",
        "details": "- TTS adapter streaming; audioWorklet playback; queue per channel\n- Voice identity map per NPC; cache synthesized clips by text+voice hash in cache\n- Controls: rate, volume, mute per channel; caption sync from TTS timestamps if available",
        "testStrategy": "- Unit: caching key correctness; fallbacks when timestamps unavailable\n- UX test: adjust rate/volume; ensure captions track\n- Performance: TTS <1.2s for ~150 chars median using local model settings",
        "priority": "medium",
        "dependencies": [
          6,
          5
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for per-NPC TTS playback, controls, caching, and caption sync (TC001, TC002, TC005)",
            "description": "Author unit and integration/UI tests that define acceptance criteria for TTS playback per NPC channel with adjustable rate/volume/mute, queueing, caching by text+voice hash, and caption synchronization using timestamps or graceful fallback.",
            "dependencies": [],
            "details": "Implement test suites before any production code:\n- Unit tests:\n  - TC001: Cache key stability and correctness. Given same text and voice identity, expect cache hit; different text or voice â†’ miss. Include Unicode and punctuation normalization cases.\n  - TC002: Channel queue behavior. Enqueue multiple utterances per NPC; ensure FIFO playback order and non-blocking behavior across different NPC channels.\n  - TC005: Caption mapping. Given TTS word/phoneme timestamps, verify caption segments align to ranges and produce correct text highlighting indices; when timestamps absent, verify fallback to timed chunks proportional to text length.\n  - Control application: Verify rate/volume/mute conversions map from UI model to adapter parameters; ensure mute overrides volume.\n  - Voice identity map: Ensure NPC->voice mapping persists and is read for synthesis; missing mapping falls back to default.\n  - Performance harness stub: Measure mocked adapter end-to-end promise resolution under 1.2s median for ~150 chars with local mock.\n- Integration/UI tests (Playwright):\n  - Render multi-NPC chat; trigger TTS for two NPCs concurrently; verify independent channel state and no cross-audio bleed; UI sliders for rate/volume update live; mute toggles silence while captions continue.\n  - Caption sync: During playback, verify active caption word/segment highlights track synthesized timestamps.\n  - Offline/latency tolerance: With adapter providing no timestamps, verify fallback captions progress smoothly.\n- Mocks/fakes:\n  - TTSAdapterFake supports: streaming chunks, optional timestamps, controllable latency, and emits per-chunk events.\n  - AudioWorkletMock/AudioContextMock to assert parameter changes and buffer scheduling.\n- Tag tests with TC labels and map to requirements. Establish coverage thresholds â‰¥80% for TTS module.\n- Define fixtures: sample texts (ASCII, Unicode/emoji, punctuation), voices, NPC IDs, campaign IDs.",
            "status": "pending",
            "testStrategy": "Run unit tests in Jest with fake timers for playback scheduling; use Playwright for UI scenarios with WebAudio and Worklet mocks. Add performance assertions with soft thresholds and artifacts on failure."
          },
          {
            "id": 2,
            "title": "Design TTS channel architecture and interfaces",
            "description": "Define core interfaces and data models for TTS channels per NPC, adapter abstraction, queue items, controls state, and caption events.",
            "dependencies": [
              "7.1"
            ],
            "details": "Create TypeScript interfaces:\n- TTSAdapter { synthesizeStream(text, voice, rate, volume): AsyncIterable<TTSChunk>; supportsTimestamps: boolean }\n- TTSChunk { audioBuffer: ArrayBuffer | Float32Array; timestamps?: WordTimestamp[]; isFinal: boolean }\n- WordTimestamp { startMs: number; endMs: number; text: string; charStart: number; charEnd: number }\n- NPCChannel { id: string; voiceId: string; queue: Utterance[]; state: 'idle'|'playing'|'paused'|'muted'; controls: { rate: number; volume: number; mute: boolean } }\n- Utterance { id: string; npcId: string; text: string; voiceId: string; hashKey: string; requestMeta: { createdAt: number } }\n- CaptionEvent { utteranceId: string; current: { startMs: number; endMs: number; text: string; index: number }; source: 'timestamps'|'fallback' }\nDefine service boundaries:\n- TTSService: manages NPC channels, enqueues utterances, resolves cache, calls adapter, emits playback and caption events.\n- AudioEngine: wraps AudioContext/AudioWorkletNode per channel, applies rate/volume/mute, schedules buffers.\n- Cache: clip store by (text+voice hash) mapping to decoded PCM and timestamps if present.\n- VoiceRegistry: NPCâ†’voice mapping with default.\nEvents bus signature for UI subscription: onPlaybackStart, onPlaybackEnd, onCaptionUpdate, onControlChange.\nHashing: stable normalized key build: normalize text (NFC), collapse whitespaces, trim, lowercase optional flag, include voiceId and rate-independent; include locale if applicable.",
            "status": "pending",
            "testStrategy": "Validate interface types compile; add minimal smoke unit tests for hash builder and model invariants. Run tests from 7.1 and ensure compile passes."
          },
          {
            "id": 3,
            "title": "Implement voice identity map per NPC",
            "description": "Create a persistent mapping from NPC IDs to voice identities with defaults and overrides, including loading/saving.",
            "dependencies": [
              "7.1",
              "7.2"
            ],
            "details": "Build VoiceRegistry module:\n- API: getVoice(npcId): voiceId; setVoice(npcId, voiceId); getDefault(): voiceId; setDefault(voiceId).\n- Persistence: store in project settings or per-campaign config; namespace by campaign_id if available; provide migration-safe schema.\n- Validation: ensure voiceId exists in supported voices list from adapter; fallback to default on invalid.\n- Events: emit 'voiceChanged' for UI to refresh.\n- Tie into TTSService so enqueue uses VoiceRegistry.getVoice(npcId) unless explicit override provided.",
            "status": "pending",
            "testStrategy": "Unit tests: set/get, default fallback, invalid voiceId handling, campaign scoping. Run existing tests; ensure no regressions."
          },
          {
            "id": 4,
            "title": "Implement text+voice hash-based clip cache",
            "description": "Add an in-memory + on-disk cache keyed by stable hash of text and voice identity to reuse synthesized audio and timestamps.",
            "dependencies": [
              "7.1",
              "7.2"
            ],
            "details": "Cache module:\n- Key builder: hash = SHA-256(JSON.stringify({text: normalize(text), voiceId})) returning hex; ensure deterministic order.\n- Store: LRU in-memory (e.g., 128 entries) and persistent file cache per-campaign subdir; index mapping keyâ†’metadata (durationMs, hasTimestamps, createdAt, version).\n- Values: PCM data (Float32Array) or encoded (Opus/PCM WAV) plus optional timestamps.\n- API: get(key)â†’{audio, timestamps}?; put(key, value); has(key).\n- Serialization: use chunked file format or simple JSON+binary split; checksum for corruption.\n- Invalidate on version bump or voice change.\n- Thread-safety: guard concurrent puts; de-dupe concurrent inflight requests via promise memoization.",
            "status": "pending",
            "testStrategy": "Unit tests from TC001 validate key stability and hit/miss. Add tests for persistence roundtrip and invalidation. Run full suite; fix failing cases."
          },
          {
            "id": 5,
            "title": "Build per-NPC channel queue and dispatcher",
            "description": "Create TTSService to manage independent queues per NPC, ensuring FIFO playback within a channel and concurrency across channels.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.3",
              "7.4"
            ],
            "details": "Implement TTSService:\n- Data: Map<npcId, NPCChannel> with queue array and state.\n- API: enqueue(npcId, text, options?): returns utteranceId; clear(npcId); skipCurrent(npcId); pause/resume.\n- Dispatcher: one async loop per channel processes queue items; resolves from cache or synthesizes via adapter; emits events; ensures errors do not break loop.\n- Concurrency: channels run independently via separate tasks.\n- Backpressure: cap queue length per channel; drop or merge policy configurable.\n- Cancellation: abort controller per utterance; skip should stop current synthesis and playback gracefully.\n- Telemetry: timings for synthesis, cache hit ratio, latency.",
            "status": "pending",
            "testStrategy": "Unit tests from TC002 cover FIFO and independence; add tests for skip/pause/resume. Run tests; ensure deterministic with fake timers."
          },
          {
            "id": 6,
            "title": "Integrate streaming TTS adapter and fallback",
            "description": "Wire a streaming TTSAdapter that yields audio chunks and optional timestamps; include a no-timestamps fallback adapter for offline/local model.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.5"
            ],
            "details": "Adapter layer:\n- Define StreamingAdapter implementation using existing provider integration (or local model). It should respect rate and volume parameters where supported, else adjust in AudioEngine.\n- Provide feature flag for timestamps availability (supportsTimestamps).\n- Normalize timestamps to WordTimestamp[] aligned to original text; map phoneme/viseme if provider returns them.\n- Error handling: retries with jitter; surface structured errors to TTSService.\n- FallbackAdapter: returns audio without timestamps; set supportsTimestamps=false.\n- Ensure adapters are swappable via DI to support tests/mocks.",
            "status": "pending",
            "testStrategy": "Extend adapter unit tests with mocked provider responses. Ensure TC005 caption tests pass with both adapters. Run full suite."
          },
          {
            "id": 7,
            "title": "Implement AudioWorklet-based playback engine per channel",
            "description": "Create AudioEngine with an AudioContext and an AudioWorkletNode per NPC channel, supporting buffer scheduling, rate, volume, and mute.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.5"
            ],
            "details": "AudioEngine design:\n- One shared AudioContext; per-channel WorkletNode instance with parameters: gain (volume), playbackRate, mute flag.\n- Buffer queue: accept PCM Float32 buffers from TTSService; schedule via ring buffer in Worklet; low-latency streaming.\n- Controls: setRate(npcId, rate), setVolume(npcId, volume), setMute(npcId, boolean); clamp ranges and smooth changes (ramps) to avoid clicks.\n- End-of-stream and underflow handling; pause/resume map to context suspend/resume or per-channel gating.\n- Clock: expose currentTime mapping to ms for caption alignment.\n- Platform fallback: if Worklet unsupported, use ScriptProcessor as fallback with a feature flag.",
            "status": "pending",
            "testStrategy": "Unit tests with AudioWorkletMock verify parameter changes propagate and buffers consumed. UI tests adjust sliders and observe audible changes via analyser-node metrics or mock assertions. Run all tests."
          },
          {
            "id": 8,
            "title": "Caption synchronization and highlighting",
            "description": "Translate TTS timestamps into caption events and provide fallback time-based segmentation when timestamps are unavailable.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.5",
              "7.6",
              "7.7"
            ],
            "details": "CaptionSync module:\n- If timestamps present: build segments/word-level map; emit CaptionEvent updates on audio clock progression; support per-word highlight.\n- If absent: estimate duration from audio buffer length; segment text into words/phrases; assign proportional timings; update on clock.\n- Handle punctuation and Unicode graphemes with Intl.Segmenter; keep char indices consistent with normalized text used in cache key.\n- Provide API: subscribe(utteranceId, listener), unsubscribe; and getCurrent(utteranceId).\n- Edge cases: fast/slow rate changes in-flight adjust mapping; seeking unsupported; pause/resume maintain indices.",
            "status": "pending",
            "testStrategy": "Leverage TC005 tests to verify alignment under both modes. Add unit tests for segmentation with emojis/RTL scripts. Run suite."
          },
          {
            "id": 9,
            "title": "User controls UI and state management for per-channel rate/volume/mute",
            "description": "Add UI controls per NPC channel to adjust rate, volume, and mute in real time, reflecting state from the TTSService and AudioEngine.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.5",
              "7.7",
              "7.8"
            ],
            "details": "UI implementation:\n- For each NPC panel, render sliders: rate (0.5xâ€“2.0x), volume (0â€“1), and a mute toggle.\n- Bind to TTSService control APIs; debounce updates and apply smooth ramps.\n- Display current voice name; allow change via dropdown to update VoiceRegistry.\n- Show live caption highlight under the current utterance.\n- Accessibility: keyboard operable, ARIA labels, focus order.\n- Persist last-used controls per NPC in state store; reset on campaign switch.",
            "status": "pending",
            "testStrategy": "Playwright tests: adjust controls and verify AudioEngine parameter changes and audible output (via mock metrics). Verify captions follow. Ensure multi-NPC independence. Run all tests and fix failures."
          },
          {
            "id": 10,
            "title": "Performance optimization and latency budget enforcement",
            "description": "Ensure median time-to-first-audio under 1.2s for ~150 chars using local settings; optimize buffering, caching, and concurrency.",
            "dependencies": [
              "7.1",
              "7.5",
              "7.6",
              "7.7"
            ],
            "details": "Optimizations:\n- Start playback on first buffered chunk threshold (e.g., 100â€“200ms) while continuing to stream.\n- Decode/convert audio off main thread (Worklet/Worker).\n- Pre-warm adapter connections; memoize inflight synthesis by identical key.\n- Measure TTFB and total synthesis durations; log to telemetry.\n- Cache fast-path: on hit, schedule immediately.\n- Rate/volume applied in Worklet avoids re-synthesis.\n- Configurable chunk size to balance latency vs. stability.",
            "status": "pending",
            "testStrategy": "Add performance tests using mock adapter timing and real AudioContext in headless mode where possible. Assert median <1.2s across 20 runs. Keep artifacts on failures. Run full suite."
          },
          {
            "id": 11,
            "title": "Error handling, fallbacks, and resilience",
            "description": "Harden the system to handle synthesis errors, audio underflow, unsupported features, and cancellation without crashing channels.",
            "dependencies": [
              "7.5",
              "7.6",
              "7.7",
              "7.8"
            ],
            "details": "Implement:\n- Retry with exponential backoff for transient adapter failures; circuit-breaker to avoid thrashing.\n- Graceful underflow handling: insert short silence buffers; keep captions paused.\n- Provider capability detection to switch to fallback adapter.\n- Timeouts for synthesis; propagate user-visible error to UI toast and event bus.\n- Ensure skip/pause/resume/cancel consistently clean resources; avoid memory leaks.",
            "status": "pending",
            "testStrategy": "Unit tests simulate adapter failures and timeouts; verify retries and UI error surfacing. Integration tests skip/cancel mid-utterance. Run whole suite."
          },
          {
            "id": 12,
            "title": "Wire campaign isolation for TTS assets and channels",
            "description": "Scope caches, voice mappings, and realtime events by campaign_id to avoid cross-campaign leakage.",
            "dependencies": [
              "7.3",
              "7.4",
              "7.5"
            ],
            "details": "Integrate with campaign context:\n- Namespaced cache directories per campaign.\n- VoiceRegistry keyed by campaign_id; default can be campaign-specific.\n- Event bus namespaces so captions/audio events do not cross campaigns.\n- Validate channel IDs encode campaign_id.",
            "status": "pending",
            "testStrategy": "Add isolation unit tests mirroring TC017 patterns for TTS context: two campaigns active, ensure no cache or event leakage. Run suite."
          },
          {
            "id": 13,
            "title": "Documentation and developer ergonomics",
            "description": "Provide usage docs, API examples, and troubleshooting for TTS per NPC with controls and captions.",
            "dependencies": [
              "7.5",
              "7.6",
              "7.7",
              "7.8",
              "7.9",
              "7.11",
              "7.12"
            ],
            "details": "Write README with:\n- Quickstart: enqueue, set controls, subscribe to captions.\n- Adapter configuration and swapping.\n- Cache behavior and invalidation.\n- Performance tuning tips.\n- Known limitations and fallback behavior.\n- Mapping to TC001/TC002/TC005.\nAdd TypeDoc comments and example snippets for common flows.",
            "status": "pending",
            "testStrategy": "Doc lints pass; run code snippets in docs as tests where possible. Re-run full test suite."
          },
          {
            "id": 14,
            "title": "Final end-to-end validation and readiness gate (TC001, TC002, TC005)",
            "description": "Execute the complete test plan, verify acceptance criteria across unit and UI layers, and ensure CI integration.",
            "dependencies": [
              "7.2",
              "7.3",
              "7.4",
              "7.5",
              "7.6",
              "7.7",
              "7.8",
              "7.9",
              "7.10",
              "7.11",
              "7.12",
              "7.13"
            ],
            "details": "Actions:\n- Run full CI matrix including Playwright UI and performance suites; ensure coverage >80% in TTS modules.\n- Verify cache key correctness (TC001), FIFO and per-channel isolation (TC002), and caption synchronization with and without timestamps (TC005) are green.\n- Export artifacts: coverage, screenshots, logs.\n- Resolve any flakiness and document waivers if any non-critical issues remain.",
            "status": "pending",
            "testStrategy": "CI run with retries and artifact collection; manual spot-check in a dev environment for audio quality and caption feel before sign-off."
          }
        ]
      },
      {
        "id": 8,
        "title": "Image Generation Service with Campaign Style Profiles and Cache",
        "description": "Generate scene/portrait/item images using prompt templates and style profiles; manage lifecycle placeholderâ†’final and caching.",
        "details": "- ImageGenAdapter usage; prompt templates with variables (scene, character, item)\n- Campaign style profile: seed, artists/tags, aspect\n- API: POST /images request returns placeholder id â†’ polls/streams to final; store in images table with hash\n- Cache reuse by prompt+style hash; SLA: cached <6s median\n- UI: show placeholder then swap to final; local asset storage\n- Dedup across campaigns only if allowed; default isolate per campaign",
        "testStrategy": "- TC003: verify lifecycle and cache reuse; measure cached retrieval latency\n- Unit: prompt rendering correctness and hash stability\n- Failure tests: provider error â†’ fallback placeholder",
        "priority": "high",
        "dependencies": [
          5,
          2,
          4,
          3
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for image lifecycle, caching, and style profiles (TC003, Unit + Integration + UI)",
            "description": "Before implementation, define unit, integration, and UI tests covering core acceptance criteria: prompt rendering correctness, prompt+style hash stability, lifecycle placeholderâ†’final, cache reuse with SLA (<6s median for cached hits), provider error fallback placeholder, and campaign isolation defaults with opt-in dedup.",
            "dependencies": [],
            "details": "â€¢ Create test plan mapping: TC003 covers lifecycle, cache reuse, latency; Unit tests for prompt template rendering and hash stability; Integration tests for API lifecycle and cache hits; UI test for placeholder-to-final swap.\nâ€¢ Define fixtures: sample prompt templates for scene/portrait/item with variables {scene, character, item}; sample campaign style profiles (seed, artists/tags, aspect); campaign A and campaign B contexts.\nâ€¢ Unit tests:\n  - PromptTemplateRenderer renders variables correctly; missing variables error; deterministic output for same inputs.\n  - StyleProfile normalization (seed, tags ordering, aspect normalization) and hash stability across processes.\n  - Hash function includes prompt, style profile, and campaign scoping flag; identical inputs produce identical hashes; different campaign IDs do not collide unless dedup allowed.\nâ€¢ Integration tests (API):\n  - POST /images returns 202 with placeholder id, placeholder status, and polling endpoint; subsequent poll transitions to final with URL and metadata.\n  - Cached request (same prompt+style, same campaign) returns final within SLA when cache is warm; record latency and assert median <6s for cached runs.\n  - Provider error simulation -> placeholder remains with error state and retry guidelines; fallback placeholder asset returned.\n  - Dedup across campaigns only when allow_cross_campaign_dedup=true; otherwise separate cache keys.\nâ€¢ UI/e2e tests:\n  - Render component shows placeholder asset immediately, then swaps to final URL when status=final.\n  - Local asset storage path correctness; image tag updates without layout shift.\nâ€¢ Performance test harness: warm the cache, then issue N=50 cached requests and compute median latency; assert <6s.\nâ€¢ Tag tests with IDs: TC003-LIFECYCLE, TC003-CACHE, TC003-SLA, TC003-ERROR, TC003-ISOLATION, TC003-UI.\nâ€¢ Define mocks for ImageGenAdapter and clock controls for deterministic timing.",
            "status": "pending",
            "testStrategy": "Run unit tests first; then integration tests with in-memory DB and file store; UI tests via headless browser. Add a perf test stage gated for TC003-SLA. All subsequent subtasks must run and keep these tests passing."
          },
          {
            "id": 2,
            "title": "Design data model and migrations for images, cache indices, and campaign scoping",
            "description": "Define the schema for images table and related indices to support lifecycle states, hashing, and campaign isolation with optional cross-campaign dedup.",
            "dependencies": [
              "8.1"
            ],
            "details": "â€¢ Table images: id (uuid), campaign_id (uuid), request_hash (string, indexed), prompt (text), style_profile (jsonb), type (enum: scene|portrait|item), status (enum: placeholder|processing|final|error), placeholder_url (string), final_url (string), provider (string), provider_job_id (string), error_code (string), error_message (text), allow_cross_campaign_dedup (bool, default false), created_at, updated_at.\nâ€¢ Unique constraint for (campaign_id, request_hash) when allow_cross_campaign_dedup=false; alternative global unique index on (request_hash) for dedup=true entries; implement via partial indices.\nâ€¢ Secondary table image_cache_index (optional) mapping request_hash -> images.id for fast lookups; consider materialized view or rely on images index.\nâ€¢ Add latency metrics table image_metrics: id, image_id, is_cached (bool), duration_ms, measured_at to support SLA validation.\nâ€¢ Local asset storage registry table (optional) or embed in images as asset_paths jsonb for variants and thumbnails.\nâ€¢ Migrations written idempotently; rollbacks provided.\nâ€¢ Update ORM models and repository interfaces.",
            "status": "pending",
            "testStrategy": "Run migration tests in a fresh DB; ensure indices exist; verify unique/partial index behavior for dedup and isolation. Re-run TC003-ISOLATION integration tests to ensure DB errors do not occur."
          },
          {
            "id": 3,
            "title": "Implement PromptTemplateRenderer and StyleProfile normalization + hashing",
            "description": "Create renderer for prompt templates and canonicalization for style profiles; implement stable request hash that powers caching and dedup behavior.",
            "dependencies": [
              "8.1",
              "8.2"
            ],
            "details": "â€¢ PromptTemplateRenderer: supports variables {scene, character, item, extras}; strict mode requiring all variables present; escape rules; deterministic whitespace normalization.\nâ€¢ StyleProfile: schema {seed:number, artists: string[], tags: string[], aspect: string | {w,h}}; normalization steps: sort artists/tags, lowercase trimmed tokens, normalize aspect to {w,h} canonical form (e.g., 16:9-> {w:16,h:9}).\nâ€¢ RequestHash: H = SHA256(canonical_json({prompt: rendered, style: normalized, type, model_version?, guidance?, steps?, seed, allow_cross_campaign_dedup, campaign_scope: allow_cross_campaign_dedup? 'global':'campaign:'+campaign_id}))\nâ€¢ Ensure stable JSON stringify: sorted keys; numeric normalization; remove non-deterministic fields.\nâ€¢ Expose: renderAndHash(input, style, type, campaign_id, flags) -> {renderedPrompt, hash}.\nâ€¢ Add unit tests from 8.1 to verify correctness and stability.",
            "status": "pending",
            "testStrategy": "Run unit tests for rendering, normalization, and hashing from 8.1. Add fuzz tests for key order variations leading to same hash."
          },
          {
            "id": 4,
            "title": "Define ImageGenAdapter interface and provider error contracts",
            "description": "Specify adapter interface and common error model to abstract providers; include retry and fallback semantics compatible with future hardening.",
            "dependencies": [
              "8.1"
            ],
            "details": "â€¢ Interface generateImage(request): input includes renderedPrompt, styleProfile, type, seed, aspect, size; returns {provider_job_id, eta_ms?, placeholder_url?} and a poll(job_id) -> {status: processing|final|error, final_url?, error_code?, error_message?}.\nâ€¢ Standardize error codes: TIMEOUT, RATE_LIMIT, PROVIDER_DOWN, INVALID_PROMPT, CONTENT_BLOCKED.\nâ€¢ Include ability to stream partial updates in future; for now polling.\nâ€¢ Provide a mock adapter for tests; wire fault injection hooks.\nâ€¢ Document retry hints but leave implementation for Task 23.",
            "status": "pending",
            "testStrategy": "Adapter unit tests with mocks; simulate errors and verify mapping to unified error codes used by API and lifecycle tests (TC003-ERROR)."
          },
          {
            "id": 5,
            "title": "Implement /images POST API: create placeholder and enqueue generation job",
            "description": "Build API to accept image generation requests, render prompt, compute hash, check cache, and return placeholder resource with polling link.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.4"
            ],
            "details": "â€¢ Request body: {campaign_id, type, template_id or inline_template, variables, style_profile, allow_cross_campaign_dedup?:bool}.\nâ€¢ Steps:\n  - Validate campaign context and isolation (default isolate per campaign; only allow dedup if flag true).\n  - Render prompt and compute request_hash via 8.3.\n  - Cache lookup: if existing final image for scope found, return existing image resource (status final) and mark as cached in metrics.\n  - If miss: create images row with status=placeholder, placeholder_url (local placeholder asset by type), return 202 + {id, status: placeholder} and enqueue async worker job with request_hash.\nâ€¢ Response includes poll URL GET /images/{id} and optional SSE endpoint for future streaming.\nâ€¢ Store initial latency start time for metrics.",
            "status": "pending",
            "testStrategy": "Integration tests: POST returns placeholder when cache miss; returns final when cache hit; respects allow_cross_campaign_dedup; records metrics. Run TC003-LIFECYCLE and TC003-CACHE partials."
          },
          {
            "id": 6,
            "title": "Background worker: generation lifecycle and persistence",
            "description": "Implement worker that consumes generation jobs, invokes ImageGenAdapter, handles polling to final, updates DB, stores assets locally, and records metrics.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.4",
              "8.5"
            ],
            "details": "â€¢ Worker flow:\n  - Idempotency: lock by request_hash to prevent duplicate provider calls; coalesce concurrent requests.\n  - On start, update images row to processing.\n  - Call adapter.generateImage(); poll until final or error; configurable max timeouts.\n  - On success: download/store final asset to local storage (per-campaign subdir), write final_url, status=final, provider metadata.\n  - On error: status=error; keep placeholder_url; error codes/messages saved.\n  - Metrics: record elapsed duration; mark is_cached=false for first final; subsequent cache hits bypass worker.\nâ€¢ Local storage layout: /assets/{campaign_id}/images/{yyyy}/{mm}/{dd}/{image_id}.png; ensure atomic writes.",
            "status": "pending",
            "testStrategy": "Integration tests simulate provider success and failure; verify DB state transitions and asset files exist; TC003-ERROR passes."
          },
          {
            "id": 7,
            "title": "GET /images/{id} API and optional polling stream",
            "description": "Expose retrieval endpoint to poll image status and metadata; include cache headers and minimal payload for UI updates.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.5",
              "8.6"
            ],
            "details": "â€¢ GET returns: {id, status, placeholder_url, final_url, type, campaign_id, created_at, updated_at, error?} with 200; 404 if not in campaign scope.\nâ€¢ Add ETag/Last-Modified for client caching.\nâ€¢ Optionally provide SSE at /images/{id}/events for status updates (queued, processing, final, error).",
            "status": "pending",
            "testStrategy": "Integration tests: poll transitions to final; 404 on cross-campaign access; UI tests use this endpoint for swap."
          },
          {
            "id": 8,
            "title": "UI component: ImagePlaceholderSwap with local asset storage",
            "description": "Implement front-end component that shows placeholder immediately and swaps to final when available; ensure smooth UX and correct local asset usage.",
            "dependencies": [
              "8.1",
              "8.7"
            ],
            "details": "â€¢ Props: imageId. On mount, fetch GET /images/{id}; display placeholder_url; start polling every 1s or use SSE; when status=final, swap img src to final_url.\nâ€¢ Avoid layout shift: reserve aspect ratio box from style_profile.aspect or metadata.\nâ€¢ Handle error state by keeping placeholder and showing tooltip.\nâ€¢ Ensure URLs point to local asset server paths.\nâ€¢ Accessibility: alt text from prompt summary.",
            "status": "pending",
            "testStrategy": "UI test: renders placeholder then swaps to final; verifies no layout shift and correct src changes; covers TC003-UI."
          },
          {
            "id": 9,
            "title": "Cache reuse logic with SLA measurement and optimization",
            "description": "Finalize cache hit path to meet <6s median for cached results; ensure fast DB and file access and precomputed metadata.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.5",
              "8.6",
              "8.7",
              "8.8"
            ],
            "details": "â€¢ On cache hit in POST /images: immediately return existing final image without spawning worker; mark metric is_cached=true and capture end-to-end latency.\nâ€¢ Optimize indices for request_hash lookup; add read-through in-memory cache (LRU) keyed by request_hash -> {image_id, final_url} with TTL.\nâ€¢ Warm-path benchmarks and micro-optimizations (avoid JSON parsing in hot path; select only needed columns).\nâ€¢ Store pre-generated thumbnails if needed to speed UI.\nâ€¢ Add API fast path testing hooks.",
            "status": "pending",
            "testStrategy": "Run performance test harness from 8.1 with warmed cache; verify median latency <6s (target much lower). Capture flamegraphs if regressions."
          },
          {
            "id": 10,
            "title": "Cross-campaign dedup controls and isolation enforcement",
            "description": "Implement strict default isolation with optional explicit dedup across campaigns, including cache key scoping and access controls.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.5",
              "8.7"
            ],
            "details": "â€¢ Enforce campaign scoping on all queries via middleware; GET /images/{id} must verify campaign_id.\nâ€¢ In POST, if allow_cross_campaign_dedup=true, use global cache index for request_hash; otherwise use campaign-scoped index.\nâ€¢ Ensure returned assets always reference correct campaign directories even if dedup is global (store final once, reference many via soft links or metadata pointers).\nâ€¢ Add audit logs when cross-campaign dedup is used.",
            "status": "pending",
            "testStrategy": "Integration tests: two campaigns issuing same request; verify no reuse by default; with flag true, reuse occurs; GET access blocked across campaigns."
          },
          {
            "id": 11,
            "title": "Failure handling and fallback placeholder policy",
            "description": "Define and implement robust error mapping, retry hints (without retries), and consistent fallback behavior on provider errors.",
            "dependencies": [
              "8.1",
              "8.4",
              "8.6",
              "8.7"
            ],
            "details": "â€¢ Map provider errors to standardized codes (from 8.4). On error, keep status=error, placeholder visible, and include user-safe message.\nâ€¢ Provide next-step guidance: retry_after_s suggestion or manual retry endpoint.\nâ€¢ Ensure no partial assets leak; clean temp files.\nâ€¢ Log correlation IDs across API and worker for observability.",
            "status": "pending",
            "testStrategy": "Run TC003-ERROR and additional unit tests verifying error payloads; simulate each standardized error and verify consistent responses."
          },
          {
            "id": 12,
            "title": "Security, validation, and content safety gates",
            "description": "Add input validation, rate limits, and content safety checks to prevent invalid prompts and unsafe outputs.",
            "dependencies": [
              "8.1",
              "8.5"
            ],
            "details": "â€¢ Validate template and variables; limit prompt size and tag lists; sanitize strings.\nâ€¢ Rate limiting per campaign and per IP.\nâ€¢ Optional content policy check prior to generation; map violations to CONTENT_BLOCKED.\nâ€¢ Sign asset URLs if needed; ensure local path traversal protections.",
            "status": "pending",
            "testStrategy": "Unit/integration tests for validation failures; ensure CONTENT_BLOCKED surfaces as error and placeholder remains."
          }
        ]
      },
      {
        "id": 9,
        "title": "Alliances/Teams and Leaderboards",
        "description": "Implement alliances/teams data model, membership flows, shared mechanics hooks, and basic leaderboards for competitive modes.",
        "details": "- Tables: alliances (id, campaign_id, name), alliance_members, scores (campaign_id, team_id, metric, value)\n- API: create/delete alliance, invite/join/leave, assign team/line\n- Leaderboard: compute on event updates or periodic job\n- Hooks into mission/rules to award points\n- UI: manage team membership and view leaderboard",
        "testStrategy": "- TC004: team/alliance setup flows verified via API/UI tests\n- TC005: leaderboard updates on scoring events; fairness invariants\n- Isolation: ensure per-campaign separation",
        "priority": "medium",
        "dependencies": [
          4,
          2,
          3
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for alliances, membership, scoring, and leaderboards (TC004, TC005, Isolation)",
            "description": "Author unit and integration/UI tests that encode core acceptance criteria before implementation: alliance CRUD and membership flows (invite/join/leave/assign team-line), scoring hooks and leaderboard updates on events/cron, and per-campaign isolation. Include negative cases and fairness invariants. No production code changes here.",
            "dependencies": [],
            "details": "â€¢ Create test plans and fixtures:\n  - Campaign fixtures: campaignA, campaignB\n  - Users: owner, member1, member2, outsider\n  - Missions/rules stubs: emits scoring events\n  - Metrics: kills, objectives, time\nâ€¢ Unit tests (Jest/TS):\n  - alliances model validation and constraints\n  - scoring aggregation functions\n  - leaderboard ranking logic (ties, stable sort, pagination)\n  - permissions matrix for endpoints\nâ€¢ API integration tests (Supertest):\n  - Create/delete alliance; invite -> accept/decline -> join; leave; assign team/line\n  - Membership enforcement and errors (outsider cannot invite; non-owner deletion forbidden)\n  - Per-campaign isolation: alliances and scores do not leak across campaigns (TC004 Isolation)\nâ€¢ Event-driven tests:\n  - Emit scoring events -> verify scores table updated and leaderboard recalculated (TC005)\n  - Periodic job computes leaderboard when no live events\nâ€¢ WebSocket gateway (Task 3) interop stub: team/alliance topic auth enforced (reference only, no dependency)\nâ€¢ UI e2e tests (Playwright):\n  - Manage team membership UI: create alliance, invite, accept, leave (TC004)\n  - View leaderboard: reflects scoring updates in near-real-time and after cron (TC005)\nâ€¢ Fairness invariants:\n  - Scores cannot be negative (unless metric allows); only whitelisted metrics accepted\n  - Idempotent event processing; at-least-once delivery safety with dedupe keys\nâ€¢ Map tests to IDs: TC004 (setup flows via API/UI), TC005 (leaderboard updates and fairness), Isolation checks.\nâ€¢ CI wiring to run tests with seeded DB and mocked mission/rules.",
            "status": "pending",
            "testStrategy": "This subtask is the test definition. Output: failing tests that encode acceptance criteria."
          },
          {
            "id": 2,
            "title": "Design relational schema and migrations for alliances, membership, and scores",
            "description": "Create normalized tables with constraints, indexes, and audit columns for alliances, alliance_members, and scores; add supportive tables for invites and deduplication of scoring events.",
            "dependencies": [
              "9.1"
            ],
            "details": "â€¢ Tables:\n  - alliances(id UUID PK, campaign_id UUID FK campaigns(id) ON DELETE CASCADE, name TEXT NOT NULL, slug TEXT UNIQUE per campaign, created_by, created_at, updated_at, UNIQUE(campaign_id, name))\n  - alliance_members(id UUID PK, alliance_id FK alliances(id) ON DELETE CASCADE, user_id UUID FK users(id), role ENUM('owner','admin','member'), team_line JSONB nullable (or columns team, line), joined_at, UNIQUE(alliance_id, user_id))\n  - alliance_invites(id UUID PK, alliance_id FK, invited_user_email TEXT or user_id, token TEXT UNIQUE, expires_at, invited_by, status ENUM('pending','accepted','declined','expired'), UNIQUE(alliance_id, invited_user_email or user_id, status='pending'))\n  - scores(id UUID PK, campaign_id FK, team_id UUID FK alliances(id), metric TEXT, value BIGINT NOT NULL DEFAULT 0, updated_at, UNIQUE(campaign_id, team_id, metric))\n  - score_events(id UUID PK, campaign_id FK, team_id FK alliances(id), metric TEXT, delta INT, source TEXT, event_idempotency_key TEXT UNIQUE, occurred_at, processed_at, status ENUM('pending','applied','rejected'), metadata JSONB)\n  - leaderboards(id UUID PK, campaign_id FK, metric TEXT, computed_at, entries JSONB, UNIQUE(campaign_id, metric))\nâ€¢ Indexing:\n  - alliances(campaign_id, name), alliance_members(alliance_id, user_id), scores(campaign_id, metric DESC, value DESC), score_events(event_idempotency_key), leaderboards(campaign_id, metric)\nâ€¢ Constraints:\n  - Enforce per-campaign isolation via FKs\n  - Check: value >= 0 for non-negative metrics (use metric policy table later if needed)\nâ€¢ Migrations and rollback scripts.\nâ€¢ Seed data for tests.",
            "status": "pending",
            "testStrategy": "Run unit tests for model validation and isolation from 9.1; ensure schema supports required flows and uniqueness constraints cause expected failures."
          },
          {
            "id": 3,
            "title": "Implement data access layer and domain models with validation",
            "description": "Add repositories/services for alliances, membership, invites, scores, score_events, and leaderboards with input validation and error semantics.",
            "dependencies": [
              "9.1",
              "9.2"
            ],
            "details": "â€¢ Tech: Node/TS, Prisma/Knex/TypeORM per project standard; zod schemas in shared package.\nâ€¢ Implement:\n  - AlliancesService: create(campaignId,name,creator), delete(id, byUser), getById, listByCampaign\n  - MembershipService: invite(allianceId, target), accept(token or inviteId, byUser), decline, join(byUser via open policy), leave, assignTeamLine(memberId, team, line), setRole\n  - ScoresService: applyDelta({campaignId, teamId, metric, delta, idempotencyKey, source, metadata}) with upsert to scores and persistence to score_events\n  - LeaderboardService: compute({campaignId, metric, limit, tieBreakers}) returns ordered list and persists to leaderboards\n  - Policy enforcement: only owners/admins can invite/delete; members can leave; outsiders blocked\nâ€¢ Validation:\n  - zod schemas for names, metrics whitelist, delta range, team/line format\n  - Idempotency: reject or no-op duplicates via score_events unique key\nâ€¢ Transactions for atomic score updates\nâ€¢ Error mapping to HTTP codes later used by API.",
            "status": "pending",
            "testStrategy": "Run unit tests from 9.1 for model/logic; add service-level tests for idempotency, transactions, and permissions."
          },
          {
            "id": 4,
            "title": "Build REST APIs for alliances CRUD and membership flows",
            "description": "Expose endpoints: create/delete alliance; invite/accept/decline; join/leave; assign team/line; list alliances and members. Secure per-campaign and role-based access.",
            "dependencies": [
              "9.1",
              "9.3"
            ],
            "details": "â€¢ Routes (prefix /campaigns/:campaignId):\n  - POST /alliances {name}\n  - DELETE /alliances/:allianceId\n  - GET /alliances\n  - GET /alliances/:allianceId/members\n  - POST /alliances/:allianceId/invites {userId|email}\n  - POST /invites/:inviteId/accept\n  - POST /invites/:inviteId/decline\n  - POST /alliances/:allianceId/join\n  - POST /alliances/:allianceId/leave\n  - PATCH /alliances/:allianceId/members/:memberId {role?, team?, line?}\nâ€¢ Middleware:\n  - Auth session -> user; campaign scope check; role checks (owner/admin)\nâ€¢ Responses follow zod schemas; errors standardized.\nâ€¢ OpenAPI/Swagger annotations for UI integration.",
            "status": "pending",
            "testStrategy": "Run API tests from 9.1 TC004 and isolation cases. Add negative tests for unauthorized access and invalid payloads."
          },
          {
            "id": 5,
            "title": "Implement scoring hooks integration with missions/rules",
            "description": "Create an event handler that listens to mission/rules events and applies scoring deltas per alliance/team according to configured metrics.",
            "dependencies": [
              "9.1",
              "9.3"
            ],
            "details": "â€¢ Event bus: subscribe to mission events (e.g., mission.completed, kill.registered, objective.captured)\nâ€¢ Mapping config: metric map per campaign (e.g., mission.completed -> objectives +10)\nâ€¢ Handler flow:\n  - Resolve player/user -> alliance/team within campaign\n  - Derive metric and delta from event payload\n  - Call ScoresService.applyDelta with idempotency key event.id\n  - Optionally emit leaderboard.updated notification\nâ€¢ Error handling: drop or quarantine events with missing mappings; maintain dead-letter queue for review.\nâ€¢ Ensure at-least-once safety and idempotent updates.",
            "status": "pending",
            "testStrategy": "Extend tests to emit mock events and assert scores and leaderboard recompute (TC005). Include idempotency duplicate event test."
          },
          {
            "id": 6,
            "title": "Create leaderboard computation job and on-event updater",
            "description": "Provide two paths to keep leaderboards fresh: immediate recompute on scoring events (throttled/debounced) and a periodic job (cron/queue) to backfill and correct.",
            "dependencies": [
              "9.1",
              "9.3",
              "9.5"
            ],
            "details": "â€¢ On-event updater:\n  - Debounce per campaign+metric (e.g., 500ms window) to recompute after bursts\n  - Compute top N (configurable), ties handled by stable sort on value desc then earliest achieved or name\n  - Persist to leaderboards table and publish cache invalidation\nâ€¢ Periodic job:\n  - Runs every N minutes; recompute for active campaigns and all metrics\n  - Metrics coverage discovered from scores table\nâ€¢ Performance: aggregate via SQL (SUM value from scores) or read from scores table directly if it stores totals\nâ€¢ Expose admin endpoint to trigger recompute for tests.",
            "status": "pending",
            "testStrategy": "API/integration tests validate leaderboard reflects events and cron; test tie cases, pagination, and stability (TC005)."
          },
          {
            "id": 7,
            "title": "Enforce team/alliance topic permissions in WebSocket gateway",
            "description": "Integrate with Task 3 gateway to ensure server-side enforcement for team/line and alliance topics based on membership.",
            "dependencies": [
              "9.1",
              "9.3"
            ],
            "details": "â€¢ Provide membership lookup module usable by gateway\nâ€¢ On join(topic): verify user belongs to alliance/team in campaign; reject otherwise\nâ€¢ On membership change: push subscription updates (kick or grant)\nâ€¢ Rate limiting and schema validation reuse from gateway\nâ€¢ Emit ticker-update for leaderboard changes if subscribed.",
            "status": "pending",
            "testStrategy": "Gateway integration tests (superwstest) verifying channel authorization (maps to TC002 in Task 3) and alliance membership updates eject unauthorized clients."
          },
          {
            "id": 8,
            "title": "Build UI: Team/Alliance management screens",
            "description": "Implement React views to manage alliances and membership within campaign context: list, create, invite, accept, leave, assign team/line; respect roles and accessibility.",
            "dependencies": [
              "9.1",
              "9.4"
            ],
            "details": "â€¢ Pages/Components:\n  - AlliancesList: fetch and display alliances; create form modal\n  - AllianceDetail: members table; invite by email/user; role dropdown; team/line editor\n  - InviteAcceptFlow: handle token link and success/failure\nâ€¢ State: use existing store; optimistic updates with rollback on error\nâ€¢ Accessibility: keyboard, focus management, proper labels; i18n strings\nâ€¢ Error toasts and empty states.",
            "status": "pending",
            "testStrategy": "Playwright UI tests for TC004: create alliance, invite member, accept, leave; snapshot tests for components; axe-core scan passes."
          },
          {
            "id": 9,
            "title": "Build UI: Leaderboard views with live updates",
            "description": "Create leaderboard UI for competitive modes: per metric tabs, sorting, pagination, and live updates via WebSocket and periodic polling fallback.",
            "dependencies": [
              "9.1",
              "9.6",
              "9.7"
            ],
            "details": "â€¢ Components:\n  - LeaderboardWidget: shows top N with rank, alliance name, score, delta indicators\n  - MetricTabs: switch metrics\nâ€¢ Data:\n  - REST fetch current leaderboard; subscribe to ticker-update for changes\n  - Debounced re-render; handle tie display\nâ€¢ UX: loading/skeletons; empty states; accessible table semantics.",
            "status": "pending",
            "testStrategy": "Playwright test for TC005: on scoring event simulation, UI reflects updated leaderboard; verify tie rendering and pagination."
          },
          {
            "id": 10,
            "title": "Security, isolation, and permissions hardening",
            "description": "Add comprehensive checks to ensure per-campaign isolation, least-privilege access, and safe inputs across API, services, and UI.",
            "dependencies": [
              "9.4",
              "9.5",
              "9.6",
              "9.8",
              "9.9"
            ],
            "details": "â€¢ Server:\n  - Verify campaign_id scoping on all queries\n  - Ensure delete alliance requires owner; admin limits\n  - Input sanitization; rate limit sensitive endpoints\nâ€¢ DB:\n  - Row-level policies if using Postgres RLS\n  - Additional indexes for isolation queries\nâ€¢ UI:\n  - Hide actions the user lacks permissions for\nâ€¢ Logging and audit trails for membership and score changes.",
            "status": "pending",
            "testStrategy": "Negative tests: cross-campaign access attempts; privilege escalation attempts; fuzz invalid inputs. Validate isolation checks from TC004/TC005."
          },
          {
            "id": 11,
            "title": "Observability and admin tooling for scoring and leaderboards",
            "description": "Add metrics, logs, and minimal admin endpoints to inspect score events, recompute leaderboards, and quarantine bad events.",
            "dependencies": [
              "9.5",
              "9.6"
            ],
            "details": "â€¢ Metrics: counters for events processed, dedup hits, recompute latency\nâ€¢ Logs: structured logs with event ids and outcomes\nâ€¢ Admin endpoints:\n  - GET /admin/campaigns/:id/score-events?status=...\n  - POST /admin/campaigns/:id/leaderboards/:metric/recompute\n  - POST /admin/score-events/:id/quarantine\nâ€¢ Protect admin routes via role/feature flag.",
            "status": "pending",
            "testStrategy": "Integration tests for admin endpoints; ensure no exposure to non-admins; verify recompute path correctness."
          },
          {
            "id": 12,
            "title": "Finalize documentation and OpenAPI contracts",
            "description": "Deliver developer docs, API reference (OpenAPI), event mappings, and UI usage guides for alliances and leaderboards.",
            "dependencies": [
              "9.4",
              "9.5",
              "9.6",
              "9.8",
              "9.9",
              "9.10",
              "9.11"
            ],
            "details": "â€¢ OpenAPI specs for all endpoints; schemas for requests/responses\nâ€¢ Event mapping docs for missions -> metrics\nâ€¢ Usage examples and error codes\nâ€¢ UI handbook: flows for admins and members\nâ€¢ Add ADR for schema and idempotency decisions.",
            "status": "pending",
            "testStrategy": "Lint OpenAPI; link checks; run example requests in CI against mock server."
          }
        ]
      },
      {
        "id": 10,
        "title": "Mission Template DSL and Executor",
        "description": "Create objective-graph DSL with twists and soft-fail states; executor to advance graph based on events and player actions.",
        "details": "- DSL: JSON schema in shared; nodes (objective, twist, soft_fail), edges with conditions; validators with zod/ajv\n- Executor: deterministic state machine; inputs: events stream; outputs: mission_progress updates and prompts for GM LLM\n- API: load mission from content packs; start/advance/end\n- Soft-fail handling transitions without ending mission; twist activation by predicates",
        "testStrategy": "- TC006: graph advancement correctness; activation of twists; soft-fail behavior under unit tests with seeded events\n- Property tests: no dead nodes; reachability\n- Snapshot tests for executor determinism",
        "priority": "high",
        "dependencies": [
          2,
          3,
          4,
          5
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for Mission DSL and Executor (TC006 + determinism)",
            "description": "Create a comprehensive test suite that encodes the core acceptance criteria before implementation. Cover graph advancement correctness, twist activation via predicates, soft-fail transitions that do not end the mission, and deterministic executor behavior with snapshot testing. Include property tests for reachability (no dead-end from start to at least one terminal state) and seed-based determinism tests.",
            "dependencies": [],
            "details": "Set up a tests package in the monorepo (e.g., packages/mission/__tests__) using Jest + ts-jest or Vitest. Define fixtures for minimal mission graphs in JSON with nodes: objective, twist, soft_fail; edges with conditions; and seeded event streams. Write tests:\n- TC006-Unit: Given events, executor advances objective nodes in order; twist nodes activate when their predicate becomes true; soft_fail transitions occur without ending the mission.\n- TC006-Integration: Load a mission from a mock content pack and drive executor with a sequence of events, assert mission_progress updates and prompts queued for GM LLM.\n- Determinism Snapshot: For a seeded event stream, executor produces identical state snapshots across runs.\n- Property: For each mission fixture, verify start node has a path to at least one terminal objective (goal) and that no edge references missing nodes.\n- Error handling: Invalid schema missions fail validation with readable errors.\nTag tests with IDs: TC006-U1/U2, TC006-I1, TC006-P1, TC006-D1.",
            "status": "pending",
            "testStrategy": "Execute tests locally and in CI across Node LTS. Use fixed seeds for random behavior. Include golden JSON snapshots for executor state after each step."
          },
          {
            "id": 2,
            "title": "Design Mission Graph JSON Schema (nodes, edges, metadata)",
            "description": "Specify the DSL as a JSON Schema defining mission graphs with node types (objective, twist, soft_fail), edges with conditions/predicates, metadata, and terminal states. Include versioning and compatibility fields.",
            "dependencies": [
              "10.1"
            ],
            "details": "In shared package, add schema v1: mission.schema.json with types: Mission, Node, Edge, Condition. Fields:\n- Mission: id, version, title, description, start_node_id, nodes[], edges[], variables (initial), metadata.\n- Node: id, type ('objective' | 'twist' | 'soft_fail'), title, description, payload (objective-specific fields like success_predicate, failure_predicate, completion_mode), prompts (for GM LLM), on_enter/on_exit actions, soft_fail_recovery (for soft_fail nodes), tags.\n- Edge: id, from, to, guard (predicate expression or predicate config), priority, kind ('normal' | 'soft_fail' | 'twist'), side_effects (declarative action ids), reentrant (bool).\n- Condition/Predicate: allow two forms: (a) declarative operator tree (left/op/right) referencing events and variables, (b) named predicate id with parameters.\n- Terminal designation: objective nodes may have terminal=true.\nInclude $defs for predicates, actions, and expressions. Provide examples section and $schema, $id. Add semver in mission.version.",
            "status": "pending",
            "testStrategy": "Run schema validation tests from TC006-U1 against fixtures; ensure invalid graphs (missing nodes, cycles without exit, invalid edge references) fail with descriptive errors."
          },
          {
            "id": 3,
            "title": "Implement Zod types and AJV validators for Mission DSL",
            "description": "Create Zod type definitions mirroring the JSON Schema and compile an AJV validator for runtime validation. Provide a unified validateMissionGraph API returning typed results and rich errors.",
            "dependencies": [
              "10.2",
              "10.1"
            ],
            "details": "In shared/mission-dsl: \n- Define zod types: ZMission, ZNode, ZObjectiveNode, ZTwistNode, ZSoftFailNode, ZEdge, ZPredicate, ZExpression.\n- Generate TypeScript types from Zod. Configure AJV with allErrors, strict, formats. Add ajv instance and precompiled validate function from mission.schema.json.\n- Export: parseMission(zod), validateMissionAjv(json): { ok, errors }, and assertMission(json): Mission.\n- Add custom validators: ensure start_node_id exists; all edges from/to exist; no duplicate ids; edge kind matches node types (e.g., soft_fail edges allowed from objectives); terminal reachability check optional at load time.",
            "status": "pending",
            "testStrategy": "Wire TC006-U1 invalid schema tests to ensure both Zod parsing and AJV validation produce consistent failures. Add unit tests for custom validations."
          },
          {
            "id": 4,
            "title": "Define predicate and condition evaluation engine",
            "description": "Implement a pure, deterministic evaluator for declarative predicates over events and variables to drive edge guards and node success/failure conditions.",
            "dependencies": [
              "10.3",
              "10.1"
            ],
            "details": "Create a module evaluator.ts with:\n- Expression AST: literals, variable refs (vars.morale, event.type), comparison ops, logical ops, temporal operators (within_ms, count_of, since), and event pattern matching (match {type, actor, target}).\n- Context: { variables, recentEvents (deque with timestamps), now, seed }.\n- Evaluate functions: evalPredicate(predicate, context), evalExpression(expr, context) with no dynamic code eval. Support named predicate registry with pluggable functions (e.g., 'player_action_equals', 'inventory_contains', 'roll_ge').\n- Determinism: ensure stable ordering, no Date.now direct callsâ€”use provided now.\n- Performance: pre-compile predicates to executable closures when loading the mission.",
            "status": "pending",
            "testStrategy": "Unit tests: truth tables for logical ops; temporal windows with seeded event streams; named predicate registry resolution; snapshot of compiled predicates for equality; TC006-U2 twist activation using predicate evaluation."
          },
          {
            "id": 5,
            "title": "Executor state machine core (advance loop and transitions)",
            "description": "Build a deterministic executor that maintains mission state, ingests events, evaluates node conditions, and advances along edges with priorities while handling twists and soft-fail states.",
            "dependencies": [
              "10.4",
              "10.3",
              "10.1"
            ],
            "details": "Create executor.ts with:\n- Types: ExecutorState { currentNodeIds[], variables, history, activeTwists[], softFailActive?, rngSeed, now }, Event, Output { mission_progress, prompts }.\n- APIs: start(mission, seed, now) -> ExecutorState; step(state, events[]) -> { state, outputs }; end(state) -> summary.\n- Logic: For each step, update context with events, evaluate node-level success/failure predicates, choose edges whose guards are true, select by highest priority and deterministic tie-break (edge id sort). Allow parallel objectives if mission allows (flag). Twists: if guard true and not active, activate and push to activeTwists; may modify variables or inject prompts. Soft-fail: if triggered (node failure or soft_fail edge), transition to soft_fail node while mission remains ongoing; support recovery via soft_fail_recovery and edges back to objectives.\n- Determinism: order evaluations by stable id sort; avoid non-deterministic iteration; RNG via seeded PRNG injected.\n- Snapshotting: produce a compact state snapshot after each step for tests.",
            "status": "pending",
            "testStrategy": "Use TC006-D1 determinism snapshot with fixed seed and event sequence; TC006-U1 advancement cases; add edge-priority tie tests; soft-fail entry and recovery tests."
          },
          {
            "id": 6,
            "title": "Mission progress and GM LLM prompt generation",
            "description": "Define mission_progress structure and generate GM-facing prompts based on node transitions, twist activations, and soft-fail events.",
            "dependencies": [
              "10.5",
              "10.3"
            ],
            "details": "Design mission_progress: { missionId, timestamp, activeObjectives[], completedObjectives[], failedObjectives[], activeTwists[], softFail?: { nodeId, since }, variablesDelta, log[] }. Implement promptBuilder that consumes transition events to produce concise prompts: on_enter objective, on_complete, on_twist_activate, on_soft_fail_enter/exit. Allow templates in node.payload.prompts with variable interpolation. Ensure outputs are deterministic and idempotent.",
            "status": "pending",
            "testStrategy": "Integration test TC006-I1: run executor over a mission with twists and soft-fail; assert mission_progress updates and that generated prompts match expected snapshots."
          },
          {
            "id": 7,
            "title": "Content pack loader and repository API",
            "description": "Implement APIs to load mission graphs from content packs, list missions, and fetch by id with validation and pre-compilation.",
            "dependencies": [
              "10.3",
              "10.2"
            ],
            "details": "Create module contentRepo.ts: loadContentPack(dirOrZip), index missions by id, run validation and precompile predicates/guards, cache compiled missions. Export getMission(id), listMissions(), and unload/reload. Support version gating and schema migration hooks.",
            "status": "pending",
            "testStrategy": "Integration test: load a mock content pack with two missions, ensure invalid mission is rejected; verify compiled predicate cache is used and consistent across loads."
          },
          {
            "id": 8,
            "title": "Public Mission API: start/advance/end with event stream input",
            "description": "Expose a stable API surface for external systems to manage mission lifecycles and feed events.",
            "dependencies": [
              "10.5",
              "10.7",
              "10.6"
            ],
            "details": "In a missions module, export:\n- startMission(missionId, seed, now): loads compiled mission, initializes ExecutorState, persists initial mission_progress.\n- advanceMission(stateOrId, events[], now): applies step, persists updated mission_progress and returns outputs.\n- endMission(stateOrId, reason): finalizes and returns summary.\nIntegrate with persistence interfaces (from Task 2) behind an adapter so this task compiles without DB if Task 2 not yet ready. Provide in-memory repository fallback. Ensure all calls run validation and respect determinism.",
            "status": "pending",
            "testStrategy": "Integration test: simulate a mission lifecycle with in-memory repo, asserting stored mission_progress history and idempotent advance on empty events."
          },
          {
            "id": 9,
            "title": "Soft-fail mechanics and recovery policies",
            "description": "Finalize semantics for soft-fail handling: entry triggers, variable penalties, cooldowns, and recovery transitions without mission termination.",
            "dependencies": [
              "10.5",
              "10.4"
            ],
            "details": "Extend executor to support:\n- soft_fail node entry via edge or objective failure; set state.softFailActive with nodeId and since timestamp; apply penalties from node.payload (e.g., reduce morale var, add complication tags) and cooldown until recovery condition met.\n- Recovery: evaluate recovery predicates/edges to return to previous or specified objective(s). Ensure multiple soft-fail cycles do not cause infinite loops using visit counters or cooldown tokens.\n- Logging: append log entries for entry/exit.",
            "status": "pending",
            "testStrategy": "Unit tests: repeated soft-fail entries respect cooldown; recovery edges activate only when predicates satisfied; ensure mission not ended accidentally. Extend TC006-U1 with soft-fail loop prevention assertions."
          },
          {
            "id": 10,
            "title": "Property-based tests for graph invariants and executor safety",
            "description": "Add fast-check property tests to ensure invariants: no dead nodes reachable from start without exit, all transitions preserve determinism, and executor never throws on unknown events.",
            "dependencies": [
              "10.5",
              "10.4",
              "10.1"
            ],
            "details": "Use fast-check to generate small mission graphs within schema constraints and random event streams. Properties:\n- Reachability: every active node has at least one possible outgoing edge or is terminal.\n- Determinism: same seed+events => same state snapshots.\n- Safety: executor handles unknown event types by ignoring or routing to default predicates.\n- No edge to non-existent node.\nLimit generation to avoid exponential explosions; cap sizes and depth.",
            "status": "pending",
            "testStrategy": "Add TC006-P1 property test suite. Run multiple seeds in CI with a time budget. Persist failing counterexamples as fixtures."
          },
          {
            "id": 11,
            "title": "Persistence integration for mission and progress (adapter for Task 2)",
            "description": "Integrate with the local SQLite access layer when available, with a clean adapter that can be swapped for in-memory during tests.",
            "dependencies": [
              "10.8"
            ],
            "details": "Define IMissionStore interface: getMissionState(id), saveMissionState(state, progress), appendLog(entry), listMissionProgress(missionId). Provide two implementations: InMemoryMissionStore (default) and SqliteMissionStore (thin wrapper expecting Task 2 tables missions, mission_progress). Use dependency injection in Public Mission API.",
            "status": "pending",
            "testStrategy": "Integration tests: run lifecycle tests with both InMemory and a mocked Sqlite implementation (using sqlite in tmp). Verify idempotent saves and transactional updates."
          },
          {
            "id": 12,
            "title": "Executor performance and backpressure handling",
            "description": "Optimize executor step throughput and add safeguards for large event batches.",
            "dependencies": [
              "10.5",
              "10.8"
            ],
            "details": "Batch events by time windows; short-circuit evaluation when terminal reached; pre-index edges by from node. Add maxStepsPerAdvance and maxEventsPerStep configs; if exceeded, return a backpressure signal in outputs. Include metrics counters (steps, evals) for diagnostics. Ensure performance optimizations keep determinism intact.",
            "status": "pending",
            "testStrategy": "Benchmark test: synthetic mission with 1k edges, event batches of 1k; assert step time under threshold locally. Unit tests: backpressure triggers and preserves correctness."
          },
          {
            "id": 13,
            "title": "API error handling, diagnostics, and logging",
            "description": "Provide structured errors and diagnostic logs for validation failures, illegal transitions, and predicate errors with redaction-friendly fields.",
            "dependencies": [
              "10.8",
              "10.6",
              "10.3"
            ],
            "details": "Create Error types: ValidationError, TransitionError, PredicateError with codes and details (nodeId, edgeId). Diagnostics: debug traces of evaluation decisions (edge considered -> accepted/rejected) gated by a flag. Logs structured as objects with no PII; integrate with project logging interfaces. Ensure error messages are stable for tests.",
            "status": "pending",
            "testStrategy": "Unit tests: simulate predicate exceptions and ensure they are caught and wrapped. Integration tests: invalid mission load produces ValidationError with path hints. Snapshot logs for a step under diagnostics mode."
          },
          {
            "id": 14,
            "title": "GM LLM prompt channel integration points",
            "description": "Define extensible hook points for emitting prompts to the GM LLM pipeline without taking a hard dependency.",
            "dependencies": [
              "10.6",
              "10.8"
            ],
            "details": "Define IPromptSink interface with method emit(prompt: Prompt). In executor outputs, include prompts[]. Provide default NoopPromptSink and a test sink collecting prompts. Allow prompt templates to include structured context (current objectives, twists, variables).",
            "status": "pending",
            "testStrategy": "Integration test: provide a test sink and assert received prompts correspond to transitions in TC006-I1."
          },
          {
            "id": 15,
            "title": "Versioning and migration strategy for DSL",
            "description": "Establish semver policy and migration utilities for mission schema changes.",
            "dependencies": [
              "10.2",
              "10.7"
            ],
            "details": "Add version field and $id to schema. Create migrateMission(missionJson, fromVersion, toVersion) with a registry of transforms. Provide a linter command to report deprecated fields and auto-fix where safe. Document backward-compat flags in validator.",
            "status": "pending",
            "testStrategy": "Unit tests: migrate from v1 to v1.x with added fields; ensure strict mode rejects incompatible versions; integration test: content pack loader auto-migrates minor versions."
          },
          {
            "id": 16,
            "title": "CLI tooling for validate, simulate, and visualize",
            "description": "Provide a developer CLI to validate missions, run simulations over event traces, and output a DOT/JSON suitable for visualization.",
            "dependencies": [
              "10.8",
              "10.7",
              "10.5"
            ],
            "details": "Create bin/mission-cli.ts with commands:\n- validate <file>\n- simulate <file> --events <trace.json> --seed <n>\n- visualize <file> -> outputs DOT and JSON including reachable subgraph and edge labels with guard summaries.\nUse shared validator and executor. Ensure deterministic outputs for CI.",
            "status": "pending",
            "testStrategy": "Integration tests: run CLI against fixtures in a temp workspace and compare outputs with snapshots."
          },
          {
            "id": 17,
            "title": "Cross-package integration test with WebSocket Gateway (Task 3)",
            "description": "Add an integration proving that mission executor outputs (ticker-update/action prompts) can be sent via the realtime gateway topics without tight coupling.",
            "dependencies": [
              "10.8",
              "10.6"
            ],
            "details": "Spin up a mocked WebSocket server or reuse Task 3 test harness. Wire a thin bridge that listens to executor outputs and publishes ticker-update and action messages on a session channel. Verify channel membership and payload schemas from shared package.",
            "status": "pending",
            "testStrategy": "Integration test mapping to TC002: multiple clients subscribe, advance mission, and receive expected updates. Ensure reconnect preserves subscriptions and resumes updates."
          },
          {
            "id": 18,
            "title": "Security and redaction hooks alignment (Task 15)",
            "description": "Ensure logs, prompts, and mission content pass through redaction middleware and no secrets or PII are persisted.",
            "dependencies": [
              "10.13"
            ],
            "details": "Introduce IRedactor interface and optional middleware in Mission API. Apply redaction to mission_progress.log entries and prompts before persistence or emission. Audit for outbound network calls (none).",
            "status": "pending",
            "testStrategy": "Integration tests aligned with TC014: scan persisted mission_progress for unredacted PII tokens from a test corpus; verify redaction happens deterministically."
          },
          {
            "id": 19,
            "title": "Finalize documentation and developer examples",
            "description": "Write reference docs and example missions demonstrating twists and soft-fails with event-driven progression.",
            "dependencies": [
              "10.16",
              "10.8",
              "10.6"
            ],
            "details": "Add README with schema overview, executor lifecycle, and sample missions. Provide example content pack and simulation traces. Include troubleshooting for validation errors and determinism pitfalls.",
            "status": "pending",
            "testStrategy": "Docs lint and build. Run examples through CLI simulate in CI to ensure they remain valid."
          }
        ]
      },
      {
        "id": 11,
        "title": "Rules Engine for d20 and Progression",
        "description": "Implement rules for d20 checks, DCs, advantage/disadvantage, conditions, XP/levels, and loot distribution.",
        "details": "- Pure TS module in shared; deterministic, side-effect free\n- Dice roller with seed; advantage/disadvantage; DC compare\n- Conditions state and effects; XP curves; loot tables\n- Hooks for alliances/team modifiers",
        "testStrategy": "- Unit tests for dice distributions and edge cases\n- Golden tests for progression and loot outcomes\n- Fuzz tests to ensure invariants (no negative XP, etc.)",
        "priority": "medium",
        "dependencies": [
          10
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write acceptance tests for d20 rules, progression, and loot (TC006â€“TC010)",
            "description": "Before implementation, author unit and integration tests that codify the core acceptance criteria for the d20 rules engine, including seeded dice behavior and advantage/disadvantage, DC comparisons, conditions effects, XP and level progression curves, loot distribution with deterministic seeding, and alliance/team modifier hooks. Include golden tests for XP curves and loot tables, fuzz tests for invariants (no negative XP, bounded probabilities), and at least one integration test simulating a full check-to-reward flow.",
            "dependencies": [],
            "details": "Create a new test suite in shared module (pure TS, deterministic). Use Jest/Vitest with seedable RNG stub. Tests:\n- TC006: Dice roller determinism with seed; uniform distribution sanity; advantage/disadvantage selects max/min correctly; tie handling defined.\n- TC007: DC compare: success/critical success/critical failure rules; modifiers stacking order; bounded final results.\n- TC008: Conditions: apply/remove; stacking policy; turn-based tick; effects on checks (e.g., disadvantage from Blinded), immunity handling; serialization round-trip.\n- TC009: XP/Levels: define XP curve; level-up thresholds; gained XP cannot be negative; level computation pure/idempotent; golden snapshot for levels 1â€“20.\n- TC010: Loot: seeded drop tables; rarity weights; pity/guarantees if applicable; quantity ranges; team/alliance modifiers hook applied; golden snapshot for representative seeds.\n- Integration: Given character with conditions + modifiers, perform check vs DC, award XP and loot deterministically for a given seed; verify outputs stable.\n- Fuzz: Randomized seeds across 10k trials validate invariants (no negative XP, loot weights sum, probabilities within tolerance).\nInclude coverage thresholds >80% lines for this module. Tag tests with TC IDs and map into Task 26 harness.",
            "status": "pending",
            "testStrategy": "Run unit + integration tests locally and in CI. Use golden files for XP/loot outcomes. Statistical assertions use confidence bounds; seed fixed for reproducibility. Ensure at least one integration test exercises full pipeline."
          },
          {
            "id": 2,
            "title": "Implement deterministic seedable RNG and dice roller with advantage/disadvantage",
            "description": "Create a pure, side-effect-free dice module supporting d20 rolls with seedable RNG, advantage/disadvantage, and roll metadata for auditing.",
            "dependencies": [
              "11.1"
            ],
            "details": "Implement RNG: xoshiro128** or Mulberry32 with explicit seed input and next() returning [0,1). Interfaces:\n- RNG { next(): number, fork(label:string): RNG } to derive independent streams deterministically via hash(seed,label).\nDice API:\n- rollD20(rng, options:{adv?:boolean, dis?:boolean}) -> {value:number, detail:{rolls:number[], mode:'normal'|'adv'|'dis', seedTrace:string[]}}\n- roll(n,sides,rng, sum|keepHighest/keepLowest k) for reuse.\nRules: advantage = max of two d20; disadvantage = min of two; if both provided, resolve precedence as config (default: they cancel to normal). Ensure no global state; all functions pure.\nInclude distribution helpers for tests.",
            "status": "pending",
            "testStrategy": "Run TC006. Verify deterministic outputs for fixed seeds; validate advantage/disadvantage semantics and tie handling; basic chi-square sanity within tolerance over many trials."
          },
          {
            "id": 3,
            "title": "Implement DC comparison and result grading",
            "description": "Provide pure functions to compute final check result given a d20 roll, modifiers, and DC, returning success tiers and critical rules.",
            "dependencies": [
              "11.1",
              "11.2"
            ],
            "details": "API:\n- computeCheck({baseRoll:number, modifiers:number[], dc:number, critRange?:{nat1CritFail?:boolean,nat20CritSuccess?:boolean, margin?:number}}, options?:{capTotal?:{min?:number,max?:number}}) -> {total:number, degree:'crit-fail'|'fail'|'success'|'crit-success', breakdown}\nRules: total = baseRoll + sum(modifiers). Degree: compare total vs DC with configurable margin for crit thresholds (e.g., â‰¥DC+10 crit success, â‰¤DC-10 crit fail). Natural 1/20 overrides if enabled. Provide breakdown object listing contributions. No mutation.",
            "status": "pending",
            "testStrategy": "Run TC007. Unit tests cover edges: DC equal, large modifiers, caps, natural 1/20 overrides, conflicting margins."
          },
          {
            "id": 4,
            "title": "Model conditions and effects framework",
            "description": "Define a condition state model and effect application pipeline that can modify dice behavior and modifiers (e.g., impose disadvantage, grant bonuses), with deterministic serialization.",
            "dependencies": [
              "11.1",
              "11.2",
              "11.3"
            ],
            "details": "Data:\n- Condition { id, name, stacks:boolean, maxStacks?:number, duration?:{turns?:number, expiresAt?:number}, tags:string[], effects: Effect[] }\n- Effect types: {type:'modifier', value:number, scope:'check'|'skill'|'attack'|'save'} | {type:'dice-mode', mode:'adv'|'dis'} | {type:'immunity', tag:string} | {type:'restriction', ruleId}\nState:\n- CharacterState { conditions: AppliedCondition[] }\nPure API:\n- applyCondition(state, condition, now)->state; removeCondition(state,id)->state; tick(state)->state; resolveCheckContext(state, checkInput)-> {modifiers:number[], dice:{adv?:boolean, dis?:boolean}, immunities:string[]}\nStacking policy: if stacks=false, refresh duration; if stacks=true, increment up to maxStacks and scale modifier if defined per stack.\nSerialization: toJSON/fromJSON stable and versioned.",
            "status": "pending",
            "testStrategy": "Run TC008. Unit tests for apply/remove, stacking, duration tick, dice-mode effect precedence, immunity preventing effects, and serialization round-trip."
          },
          {
            "id": 5,
            "title": "Implement XP curve and level computation",
            "description": "Provide deterministic, pure functions to compute XP required per level, accumulate XP, and derive level from total XP with golden curve support.",
            "dependencies": [
              "11.1"
            ],
            "details": "API:\n- xpForLevel(level:number, scheme:'linear'|'quadratic'|'custom', custom?:number[]) -> number\n- levelForXp(xp:number, scheme, custom?) -> number\n- grantXp(currentXp:number, gained:number)->number ensuring gained>=0 by clamping and guarding overflow.\nInclude default curve for levels 1â€“20 (configurable). Provide table generation utility for golden snapshot testing.",
            "status": "pending",
            "testStrategy": "Run TC009. Verify monotonic xpForLevel, levelForXp inverses on table points, no negative XP, golden snapshot for default 1â€“20."
          },
          {
            "id": 6,
            "title": "Implement loot tables and deterministic distribution",
            "description": "Create loot table structures with weighted choices, quantity ranges, rarity categories, and seeded deterministic sampling, plus team/alliance modifier hooks.",
            "dependencies": [
              "11.1",
              "11.2",
              "11.4"
            ],
            "details": "Data:\n- LootTable { id, entries: LootEntry[], pity?:{counterKey:string, threshold:number, reward:LootEntry} }\n- LootEntry { id, itemId, weight:number, qty:{min:number,max:number}, tags:string[], modifiers?:{teamBonus?:number, allianceBonus?:number} }\nAPI:\n- rollLoot(table:LootTable, rng, context:{teamId?:string, allianceId?:string, hooks?:HookFns}) -> LootResult\n- weightedPick deterministic via cumulative weights; quantity via RNG; apply hooks from alliances module via provided hook functions (no import dependency): e.g., hooks.getTeamModifier(teamId) returns multiplier.\n- Support multi-drop and pity: maintain counters via caller-provided state object; engine remains pure by returning updated counters as part of result.",
            "status": "pending",
            "testStrategy": "Run TC010. Golden tests for specific seeds; verify weights respected over many trials; verify team/alliance modifiers applied; pity triggers at threshold deterministically."
          },
          {
            "id": 7,
            "title": "Compose check pipeline: state -> roll -> compare -> rewards",
            "description": "Provide a high-level pure function that, given character state, DC, and RNG, produces a full check outcome including applied conditions, d20 roll with (dis)advantage, DC result, and reward hooks (XP and loot) without side effects.",
            "dependencies": [
              "11.2",
              "11.3",
              "11.4",
              "11.5",
              "11.6"
            ],
            "details": "API:\n- performCheck(input:{state:CharacterState, baseModifiers:number[], dc:number, rng:RNG, xpReward:number, lootTable?:LootTable, lootContext?:{}, options?:{critMargin?:number}}) -> {roll:{value, detail}, result:{total, degree}, rewards:{xp:number, loot?:LootResult}, stateUpdates:{conditions?:AppliedCondition[]}, audit:{seedTrace, breakdown}}\nFlow:\n1) resolveCheckContext -> merge base modifiers with condition-derived modifiers; compute dice mode.\n2) rollD20 with mode.\n3) computeCheck to determine degree.\n4) award XP: grantXp(currentXp, xpReward adjusted by degree if rules specify multipliers).\n5) optional rollLoot with provided table and context hooks.\nNo external state written; return all data and any updated counters via result.",
            "status": "pending",
            "testStrategy": "Extend integration test to call performCheck and assert deterministic full pipeline outputs for fixed seeds; verify invariants (no negative XP, loot deterministic)."
          },
          {
            "id": 8,
            "title": "Define alliance/team modifier hook interfaces",
            "description": "Publish minimal hook interfaces in shared module that the alliances/teams feature can implement to adjust modifiers, XP, or loot without creating a hard dependency.",
            "dependencies": [
              "11.1",
              "11.6",
              "11.7"
            ],
            "details": "Define types:\n- HookFns { getTeamModifier?(teamId:string, context:any): number, getAllianceModifier?(allianceId:string, context:any): number, adjustXp?(xp:number, context:any): number }\nAll rule engine public APIs accept an optional hooks:HookFns parameter and must apply these adjustments in a documented, deterministic order (team then alliance then cap). Provide no-op defaults. Ensure that serialization of context excludes functions.",
            "status": "pending",
            "testStrategy": "Unit tests verify that when hooks are provided, outputs are scaled accordingly and order-of-operations is respected. Extend integration test to include mock hooks and validate results."
          },
          {
            "id": 9,
            "title": "Golden data generators and snapshot fixtures",
            "description": "Implement utilities to generate golden fixtures for XP curves and loot outcomes, and wire snapshot testing helpers to prevent regressions.",
            "dependencies": [
              "11.1",
              "11.5",
              "11.6"
            ],
            "details": "Create generator functions:\n- generateXpTable(levels:number, scheme) -> number[]\n- generateLootOutcomes(table, seeds:string[], context) -> LootResult[]\nStore snapshots under tests/__golden__/ with stable JSON serialization (sorted keys). Provide compare helper that pretty-diffs deviations and suggests update via explicit flag.",
            "status": "pending",
            "testStrategy": "Run golden tests in TC009/TC010 to verify snapshots. Manual review required on intended changes."
          },
          {
            "id": 10,
            "title": "Fuzz and property-based tests for invariants",
            "description": "Add property-based tests across dice, DC grading, conditions, XP, and loot to ensure invariants hold and detect edge cases.",
            "dependencies": [
              "11.1",
              "11.2",
              "11.3",
              "11.4",
              "11.5",
              "11.6",
              "11.7"
            ],
            "details": "Use fast-check (or similar) to generate random seeds, modifiers, DCs, and condition sets. Properties:\n- Dice: values in [1,20], advantage >= normal, disadvantage <= normal.\n- DC grading: monotonic w.r.t increasing modifiers; crit-success implies success; crit-fail implies fail.\n- Conditions: serialization round-trip; stacking never exceeds max; dice-mode resolution deterministic.\n- XP: non-negative, non-decreasing with gains; levelForXp(xpForLevel(n)) == n.\n- Loot: weights normalized; probabilities approximate weights over large N; pity triggers within threshold.\nKeep tests deterministic with seeded generators.",
            "status": "pending",
            "testStrategy": "Execute property tests in CI as part of this moduleâ€™s suite with time budget controls. Fail on counterexamples with minimized cases saved."
          },
          {
            "id": 11,
            "title": "Documentation and examples for the rules engine APIs",
            "description": "Provide concise API docs and example usage covering common flows: rolling checks with conditions, computing levels, and generating loot, emphasizing purity and determinism.",
            "dependencies": [
              "11.2",
              "11.3",
              "11.4",
              "11.5",
              "11.6",
              "11.7",
              "11.8",
              "11.9",
              "11.10"
            ],
            "details": "Add TSDoc comments to all public types/functions. Write examples in a docs/examples folder demonstrating: seeded roll with advantage; applying a condition; performing a check with hooks; generating XP table; rolling loot with team modifier. Include guidance on seeding, forking RNGs, and integrating hooks from alliances. Note no side effects and no global state.",
            "status": "pending",
            "testStrategy": "Run examples in a small doc-test harness to ensure they compile and produce expected outputs with fixed seeds."
          }
        ]
      },
      {
        "id": 12,
        "title": "Vector Memory with Per-Player Privacy and Campaign Memory",
        "description": "Provide vector memory supporting episodic/semantic/declarative/procedural types with strict per-player isolation and shared campaign memory.",
        "details": "- Namespaces: campaign:<id>, player:<id>\n- Hybrid retrieval: BM25 (sqlite fts5) + vector; rerank with small local model or LLM if available\n- Summarization pipeline promotes memories to campaign memory per policy\n- Redaction of PII before storage; policies configurable\n- API: write_memory, retrieve(query, scope), promote",
        "testStrategy": "- TC007: enforce per-player isolation in queries\n- TC008: recall relevance tests with seeded corpus and summarization correctness checks\n- Bench: retrieval latency under target",
        "priority": "high",
        "dependencies": [
          2,
          5
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Acceptance Tests for Vector Memory, Privacy, and Promotion (TC007, TC008, Perf)",
            "description": "Write unit and integration tests that capture the core acceptance criteria before implementation. Cover per-player isolation (TC007), hybrid retrieval relevance and summarization/promotion correctness (TC008), namespace scoping, PII redaction policies, and performance benchmarks for retrieval latency. Stub/mock embeddings and reranker to make tests deterministic.",
            "dependencies": [],
            "details": "Implement tests in two layers: (a) unit tests for API surface and policy logic, (b) integration tests over SQLite+FTS5 and a pluggable vector index with in-memory dataset. Seed a small corpus with memories across namespaces campaign:42, player:101, player:202, with types episodic/semantic/declarative/procedural and metadata. Add a seeded query set with expected relevant IDs. Provide a mock EmbeddingsProvider returning fixed vectors; provide a stub Reranker that returns input order unless score margins enforce swaps. Include PII samples (email, phone, address) to verify redaction pre-storage and retrieval. Define tests: - TC007: retrieve(scope=\"player\", playerId=101) never returns data from player:202 or other campaigns; retrieve(scope=\"campaign\", campaignId=42) may return campaign namespace but not any other campaign or players from other campaigns. - TC008a: Hybrid retrieval returns top-k containing at least N of expected relevant items given seeded BM25+vector mix; assert reranker improves MRR@k over unreranked baseline on seeded set. - TC008b: Summarization pipeline produces concise summary and promotion to campaign memory obeys policy (e.g., if item meets threshold and not PII-blocked). - Policy Redaction: verify PII is removed or masked in stored memory content and summaries; raw input never stored. - API contract: write_memory, retrieve(query, scope), promote. - Latency bench: vector+BM25 end-to-end under target (e.g., p50 < 60 ms local, adjustable via env). - Determinism: snapshot tests for summary schema and metadata fields. Provide fixtures and helpers to reset DB between tests.",
            "status": "pending",
            "testStrategy": "Use Jest/Vitest (Node) with sqlite3/better-sqlite3 in temp files. Seed DB in beforeAll, clean in afterEach. For performance, run 100 queries and compute p50/p95; mark as skipped in CI if no perf env. Add property-based tests for namespace isolation. Use data-driven table tests to cover types and scopes."
          },
          {
            "id": 2,
            "title": "Design Memory Schema, Namespaces, and Index Abstractions",
            "description": "Define DB schema for memories and supporting tables, and the abstraction interfaces for vector index and reranking to support campaign:<id> and player:<id> namespaces.",
            "dependencies": [
              "12.1"
            ],
            "details": "Add/extend tables: memories(id PK, namespace TEXT, campaign_id INTEGER, player_id INTEGER NULL, type TEXT CHECK IN('episodic','semantic','declarative','procedural'), content TEXT, content_redacted TEXT, metadata JSON, created_at, updated_at, embedding BLOB/VSS column if using sqlite-vss, bm25_doc TEXT for FTS). memory_summaries(id PK, source_memory_id FK, namespace TEXT, summary TEXT, metadata JSON, created_at). memory_promotions(id PK, source_memory_id, target_namespace TEXT, policy_id TEXT, reason TEXT, created_at). pii_redaction_logs(id, memory_id, fields JSON, policy_version). Create FTS5 virtual table memories_fts(content_redacted, metadata) with content='memories', content_rowid='id'. Define VectorIndex interface: upsert(vector, id, namespace, metadata), query(vector, namespace, k, filter), delete(id, namespace), flush. Provide namespace as exact match partition key. Define HybridRetriever composing: - BM25 via FTS5 MATCH query scoped by namespace - Vector via VectorIndex.query - Fusion mechanism (e.g., reciprocal rank fusion) before rerank. Define Reranker interface with rerank(query, docs) supporting local small model or no-op. Document scope: 'player' resolves to namespace=player:<id>, 'campaign' to campaign:<id>. Ensure columns to enforce campaign_id consistency with namespace.",
            "status": "pending",
            "testStrategy": "Run existing tests; verify schema migration runs and tables exist. Add unit tests for namespace parsing and validation."
          },
          {
            "id": 3,
            "title": "Implement PII Redaction Policy Engine and Transformers",
            "description": "Create a configurable PII redaction pipeline applied before storage that supports masking/removal of emails, phones, addresses, and custom regexes; store redacted content separately and log redaction metadata.",
            "dependencies": [
              "12.1",
              "12.2"
            ],
            "details": "Implement RedactionPolicy with config: { strategies: ['mask','remove'], rules: [builtin.email, builtin.phone, builtin.ssn, builtin.address], customRules: [{name, regex, action}], preserveHints: boolean }. Build redact(text, policy) -> { redactedText, findings:[{type, start,end, original?, replacement}], policyVersion }. Ensure redact is idempotent. Integrate with write_memory transformer chain: normalize whitespace, truncate overly long inputs (configurable), redact according to policy, compute bm25_doc and embedding from redactedText only. Store content as original input? For privacy, do not store original PII: either discard original or store only redacted version; reflect in config to forbid keeping raw. Persist pii_redaction_logs. Provide utility to scrub metadata fields too.",
            "status": "pending",
            "testStrategy": "Unit tests on diverse PII samples verifying matches and replacements; ensure no PII remnants remain by negative regex checks. Verify logs written. Run TC008 policy redaction tests."
          },
          {
            "id": 4,
            "title": "Implement Embeddings Provider and VectorIndex Adapter with Namespaces",
            "description": "Provide an EmbeddingsProvider abstraction with a default local/small model or stub and implement a VectorIndex adapter for sqlite-vss with FAISS fallback, enforcing namespace partitioning.",
            "dependencies": [
              "12.1",
              "12.2"
            ],
            "details": "EmbeddingsProvider: interface embed(text|texts[], dim), deterministic mode for tests (hash-based vector) and real mode (pluggable). VectorIndexSqliteVSS: create vss0 table per memories or a single table with namespace column; ensure index supports cosine similarity. Implement upsert/query/delete using namespace WHERE clause and optional metadata filters (e.g., type). FAISS fallback behind same interface stored in files per namespace directory. Ensure migrations create vss indexes and FTS5 view. Implement health checks and graceful no-vector mode where hybrid falls back to BM25 only.",
            "status": "pending",
            "testStrategy": "Vector unit tests for insert/query cosine similarity, namespace isolation, and deletion. Run TC007 isolation with vector path active and inactive."
          },
          {
            "id": 5,
            "title": "Build Hybrid Retrieval (BM25 + Vector) with Fusion and Optional Reranking",
            "description": "Compose BM25 via FTS5 and VectorIndex results into a unified ranked list using reciprocal rank fusion, then optionally rerank with a local model or pass-through fallback.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.4"
            ],
            "details": "Implement HybridRetriever.retrieve(query, scope, k, filters) -> results[]. Steps: - Resolve namespaces from scope. - Generate query embedding. - Query FTS5 with MATCH across content_redacted and metadata fields, constrained by namespace and filters; collect top N_bm25 with scores. - Query VectorIndex for top N_vec. - Normalize scores and apply Reciprocal Rank Fusion (RRF) with tunable k parameter; de-duplicate by id. - If Reranker available, rerank top M with query and snippets. - Fetch full records, include highlights from FTS5 offsets. Ensure deterministic behavior in tests. Provide configs for weights. Handle missing vector index or embeddings gracefully.",
            "status": "pending",
            "testStrategy": "Integration tests from TC008a check recall and MRR improvement. Unit tests for fusion correctness on synthetic lists. Run latency bench to ensure under target for small corpora."
          },
          {
            "id": 6,
            "title": "Implement Memory Types, Write Path, and API: write_memory",
            "description": "Create the write_memory API to accept memory entries with types, apply redaction, compute embeddings, and index into FTS and vector stores within namespaces.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.3",
              "12.4"
            ],
            "details": "API write_memory(input): { campaignId, playerId?, type, content, metadata } -> returns memoryId, namespace, redactionSummary. Steps: - Validate type in allowed set; require campaignId; playerId optional; derive namespace. - Apply redaction policy; compute embedding on redacted text. - Insert into memories with content_redacted as stored content; bm25_doc mirrors content_redacted. - Upsert into VectorIndex with namespace and metadata filters. - Index into FTS5. - Return identifiers and redaction findings. Ensure transactional integrity across DB and vector index; rollback on failure.",
            "status": "pending",
            "testStrategy": "Unit tests verifying insert success, redaction applied, correct namespace, and index calls. Integration tests that subsequent retrieval finds the item in correct scope. Run existing tests."
          },
          {
            "id": 7,
            "title": "Implement Retrieval API: retrieve(query, scope)",
            "description": "Expose retrieve API that accepts query and scope (player or campaign), resolves namespaces, executes hybrid retrieval, and returns ranked results with snippets and metadata.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.5"
            ],
            "details": "API retrieve({query, scope: {type:'player'|'campaign', campaignId, playerId?}, k, filters, rerank:boolean}). Validate scope; map to one or more namespaces (player maps to a single player:<id>, campaign maps to campaign:<id>). Use HybridRetriever to fetch results. Return: [{id, type, namespace, score, snippet, metadata}]. Enforce per-player isolation by never including other players' namespaces when scope=player. Ensure campaign scope includes only campaign:<id> namespace, not players' private memories unless policy allows (default: exclude).",
            "status": "pending",
            "testStrategy": "Integration tests for TC007 and TC008 run through public API. Add negative tests ensuring cross-campaign leakage does not occur. Run tests."
          },
          {
            "id": 8,
            "title": "Summarization and Promotion Pipeline",
            "description": "Implement a pipeline that summarizes selected memories and promotes them to campaign memory according to configurable policies.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.3",
              "12.6",
              "12.7"
            ],
            "details": "Define PromotionPolicy: thresholds (e.g., frequency, recency, access count, type whitelist), size limits, and PII gate (block if findings present). Implement summarize(memory|batch) using a pluggable Summarizer interface: default rule-based/LLM adapter; operate only on redacted content. Promotion flow: evaluate candidates (e.g., after N accesses or explicit promote call), generate summary, write to campaign:<campaignId> namespace via write_memory with type=semantic or declarative per policy, record in memory_promotions with policy_id and reason. Ensure deduplication (hash summaries), and link back with source_memory_id.",
            "status": "pending",
            "testStrategy": "TC008b: verify summary created, meets schema, and promotion stored only when policy passes; ensure blocked when PII present. Snapshot test for summary fields. Run tests."
          },
          {
            "id": 9,
            "title": "Implement promote API and Policy Enforcement",
            "description": "Expose promote API to allow explicit promotion of player memories to campaign memory while enforcing policy and privacy gates.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.6",
              "12.8"
            ],
            "details": "API promote({memoryId, campaignId, policyOverride?}). Steps: - Fetch memory; verify it belongs to the same campaign as target. - Check policy (type whitelist, PII gate, dedupe). - Summarize if required; write to campaign namespace via write_memory; record promotion entry. - Return promoted record reference. Log decision outcomes.",
            "status": "pending",
            "testStrategy": "Unit tests for policy branches (allow, block, dedupe). Integration test that promotion results are retrievable in campaign scope but not in other campaigns. Run tests."
          },
          {
            "id": 10,
            "title": "Reranker Integration with Local Model or LLM Fallback",
            "description": "Plug in an optional reranker component to reorder the fused results using a small local model when available, otherwise no-op or LLM API when configured.",
            "dependencies": [
              "12.1",
              "12.5"
            ],
            "details": "Implement Reranker interface adapters: LocalCrossEncoderReranker (if packaged) and LLMBasedReranker (budget-guarded). Add capability detection and configuration. Ensure deterministic behavior in tests by using a mock reranker. Provide timeouts and graceful degradation to baseline fusion if reranker unavailable.",
            "status": "pending",
            "testStrategy": "Unit tests for adapter selection and no-op fallback. Integration test showing improved ordering on synthetic dataset. Run tests."
          },
          {
            "id": 11,
            "title": "Access Control and Namespace Enforcement Middleware",
            "description": "Add a guard layer ensuring APIs only access allowed namespaces derived from input scope and session context, preventing cross-player data access.",
            "dependencies": [
              "12.1",
              "12.7"
            ],
            "details": "Implement a middleware/utility that derives allowedNamespaces from {campaignId, playerId, scope.type}. Validate every request: - write_memory requires campaignId and optional playerId; verify caller has rights. - retrieve restricts namespace list strictly. - promote checks campaign match and policy gate. Provide audit logging on denials.",
            "status": "pending",
            "testStrategy": "Unit tests stubbing session context to verify denials on mismatched IDs and allowed paths for correct scopes. Re-run TC007 to ensure isolation still holds."
          },
          {
            "id": 12,
            "title": "Observability, Telemetry, and Latency Bench Hooks",
            "description": "Instrument memory operations with timings, counters, and tracing to support latency acceptance and debugging.",
            "dependencies": [
              "12.1",
              "12.5",
              "12.7"
            ],
            "details": "Add metrics: write_memory duration, retrieve total, FTS5 time, vector time, rerank time, fusion time, promotions count, policy blocks. Add histograms and p50/p95. Integrate simple tracing spans. Expose a diagnostics endpoint to dump recent metrics (redaction-safe). Wire benchmarks used by tests.",
            "status": "pending",
            "testStrategy": "Perf tests from TC008 and bench run read metrics to assert p50 target. Unit tests for metrics emission using a test sink."
          },
          {
            "id": 13,
            "title": "Data Migration and Backfill Utilities",
            "description": "Provide scripts to migrate existing memories to include redacted content, embeddings, and to populate vector/FTS indexes with namespaces.",
            "dependencies": [
              "12.2",
              "12.3",
              "12.4",
              "12.6"
            ],
            "details": "Write CLI: mem-migrate --reindex --redact --namespace-fix. Steps: scan memories, apply redaction if missing, compute embeddings, upsert into vector index, update FTS5. Support dry-run and progress logging. Handle large batches with pagination.",
            "status": "pending",
            "testStrategy": "Integration test on a temp DB populated with legacy-like rows; after migration, retrieval works and PII absent. Run tests."
          },
          {
            "id": 14,
            "title": "Configuration, Policies, and Feature Flags",
            "description": "Centralize configuration for redaction, retrieval fusion weights, reranker toggle, promotion policy, and fallback behaviors with safe defaults.",
            "dependencies": [
              "12.3",
              "12.5",
              "12.8",
              "12.10"
            ],
            "details": "Implement config loader supporting env and file-based overrides. Keys: MEMORY_REDACTION_POLICY, HYBRID_WEIGHTS, RERANKER_MODE, PROMOTION_POLICY, NAMESPACE_RULES, LATENCY_TARGETS. Add validation and config hot-reload if supported. Tie into A/B harness later.",
            "status": "pending",
            "testStrategy": "Unit tests for config parsing and defaulting; integration smoke where toggling reranker changes behavior. Re-run test suite with different configs."
          },
          {
            "id": 15,
            "title": "Security Review: No Raw PII Storage and Audit",
            "description": "Ensure that raw PII is never persisted, secrets are not leaked in logs, and access paths are audited.",
            "dependencies": [
              "12.3",
              "12.6",
              "12.11"
            ],
            "details": "Add safeguards: prohibit storing original content when policy forbids; scrub logs; add DB scan utility to assert no PII patterns exist. Implement audit events for cross-namespace access attempts and promotions. Document threat model and controls.",
            "status": "pending",
            "testStrategy": "Run DB scan test to confirm absence of PII patterns in stored fields. Unit tests for logger scrub. Negative tests triggering audit on denied access."
          },
          {
            "id": 16,
            "title": "Documentation and Developer Examples",
            "description": "Provide developer docs and runnable examples demonstrating write, retrieve by scope, and promotion flow, including configuration of policies.",
            "dependencies": [
              "12.6",
              "12.7",
              "12.8",
              "12.9",
              "12.14"
            ],
            "details": "Write README with API contracts, scope semantics, memory types, and examples. Include a sample script that seeds memories for two players in one campaign, runs queries, shows isolation, and promotes a memory to campaign. Document performance tips and limitations.",
            "status": "pending",
            "testStrategy": "Execute examples as part of CI to ensure they run without errors. Validate outputs contain expected IDs and namespaces."
          }
        ]
      },
      {
        "id": 13,
        "title": "Event Sourcing and Snapshots with Resume/Branch",
        "description": "Persist event-sourced state with periodic snapshots; allow resume and branching timelines from any snapshot.",
        "details": "- Event store: append-only events table (session_id, seq, type, payload, ts)\n- Snapshot service: periodic every N events/time; store snapshot blob and hash\n- Replay engine reconstructs state; branch creates new session from snapshot with pointer to parent\n- UI: branch action in session history",
        "testStrategy": "- TC009: snapshot+replay deterministic state vs live\n- TC010: branch creation yields isolated new session; no leakage\n- Corruption tests: invalid snapshot hash triggers fallback replay",
        "priority": "high",
        "dependencies": [
          2,
          3,
          4,
          10,
          11
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write acceptance tests for snapshots, replay determinism, branching, and corruption handling",
            "description": "Create unit and integration/UI tests that define the acceptance criteria for event sourcing with snapshots, resume, and branching. Include tests for deterministic replay from events vs snapshot+delta (TC009), branch creation isolation (TC010), and corruption handling where invalid snapshot hash triggers full replay fallback. Add UI test for branch action in session history. No implementation yet; tests should initially fail.",
            "dependencies": [],
            "details": "â€¢ Tech stack: TypeScript/Node, Jest (unit), Playwright (UI), and a lightweight in-memory SQLite or better-sqlite3 for integration tests.\nâ€¢ Define fixtures: sample event types (type, payload), sessions, and snapshot blobs. Use seeded timestamps and sequences.\nâ€¢ Unit tests:\n  - TC009-UNIT: Given a session with N events and snapshots every k events, reconstruct state via: (a) full replay; (b) latest snapshot + replay of subsequent events; assert deep equality of states and version.\n  - TC010-UNIT: Branch from snapshot S to new session B; append events to B; assert no changes in parent session events or state; ensure branch has parent pointer.\n  - Corruption-UNIT: Tamper snapshot blob or stored hash; assert engine detects hash mismatch and falls back to full replay; log/metric is emitted.\n  - Sequencing: Ensure seq strictly increases per session; inserting out-of-order should be rejected.\n  - Idempotency: Re-applying same event seq should be no-op and duplicates with same seq rejected.\nâ€¢ Integration tests (Jest with real sqlite):\n  - TC009-INT: Populate events table; run snapshot service policy (every N events); verify read path boots from snapshot and only queries deltas.\n  - TC010-INT: Create branch from snapshot; write subsequent events to branch; query both sessions and verify isolation at DB-level.\n  - Corruption-INT: Manually flip snapshot hash; ensure read falls back to full replay and records an audit entry.\nâ€¢ UI test (Playwright):\n  - TC010-UI: In session history page, click Branch on a snapshot row; verify new session appears with parent pointer and timeline starts at branched state.\nâ€¢ Add verification ID tags in test names/comments: [TC009], [TC010].",
            "status": "pending",
            "testStrategy": "Run Jest unit/integration suites and Playwright UI tests in CI. Expect tests to fail until implementation exists."
          },
          {
            "id": 2,
            "title": "Design and migrate relational schema for events, snapshots, and branches",
            "description": "Create or migrate the database schema to support append-only events, snapshots with integrity hashes, and session branching pointers. Ensure constraints enforce sequencing, immutability, and referential integrity.",
            "dependencies": [
              "13.1"
            ],
            "details": "â€¢ Tables:\n  - sessions(id PK, parent_session_id NULL FK->sessions(id), created_at, metadata JSON)\n  - events(id PK, session_id FK->sessions(id), seq INTEGER, type TEXT, payload JSON, ts INTEGER, UNIQUE(session_id, seq)) with CHECK(seq>0)\n  - snapshots(id PK, session_id FK->sessions(id), upto_seq INTEGER, blob BLOB, hash TEXT, created_at, UNIQUE(session_id, upto_seq))\nâ€¢ Indexes: events(session_id, seq), snapshots(session_id, upto_seq DESC), sessions(parent_session_id).\nâ€¢ Triggers/constraints:\n  - Prevent DELETE/UPDATE on events.type/payload/seq/ts after insert (soft enforcement via application + optional DB trigger).\n  - Ensure snapshots.upto_seq corresponds to an existing event seq per session (FK-like via deferred trigger).\nâ€¢ Migration scripts: up/down SQL; seed dev data.\nâ€¢ Data size: ensure blob column uses efficient storage (e.g., SQLite BLOB; Postgres bytea if applicable).",
            "status": "pending",
            "testStrategy": "Integration tests from 13.1 run migrations in test DB and validate constraints by attempting invalid inserts (e.g., duplicate seq, missing parent) and expecting failures."
          },
          {
            "id": 3,
            "title": "Implement append-only EventStore with optimistic concurrency",
            "description": "Build a repository/service to append and read ordered events per session with sequence guarantees, and to guard against duplicates and race conditions using expected sequence checks.",
            "dependencies": [
              "13.1",
              "13.2"
            ],
            "details": "â€¢ API (TypeScript):\n  - appendEvents(sessionId, expectedLastSeq, events: {type, payload, ts}[]): returns {lastSeq}\n  - readEvents(sessionId, fromSeqInclusive): returns ordered array\n  - createSession(parentSessionId?, metadata?): returns sessionId\nâ€¢ Implementation:\n  - Use a transaction to compute next seq = COALESCE(MAX(seq),0)+1, compare against expectedLastSeq+1 for first event; assign increasing seq for batch.\n  - Enforce immutability: no updates to stored events; only inserts allowed.\n  - Validate payload JSON schema per event type (pluggable validators).\nâ€¢ Telemetry: counters for appends, rejects, latency.",
            "status": "pending",
            "testStrategy": "Run tests: sequencing and idempotency tests from 13.1 should now pass for EventStore behaviors. Add race test using parallel appends expecting one to fail with concurrency error."
          },
          {
            "id": 4,
            "title": "Implement SnapshotStore with hash integrity and retention policy",
            "description": "Create service to persist and fetch latest snapshot per session, compute and verify hashes, and enforce retention (keep last M or by age).",
            "dependencies": [
              "13.1",
              "13.2"
            ],
            "details": "â€¢ API:\n  - saveSnapshot(sessionId, uptoSeq, stateBlob: Uint8Array): returns {id, hash}\n  - getLatestSnapshot(sessionId): returns {uptoSeq, blob, hash} | null\n  - verifySnapshot({blob, hash}): boolean\nâ€¢ Hashing: SHA-256 over canonicalized blob bytes. Include sessionId and uptoSeq in the hash preimage to prevent cross-session substitution.\nâ€¢ Retention: configurable M and TTL; delete older snapshots beyond policy in a background job.\nâ€¢ Store blob as compressed (e.g., gzip) for size; record encoding in metadata if needed.",
            "status": "pending",
            "testStrategy": "From 13.1 corruption tests: tamper hash to force verifySnapshot=false and assert the replay engine falls back. Add unit tests to ensure save and retrieval round-trip with matching hash."
          },
          {
            "id": 5,
            "title": "Build SnapshotPolicy scheduler (periodic every N events and/or time)",
            "description": "Implement policy engine to decide when to snapshot a session based on thresholds: every K events, and/or every T minutes since last snapshot or since session start.",
            "dependencies": [
              "13.1",
              "13.3",
              "13.4"
            ],
            "details": "â€¢ Inputs: thresholds {eventsEveryK, timeEveryTms}. Track last snapshot seq and timestamp per session.\nâ€¢ On each appendEvents success, evaluate policy: if events since last snapshot >= K or time since last snapshot >= T, enqueue snapshot job for that session.\nâ€¢ Use job queue (in-memory or lightweight queue) to decouple from write path; batchable.\nâ€¢ Provide dry-run mode for testing to snapshot synchronously.",
            "status": "pending",
            "testStrategy": "Integration tests seed sessions and append events crossing thresholds; assert snapshot jobs were produced and snapshots saved at expected uptoSeq values. Ensure no duplicate snapshots for same uptoSeq."
          },
          {
            "id": 6,
            "title": "Implement deterministic Reducer and ReplayEngine",
            "description": "Create a pure, deterministic reducer to apply events to state and a replay engine that loads from latest snapshot when present, validates hash, and applies remaining events. On hash failure, fall back to full replay and flag snapshot as corrupted.",
            "dependencies": [
              "13.1",
              "13.3",
              "13.4"
            ],
            "details": "â€¢ Reducer signature: reduce(currentState, event) -> nextState, with serialization-stable state.\nâ€¢ ReplayEngine API:\n  - loadState(sessionId): returns {state, uptoSeq}\n  - rebuildFromSnapshot(snapshot): verify hash; if invalid, mark corrupted and rebuild from seq=0; else apply events from uptoSeq+1.\nâ€¢ Determinism:\n  - No wall-clock usage during reduce; use event.ts exclusively.\n  - Ensure stable ordering by seq; guard against gaps or duplicates.\nâ€¢ Corruption handling:\n  - If hash mismatch, record incident row (snapshots_corrupted) and emit metric.\n  - Optionally re-create a fresh snapshot after full replay.",
            "status": "pending",
            "testStrategy": "Run TC009 unit/integration tests. Add unit test where reducer is applied across two paths (full vs snapshot+delta) and yields identical state object structure and checksum."
          },
          {
            "id": 7,
            "title": "Implement Branching: create new session from snapshot",
            "description": "Enable branching a session timeline from any snapshot. The branch starts with the state of the chosen snapshot and references the parent session.",
            "dependencies": [
              "13.1",
              "13.2",
              "13.4",
              "13.6"
            ],
            "details": "â€¢ API:\n  - createBranch(parentSessionId, snapshotSeq, metadata?): returns newSessionId\nâ€¢ Steps:\n  - Load snapshot at or before snapshotSeq (exact preferred; else pick latest <= snapshotSeq), verify hash; if invalid, rebuild to snapshotSeq and produce a fresh branch base state.\n  - Create new session row with parent_session_id=parentSessionId and metadata including branchOriginSeq.\n  - Option A (no initial events in branch): Store an initial branch snapshot blob representing state at snapshotSeq with uptoSeq=0 for branch, or store origin metadata and compute state via parent snapshot when first read.\n  - Ensure subsequent events appended to branch are isolated under new session_id and start seq at 1.\nâ€¢ Permissions/hooks: check access if needed.",
            "status": "pending",
            "testStrategy": "Run TC010 unit/integration tests to validate isolation: appending to branch must not change parent state or events. Verify parent pointer and branch origin metadata are persisted."
          },
          {
            "id": 8,
            "title": "Expose Resume/Read API with snapshot-aware fast path",
            "description": "Provide a high-level API for clients to resume a session by reconstructing current state using snapshot+delta and to read session timelines efficiently.",
            "dependencies": [
              "13.6",
              "13.3",
              "13.4"
            ],
            "details": "â€¢ API:\n  - resume(sessionId): returns {state, lastSeq}\n  - getTimeline(sessionId, {fromSeq, limit}): returns events page\nâ€¢ Implementation:\n  - resume delegates to ReplayEngine.loadState.\n  - getTimeline streams events with pagination sorted by seq.\nâ€¢ Caching: optional in-memory cache keyed by (sessionId, uptoSeq) to avoid repeated replays within a request scope.",
            "status": "pending",
            "testStrategy": "Integration tests calling resume on sessions with/without snapshots, ensuring correctness and performance (fewer queries when snapshots exist)."
          },
          {
            "id": 9,
            "title": "Add UI: session history with Branch action and branch visualization",
            "description": "Implement UI elements to show session history with snapshots and provide a Branch action to create a new session from a selected snapshot. Visualize parent-child relationship.",
            "dependencies": [
              "13.1",
              "13.7",
              "13.8"
            ],
            "details": "â€¢ UI components:\n  - SessionHistory list showing events and snapshot markers.\n  - For each snapshot row, a Branch button opens a dialog to confirm and enter metadata; on confirm, call createBranch.\n  - After creation, navigate to new session view; display parent pointer and branch origin info.\nâ€¢ Visualization: simple tree or breadcrumb indicating branch hierarchy.\nâ€¢ Accessibility and error handling: display hash corruption warnings if snapshot invalidated and fallback occurred.",
            "status": "pending",
            "testStrategy": "Playwright test (TC010-UI) clicks Branch and verifies new session appears with correct parent and isolated timeline."
          },
          {
            "id": 10,
            "title": "Implement snapshot compaction and housekeeping jobs",
            "description": "Background jobs to prune old snapshots per retention, rehydrate and re-snapshot hot sessions, and mark corrupted snapshots for re-creation.",
            "dependencies": [
              "13.4",
              "13.5",
              "13.6"
            ],
            "details": "â€¢ Jobs:\n  - RetentionPruner: enforce keep-last-M and TTL per session.\n  - Rehasher: periodically verify hashes of latest snapshots.\n  - Resnapshotter: for sessions with large deltas since last snapshot, generate a fresh snapshot.\nâ€¢ Scheduling: cron-like scheduler or reuse existing job framework.",
            "status": "pending",
            "testStrategy": "Integration tests create multiple snapshots and verify pruning rules; simulate corruption and ensure re-snapshotting occurs."
          },
          {
            "id": 11,
            "title": "Observability: metrics, logging, and audit for snapshot/replay/branch",
            "description": "Add structured logs, metrics, and audit trails for key operations: appends, snapshot saves, replay paths, branch creation, and corruption events.",
            "dependencies": [
              "13.3",
              "13.4",
              "13.6",
              "13.7",
              "13.8"
            ],
            "details": "â€¢ Metrics: counts and latencies for appendEvents, saveSnapshot, loadState (full vs snapshot path), createBranch; gauge for snapshots per session; corruption count.\nâ€¢ Logs: include session_id, upto_seq, hash, parent_session_id, outcome fields; redact payloads per security policy.\nâ€¢ Audit table: audits(id, ts, actor, action, session_id, details JSON).",
            "status": "pending",
            "testStrategy": "Add assertions in integration tests that specific metrics/log lines/audit rows are emitted for operations (use test logger/sink)."
          },
          {
            "id": 12,
            "title": "Hardening: concurrency, integrity, and failure scenarios",
            "description": "Handle edge cases like concurrent snapshot creation, out-of-order reads, partial writes, and ensure idempotency and retries.",
            "dependencies": [
              "13.3",
              "13.4",
              "13.5",
              "13.6",
              "13.7"
            ],
            "details": "â€¢ Concurrency control: use DB transactions at SERIALIZABLE or REPEATABLE READ; unique (session_id, upto_seq) prevents duplicate snapshots.\nâ€¢ Snapshot races: only one snapshot per uptoSeq; use INSERT ... ON CONFLICT DO NOTHING.\nâ€¢ Retry policy for transient DB errors; exponential backoff.\nâ€¢ Validation: detect gaps in seq during replay; if gaps, error and require maintenance.\nâ€¢ Large payloads: stream snapshot blob to DB to avoid memory spikes.",
            "status": "pending",
            "testStrategy": "Stress tests with parallel appends and snapshot jobs; assert no duplicate snapshots and no lost events. Fault injection to simulate transient failures and ensure retries succeed."
          },
          {
            "id": 13,
            "title": "Documentation and developer tooling",
            "description": "Provide README and API docs for EventStore, SnapshotStore, ReplayEngine, and Branch API. Add CLI tooling to inspect sessions, list snapshots, verify hashes, and create branches.",
            "dependencies": [
              "13.3",
              "13.4",
              "13.6",
              "13.7",
              "13.8",
              "13.11"
            ],
            "details": "â€¢ Docs: architecture overview, data model diagrams, sequence charts for snapshotting and branching, configuration of policies, and how to run tests [TC009, TC010].\nâ€¢ CLI commands: events:list, snapshots:list, snapshot:verify, branch:create.\nâ€¢ Examples: sample reducers and state schemas.",
            "status": "pending",
            "testStrategy": "Manual verification by running CLI against test DB; lint docs build."
          }
        ]
      },
      {
        "id": 14,
        "title": "A/B Harness for Model Comparison",
        "description": "Implement A/B evaluation harness across LLM/STT/TTS/Image adapters with metrics capture and toggle per campaign.",
        "details": "- Experiment config: variant allocation, paired or split traffic\n- Capture latency, token usage, quality tags; store in llm_messages/metrics\n- UI: enable per-campaign; view basic charts\n- Safe rollbacks; guardrails for budget limits",
        "testStrategy": "- TC013: structural checks and metrics correctness under simulated runs\n- Unit: allocation reproducibility with seed\n- Load: run concurrent experiments without cross-talk",
        "priority": "medium",
        "dependencies": [
          5,
          4,
          2
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for A/B harness acceptance criteria (TC013, unit, integration, UI, load)",
            "description": "Create a comprehensive automated test suite defining acceptance criteria for the A/B evaluation harness across LLM/STT/TTS/Image adapters. Cover configuration, allocation determinism, metrics capture, per-campaign toggles, charts visibility, budget guardrails, and safe rollback behavior. Include at least one unit test and one integration/UI test, plus a load test skeleton for concurrent experiments without cross-talk.",
            "dependencies": [],
            "details": "Implement tests first using your project's chosen stack (e.g., Jest + TS for unit/integration, Playwright for UI, k6 or node worker-based script for load). Scope:\n- TC013 Structural/metrics correctness: simulate experiment runs and verify metrics persistence into llm_messages and metrics tables, including latency, token usage, and quality tags.\n- Unit tests:\n  - Allocation reproducibility with a seed: given an experiment id, user/session id, and seed, the same subject is assigned to the same variant for split traffic; for paired mode both variants are run and linked.\n  - Budget guardrail: when spend or token budget threshold is reached per campaign, new traffic allocation halts or routes to control as configured.\n  - Config validation: invalid variant allocation sums, missing adapters, or negative budgets are rejected.\n- Integration tests:\n  - Run harness across mock adapters implementing LLM/STT/TTS/Image interfaces; ensure per-adapter metrics captured and aggregated.\n  - Concurrent experiments on different campaigns do not interfere (namespace isolation).\n  - Safe rollback: toggling off experiment reverts to prior provider settings.\n- UI tests (Playwright):\n  - Enable A/B per campaign; configure variants, allocation, mode (paired/split), budgets; verify charts render basic metrics.\n  - Verify guardrail banner/notice appears when budget hit and new allocations stop.\n- Load test skeleton: spin N concurrent simulated sessions across two campaigns and two experiments; assert no cross-talk and acceptable latency aggregation.\nProduce fixtures: mock adapters that return deterministic outputs with configurable latency and token usage. Seeded RNG helper for allocation.",
            "status": "pending",
            "testStrategy": "Map assertions to IDs: TC013 for structural and metrics checks; add TC014-UI for per-campaign toggle and charts; TC015-Load for concurrency isolation; TC016-Budget for guardrails; TC017-AllocationSeed for reproducibility. Tests must fail initially and be run in CI."
          },
          {
            "id": 2,
            "title": "Design experiment configuration schema and validation",
            "description": "Define the A/B experiment domain model and validation rules to support variant allocation, paired vs split traffic, per-campaign enablement, budgets, and rollback strategy.",
            "dependencies": [
              "14.1"
            ],
            "details": "Add a versioned schema (Zod or io-ts) for ExperimentConfig with fields: id, campaignId, name, status (draft|running|paused|archived), mode (paired|split), allocation [{variantId, adapterKind (LLM|STT|TTS|Image), providerKey, model, weight 0..1}], seed (optional), trafficFilter (optional), startAt/stopAt (optional), guardrails {maxTokens, maxCost, maxRequests, actionOnExceed: halt|route_control|pause}, rollback {toProviderConfigSnapshotId}, metricsConfig {captureLatency: boolean, captureTokens: boolean, qualityTags: string[]}, createdBy, createdAt, updatedAt.\nValidation rules:\n- Sum of weights per adapterKind equals 1.0 for split mode.\n- Paired mode requires exactly 2 variants per adapterKind or explicit pairing rules; allocation ignored.\n- providerKey/model must exist in Provider Adapter Registry (Task 5 dependency).\n- Budget values >= 0; at least one guardrail enabled or explicitly disabled.\n- status transitions allowed: draft->running->paused/archived; paused->running.\nPersist schema type in shared package. Implement validateExperimentConfig(config) that returns typed config or throws detailed errors.",
            "status": "pending",
            "testStrategy": "Run tests from 14.1; ensure invalid configs are rejected and valid pass. Add unit tests for edge cases: rounding of weights, missing variants, unknown providerKey."
          },
          {
            "id": 3,
            "title": "Extend database schema for experiments and metrics storage",
            "description": "Add migrations and data access for experiments, allocations, runs, and metrics, integrating with existing llm_messages and a new metrics table.",
            "dependencies": [
              "14.1",
              "14.2"
            ],
            "details": "Using existing DB stack (Task 2), add:\n- Tables:\n  - experiments: id, campaign_id, name, status, mode, seed, guardrails JSON, rollback_snapshot_id, created_at, updated_at.\n  - experiment_variants: id, experiment_id, adapter_kind, provider_key, model, weight, metadata JSON.\n  - experiment_runs: id, experiment_id, campaign_id, subject_key (user/session/message id), adapter_kind, mode, variant_a_id, variant_b_id (nullable), assigned_variant_id (nullable for paired), paired_group_id (for paired linking), started_at, completed_at, status, error.\n  - metrics: id, experiment_run_id, adapter_kind, latency_ms, input_tokens, output_tokens, cost_micro, quality_tags TEXT[]/JSON, created_at.\n- Augment existing llm_messages: add experiment_run_id nullable FK; ensure indices on campaign_id, created_at.\n- Indices: experiments(campaign_id,status), experiment_runs(experiment_id,subject_key), metrics(experiment_run_id), and partial index for status='running'.\n- Data access layer (repository functions) with transaction-safe inserts for run + metrics.\n- Seed script updates for dev examples.\nHandle SQLite compatibility (arrays via JSON). Ensure foreign keys and cascade deletes for archiving experiments.",
            "status": "pending",
            "testStrategy": "Execute migration tests for up/down idempotency and CRUD. From 14.1 tests, verify metrics persist correctly and link to runs and llm_messages. Add performance smoke: insert >2k metrics/s on small batch locally if feasible."
          },
          {
            "id": 4,
            "title": "Implement allocation engine with seeded determinism and paired/split modes",
            "description": "Create the runtime allocator that assigns variants per request/session with deterministic results under a given seed and subject key, supporting split and paired traffic.",
            "dependencies": [
              "14.1",
              "14.2",
              "14.3"
            ],
            "details": "Implement module allocateVariant({experiment, adapterKind, subjectKey}):\n- For split mode: use a stable hash (e.g., murmurhash) seeded by experiment.seed to map subjectKey to [0,1) and select variant by cumulative weights. Ensure consistent across processes.\n- For paired mode: return both variants (A and B) and generate a paired_group_id; executor will run both in sequence or parallel depending on adapter capability.\n- Support traffic filtering and sticky assignment per subjectKey stored in experiment_runs to maintain consistency.\n- Handle multiple adapter kinds by independent allocations per kind.\nAdd reproducibility options for test replays. Implement small PRNG utility to avoid platform differences.",
            "status": "pending",
            "testStrategy": "Use tests from 14.1 (TC017-AllocationSeed). Add unit tests verifying boundary conditions (exact weight edges), stability across process restarts, and paired linking."
          },
          {
            "id": 5,
            "title": "Execution harness integrating Provider Adapter Framework",
            "description": "Build the execution layer that takes allocations and invokes the correct adapter variant(s), captures timings, tokens, costs, and stores messages and metrics atomically.",
            "dependencies": [
              "14.1",
              "14.2",
              "14.3",
              "14.4"
            ],
            "details": "Create AbHarness.execute(request) where request includes campaignId, adapterKind, payload (prompt/audio/text/image spec), subjectKey, experimentId (optional). Steps:\n- Resolve active experiment for campaign+adapterKind; if multiple, support single active per adapterKind or fail fast.\n- Allocate variant(s) using allocation engine.\n- For split: run selected adapter; for paired: run both variants; for LLM paired, optionally run A then B with same prompt and context; for STT/TTS/Image ensure same input.\n- Capture timing via high-resolution timers; gather token usage/cost from adapter responses or estimate via tokenizer if needed.\n- Begin transaction: insert experiment_run, store adapter outputs into llm_messages (link run id), write metrics row(s) with latency_ms, tokens, cost, quality_tags (initially empty).\n- Return unified response with metadata {experimentRunId, variant info}.\n- Provide hooks for post-run quality tagging and custom metrics enrichment.\nImplement error handling: if variant call fails, record status=error, fallback to control variant if configured, and continue according to guardrails.",
            "status": "pending",
            "testStrategy": "Run integration tests from 14.1 for multi-adapter execution and metrics correctness. Add unit tests with mock adapters to simulate latency and token outputs and verify atomic writes."
          },
          {
            "id": 6,
            "title": "Budget guardrails and enforcement with safe rollback",
            "description": "Implement budget tracking (tokens, cost, requests) per campaign/experiment with enforcement actions and automatic rollback to prior provider settings when configured.",
            "dependencies": [
              "14.1",
              "14.3",
              "14.5"
            ],
            "details": "Implement GuardrailService:\n- Maintain counters aggregated from metrics table per experiment and campaign.\n- On each new allocation/execution, check thresholds {maxTokens, maxCost, maxRequests}; if exceeded, apply actionOnExceed:\n  - halt: reject new allocations for experiment and log event.\n  - route_control: bypass experiment and use baseline provider config.\n  - pause: set experiment.status=paused.\n- Safe rollback: if rollback.toProviderConfigSnapshotId provided, restore provider settings atomically. Capture a pre-experiment snapshot when enabling experiment.\n- Expose events for UI notifications and audit log entries.\nEnsure concurrency-safety with DB transactions and last-write-wins guards.",
            "status": "pending",
            "testStrategy": "Use TC016-Budget and relevant integration tests from 14.1. Add unit tests for threshold boundary behavior and rollback idempotency. Simulate concurrent increments to ensure no double counting."
          },
          {
            "id": 7,
            "title": "Per-campaign experiment toggle and settings plumbing (backend API)",
            "description": "Expose REST/IPC endpoints to create, validate, enable, pause, and archive experiments per campaign and snapshot provider settings for rollback.",
            "dependencies": [
              "14.1",
              "14.2",
              "14.3",
              "14.6"
            ],
            "details": "Add API routes:\n- POST /campaigns/:id/experiments (create+validate config)\n- POST /campaigns/:id/experiments/:expId/enable (snapshot provider config, set running)\n- POST /campaigns/:id/experiments/:expId/pause\n- POST /campaigns/:id/experiments/:expId/archive\n- GET /campaigns/:id/experiments (list with status and guardrail state)\n- GET /experiments/:expId/metrics/summary (latency p50/p95, tokens, cost, by variant)\nAuth/permissions per existing model. Wire to GuardrailService and Allocation/Execution layers. Emit events for UI. Ensure idempotency and proper status transitions.",
            "status": "pending",
            "testStrategy": "Run integration tests to enable experiment and execute mock runs. Verify rollback snapshot existence. Add contract tests for each endpoint response shape and error codes."
          },
          {
            "id": 8,
            "title": "Metrics aggregation and basic charts backend",
            "description": "Implement metrics aggregation queries and DTOs powering UI charts for latency, token usage, cost, and quality tags by variant over time.",
            "dependencies": [
              "14.1",
              "14.3",
              "14.5",
              "14.7"
            ],
            "details": "Create aggregation service:\n- Time-bucketed summaries (e.g., 5m/1h/day) per experimentId, adapterKind, variantId: count, avg, p50, p95 latency, total input/output tokens, total cost, tag counts.\n- Comparative snapshot for A vs B deltas.\n- Budget utilization percentages vs guardrails.\nOptimize with SQL views or materialized summaries if needed; otherwise compute on demand with indexes. Define DTOs for UI: Series points and legend metadata.",
            "status": "pending",
            "testStrategy": "Extend TC013 to validate aggregated values against known fixtures. Unit test percentile calcs and tag aggregation. Performance test aggregation on sample dataset."
          },
          {
            "id": 9,
            "title": "React UI: per-campaign A/B toggle and configuration form",
            "description": "Add UI to enable/disable experiments per campaign, configure variants, allocation, mode, budgets, and seed; ensure accessibility and validation feedback.",
            "dependencies": [
              "14.1",
              "14.2",
              "14.7"
            ],
            "details": "Within Campaign Settings, add an Experiments panel:\n- List experiments with status chips.\n- Create/Edit form: adapter kind, mode, variants (provider/model selection via Provider Registry), allocation sliders with sum-to-100 indicator, budgets, seed, guardrail action, rollback option.\n- Client-side validation mirroring schema; surface backend errors.\n- Actions: Enable, Pause, Archive with confirmations.\n- Accessibility: keyboard, labels, ARIA, color contrast. Localized strings.\nPersist via backend API. Capture snapshot confirmation on enable.",
            "status": "pending",
            "testStrategy": "Playwright UI tests from 14.1 (TC014-UI). Snapshot tests for form. Axe-core accessibility scan must pass. Verify validation errors and successful enable flows."
          },
          {
            "id": 10,
            "title": "React UI: basic charts and experiment status indicators",
            "description": "Create a metrics dashboard per experiment showing latency, tokens, cost, and tag distributions with variant comparison and budget guardrail status.",
            "dependencies": [
              "14.1",
              "14.8",
              "14.9"
            ],
            "details": "Add an Experiment Dashboard page:\n- Charts: time series for latency (p50/p95), stacked bars for tokens, cost trend, and a tag distribution pie/bar by variant.\n- Controls: time range, adapter kind filter, paired/split mode indicator.\n- Badges/alerts when guardrails engaged (halt/route_control/pause) and budget utilization bars.\n- Empty states and loading skeletons.\nUse a lightweight charting lib. Fetch data from aggregation endpoints, poll at intervals.",
            "status": "pending",
            "testStrategy": "Playwright tests to verify charts render with mock data and reflect state changes (e.g., budget exceeded banner). Visual snapshot tests for charts with deterministic fixtures."
          },
          {
            "id": 11,
            "title": "Quality tagging workflow and APIs",
            "description": "Enable attaching quality tags to experiment runs/messages (manual or automated), and include tags in aggregation.",
            "dependencies": [
              "14.1",
              "14.5",
              "14.8",
              "14.7"
            ],
            "details": "Add API to POST tags to an experiment_run or llm_message (e.g., ['helpful','off-topic','hallucination']). Provide batch tagging endpoint for evaluator jobs. Update aggregation to include tag counts by variant. Optionally, add a small UI control to tag recent runs from dashboard.",
            "status": "pending",
            "testStrategy": "Unit tests for tag validation and persistence. Integration test that tags affect aggregation counts. UI test for tagging control if implemented."
          },
          {
            "id": 12,
            "title": "Safe rollback executor and provider snapshot manager",
            "description": "Implement provider configuration snapshotting per campaign and reliable rollback application when experiments are paused/archived or guardrails trigger route to control.",
            "dependencies": [
              "14.1",
              "14.6",
              "14.7"
            ],
            "details": "Create SnapshotService capturing current provider settings for a campaign at enable-time. Store snapshots in settings table with diff metadata. On rollback action: apply snapshot atomically, verify with post-apply read-back, and record audit event. Ensure idempotency and handle partial failures with retry and compensating actions.",
            "status": "pending",
            "testStrategy": "Integration tests: enable experiment -> mutate providers -> trigger rollback -> verify providers restored exactly. Unit tests for diff/apply logic and idempotency."
          },
          {
            "id": 13,
            "title": "Concurrency isolation and cross-talk prevention",
            "description": "Ensure experiments across campaigns and adapter kinds are isolated in allocation, execution, metrics, and guardrails under concurrent load.",
            "dependencies": [
              "14.1",
              "14.4",
              "14.5",
              "14.6",
              "14.8"
            ],
            "details": "Audit code paths to include campaignId and experimentId scoping in queries and caches. Namespaces for any in-memory caches keyed by campaign+experiment+adapterKind. Add advisory locks or compare-and-swap on run creation to avoid duplicate runs for the same subjectKey. Verify queue/executor isolation if present.",
            "status": "pending",
            "testStrategy": "Use TC015-Load from 14.1 to run concurrent experiments and assert no cross-talk (e.g., variant assignment leakage, metric aggregation mixing). Add race-condition unit tests with fake timers and parallel tasks."
          },
          {
            "id": 14,
            "title": "Documentation and operational playbooks",
            "description": "Add developer and operator docs describing configuration, running experiments, interpreting charts, budgets, and rollback procedures.",
            "dependencies": [
              "14.2",
              "14.5",
              "14.6",
              "14.7",
              "14.8",
              "14.10"
            ],
            "details": "Write README and runbooks: schema reference, API usage, UI flows, how to add new adapters, seeding/replay for reproducibility, troubleshooting guardrails, and safe rollback steps. Include examples for paired and split experiments and metrics interpretation.",
            "status": "pending",
            "testStrategy": "Validate examples by running them as part of an examples test script. Link docs in UI help."
          },
          {
            "id": 15,
            "title": "Release toggle and feature flagging",
            "description": "Gate the A/B harness behind a feature flag and provide a kill switch to disable experiments globally in case of issues.",
            "dependencies": [
              "14.1",
              "14.5",
              "14.7"
            ],
            "details": "Introduce feature flag abHarnessEnabled with remote/local override. Wrap API routes and UI panels. Add global kill switch that pauses all running experiments and routes traffic to control, emitting alerts and audit entries.",
            "status": "pending",
            "testStrategy": "Unit tests for flag evaluation and route guarding. Integration test toggling flag disables allocations and hides UI, ensuring safe behavior."
          }
        ]
      },
      {
        "id": 15,
        "title": "Local-First Security and PII Redaction",
        "description": "Enforce local-only data, encrypted provider keys at rest, and PII redaction on logs and transcripts per policy.",
        "details": "- Network guard: deny outbound except explicit provider hosts; config flag to fully offline\n- Key storage via keytar; never write plaintext keys to DB or logs\n- Redaction middleware for transcripts/logs using deterministic masking; consent flags for PvP interactions\n- Structured logging with redacted fields",
        "testStrategy": "- TC014: assert no unintended external writes via network interceptor tests\n- Verify key encryption by attempting to read DB and finding no keys\n- Redaction test corpus covering emails, names, locations",
        "priority": "high",
        "dependencies": [
          2,
          5,
          3
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for network guard, key storage, and PII redaction (TC014, TC015â€“TC017)",
            "description": "Create unit, integration, and E2E tests capturing acceptance criteria for local-only networking, encrypted-at-rest provider keys, and deterministic PII redaction across logs/transcripts. Include offline mode behavior and consent flags for PvP interactions. No production code changes yet.",
            "dependencies": [],
            "details": "â€¢ Network guard tests (TC014):\n  - Unit: mock HTTP client/interceptor; assert outbound requests are blocked by default and only allowed to explicit allowlist hosts; assert DNS/IP literal requests to non-allowed hosts are denied; assert protocol restrictions (http/https only) and port allow rules; assert environment variable proxy is ignored unless allowlisted.\n  - Integration: spin a local test server and a disallowed remote host (use nock or msw). Verify attempts to call disallowed hosts fail with specific error code and are logged as security events without leaking request bodies. Verify offline flag denies even allowlisted hosts.\n  - E2E: run a minimal app boot flow with offline flag true and ensure no outbound sockets are established (capture with a socket/sniffing helper) and that functionality relying on local cache works.\nâ€¢ Key storage tests (TC015):\n  - Unit: mock key storage adapter; ensure plaintext keys are never returned from persistence layer; verify encryption/decryption boundaries; attempt to log keys and assert structured logger redacts.\n  - Integration: write provider keys via API; inspect DB/files to verify no plaintext keys or decryptable material without OS keystore; simulate corrupted store; assert safe failures and no logs with secrets.\nâ€¢ PII redaction tests (TC016):\n  - Unit: provide corpus with emails, names, phones, SSNs, addresses, coordinates, IPs, credit card numbers; assert deterministic masking (same token -> same mask), irreversible format; preserve structure for analytics fields; ensure Unicode and locale variations.\n  - Snapshot: redact sample transcripts and logs; assert snapshots contain masked tokens and required structured fields remain.\nâ€¢ Consent flags for PvP tests (TC017):\n  - Unit: when consent=false, redact or drop personally identifying speaker tags; when consent=true, allow pseudonymous identifiers; verify consent toggling mid-session re-redacts past messages where policy requires.\nâ€¢ Logging structure tests:\n  - Unit: logger enforces redacted fields schema; disallows emitting objects with forbidden keys (e.g., apiKey, token) and auto-redacts.\n",
            "status": "pending",
            "testStrategy": "Map tests to TC IDs: TC014 (network egress policy), TC015 (keys never plaintext), TC016 (PII redaction determinism/coverage), TC017 (PvP consent). Include CI jobs running unit, integration, and an E2E smoke with offline flag. Use seeded randomness for deterministic masking and snapshots."
          },
          {
            "id": 2,
            "title": "Implement network guard with outbound deny-by-default and offline mode",
            "description": "Add a process-wide network guard that intercepts all HTTP(S) egress and denies by default except explicit provider allowlist. Provide a config flag to force fully offline operation.",
            "dependencies": [
              "15.1"
            ],
            "details": "â€¢ Interception layer:\n  - Node: wrap globalAgent/undici/axios/fetch with a policy interceptor; optionally use net.connect monkeypatch to enforce at socket level. In Electron, also register protocol interceptors.\n  - Policy: default deny; allowlist of hostnames and pinned ports; support SNI/hostname verification; resolve DNS and verify final destination IP matches expected CIDR ranges if specified; block plain IP unless explicitly allowlisted; block non-TCP schemes.\n  - Offline flag: config.local.offline=true short-circuits all outbound attempts with a typed error (ERR_OFFLINE_BLOCKED) and increments a metric.\n  - Observability: structured security log event on block with: timestamp, dest_host (redacted if contains PII), reason, rule_id; no request body logged; include correlationId.\n  - Configuration: load allowlist from signed config or environment; hot-reloadable; include explicit provider hosts (e.g., openai.com, anthropic.com) as examples in config only, not hardcoded.\n  - Tests: run and fix failing tests from 15.1; add integration harness using nock/msw; validate no regressions.",
            "status": "pending",
            "testStrategy": "Run TC014 tests. Add additional tests: proxy bypass attempts, IPv6 literals, redirect chains where initial host is allowed but redirect to disallowed host must be blocked."
          },
          {
            "id": 3,
            "title": "Add configuration management for allowlist and offline toggle",
            "description": "Introduce secure configuration sources for network allowlist and an offline toggle with environment and file-based overrides, including validation and hot-reload.",
            "dependencies": [
              "15.1",
              "15.2"
            ],
            "details": "â€¢ Config schema: define zod/ajv schema: { offline: boolean, allowlist: [{ host, ports, cidrs?, protocols? }] } with defaults to safest settings.\nâ€¢ Load order: env vars -> signed config file -> runtime admin API; validate and reject unsafe values.\nâ€¢ Hot-reload: watch config file; if changes, update the network guard rules atomically with versioning; emit audit log entry.\nâ€¢ Admin API (local-only): read-only endpoint to display current policy for UI; ensure not exposed over network in offline mode.\nâ€¢ Tests: re-run 15.1; add hot-reload tests ensuring in-flight connections are unaffected and new connections apply new policy.",
            "status": "pending",
            "testStrategy": "Property tests for schema validation; mutation tests for unsafe config (e.g., allowlist '*')."
          },
          {
            "id": 4,
            "title": "Implement key storage using OS keychain via keytar",
            "description": "Store provider API keys using OS keystore (keytar). Ensure keys are never written in plaintext to DB, files, or logs. Provide typed adapter APIs.",
            "dependencies": [
              "15.1"
            ],
            "details": "â€¢ Adapter design: KeyVault interface: setKey(provider, accountId, secret), getKey(provider, accountId), deleteKey, listEntries(). Implement KeytarKeyVault using keytar.\nâ€¢ Persistence: DB stores only references (provider, accountId, keyRefId), not secrets. Migrations to remove any legacy plaintext fields and replace with nullable references.\nâ€¢ Logging: redact on toString/inspect; structured logger sanitizer strips fields named apiKey/token/secret by path.\nâ€¢ Error handling: map keytar errors to domain errors; fallback behavior disabled by default (no plaintext fallback). Provide dev-only mock vault behind explicit ALLOW_INSECURE_DEV_VAULT.\nâ€¢ Tests: execute TC015; simulate DB reads to confirm absence of plaintext; attempt to log secrets and verify redaction.",
            "status": "pending",
            "testStrategy": "Integration tests across supported OSs via CI matrix (macOS, Windows, Linux) with keytar. If unavailable in CI, use container images with libsecret/gnome-keyring for Linux."
          },
          {
            "id": 5,
            "title": "Add secure key ingestion and rotation APIs",
            "description": "Expose local-only APIs/UI flows to add, rotate, and delete provider keys, enforcing validation and audit logging while keeping secrets only in keytar.",
            "dependencies": [
              "15.1",
              "15.4"
            ],
            "details": "â€¢ API: POST /secrets/:provider (validate format via regex/luhn where applicable), POST /secrets/:provider/rotate, DELETE /secrets/:provider/:accountId.\nâ€¢ Transport: local IPC or localhost-only with mTLS disabled in offline mode; never send secrets over outbound network.\nâ€¢ Audit log: structured event with provider, accountId hash, action, initiator, result; no secret content.\nâ€¢ Rotation: dual-write window with old/new keyRefs, automatic cutover after validation ping (if offline, defer until connectivity resumes or manual confirm).\nâ€¢ UI: minimal modal that never echoes back full secret; show last4 and createdAt only.\nâ€¢ Tests: update TC015 integration; add negative tests for invalid formats and ensure no secret appears in any log.",
            "status": "pending",
            "testStrategy": "Contract tests for API; UI test for modal masking and copy-to-clipboard behavior without exposing full value."
          },
          {
            "id": 6,
            "title": "Build deterministic PII redaction engine and policy config",
            "description": "Create a streaming-capable redaction engine with deterministic masking for PII types (emails, names, phones, SSNs, addresses, IPs, GPS, credit cards) and policy-driven controls.",
            "dependencies": [
              "15.1"
            ],
            "details": "â€¢ Engine: tokenization + pattern/rule-based detectors (regex + locale-aware libs) with optional ML hook later; map tokens to stable pseudonyms using HMAC(key, token) -> stable ID, format-preserving masks.\nâ€¢ Policy: config defines which entities to redact vs hash vs drop; include context-aware exceptions (e.g., system usernames). Seed key stored in keytar as RedactionSalt; rotate with versioning.\nâ€¢ Streaming: support incremental masking for transcripts/logs.\nâ€¢ Determinism: same input maps to same mask within a policy version; changing salt/version invalidates mapping.\nâ€¢ Performance: compile regexes; apply trie for known names list; limit backtracking; process UTF-8 safely.\nâ€¢ Tests: run TC016 corpus and snapshot tests; add property tests for determinism and irreversibility.",
            "status": "pending",
            "testStrategy": "Fuzz tests over random PII-like strings; performance benchmark to ensure under 5 ms/KB typical."
          },
          {
            "id": 7,
            "title": "Integrate redaction middleware into logging pipeline",
            "description": "Introduce middleware that enforces redaction on all structured logs before emission with schema enforcement and forbidden fields auto-redaction.",
            "dependencies": [
              "15.1",
              "15.6"
            ],
            "details": "â€¢ Logger wrapper: before write, pass message through redaction engine; drop or mask fields per policy; enforce schema shape (level, msg, eventId, fields).\nâ€¢ Field guards: recursively scan object keys for sensitive names (apiKey, token, secret, password, Authorization) and replace with [REDACTED].\nâ€¢ Metadata: attach redaction_version and policy_id; allow safe list of fields for observability.\nâ€¢ Sinks: console, file, and in-app viewer; ensure file sink uses append-only permissions.\nâ€¢ Tests: extend TC016 snapshots; ensure any attempt to log secret values gets masked; check performance overhead.",
            "status": "pending",
            "testStrategy": "Golden tests for representative log events; mutation tests ensuring no bypass when nested."
          },
          {
            "id": 8,
            "title": "Add transcript redaction middleware with consent-aware PvP handling",
            "description": "Apply redaction to chat/transcript streams, honoring consent flags for player-vs-player interactions and pseudonymous identifiers.",
            "dependencies": [
              "15.1",
              "15.6"
            ],
            "details": "â€¢ Middleware placement: before persistence and before any UI rendering/export.\nâ€¢ Consent: per-participant consent flag; if false, strip PII and replace speaker identifiers with pseudonyms; if true, allow pseudonymous ID but still redact sensitive PII; changes propagate historically if policy demands.\nâ€¢ Deterministic pseudonyms: use HMAC(seed, userId) to generate stable alias per campaign/session.\nâ€¢ Exports: ensure exported transcripts apply same policy; include redaction metadata.\nâ€¢ Tests: run TC017; regression tests for toggling consent mid-session; verify deterministic aliasing.",
            "status": "pending",
            "testStrategy": "Integration tests simulating multi-user chat with mixed consent; UI snapshot to verify masked display."
          },
          {
            "id": 9,
            "title": "Implement structured security and audit logging",
            "description": "Standardize structured logging with redacted fields, security events taxonomy, and audit trail for key and policy operations.",
            "dependencies": [
              "15.1",
              "15.7",
              "15.8"
            ],
            "details": "â€¢ Event taxonomy: SECURITY_BLOCK, POLICY_CHANGE, SECRET_WRITE, SECRET_ROTATE, SECRET_DELETE, CONSENT_UPDATE.\nâ€¢ Schema: include actor (pseudonymous), action, objectRef, outcome, correlationId; ensure all payloads pass redaction middleware.\nâ€¢ Storage: append-only local file with rotation; protect with file permissions; optional local SQLite table with checksum.\nâ€¢ Query API: local-only read interface for UI.\nâ€¢ Tests: validate schema; verify no PII leakage; ensure events written for key ops and policy changes.",
            "status": "pending",
            "testStrategy": "E2E test where key rotation and policy change generate correct audit entries with no secrets."
          },
          {
            "id": 10,
            "title": "Add admin UI for security settings, keys, and redaction policy",
            "description": "Provide a local-only admin UI to manage offline toggle, allowlist, keys, and redaction policy with safe UX that avoids exposing secrets.",
            "dependencies": [
              "15.3",
              "15.5",
              "15.6",
              "15.9"
            ],
            "details": "â€¢ UI sections: Network (offline, allowlist), Keys (add/rotate/delete with masked display), Redaction Policy (entity toggles), Audit Log viewer.\nâ€¢ Security: ensure UI reads via local IPC; no external calls; copy-to-clipboard uses masked preview; confirm dialogs for destructive actions.\nâ€¢ Accessibility: clear labels and warnings when offline mode blocks providers.\nâ€¢ Tests: UI integration test to ensure no secret text nodes; snapshot for masked outputs; flow tests for key rotation and policy toggle updating runtime.",
            "status": "pending",
            "testStrategy": "Automated UI tests (Playwright) running locally; enforce no network requests during UI suite."
          },
          {
            "id": 11,
            "title": "Introduce policy versioning, rotation, and redaction salt management",
            "description": "Manage redaction policy versions and rotation of the HMAC salt stored in keytar with safe reprocessing of stored logs/transcripts when required.",
            "dependencies": [
              "15.4",
              "15.6",
              "15.8",
              "15.9"
            ],
            "details": "â€¢ Versioning: policy_id and salt_version; store in config and audit on change.\nâ€¢ Rotation: generate new salt, store in keytar; fromVersion -> toVersion migrator to re-redact stored artifacts or mark as legacy with compatibility view.\nâ€¢ Backfill job: batch reprocess transcripts/logs; track progress; throttle IO.\nâ€¢ Tests: simulate rotation; assert determinism changes; ensure old artifacts are either reprocessed or labeled; ensure audit entries created.",
            "status": "pending",
            "testStrategy": "Long-running integration test with dataset; verify no PII regression during rotation."
          },
          {
            "id": 12,
            "title": "Harden transports and dependency surfaces against leaks",
            "description": "Ensure no unintended external writes via SDKs, telemetry, crash reporters, or dependency defaults. Disable or stub all third-party telemetry by default.",
            "dependencies": [
              "15.2",
              "15.3"
            ],
            "details": "â€¢ Survey dependencies for telemetry; set env flags (e.g., ELECTRON_DISABLE_SECURITY_WARNINGS does not emit data; disable Sentry/Crashpad unless opt-in local-only).\nâ€¢ Replace global fetch/WS with guarded implementations; block WebSocket egress via the same network guard.\nâ€¢ Ensure DNS prefetching and auto-update are disabled.\nâ€¢ Tests: extend TC014 to include WebSocket and DNS prefetch attempts; verify blocks.",
            "status": "pending",
            "testStrategy": "Static analysis to search for known telemetry endpoints; runtime hooks to detect unexpected sockets."
          },
          {
            "id": 13,
            "title": "Implement data retention and secure deletion for redacted artifacts",
            "description": "Define retention policies for logs/transcripts and implement secure deletion routines with index updates and audit logging.",
            "dependencies": [
              "15.7",
              "15.8",
              "15.9",
              "15.11"
            ],
            "details": "â€¢ Retention config: max days/size; per-campaign overrides.\nâ€¢ Deletion: secure overwrite for files; for DB rows, wipe blob content and remove indexes; write AUDIT events.\nâ€¢ Compaction: rotate log files; prune old snapshots.\nâ€¢ Tests: ensure deletion removes PII even if policy rotates; verify audit entries and no dangling references.",
            "status": "pending",
            "testStrategy": "E2E retention expiry test with fake clock; validate disk usage before/after."
          },
          {
            "id": 14,
            "title": "Documentation and developer tooling for local-first security",
            "description": "Provide clear docs, code owners, and pre-commit hooks that prevent accidental logging of secrets and enforce offline-safe patterns.",
            "dependencies": [
              "15.2",
              "15.4",
              "15.6",
              "15.7"
            ],
            "details": "â€¢ Docs: threat model, network guard rules, redaction policy, key storage design, operational runbooks.\nâ€¢ Tooling: eslint rule to forbid logging certain keys; commit hook scanning for secrets; template examples for using redaction and key vault APIs.\nâ€¢ Onboarding: short guide for running in offline mode and testing flows.\nâ€¢ Tests: verify lint rules catch samples; ensure pre-commit hook blocks sample secrets.",
            "status": "pending",
            "testStrategy": "CI checks for docs presence; unit tests for custom ESLint rules."
          }
        ]
      },
      {
        "id": 16,
        "title": "Periodic Situation Updates (Ticker)",
        "description": "Broadcast periodic situation updates by time or event cadence to keep clients synchronized.",
        "details": "- Ticker service: cron-like and event-driven triggers\n- Compose updates from world state, mission progress, alliances status\n- WebSocket broadcast on channels; throttle to avoid spam\n- Configurable cadence per campaign",
        "testStrategy": "- TC015: validate cadence and content fidelity vs true state\n- Load test: ensure ticker doesnâ€™t starve main loop\n- Client receives without duplication",
        "priority": "medium",
        "dependencies": [
          3,
          10,
          11,
          9
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for ticker cadence, content fidelity, throttling, and client delivery",
            "description": "Author unit and integration tests that define the acceptance criteria for the Periodic Situation Updates (Ticker), covering time-based cadence, event-driven triggers, content composition from world/mission/alliance state, per-campaign configurable cadence, throttling to prevent spam, WebSocket broadcast on channels, no-duplication guarantees, and non-starvation under load.",
            "dependencies": [],
            "details": "Create test skeletons and assertions before implementation. Map to verification IDs: TC015 (cadence and content fidelity), plus additional internal cases for load and deduplication. Define fixtures to simulate world state, mission progress, and alliance status. Include: 1) Unit tests for scheduler cadence: cron-like spec parsing, jitter, per-campaign overrides; 2) Unit tests for event-driven triggers firing on state changes; 3) Unit tests for composer correctness: assembling situation updates from supplied state snapshots; 4) Unit tests for throttler behavior and backoff; 5) Integration tests: WebSocket broadcast on named channels, multi-client receipt without duplicates, correct routing by campaign; 6) Load test stub to ensure ticker loop does not starve the main loop under configured QPS. Tag tests with TC015 where applicable.",
            "status": "pending",
            "testStrategy": "- Unit: schedule parsing, next-run computation, event trigger debounce, content composer correctness against fixtures (TC015). - Integration: WebSocket broadcast delivery to multiple clients with deduplication and channel routing; verify receipt order/time within tolerance. - Load: simulate N campaigns and M clients; assert main loop metrics remain within thresholds; ensure throttling engages. - Negative: invalid cadence config falls back to default with warning; malformed events don't crash."
          },
          {
            "id": 2,
            "title": "Define ticker domain model and configuration schema",
            "description": "Create data models and configuration schema for ticker, including per-campaign cadence, event trigger specs, channel mapping, throttling parameters, and content template configuration.",
            "dependencies": [
              "16.1"
            ],
            "details": "Implement types/interfaces: TickerConfig { campaignId, cadence: { cron?: string, intervalMs?: number, jitterPct?: number }, events: { enabled: boolean, topics: string[], debounceMs: number }, channels: { updates: string }, throttle: { minIntervalMs: number, burst: number, windowMs: number }, payload: { include: { world: boolean, mission: boolean, alliances: boolean }, redact?: string[] } }. Provide JSON Schema/Zod validation with descriptive errors and defaults (e.g., intervalMs default 30000, jitterPct 0.1, debounceMs 500, throttle.minIntervalMs 2000). Add config loader resolving campaign-level overrides and env defaults. Run tests from 16.1 and fix any schema-related test failures.",
            "status": "pending",
            "testStrategy": "Unit: schema validates good configs, rejects invalid; defaulting behavior; override precedence (global -> campaign)."
          },
          {
            "id": 3,
            "title": "Implement cron-like and interval scheduler with jitter",
            "description": "Create scheduling engine to compute next tick times from cron expressions or fixed intervals, including jitter support and pause/resume hooks.",
            "dependencies": [
              "16.1",
              "16.2"
            ],
            "details": "Implement Scheduler service with APIs: scheduleInterval(campaignId, intervalMs, jitterPct), scheduleCron(campaignId, cronExpr), cancel(campaignId), pause/resume. Use a priority timer wheel or min-heap of next-run timestamps. Ensure drift-correct scheduling (compute next based on previous scheduled time, not actual fire time). Add clock abstraction for testability. Integrate per-campaign instances via TickerConfig. Run the cadence unit tests; adjust to meet time tolerance (e.g., Â±5%).",
            "status": "pending",
            "testStrategy": "Unit: next-run computation for various crons, jitter bounds, pause/resume, cancellation; fake timers for deterministic checks (TC015 cadence aspect)."
          },
          {
            "id": 4,
            "title": "Implement event-driven trigger subsystem with debounce",
            "description": "Build event listeners for world, mission, and alliance state topics that can trigger updates based on configured topics with debouncing and deduplication.",
            "dependencies": [
              "16.1",
              "16.2"
            ],
            "details": "Create EventTrigger service that subscribes to message bus topics (e.g., world.updated, mission.progressed, alliances.changed). Implement debounce per campaign/topic using timers keyed by campaignId+topic with debounceMs from config. Coalesce multiple events during debounce window into one trigger with merged context (e.g., union of changed entity IDs). Provide backpressure: cap pending triggers and drop oldest with metrics logging. Run tests for event trigger firing and debounce behavior.",
            "status": "pending",
            "testStrategy": "Unit: fires once per debounce window; multiple topics produce separate triggers; disabled events do not fire; malformed events handled safely."
          },
          {
            "id": 5,
            "title": "Implement situation update composer",
            "description": "Create a deterministic composer that assembles an update payload from world state, mission progress, and alliance status, with optional redaction and templated summary text.",
            "dependencies": [
              "16.1",
              "16.2"
            ],
            "details": "Design Composer with interface compose(campaignId, snapshot): returns { campaignId, ts, seq, summary, world, mission, alliances, version }. Pull snapshot from provided state accessors. Apply payload.include flags and redact fields listed in config.redact. Implement summary templates with i18n-ready tokens and length guard (e.g., 140â€“280 chars). Increment a per-campaign monotonic sequence number for deduplication. Ensure stable field ordering for test assertions. Run content fidelity tests from 16.1.",
            "status": "pending",
            "testStrategy": "Unit: given seeded fixtures, composer matches expected payload (TC015 content fidelity); redaction removes configured paths; sequence increments correctly."
          },
          {
            "id": 6,
            "title": "Build throttling and rate control",
            "description": "Implement per-campaign throttle to prevent spam from time and event bursts, enforcing minimum intervals and token-bucket style burst limits.",
            "dependencies": [
              "16.1",
              "16.2",
              "16.3",
              "16.4",
              "16.5"
            ],
            "details": "Introduce Throttler with config throttle: { minIntervalMs, burst, windowMs }. Use a token bucket per campaign: tokens refill at burst/windowMs, capped at burst. Allow pass if lastSentAt older than minIntervalMs and tokens available; else queue last-update-only or drop with metric depending on policy. Integrate with Scheduler and EventTrigger so both routes pass through Throttler before publish. Run throttling unit tests and integration tests to confirm reduced spam without starving.",
            "status": "pending",
            "testStrategy": "Unit: respects minInterval and burst semantics; boundary conditions around window refill. Integration: burst of events results in <= allowed publishes; ensures last event eventually published."
          },
          {
            "id": 7,
            "title": "Implement WebSocket channel broadcasting with deduplication",
            "description": "Broadcast updates on per-campaign channels over WebSocket, ensuring no duplicates and correct client routing.",
            "dependencies": [
              "16.1",
              "16.2",
              "16.5",
              "16.6"
            ],
            "details": "Create TickerPublisher using existing WebSocket gateway. Channel name from config.channels.updates (e.g., campaign:{id}:ticker). Include payload with seq and hash (e.g., SHA-256 of normalized payload) to support deduplication. Maintain per-campaign lastHash/lastSeq to avoid sending identical payloads twice. Set message type 'ticker.update'. Implement idempotent publish and retry on transient failures with exponential backoff. Run integration tests from 16.1 to verify multi-client receipt and no duplication.",
            "status": "pending",
            "testStrategy": "Integration: multiple clients subscribe and receive exactly one message per update; order preserved by seq. Negative: simulated network retries do not produce duplicates."
          },
          {
            "id": 8,
            "title": "Wire ticker orchestration loop",
            "description": "Compose scheduler, event triggers, composer, throttler, and publisher into a cohesive ticker service managing multiple campaigns.",
            "dependencies": [
              "16.1",
              "16.2",
              "16.3",
              "16.4",
              "16.5",
              "16.6",
              "16.7"
            ],
            "details": "Implement TickerService managing CampaignTicker instances. Each instance registers interval/cron schedules and event subscriptions. On trigger: fetch snapshot, build payload via Composer, pass through Throttler, then publish via Publisher. Ensure isolation per campaign. Add lifecycle methods start(campaignId), stop(campaignId), reloadConfig(campaignId). Provide metrics: ticks_scheduled, triggers_received, composed_ok, throttled, published, dropped_duplicate, errors. Run all existing tests; adjust orchestration to satisfy them.",
            "status": "pending",
            "testStrategy": "Integration: end-to-end trigger to client flow works for multiple campaigns concurrently; stop() halts emits; reloadConfig applies new cadence without restart."
          },
          {
            "id": 9,
            "title": "Add configurable cadence per campaign and admin controls",
            "description": "Expose configuration entry points and admin APIs to set and update cadence and event settings per campaign at runtime.",
            "dependencies": [
              "16.1",
              "16.2",
              "16.8"
            ],
            "details": "Implement Admin API endpoints or CLI: GET/PUT /campaigns/{id}/ticker-config. Validate via schema; persist to config store. On update, call TickerService.reloadConfig(campaignId). Add RBAC checks. Provide audit logs of changes. Update tests to exercise dynamic cadence change and confirm scheduler reconfigures without message loss.",
            "status": "pending",
            "testStrategy": "Integration: change cadence from 30s interval to cron spec and verify emission timing transitions cleanly; permissions enforced; invalid config rejected with clear errors."
          },
          {
            "id": 10,
            "title": "Ensure ticker does not starve main loop under load",
            "description": "Introduce resource isolation and backpressure so ticker work cannot starve the main game loop under heavy load.",
            "dependencies": [
              "16.1",
              "16.8"
            ],
            "details": "Run ticker tasks on a bounded worker pool or queue with priority lower than the main loop. Use asynchronous snapshot retrieval with timeouts and cancellation. Set per-campaign in-flight cap. Add metrics and configurable limits. Execute load tests from 16.1 and tune parameters to meet CPU and latency budgets.",
            "status": "pending",
            "testStrategy": "Load: simulate high event rates across campaigns; assert main loop tick time and GC metrics remain within target; ticker publishes may be throttled but not block main loop."
          },
          {
            "id": 11,
            "title": "Implement persistence for sequence and last-hash state",
            "description": "Persist per-campaign sequence counters and last-hash to survive restarts and avoid duplicates or regressions.",
            "dependencies": [
              "16.1",
              "16.7",
              "16.8"
            ],
            "details": "Add lightweight storage (e.g., Redis or DB table) keyed by campaignId: { seq, lastHash, lastSentAt }. Initialize CampaignTicker from persisted state; flush updates atomically after publish. Handle migration defaults. Update tests to restart service and ensure continuity of seq and dedup behavior.",
            "status": "pending",
            "testStrategy": "Integration: after restart, next seq increments correctly; duplicate suppression still works; no replays unless explicitly requested."
          },
          {
            "id": 12,
            "title": "Observability: metrics, logs, and alerts",
            "description": "Provide comprehensive instrumentation and alerting for ticker performance and correctness.",
            "dependencies": [
              "16.8",
              "16.10",
              "16.11"
            ],
            "details": "Emit Prometheus metrics for scheduling, queue sizes, throttle events, publish counts, errors, and latencies (compose, publish). Structured logs include campaignId, triggerType, seq. Add SLOs and alerts (e.g., zero publishes over 5m during active hours, error rate >1%). Integrate tracing spans across components. Ensure tests assert presence of key metrics in integration runs.",
            "status": "pending",
            "testStrategy": "Integration: verify metrics endpoints expose expected series after simulated activity; log lines include correlation IDs."
          },
          {
            "id": 13,
            "title": "Security and validation hardening",
            "description": "Harden inputs and outputs: validate snapshots, sanitize payloads, enforce channel authorization, and prevent information leakage.",
            "dependencies": [
              "16.2",
              "16.5",
              "16.7",
              "16.8"
            ],
            "details": "Add strict schema validation for composed payloads; enforce max payload size; redact configured fields; verify only authorized clients can subscribe to campaign channels. Fuzz tests for snapshot anomalies. Ensure PII is not broadcast if marked for redaction. Run full test suite.",
            "status": "pending",
            "testStrategy": "Integration: unauthorized client cannot subscribe; payloads pass schema; redaction verified by golden tests."
          },
          {
            "id": 14,
            "title": "Client-side subscription and UI validation tests",
            "description": "Add UI/integration tests ensuring clients subscribe to ticker channels, display updates without duplication, and handle throttled bursts gracefully.",
            "dependencies": [
              "16.7",
              "16.8"
            ],
            "details": "Using Playwright or equivalent, spin up two clients in the same campaign. Subscribe to ticker channel; trigger updates via test hooks. Assert both clients render exactly one card/toast per update, in order, with correct summary. Simulate burst and ensure UI shows latest state without flicker. Tag with TC015 client receipt aspect.",
            "status": "pending",
            "testStrategy": "UI/Integration: subscription success, render correctness, dedup on client, resilience to reconnects."
          },
          {
            "id": 15,
            "title": "Operational runbooks and configuration examples",
            "description": "Document runbooks for configuring ticker cadence, troubleshooting, and capacity planning; provide sample configs per campaign archetype.",
            "dependencies": [
              "16.8",
              "16.9",
              "16.12"
            ],
            "details": "Create docs covering: enabling ticker, cadence options, event topics, throttling tuning, metrics to watch, common errors, and rollback. Provide YAML/JSON examples for slow/medium/fast campaigns. Include procedures for safe config changes during live operations.",
            "status": "pending",
            "testStrategy": "Doc linting and example schema validation in CI; manual review checklist."
          }
        ]
      },
      {
        "id": 17,
        "title": "Content Packs: Import/Export with Signing and Validation",
        "description": "Support signed JSON content packs for worlds, missions, items with schema and signature validation.",
        "details": "- Pack format: manifest.json, assets/, signatures\n- Sign/verify with ed25519 local keys; store public keys whitelist\n- Validate JSON schema; write to content/packs/\n- Import UI flow; export existing campaign content\n- Safe sandbox: no code execution",
        "testStrategy": "- TC016: import/export flows; reject invalid signatures/schemas\n- Unit: schema validation and asset linking\n- Security: path traversal prevention tests",
        "priority": "high",
        "dependencies": [
          4,
          2,
          10,
          8
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for signed content pack import/export (TC016, security, schema, UI)",
            "description": "Create comprehensive unit, integration, and UI tests that define the acceptance criteria for content pack import/export with schema and signature validation, asset handling, and sandbox safety. Include negative tests for signature and schema failures, and path traversal prevention.",
            "dependencies": [],
            "details": "Implement tests first. Cover: 1) Unit tests: a) Schema validation for worlds, missions, items manifests/manifests.json using JSON Schema; b) Ed25519 signature verify success/failure with key whitelist; c) Asset linking rules and missing asset rejection; d) Safe extraction prevents path traversal and symlink escapes; e) No code execution within packs (e.g., .js/.sh ignored); f) Writing to content/packs/ only; g) Public key whitelist CRUD persistence. 2) Integration tests (TC016): a) End-to-end import of a valid signed .zip pack with manifest.json and assets/; b) Export existing campaign content to a pack, sign it, then import back and assert equivalence; c) Reject packs with invalid/unknown signatures; d) Reject invalid schema; e) Clean rollback on partial failures. 3) UI tests: a) Import flow prompts file selection and displays validation summary; b) Export flow allows selecting campaign scope and shows success; c) Error banners for invalid signature/schema. 4) Security tests: path traversal attempts in zip (../, absolute paths), zip bombs (huge zip central directory vs uncompressed), and signature replay with modified payload.",
            "status": "pending",
            "testStrategy": "Use Jest/Vitest for unit tests, Playwright/Cypress for UI, and a temporary filesystem sandbox for integration. Tag key cases as TC016-UT-001.., TC016-IT-001.., TC016-UI-001..; include Security: TC016-SEC-001.. for traversal/zip bomb. Use deterministic fixtures for ed25519 keys and sample packs."
          },
          {
            "id": 2,
            "title": "Design content pack specification and JSON Schemas",
            "description": "Define the content pack structure and JSON Schemas for manifest and domain objects (worlds, missions, items). Document the format, required fields, and constraints.",
            "dependencies": [
              "17.1"
            ],
            "details": "Specify pack layout: root contains manifest.json, assets/ directory with referenced files, signatures/ directory containing detached signatures. Manifest fields: packId (UUID), name, version (semver), type(s) [world|mission|item], createdAt, toolVersion, entries array with per-object metadata {id, kind, schemaVersion, path (JSON file path in pack), assets: [relative asset paths], integrity: SHA256 of object JSON}. Signatures: signatures/manifest.json.sig (ed25519 detached over canonicalized manifest.json), signatures/entries/<entry-id>.sig (optional per-entry). Define JSON Schemas (Draft 2020-12): a) manifest.json; b) world.json; c) mission.json; d) item.json. Include $id and schemaVersion. Add constraints: disallow absolute paths; paths must be normalized and under pack root; asset filenames whitelist (png,jpg,jpeg,webp,ogg,mp3,wav,json). Document signature canonicalization (UTF-8, JSON canonical serializer e.g., RFC8785 or deterministic stable stringify).",
            "status": "pending",
            "testStrategy": "Validate schemas against fixtures in tests from 17.1. Ensure examples pass and counterexamples fail. Version schemas and include backwards compatibility notes."
          },
          {
            "id": 3,
            "title": "Implement Ed25519 key management with whitelist persistence",
            "description": "Create services to generate/import/export local ed25519 keys and maintain a whitelist of trusted public keys for verification.",
            "dependencies": [
              "17.1",
              "17.2"
            ],
            "details": "Implement KeyStore: a) Generate local ed25519 keypair using libsodium/tweetnacl; b) Store private key securely (OS keychain if available, else encrypted at rest); c) Persist public key whitelist with metadata (keyId, label, createdAt, fingerprint) in app config store; d) CRUD operations: add/remove/list; e) Provide sign(data) and verify(data, signature, pubkey) methods; f) Fingerprint: SHA256(pubkey) hex. Expose API for UI to manage whitelist.",
            "status": "pending",
            "testStrategy": "Unit tests: key generation determinism not required but verify key lengths, fingerprint formation, sign/verify roundtrip, whitelist add/remove/list persistence, and rejection when pubkey not in whitelist (TC016-UT-key-001..)."
          },
          {
            "id": 4,
            "title": "Implement JSON canonicalization and signing/verification utilities",
            "description": "Build utilities to canonicalize JSON and perform detached ed25519 signing and verification for manifest and entries.",
            "dependencies": [
              "17.1",
              "17.2",
              "17.3"
            ],
            "details": "Implement canonicalizer using RFC8785 or stable stringify: sort object keys, normalize numbers/booleans/strings, UTF-8 encoding. Create functions: canonicalizeJson(obj) -> Uint8Array; signJson(obj, privateKey) -> signature; verifyJson(obj, signature, publicKey) -> boolean. For entries with integrity hash, ensure signing covers the canonicalized JSON exactly as stored. For manifest, sign the canonicalized manifest.json. Provide file helpers to read JSON, canonicalize, and compute SHA-256 integrity to compare with manifest entries.",
            "status": "pending",
            "testStrategy": "Unit tests: canonicalization stability across equivalent objects, signature ver/invalid with mutated fields, mismatch when whitespace differs but canonical content same passes, integrity hash changes upon mutation (TC016-UT-sig-001..)."
          },
          {
            "id": 5,
            "title": "Safe ZIP reader and extractor with sandboxing",
            "description": "Create a secure ZIP processing module that parses and extracts packs into a temp sandbox, preventing path traversal, symlink escapes, and zip bombs. No code execution.",
            "dependencies": [
              "17.1"
            ],
            "details": "Implement zip reading using a streaming parser. Before extraction, scan entries: reject entries with absolute paths, .. segments, backslashes on non-Windows normalized outside root, or symlinks. Enforce size limits: total uncompressed bytes cap (configurable), per-file cap, entry count cap; detect zip bombs via compression ratio thresholds. Extract to a temporary directory under app cache. Disallow executing any files; ignore executable bits; filter only allowed filetypes. After validation & verification, move into content/packs/<packId-version>/ atomically.",
            "status": "pending",
            "testStrategy": "Security tests from 17.1 should pass: path traversal (../evil), absolute path (/etc/passwd), symlink entries, zip bomb heuristic. Add unit tests for normalization logic across OS path separators (TC016-SEC-001..)."
          },
          {
            "id": 6,
            "title": "Schema validation engine and domain validators",
            "description": "Implement JSON Schema validation for manifest and domain objects with helpful error reporting and version handling.",
            "dependencies": [
              "17.1",
              "17.2"
            ],
            "details": "Use Ajv (Draft 2020-12) with formats and strict mode. Precompile schemas for manifest, world, mission, item. Implement validateManifest(json) and validateEntry(kind, json). Include schemaVersion checks and migrations stub for future versions. Produce user-friendly error messages for UI. Integrate integrity check: compute SHA256 of entry JSON and compare to manifest.integrity.",
            "status": "pending",
            "testStrategy": "Unit tests: valid fixtures pass, invalid required fields/type mismatches fail with clear messages; integrity mismatch rejects; version bump behavior verified (TC016-UT-schema-001..)."
          },
          {
            "id": 7,
            "title": "Content repository writer with atomic install to content/packs/",
            "description": "Implement writing imported packs to the content repository with atomic moves and rollback on failure.",
            "dependencies": [
              "17.1",
              "17.5",
              "17.6"
            ],
            "details": "Create ContentRepo service: a) Staging directory for validated packs; b) Atomic move to content/packs/<packId>/<version>/ with lockfile to prevent races; c) Index file updating a registry of installed packs (packId, version, keys used, install date); d) On failure, clean staging and do not leave partial state; e) Ensure file permissions safe and no executables marked.",
            "status": "pending",
            "testStrategy": "Integration tests: simulate mid-operation failure to assert rollback; verify final layout matches spec; concurrency test with two imports of same pack to ensure one wins and the other reports duplicate (TC016-IT-repo-001..)."
          },
          {
            "id": 8,
            "title": "Import pipeline: verify, validate, and install",
            "description": "Build the end-to-end import pipeline that consumes a .zip, performs all security and validity checks, and installs the pack.",
            "dependencies": [
              "17.1",
              "17.3",
              "17.4",
              "17.5",
              "17.6",
              "17.7"
            ],
            "details": "Pipeline steps: 1) Open zip in sandbox; 2) Locate required files (manifest.json, signatures/manifest.json.sig); 3) Parse manifest; 4) Verify signature against a public key present in whitelist; 5) For each entry, load JSON, validate schema by kind, verify integrity hash; optionally verify per-entry signatures if provided; 6) Validate asset files exist and are within assets/ and match referenced paths; 7) Enforce safe sandbox rules; 8) If all checks pass, install via ContentRepo; 9) Emit structured result with warnings and errors.",
            "status": "pending",
            "testStrategy": "Integration tests (TC016): valid pack imports successfully; invalid signature/schema rejected with clear errors; missing asset rejection; ensure no writes outside content/packs/. UI tests will consume messages."
          },
          {
            "id": 9,
            "title": "Export pipeline: serialize, hash, and sign existing content",
            "description": "Implement export of selected campaign/world/mission/item data into a signed content pack zip with correct layout.",
            "dependencies": [
              "17.1",
              "17.2",
              "17.3",
              "17.4"
            ],
            "details": "Steps: 1) Select objects to export via API filters; 2) Serialize domain objects to stable JSON; 3) Build manifest.json with entries and SHA-256 integrity for each JSON file; 4) Collect referenced assets from repository into assets/; 5) Canonicalize manifest and create detached ed25519 signature using local private key; 6) Optionally include per-entry signatures; 7) Package into .zip with safe paths; 8) Output file named <packId>-<version>.zip.",
            "status": "pending",
            "testStrategy": "Integration tests: export then import round-trip preserves data equivalence; signature verifies; tamper with zip and expect import failure (TC016-IT-export-001..)."
          },
          {
            "id": 10,
            "title": "UI: Import flow with validation summary",
            "description": "Build UI to select a pack file, run import pipeline, and present a clear validation summary, errors, and installed pack details.",
            "dependencies": [
              "17.1",
              "17.8"
            ],
            "details": "UI components: file picker; progress display (parsing, verifying, validating, installing); results panel listing entries, asset counts, signer fingerprint and label, and any warnings/errors. Provide actions: view manifest, view errors, open installed location. Handle large packs with streaming progress updates. Respect safe sandbox (disable execution).",
            "status": "pending",
            "testStrategy": "UI tests (Playwright/Cypress): happy path shows success with details; invalid signature shows error banner and no installation occurs; schema errors surfaced per entry (TC016-UI-import-001..)."
          },
          {
            "id": 11,
            "title": "UI: Export flow with scope selection and signer choice",
            "description": "Build UI to export existing campaign content with selection of scope and signer key, then run export pipeline and offer download.",
            "dependencies": [
              "17.1",
              "17.9"
            ],
            "details": "UI allows: selecting campaign/worlds/missions/items; choose version and pack metadata; pick signer key from local key store; run export; show result including manifest preview, signature fingerprint, counts, and file size; provide Save As dialog. Persist last-used options.",
            "status": "pending",
            "testStrategy": "UI tests: select scope, export completes, file downloaded; invalid configuration (no key) blocks export with guidance; round-trip test pairs with 17.8 (TC016-UI-export-001..)."
          },
          {
            "id": 12,
            "title": "Public key whitelist management UI",
            "description": "Provide UI for managing trusted public keys used to verify content pack signatures.",
            "dependencies": [
              "17.1",
              "17.3"
            ],
            "details": "Implement list/add/remove UI: display key label, fingerprint, createdAt; import public key from file/paste; validate format; prevent duplicates; allow revoke/disable. Expose integration for import pipeline to display which key verified the pack.",
            "status": "pending",
            "testStrategy": "UI tests: add valid key, reject malformed, remove key, verify that import of a pack signed by removed key now fails (TC016-UI-keys-001..)."
          },
          {
            "id": 13,
            "title": "Security hardening: filetype filtering, PII-safe logs, and no code execution",
            "description": "Finalize security controls ensuring only allowed file types are processed, logs are redacted, and no code is executed from packs.",
            "dependencies": [
              "17.1",
              "17.5",
              "17.8"
            ],
            "details": "Implement allowlist-based MIME detection (magic numbers) for assets; block scripts/binaries; ensure logs redact sensitive fields (file paths, key material) and avoid printing JSON secrets; enforce read-only handling of pack contents until installation; disable any dynamic code loading on import; integrate with existing redaction middleware from Task 15 if available.",
            "status": "pending",
            "testStrategy": "Security tests: attempt to include .js/.sh/.exe assets and ensure they are rejected; confirm logs contain redacted fields and no secrets; attempt to trigger code execution via crafted manifest and verify none occurs (TC016-SEC-filetype-001..)."
          },
          {
            "id": 14,
            "title": "Repository indexing and query APIs",
            "description": "Expose APIs to list installed packs, query by kind/version, and fetch entries/assets for use by other modules.",
            "dependencies": [
              "17.1",
              "17.7"
            ],
            "details": "Implement read APIs over the content repo registry: listPacks(), getPack(packId, version), listEntries(packId), getEntryJson(packId, entryId), getAssetStream(packId, path). Enforce read paths within repo root. Provide pagination for large collections.",
            "status": "pending",
            "testStrategy": "Unit/integration tests: install sample pack and ensure query APIs return correct metadata and content; path traversal attempts on getters rejected (TC016-IT-repoapi-001..)."
          },
          {
            "id": 15,
            "title": "Error handling, rollback, and user-facing messages",
            "description": "Standardize error codes, rollback behavior, and user-visible messages for all import/export operations.",
            "dependencies": [
              "17.1",
              "17.8",
              "17.9",
              "17.10"
            ],
            "details": "Define error taxonomy: SIGNATURE_INVALID, SIGNER_UNTRUSTED, SCHEMA_INVALID, INTEGRITY_MISMATCH, ASSET_MISSING, ZIP_UNSAFE, REPO_CONFLICT, EXPORT_FAILED. Map internal exceptions to codes and localized messages. Ensure partial states are rolled back and temporary files cleaned. Surface actionable guidance in UI.",
            "status": "pending",
            "testStrategy": "Integration/UI tests: simulate each error and verify correct code/message shown; inspect filesystem to confirm no partial installs remain (TC016-IT-errors-001..)."
          },
          {
            "id": 16,
            "title": "Performance and scalability tuning",
            "description": "Optimize import/export for large packs with many entries and assets.",
            "dependencies": [
              "17.1",
              "17.8",
              "17.9"
            ],
            "details": "Add streaming hashing and verification; parallelize schema validation with a worker pool; throttle I/O to avoid UI stalls; progress events with percentage and ETA. Add config for size limits and timeouts. Ensure memory usage stays bounded.",
            "status": "pending",
            "testStrategy": "Bench tests: import 1â€“5 GB packs with thousands of assets in a controlled environment; ensure throughput targets and no timeouts; verify correctness not affected (TC016-PERF-001..)."
          },
          {
            "id": 17,
            "title": "Documentation and developer guide",
            "description": "Write developer and user documentation for content pack format, signing, verification, and UI flows.",
            "dependencies": [
              "17.2",
              "17.8",
              "17.9",
              "17.10",
              "17.11",
              "17.12",
              "17.15"
            ],
            "details": "Provide spec docs for pack structure and schemas; CLI/API examples for signing and verifying; screenshots of UI flows; troubleshooting guide mapping errors to fixes; security notes on safe packaging and allowed file types. Include versioning policy and migration guidance.",
            "status": "pending",
            "testStrategy": "Docs linting and example validation: run schema examples through validators; run CLI examples as part of CI to ensure they work (TC016-DOC-001..)."
          }
        ]
      },
      {
        "id": 18,
        "title": "Multi-Campaign Isolation Layer",
        "description": "Ensure full data, assets, vector memories, and schedules isolation for parallel campaigns.",
        "details": "- Context object carries campaign_id; middleware enforces scoping on all queries\n- File cache per-campaign subdirs\n- Realtime namespace per campaign; no cross-broadcasts\n- Clone/Archive flows implemented in APIs",
        "testStrategy": "- TC017: run two concurrent campaigns and verify no leakage across DB queries, caches, WS channels\n- Unit: guard middleware blocks cross-campaign access\n- E2E: clone and archive then verify isolation",
        "priority": "high",
        "dependencies": [
          3,
          2,
          4,
          12,
          8,
          17
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and unit/integration tests for isolation (TC017, TC018, TC019)",
            "description": "Author tests that codify multi-campaign isolation across data queries, file cache, realtime namespaces, vector memories, and schedules. Include: (a) unit tests for middleware scoping by campaign_id and guard rails blocking cross-campaign access; (b) integration/E2E tests that run two concurrent campaigns and verify no leakage across DB queries, caches, and WebSocket channels; (c) API tests for Clone and Archive flows to ensure isolation is preserved post-operation. Map cases to TC017 (parallel isolation), TC018 (clone/archive isolation), and TC019 (schedule/job isolation).",
            "dependencies": [],
            "details": "Create a top-level test plan and scaffolding:\n- Test IDs: TC017: end-to-end isolation across DB, cache, WS; TC018: clone/archive isolation; TC019: schedule/job isolation.\n- Unit tests (server):\n  - Middleware: rejects/filters queries where request context campaign_id does not match resource campaign_id.\n  - Repository layer: all queries require campaign scope; verify parameterized campaign_id use; fail without scope.\n  - File cache helper: resolves paths under campaign-specific subdirs and forbids path traversal between campaigns.\n  - Realtime broker: publishes to `realtime:<campaign_id>` namespace only; verify no cross-broadcasts when subscribed to different namespaces.\n  - Vector memory store: namespaces `campaign:<id>` and `player:<id>` enforced; cross-campaign retrieval returns empty.\n  - Scheduler: jobs tagged with campaign_id; dispatch filters by campaign; ensure no cross-trigger.\n- Integration tests:\n  - Spin up two campaigns A and B with seeded users, assets, vector memories, schedules.\n  - Verify querying A cannot access B records, assets, vectors, or WS messages.\n  - File cache writes in A are not visible in B and vice versa.\n  - WebSocket: two clients subscribe to different namespaces; verify messages do not leak.\n  - Clone Aâ†’A2: verify A2 receives only cloned artifacts under new IDs/namespaces; A remains unaffected; no reference pointers back to A.\n  - Archive B: verify archived campaign becomes read-only; no broadcasts; schedules disabled; no effect on A.\n- Data fixtures: factories for Campaign, Player, Memory, Asset, Schedule; utilities to create WS clients bound to campaign namespace.\n- CI configuration: mark TC017/TC018/TC019; parallelize tests to simulate concurrent campaigns.",
            "status": "pending",
            "testStrategy": "Execute unit tests first to lock guard behavior; then run integration tests bringing up minimal services (DB, cache, WS broker, scheduler). Use coverage thresholds on guard modules (>90%)."
          },
          {
            "id": 2,
            "title": "Implement and enforce context propagation of campaign_id across request lifecycle",
            "description": "Ensure campaign_id from the authenticated principal or request parameters is propagated deterministically through all layers (HTTP, jobs, WS, repositories, file cache, vector memory, and scheduler). Block processing if campaign_id is missing or ambiguous.",
            "dependencies": [
              "18.1"
            ],
            "details": "Implementation guidance:\n- Context object: define `RequestContext { campaignId: string; userId?: string; roles?: string[]; }`.\n- HTTP middleware: extract campaign_id from route param/header/token; validate against user entitlements; attach to RequestContext; reject requests without valid campaign scope (HTTP 400/403).\n- WS connection handshake: require campaign_id param; bind connection to `realtime:<campaignId>` room; store on connection context.\n- Job queue: include campaignId in job payload and in job metadata; worker bootstraps RequestContext per job.\n- Repository base class: require campaignId argument; generic guard that throws if undefined; ensure every method includes scoped filters.\n- Utilities (file cache, vector store, scheduler): accept RequestContext or explicit campaignId; remove unscoped overloads to prevent misuse.\n- Add lint rule or TypeScript types that disallow calling repository methods without campaignId param.",
            "status": "pending",
            "testStrategy": "Run unit tests for context extraction and propagation. Ensure failing paths for missing campaignId. Re-run TC017 unit subset."
          },
          {
            "id": 3,
            "title": "Middleware guards for DB query scoping by campaign_id",
            "description": "Implement DB-layer scoping: every read/write query must include campaign_id filter and writes must set campaign_id. Block cross-campaign access even if primary keys are known.",
            "dependencies": [
              "18.1",
              "18.2"
            ],
            "details": "Implementation guidance:\n- Query builder wrapper: augment with `withCampaignScope(campaignId)` that injects `WHERE campaign_id = ?` for SELECT/UPDATE/DELETE and sets `campaign_id` on INSERT.\n- Row-level security (optional if supported): add DB RLS policy enforcing `current_setting('app.campaign_id')` match; set via per-connection session variable from middleware.\n- Repository audit: refactor repositories to use the scoped builder; remove unsafe methods.\n- Add guard tests for typical entities: Messages, Assets, Players, Schedules, Memories.\n- Add migration checks: ensure tables have campaign_id column and composite indices `(campaign_id, key)` for performance.",
            "status": "pending",
            "testStrategy": "Execute unit tests for middleware guards and repository scoping; run integration DB tests for campaigns A and B performing cross reads/writes expected to fail."
          },
          {
            "id": 4,
            "title": "Per-campaign file cache directories and access controls",
            "description": "Ensure all cached assets are stored under per-campaign subdirectories and cannot be read across campaigns. Prevent path traversal and enforce read/write isolation.",
            "dependencies": [
              "18.1",
              "18.2"
            ],
            "details": "Implementation guidance:\n- Directory structure: `<CACHE_ROOT>/campaigns/<campaignId>/<assetType>/<hash or uuid>`.\n- Helper API: `getCampaignCachePath(campaignId, ...segments)` validates segments (no `..`, no absolute paths) and ensures directory exists with strict permissions.\n- File read/write wrappers require campaignId and enforce path within the campaign root.\n- Garbage collection: clean only within campaign root.\n- Add OS-level permissions if applicable (uid/gid separation in multi-tenant hosts).",
            "status": "pending",
            "testStrategy": "Run unit tests for path resolver/traversal prevention and cross-campaign access denial. Integration: write assets in A and verify they are absent/inaccessible in B."
          },
          {
            "id": 5,
            "title": "Realtime namespaces per campaign; prevent cross-broadcasts",
            "description": "Create isolated realtime namespaces keyed by campaign_id and ensure events emitted in one namespace are never delivered to another.",
            "dependencies": [
              "18.1",
              "18.2"
            ],
            "details": "Implementation guidance:\n- Namespace schema: `realtime:<campaignId>` rooms/topics.\n- On connect: validate campaignId; join only that room; store mapping connectionIdâ†’campaignId.\n- Publish API: requires campaignId; automatically routes to the correct namespace; reject attempts to publish to mismatched campaign.\n- Server-side filters: beforeEmit hook checks message.campaignId matches connection's campaignId.\n- Monitoring: metrics per namespace to detect anomalies.",
            "status": "pending",
            "testStrategy": "Unit: verify publish/subscribe isolation rules. Integration: spawn two WS clients for A and B; publish in A; assert B receives nothing (TC017)."
          },
          {
            "id": 6,
            "title": "Vector memory namespaces with campaign and player isolation",
            "description": "Implement vector memory segregation using explicit namespaces for campaign and player data; enforce retrieval scoped to the callerâ€™s campaign and optional player.",
            "dependencies": [
              "18.1",
              "18.2",
              "18.3"
            ],
            "details": "Implementation guidance:\n- Namespace keys: `campaign:<campaignId>` for shared memory; `player:<playerId>` for per-player; both always tied to campaignId in metadata.\n- Write API requires campaignId; for player memory, also require playerId that is validated within the same campaign.\n- Retrieval API: `retrieve(query, scope)` requires scope âˆˆ {campaign, player}; when player, include both playerId and campaignId; ensure cross-campaign queries return empty.\n- Storage backends: ensure embeddings index is partitioned or filtered by namespace; if single index, always include namespace token in vector metadata and filter pre/post search.\n- Auditing: log namespace and campaignId for writes/reads.",
            "status": "pending",
            "testStrategy": "Unit: namespace enforcement and cross-campaign retrieval returns empty. Integration: seed A and B with distinct vectors; verify isolation holds; align with TC017."
          },
          {
            "id": 7,
            "title": "Scheduler isolation: per-campaign job tagging and dispatch filtering",
            "description": "Ensure scheduled tasks and background jobs are isolated by campaign_id, including triggers, runners, and time-based schedules.",
            "dependencies": [
              "18.1",
              "18.2"
            ],
            "details": "Implementation guidance:\n- Job schema: include `campaignId` and optional `tenantKey` in job payload and indexing.\n- Enqueue API requires campaignId; worker initializes RequestContext and validates job.campaignId.\n- Dispatch filters: workers subscribe to streams filtered by campaignId; prevent a worker from handling jobs of a different campaign context unless explicitly multi-campaign safe.\n- Cron/schedule store: persist schedules with campaignId; when firing, pass campaignId into job creation.\n- Archive state handling: if campaign archived, skip/disable schedules.",
            "status": "pending",
            "testStrategy": "Unit: verify enqueuing without campaignId fails; worker refuses mismatched jobs. Integration: two campaigns with overlapping schedules fire independently (TC019)."
          },
          {
            "id": 8,
            "title": "Clone flow: deep copy campaign data into new isolated campaign",
            "description": "Implement clone API to deep copy campaign-scoped entities (data, assets, vector memories, schedules) into a new campaign with new identifiers and namespaces, ensuring no shared references or cross-links.",
            "dependencies": [
              "18.1",
              "18.3",
              "18.4",
              "18.5",
              "18.6",
              "18.7"
            ],
            "details": "Implementation guidance:\n- Clone plan: create new campaign record; map oldâ†’new IDs; copy DB records with campaign_id set to new; regenerate secrets/tokens.\n- Assets: duplicate files from `<A>` to `<A2>` cache directory; re-hash if necessary; update references.\n- Vector memories: reindex into `campaign:<A2>` namespace; do not share underlying vector IDs.\n- Schedules: duplicate with new identifiers and ensure next-run timestamps preserved or offset per spec.\n- Realtime: create namespace for new campaign; no clients auto-subscribed.\n- Validation: ensure no foreign keys or URLs point to original campaign after clone.",
            "status": "pending",
            "testStrategy": "Integration: TC018 part 1. After clone, assert all artifacts exist under new campaign and none are referenced back to the source. Run WS isolation and cache isolation on cloned campaign."
          },
          {
            "id": 9,
            "title": "Archive flow: enforce read-only state and disable schedules/broadcasts",
            "description": "Implement campaign archive operation that marks campaign as archived and enforces read-only access, disables schedules, and blocks realtime broadcasts for that campaign.",
            "dependencies": [
              "18.1",
              "18.3",
              "18.5",
              "18.7"
            ],
            "details": "Implementation guidance:\n- DB: campaign status field `active|archived`.\n- Middleware: if archived, reject mutating operations (POST/PUT/PATCH/DELETE) with 409/423.\n- Scheduler: on archive, cancel or pause schedules; workers drop jobs with archived campaignId.\n- Realtime: publishing in archived campaign returns error/no-op.\n- File cache: keep assets accessible read-only; block writes.\n- Admin override: explicit maintenance token for unarchive if needed.",
            "status": "pending",
            "testStrategy": "Integration: TC018 part 2. Archive a campaign; verify writes fail, schedules stop, and realtime publish is blocked; reads still scoped and allowed."
          },
          {
            "id": 10,
            "title": "API surface validation: enforce campaign_id requirement on all endpoints",
            "description": "Audit and update all API endpoints to require campaign_id in path or header, validate authorization, and pass context downstream. Add contract tests.",
            "dependencies": [
              "18.2",
              "18.3"
            ],
            "details": "Implementation guidance:\n- OpenAPI: declare campaignId parameter for relevant routes; mark required.\n- Middleware binding: standardize extraction from path `/campaigns/{campaignId}/...` or `X-Campaign-Id` header.\n- Reject endpoints lacking campaignId in definition unless explicitly global/admin.\n- Contract tests: generate client from OpenAPI and assert required parameter presence.",
            "status": "pending",
            "testStrategy": "Run API contract tests and unit tests on middleware extraction; smoke E2E on a few endpoints to ensure context propagation."
          },
          {
            "id": 11,
            "title": "Security hardening: deny and log cross-campaign access attempts",
            "description": "Add centralized denial and security logging for any cross-campaign access attempt across layers (HTTP, WS, jobs, DB), with deterministic messages and redacted sensitive data.",
            "dependencies": [
              "18.2",
              "18.3",
              "18.5"
            ],
            "details": "Implementation guidance:\n- Central Guard: `assertCampaignScope(expected, actual, contextInfo)` throws `ScopeViolationError` with code and correlation ID.\n- Logging: structured logs include campaignId, userId, endpoint, resourceType, action, correlationId; exclude PII.\n- Metrics/alerts: counter for scope violations per endpoint; alert on spikes.\n- Rate limit repeated violations.",
            "status": "pending",
            "testStrategy": "Unit: error type and message content. Integration: simulate cross-campaign requests and verify denial + logs emitted; ensure no data returned (TC017 negative cases)."
          },
          {
            "id": 12,
            "title": "Performance and scalability validation under parallel campaigns",
            "description": "Benchmark isolation mechanisms with multiple concurrent campaigns to ensure acceptable latency/throughput and no contention between namespaces.",
            "dependencies": [
              "18.3",
              "18.4",
              "18.5",
              "18.6",
              "18.7"
            ],
            "details": "Implementation guidance:\n- Load scenarios: N=10 campaigns, M=50 concurrent users each; mixed DB reads/writes, WS messages, vector queries, file cache ops, scheduler triggers.\n- Metrics: p50/p95 latencies per campaign; verify no cross-campaign degradation.\n- Indexing and partitioning: validate composite indices; adjust cache directory structure and vector index sharding if needed.\n- Tune WS rooms and backpressure per namespace.",
            "status": "pending",
            "testStrategy": "Automated load tests; assert latency SLOs and zero cross-campaign events. Keep TC017 as gating checks after load."
          },
          {
            "id": 13,
            "title": "Developer tooling and lint rules to prevent unscoped access",
            "description": "Provide tooling that prevents introducing unscoped repository calls or APIs, including type-level enforcement and linters.",
            "dependencies": [
              "18.2",
              "18.3",
              "18.10"
            ],
            "details": "Implementation guidance:\n- TypeScript: define interfaces where `campaignId` is a required parameter; mark deprecated any unscoped overloads.\n- ESLint custom rule: flag repository calls that lack campaignId argument; forbid `SELECT *` without campaign filter in SQL strings.\n- CI step: run lints and fail on violations.\n- Code templates: generators pre-wire campaignId in new modules.",
            "status": "pending",
            "testStrategy": "Run lint tests with fixtures containing intentional violations; ensure CI fails. Re-run unit tests to ensure no regressions."
          },
          {
            "id": 14,
            "title": "Documentation and runbooks for isolation layer",
            "description": "Produce developer and ops documentation detailing isolation guarantees, required parameters, error codes, and operational procedures for clone/archive.",
            "dependencies": [
              "18.8",
              "18.9",
              "18.10",
              "18.11"
            ],
            "details": "Implementation guidance:\n- Dev docs: context propagation patterns, repository usage, WS namespaces, scheduler tagging, vector namespaces.\n- API docs: OpenAPI examples with campaignId.\n- Ops runbooks: cloning steps, archiving, restoring from backups per campaign, troubleshooting scope violations.\n- Security notes: logging, metrics, alerts, compliance posture.",
            "status": "pending",
            "testStrategy": "Docs linting, link checks; have an internal DRY-RUN using docs to perform clone/archive and verify TC018 steps."
          },
          {
            "id": 15,
            "title": "Final E2E isolation validation suite and CI gating",
            "description": "Integrate TC017â€“TC019 into CI as required gates, running full E2E suite across two or more campaigns on every PR touching isolation-critical code.",
            "dependencies": [
              "18.5",
              "18.6",
              "18.7",
              "18.8",
              "18.9",
              "18.10",
              "18.11",
              "18.12",
              "18.13",
              "18.14"
            ],
            "details": "Implementation guidance:\n- CI workflow: spin ephemeral environment; seed campaigns A and B; execute E2E tests for DB/cache/WS/vector/scheduler isolation; run clone and archive scenarios.\n- Artifacts: collect logs and metrics; fail build on any leakage or guard bypass.\n- Flake control: retries with idempotent steps; timeouts tuned for stability.",
            "status": "pending",
            "testStrategy": "Ensure CI must pass TC017â€“TC019. Periodically chaos-test by running load + E2E concurrently."
          }
        ]
      },
      {
        "id": 19,
        "title": "Scheduling with RRULE, Reminders, and Warmups",
        "description": "Implement campaign schedules with CRUD, recurrence (RRULE), reminders, and pre-session warmups (keys validation, memory prefetch, image pregen).",
        "details": "- Use rrule library for recurrence\n- Schedules table and API /schedules CRUD; optional ICS export\n- Reminder service: local notifications/email optional local SMTP off by default\n- Warmups: validate provider keys, prefetch relevant memories, pre-generate key images; structured logs\n- UI schedule editor integrated into campaign",
        "testStrategy": "- TC018: CRUD+recurrence correctness; reminders fired; warmups executed and logged with success/failure stats\n- Time travel tests using fake timers\n- ICS export validated by parser",
        "priority": "medium",
        "dependencies": [
          2,
          4,
          5,
          12,
          8,
          15
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for schedules CRUD, RRULE recurrence, reminders, warmups, and ICS export (TC018)",
            "description": "Author unit, integration, and UI tests that define acceptance criteria for campaign scheduling: CRUD on /schedules, RRULE evaluation correctness including time zones and exceptions, reminder dispatch timing with fake timers, warmups execution and structured logging, and ICS export validity. Include at least one unit test and one integration/UI test. Tag all with TC018. Do NOT implement production code yet.",
            "dependencies": [],
            "details": "- Tech: Node/Jest or Vitest with ts-node, Supertest for API, Playwright for UI, Sinon/Jest fake timers, an ICS parser (e.g., ical.js), and rrule test vectors.\n- Unit tests:\n  - Model/validator tests for schedule payload shape (RRULE strings, DTSTART, EXDATE, timezone, reminders array, warmups flags).\n  - RRULE expansion tests (daily/weekly/monthly, BYDAY, COUNT/UNTIL, EXDATE, DTSTART in different TZ) comparing expected occurrences.\n  - Reminder scheduler tests: given upcoming occurrence times, ensure reminders fire at offsets (e.g., -15m, -1h) using fake timers; verify de-duplication and idempotency.\n  - Warmups pipeline tests: simulate providers and verify steps (keys validation, memory prefetch, image pregen) are called and log structured entries with success/failure counts.\n  - ICS export tests: parse generated ICS, assert VEVENT fields (UID, DTSTART/DTEND with TZID, RRULE/EXDATE), and round-trip RRULE.\n- Integration tests (API):\n  - CRUD flows on /schedules: create->get->update->list->delete; validate persisted fields and soft-delete if applicable.\n  - Time-travel: create schedule with next occurrence in near future with reminders; advance timers and assert reminder events enqueued and dispatched.\n- UI tests (Playwright):\n  - Open campaign schedule editor, create a recurring schedule, set reminders and warmups, save; verify rendering of upcoming occurrences list.\n  - Accessibility smoke with axe-core.\n- Fixtures: seed campaign/session records; env with SMTP disabled by default and local notification sink.\n- Test IDs: map to TC018 and sub-ids (e.g., TC018-CRUD, TC018-RRULE, TC018-REMINDERS, TC018-WARMUPS, TC018-ICS, TC018-UI).",
            "status": "pending",
            "testStrategy": "Run `pnpm test` for unit/integration with fake timers and `pnpm test:e2e` for Playwright. Tests should fail until implementation exists."
          },
          {
            "id": 2,
            "title": "Design schedules schema, domain model, and migrations",
            "description": "Define DB schema for schedules with recurrence and reminders, including migrations and typed ORM models. Cover timezone, RRULE, EXDATE, reminders, warmups config, and audit fields.",
            "dependencies": [
              "19.1"
            ],
            "details": "- Table schedules:\n  - id (uuid), campaign_id (fk), title, description\n  - dtstart (datetime with tz), dtend (nullable), timezone (IANA string)\n  - rrule (text), exdates (json array of ISO with tz), rdate (optional json)\n  - reminders (json: [{offsetMs:number, channel:'local'|'email'}])\n  - warmups (json: {validateKeys:boolean, prefetchMemories:boolean, pregenImages:boolean})\n  - enabled (boolean), created_at, updated_at, deleted_at (nullable)\n  - metadata (jsonb) for future\n- Indexes: by campaign_id, enabled, next_run_at (if maintained), and GIN on reminders if needed.\n- Consider a materialized next_occurrence cache table or computed view later; start with on-the-fly expansion.\n- ORM models (Drizzle/Kysely) with zod schemas for API validation.\n- Migration scripts up/down; seed example schedules for tests.\n- Update ERD and data access layer interfaces: ScheduleRepo with CRUD and occurrence query.",
            "status": "pending",
            "testStrategy": "Run TC018-CRUD unit/integration tests; ensure schema validation tests pass."
          },
          {
            "id": 3,
            "title": "Implement RRULE parsing/expansion service with timezone and exceptions",
            "description": "Create a service that expands occurrences from RRULE/RDATE/EXDATE with DTSTART and IANA timezone support using rrule library. Provide APIs to get next N occurrences and next occurrence after a timestamp.",
            "dependencies": [
              "19.1",
              "19.2"
            ],
            "details": "- Use rrule library: construct RRuleSet combining RRULE, RDATEs, and EXDATEs.\n- Timezones: store DTSTART as zoned; convert to UTC for storage but preserve timezone for expansion using luxon or date-fns-tz; ensure DTSTART with TZID is honored.\n- API:\n  - getNextOccurrences(schedule, {after: Date, limit: number}) => Date[]\n  - getNextOccurrence(schedule, after) => Date | null\n- Handle COUNT and UNTIL; validate invalid RRULE strings with descriptive errors.\n- Performance: cap expansions (e.g., 1000) and guard against infinite rules.\n- Deterministic tests using fake timers.\n- Logging: debug-level inputs/outputs for TC018 diagnostics.",
            "status": "pending",
            "testStrategy": "Run TC018-RRULE unit tests to verify daily/weekly/monthly patterns, BYDAY, COUNT/UNTIL, EXDATE."
          },
          {
            "id": 4,
            "title": "Build /schedules REST API with validation and CRUD",
            "description": "Expose schedules CRUD endpoints with payload validation, RBAC/ownership checks, and integration with RRULE service for preview of upcoming occurrences.",
            "dependencies": [
              "19.1",
              "19.2",
              "19.3"
            ],
            "details": "- Endpoints:\n  - POST /schedules: create; validate with zod; verify RRULE parses; default warmups false; normalize timezone.\n  - GET /schedules/:id: fetch by id; includes computed preview upcomingOccurrences (e.g., next 5) via RRULE service.\n  - GET /campaigns/:id/schedules: list for campaign; pagination.\n  - PATCH /schedules/:id: partial update; re-validate rule.\n  - DELETE /schedules/:id: soft delete.\n- Auth: ensure campaign-level access per user/session.\n- Serialization: ISO 8601 with timezone; include reminders and warmups configs.\n- Errors: standardized problem+json.\n- Structured logs for create/update/delete with IDs and campaign context.",
            "status": "pending",
            "testStrategy": "Run TC018-CRUD API tests; verify 2xx/4xx flows, validation errors, and preview correctness."
          },
          {
            "id": 5,
            "title": "Implement ICS export endpoint",
            "description": "Provide ICS generation for a schedule or campaign schedules, including RRULE/EXDATE, DTSTART/DTEND with TZID, and UID. Optionally authenticated tokenized URL.",
            "dependencies": [
              "19.1",
              "19.3",
              "19.4"
            ],
            "details": "- Endpoint: GET /schedules/:id.ics and GET /campaigns/:id/schedules.ics.\n- Use ical-generator or node-ical builder to emit VCALENDAR with VEVENT per schedule.\n- Map fields: SUMMARY=title, DESCRIPTION, DTSTART/DTEND with TZID, RRULE string, EXDATEs, UID=schedule.id@app-domain, SEQUENCE from updated_at.\n- Content-Type: text/calendar; CRLF line endings.\n- Option: signed token query for unauthenticated calendar clients; rotateable.\n- Tests parse ICS with ical.js and verify fields and RRULE round-trip.",
            "status": "pending",
            "testStrategy": "Run TC018-ICS tests; ensure parser reads exported files and matches schedule data."
          },
          {
            "id": 6,
            "title": "Develop reminder scheduler and dispatcher",
            "description": "Create a background scheduler that computes upcoming occurrences and schedules reminder jobs at specified offsets; implement dispatch to local notifications and optional email via SMTP (off by default).",
            "dependencies": [
              "19.1",
              "19.3",
              "19.4"
            ],
            "details": "- Components:\n  - ReminderPlanner: periodically scans enabled schedules and computes reminder fire times using RRULE service; persists jobs in reminders_jobs table (id, schedule_id, occurrence_at, fire_at, channel, status, attempts, payload, dedupe_key).\n  - ReminderWorker: processes due jobs, sends via channel adapters.\n- Channel adapters:\n  - local: writes to a notifications table/stream for UI consumption.\n  - email: nodemailer with local SMTP transport disabled by default; config flag to enable.\n- Idempotency: dedupe_key = schedule_id + occurrence_at + offset + channel; enforce unique index.\n- Time: all comparisons in UTC; supports fake timers in tests.\n- Backoff/retry policy with max attempts and DLQ logging.\n- Structured logs for plan, enqueue, dispatch, success/failure counts.",
            "status": "pending",
            "testStrategy": "Run TC018-REMINDERS with fake timers: create schedule with T+10m occurrence and -5m reminder; advance time and assert a single reminder is dispatched with correct payload."
          },
          {
            "id": 7,
            "title": "Implement warmups pipeline (keys validation, memory prefetch, image pre-generation) with structured logging",
            "description": "Build a pre-session warmups executor that runs before each occurrence: validates provider keys, prefetches relevant memories, and pre-generates key images, emitting structured logs and metrics.",
            "dependencies": [
              "19.1",
              "19.5",
              "19.6"
            ],
            "details": "- Trigger: when ReminderWorker dispatches a special 'warmup' job at a configurable lead time (e.g., -10m) or on-demand; alternatively, chain after reminder planning for occurrence.\n- Steps:\n  - Keys validation: use Provider Adapter Framework (Task 5) to check configured adapters are reachable; do not store raw keys; return capability snapshot.\n  - Memory prefetch: query VectorIndex/DB (Task 2) for top-N memories by campaign/session context; warm cache layer.\n  - Image pregen: call ImageGenAdapter to pre-generate commonly used images; store in images cache and index to campaign assets.\n- Concurrency: run steps in parallel with bounded pool; collect per-step success/failure.\n- Logging: structured event per step with schedule_id, occurrence_at, step, duration_ms, success, error.\n- Config: warmups flags on schedule decide which steps to execute.",
            "status": "pending",
            "testStrategy": "Run TC018-WARMUPS: simulate providers and vector index with fakes; trigger warmups and assert each step executed conditionally with logs and success/failure stats."
          },
          {
            "id": 8,
            "title": "Integrate reminder and warmup events with UI notifications stream",
            "description": "Expose a notifications feed for the UI to consume local reminders and warmup results for campaigns, enabling surface in the schedule editor and lobby.",
            "dependencies": [
              "19.4",
              "19.6",
              "19.7"
            ],
            "details": "- Server: SSE or WebSocket endpoint /notifications subscribing to campaign_id topics.\n- Message schema: {type:'reminder'|'warmup', scheduleId, occurrenceAt, title, severity, details}.\n- Persistence: notifications table for replay; cursor-based pagination.\n- UI: lightweight badge/ toast hooks to display incoming reminders and warmup statuses; integrate into existing UI shell (Task 4) surfaces.\n- Security: authorize by campaign membership.",
            "status": "pending",
            "testStrategy": "Extend TC018-REMINDERS integration/UI to assert a reminder appears in UI via notifications; verify warmup result message received."
          },
          {
            "id": 9,
            "title": "Build Schedule Editor UI integrated into campaign view",
            "description": "Implement a React-based schedule editor to create, update, and delete schedules with RRULE builder, timezone picker, reminders, warmups toggles, and preview of upcoming occurrences.",
            "dependencies": [
              "19.4",
              "19.8"
            ],
            "details": "- Components:\n  - ScheduleList: list schedules per campaign with enable/disable, next occurrence, and actions.\n  - ScheduleForm: fields for title, description, DTSTART/DTEND pickers, timezone, RRULE builder (frequency, interval, BYDAY, COUNT/UNTIL), EXDATE editor, reminders editor, warmups toggles.\n  - Preview panel showing next 5 occurrences using API preview.\n- Accessibility: keyboard navigation, labels, contrast tokens; validation errors inline.\n- State: use existing store (Zustand/RTK); optimistic updates with rollback on error.\n- ICS export buttons linking to .ics endpoints.\n- Structured analytics events on save/delete.",
            "status": "pending",
            "testStrategy": "Playwright UI test (TC018-UI): create a weekly schedule with a -15m reminder and warmups enabled; verify list shows next occurrence, notifications appear on time with fake timers, and form validation works."
          },
          {
            "id": 10,
            "title": "Add admin observability: logs, metrics, and dashboards for schedules/reminders/warmups",
            "description": "Expose structured logs and counters for schedule planning, reminder dispatch, warmup steps, and failures. Provide a simple dashboard view or API for monitoring.",
            "dependencies": [
              "19.6",
              "19.7"
            ],
            "details": "- Metrics: counters (reminders_planned, reminders_sent, warmups_started/succeeded/failed), gauges (pending_jobs), histograms (dispatch_latency_ms, warmup_step_duration_ms).\n- Export to existing logging/metrics sinks (pino + Prometheus if available) and expose /metrics endpoint.\n- Admin UI panel: table of recent events with filters by campaign/schedule and status.\n- Alerts: optional threshold-based warnings surfaced in admin panel.\n- Correlation IDs: propagate schedule_id and occurrence_at across logs.",
            "status": "pending",
            "testStrategy": "Unit tests assert metrics increment; integration test queries /metrics to contain expected counters after simulated runs."
          },
          {
            "id": 11,
            "title": "Hardening: idempotency, race conditions, and backfill handling",
            "description": "Ensure scheduler handles restarts, avoids duplicate reminders, and can backfill missed reminders after downtime with safe deduplication.",
            "dependencies": [
              "19.6"
            ],
            "details": "- Enforce unique index on reminders_jobs.dedupe_key; worker uses SELECT ... FOR UPDATE / transactional update to mark in-progress.\n- On startup, scan for jobs with fire_at <= now and status=pending; process with rate limits.\n- Graceful shutdown: drain worker.\n- Race tests: simulate concurrent workers; ensure only one dispatch occurs.\n- Backfill policy: time window cap (e.g., last 24h) to avoid storm.",
            "status": "pending",
            "testStrategy": "Integration tests create overlapping jobs and run two workers; assert single dispatch. Advance time over downtime window and verify capped backfill."
          },
          {
            "id": 12,
            "title": "Documentation and examples",
            "description": "Write developer and user docs: API contracts, payload examples, RRULE guidance, ICS subscriptions, reminder channels config, warmups behavior, and troubleshooting.",
            "dependencies": [
              "19.4",
              "19.5",
              "19.6",
              "19.7",
              "19.9",
              "19.10",
              "19.11"
            ],
            "details": "- README sections: schedules schema, example POST payloads, RRULE cheat sheet, timezone caveats, ICS examples, enabling email reminders, warmups flags and logs.\n- Include curl and UI walkthrough GIFs.\n- Provide example RRULEs (weekly on Mon 9am TZ) and their preview outputs.\n- Troubleshooting: common RRULE errors, SMTP off-by-default note, how to read structured logs.",
            "status": "pending",
            "testStrategy": "Docs linting; sample commands executed in CI to ensure examples remain valid."
          }
        ]
      },
      {
        "id": 20,
        "title": "CRDT Realtime for Shared Notes/Map/Inventory",
        "description": "Add CRDT-based collaboration for shared notes/map/inventory with convergence over WebSockets.",
        "details": "- Choose Yjs or Automerge; define documents per campaign/session\n- Sync protocol over existing WS; persistence snapshots in DB\n- Permissions: role-based access to docs\n- Conflict resolution tested via CRDT invariants",
        "testStrategy": "- Convergence tests under random edits\n- Disconnect/reconnect merges without data loss\n- Performance with 10+ concurrent editors locally",
        "priority": "medium",
        "dependencies": [
          3,
          2,
          4
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and unit/integration tests for CRDT realtime (TC001â€“TC006)",
            "description": "Before implementation, codify the core acceptance criteria and create failing tests covering convergence, conflict resolution, permission enforcement, persistence, and WS sync for notes/map/inventory documents.",
            "dependencies": [],
            "details": "Create a test plan mapping to verification IDs:\n- TC001 Convergence: Random concurrent edits across 3 replicas converge to identical state for notes, map annotations, and inventory.\n- TC002 Reconnection: Disconnect/reconnect with buffered ops results in convergence without data loss.\n- TC003 Permissions: Role-based access enforced (viewer: read-only, editor: mutate allowed docs, GM: full access). Unauthorized ops are rejected and do not apply.\n- TC004 Persistence: Snapshot and incremental updates persisted and restored produce identical document state hashes.\n- TC005 Performance: Local 10+ simulated editors maintain <150ms average latency for visible updates and complete convergence within 2s after burst.\n- TC006 Protocol Validations: WS crdt-sync schema validation and backpressure handling; duplicate/out-of-order messages handled idempotently.\nImplement tests:\n- Unit tests (Jest/Vitest) for CRDT object composition (notes text, map layers/markers, inventory items), merge semantics, and invariants.\n- Property-based tests for convergence under random operation interleavings (fast-check).\n- Integration tests using ws/superwstest to spin up WS gateway (Task 3 dependency mocked if needed) with 3â€“5 clients performing edits and network partitions.\n- Persistence roundtrip tests using SQLite (Task 2) with snapshot+incremental log.\n- Permission tests via mocked auth contexts and role matrices.\nDefine helper utilities: Replica harness, op generators for each document type, deterministic seed for reproducibility, state hash function (stable JSON + hash).",
            "status": "pending",
            "testStrategy": "Start with red tests. Use seed-based fuzzing (N=200 sequences). Add metrics assertions for latency using fake timers where applicable."
          },
          {
            "id": 2,
            "title": "Select CRDT library and document model (Yjs vs Automerge) and scaffold types",
            "description": "Evaluate Yjs vs Automerge for text, map structures, and inventory; decide and scaffold TypeScript types and document schemas per campaign/session.",
            "dependencies": [
              "20.1"
            ],
            "details": "Decision criteria: performance with 10+ editors, text CRDT maturity, binary encoding, GC/tombstone handling, conflict semantics, ecosystem.\nRecommendation: Choose Yjs for production-grade text and map/list structures with awareness of optimized sets and composition techniques; model complex docs via CRDT object composition and CRDT-valued maps.[2][3] Adopt techniques to avoid tombstones where possible.[1]\nDefine document types:\n- NotesDoc: Y.Text for rich/plain text per note; metadata registers (title LWW-style), map of notes within session.\n- MapDoc: map layers (Y.Map), list of markers (Y.Array of objects with id, pos, label), per-marker metadata as nested maps; treat as list/set of CRDTs.[3]\n- InventoryDoc: Y.Map of itemId -> object (qty counter, props LWW registers), collection modeled as CRDT map.[4][5]\nNamespaces: campaign:<id>/session:<id>/<doc-kind>/<doc-id>.\nCreate TypeScript interfaces for DocManager, DocHandles, and serialization boundaries.",
            "status": "pending",
            "testStrategy": "Run TC001 unit tests focused on type-level constraints and basic merge semantics using Yjs in-memory providers until tests pass."
          },
          {
            "id": 3,
            "title": "Design CRDT message schema and zod validators for crdt-sync",
            "description": "Specify and implement the wire protocol messages for CRDT sync over existing WebSockets, including schemas and versioning.",
            "dependencies": [
              "20.1",
              "20.2"
            ],
            "details": "Define message types (all include protocolVersion, campaignId, sessionId, docKind, docId):\n- crdt-sync-init: client->server subscribe with auth token and role.\n- crdt-sync-update: server<->client binary update payload (Yjs update Uint8Array base64-encoded), seq, timestamp, replicaId.\n- crdt-sync-snapshot-req/resp: request snapshot and receive compressed snapshot blob + clock/vector info.\n- crdt-sync-ack: acknowledge receipt with seq; supports backpressure.\n- crdt-sync-error: validation or permission errors.\nImplement zod schemas shared between client/server; integrate with existing message routing from Task 3. Include idempotency keys and causal metadata fields informed by CRDT composition guidance.[2][3]\nAdd schema versioning and feature flags per doc kind.",
            "status": "pending",
            "testStrategy": "Execute TC006 protocol validation tests: invalid messages rejected, duplicates ignored, out-of-order updates applied via Yjs merge to same state."
          },
          {
            "id": 4,
            "title": "Implement CRDT DocManager and in-memory replica harness",
            "description": "Create a DocManager that opens/creates Yjs documents per namespace, applies updates, emits deltas, and integrates with the replica test harness.",
            "dependencies": [
              "20.1",
              "20.2",
              "20.3"
            ],
            "details": "Components:\n- DocRegistry keyed by namespace -> Y.Doc, with per-doc awareness of substructures (notes/map/inventory) using composition patterns.[2]\n- ApplyUpdate(doc, update, origin) and EncodeUpdate events for outgoing changes.\n- State hashing function for test equality (deterministic stable stringify + hash).\n- ReplicaHarness: create N replicas, simulate random ops for notes/map/inventory, collect updates, and apply across replicas to verify convergence (inspired by composition and collection patterns).[2][3]\n- GC/awareness: disable heavy GC during tests; expose ability to encode state vector and diff updates.\nEnsure no tombstone leaks by relying on Yjs internal optimizations and documented techniques to avoid unbounded metadata.[1]",
            "status": "pending",
            "testStrategy": "Run TC001 property tests using harness; ensure all replicas converge after randomized operation sequences across structures."
          },
          {
            "id": 5,
            "title": "Integrate with WebSocket Gateway channels and presence",
            "description": "Wire DocManager updates to WS gateway (Task 3) using crdt-sync topics; manage joins/leaves, subscriptions, and presence for editors.",
            "dependencies": [
              "20.1",
              "20.3",
              "20.4"
            ],
            "details": "Server:\n- On crdt-sync-init: validate auth, role, campaign/session membership; subscribe connection to doc topic; send snapshot+state vector; backfill missed updates.\n- On crdt-sync-update: validate schema, permissions, apply to DocManager, broadcast diff to subscribers except origin.\n- Presence: maintain editor list per doc; heartbeat using existing ping; publish presence changes.\nClient SDK:\n- Connect, subscribe, apply incoming updates to local Y.Doc, encode local changes and send updates with backpressure-aware batching.\n- Reconnect tokens to resume missed seq range (Task 3 capability).\nUse schemas from 20.3 and channels defined in Task 3.",
            "status": "pending",
            "testStrategy": "Run integration tests: multiple clients join/leave, perform concurrent edits; verify TC002 reconnect merges and TC006 backpressure/acks via simulated packet loss."
          },
          {
            "id": 6,
            "title": "Persistence: snapshotting and incremental update log in SQLite",
            "description": "Persist Y.Doc snapshots and incremental updates to local SQLite with compaction and restore paths.",
            "dependencies": [
              "20.1",
              "20.4",
              "20.5"
            ],
            "details": "Schema:\n- crdt_documents(docKey, kind, campaignId, sessionId, version, snapshotBlob, stateVector, updatedAt)\n- crdt_updates(id, docKey, seq, updateBlob, createdAt)\nImplement:\n- On interval or size threshold, snapshot current doc (encodeStateAsUpdate from empty) and store state vector; truncate updates older than latest snapshot seq.\n- On startup or client subscribe, load latest snapshot + subsequent updates to hydrate DocManager.\n- Ensure atomic writes using transactions; compress blobs (gzip/brotli).\n- Provide compaction job.\nMap composition of nested CRDTs into single Y.Doc snapshot consistent with object composition guidance.[2]",
            "status": "pending",
            "testStrategy": "Execute TC004 persistence tests: write/read roundtrip yields identical state hash; restart server and verify hydration; simulate crash between update and snapshot and ensure recovery."
          },
          {
            "id": 7,
            "title": "Role-based permissions and access control for CRDT operations",
            "description": "Enforce role-based permissions at message ingress and document mutation boundaries; implement doc-level ACLs.",
            "dependencies": [
              "20.1",
              "20.3",
              "20.5"
            ],
            "details": "Define roles: viewer, editor, GM/admin. Policy matrix:\n- viewer: subscribe read-only; cannot send crdt-sync-update.\n- editor: can update allowed docs within campaign/session.\n- GM: can create/delete docs, manage map layers, force overwrite metadata.\nImplement middleware: validate on crdt-sync-init and crdt-sync-update using campaign/session membership and doc ACLs. For inventory, enforce item-specific constraints (qty >= 0) via pre-apply checks; reject invalid ops.\nEmit crdt-sync-error with codes (PERMISSION_DENIED, INVALID_OP).",
            "status": "pending",
            "testStrategy": "Run TC003 tests: attempt unauthorized updates, ensure no state change and error returned; validate role transitions at runtime."
          },
          {
            "id": 8,
            "title": "Map document structures and operations",
            "description": "Implement high-level operations for collaborative map: layers, markers, shapes with IDs; ensure list/set semantics and stable IDs.",
            "dependencies": [
              "20.2",
              "20.4",
              "20.5"
            ],
            "details": "Within MapDoc (Y.Doc):\n- layers: Y.Map<string, Layer>, where Layer has Y.Map props and Y.Array markerIds.\n- markers: Y.Map<string, Marker>, Marker: { id, position {x,y}, label (Y.Text), props } using object composition of CRDTs.[2][3]\n- shapes: optional Y.Array of shape objects with control points.\nProvide API: addLayer, renameLayer (LWW), addMarker (generate id), moveMarker, editLabel, deleteMarker (tombstone-free by removing entry), reorder layers using Y.Array.\nEnsure independent operations act on independent state to preserve intention.[3]\nWire UI events to these APIs in client SDK.",
            "status": "pending",
            "testStrategy": "Unit tests: concurrent moves and label edits converge; deleting a marker concurrently with label edit results in delete-wins behavior as specified. Integration test: 3 clients rapidly move the same marker and edit labels; verify TC001/TC002 convergence."
          },
          {
            "id": 9,
            "title": "Notes document structures and operations",
            "description": "Implement collaborative notes with Y.Text, titles, and note collections per session.",
            "dependencies": [
              "20.2",
              "20.4",
              "20.5"
            ],
            "details": "Within NotesDoc:\n- notes: Y.Map<noteId, { title: Y.Text or LWW string, body: Y.Text, tags: Y.Array<string> }>. Prefer Y.Text for title if collaborative inline editing; otherwise LWW register semantics for last-writer-wins using logical time.[4]\nAPIs: createNote, editTitle, editBody (apply Y.Text deltas), addTag/removeTag, deleteNote.\nUse CRDT object composition to keep title/body independent.[2]",
            "status": "pending",
            "testStrategy": "Unit tests: concurrent title/body edits; delete concurrent with edit; collection add/remove races yield intended behavior. Integration: 3 clients edit same note; verify convergence and low latency (TC001/TC005)."
          },
          {
            "id": 10,
            "title": "Inventory document structures and operations",
            "description": "Implement collaborative inventory with quantities, item properties, and move operations between containers.",
            "dependencies": [
              "20.2",
              "20.4",
              "20.5",
              "20.7"
            ],
            "details": "Within InventoryDoc:\n- items: Y.Map<itemId, { name (LWW), qty (integer counter via composed register with invariants), props (Y.Map), containerId (LWW) }>. Use object composition; avoid physical timestamps pitfalls by using logical clocks/Lamport semantics via CRDT library rather than wall clocks.[5]\nAPIs: addItem, updateQty(delta), moveItem(containerId), updateProps, deleteItem. Ensure qty never negative; reject at ingress (permission layer) and clamp in client UI.\nOptionally model qty using add-wins counter if needed.",
            "status": "pending",
            "testStrategy": "Unit tests: concurrent qty updates merge associatively; move and rename conflicts resolved per LWW policy; deletion wins vs prop edits. Integration: 3 clients adjust quantities and move items; verify TC001/TC003."
          },
          {
            "id": 11,
            "title": "Client SDK: CRDT binding and offline queue",
            "description": "Create client-side bindings to UI models, manage local Y.Doc, offline queueing, and reconnection with state vector diffs.",
            "dependencies": [
              "20.5",
              "20.8",
              "20.9",
              "20.10"
            ],
            "details": "Implement a ClientDocBinding with:\n- Local Y.Doc per namespace, awareness API for cursors/presence (optional), and event listeners mapping to app state.\n- Outbox queue for updates when offline; on reconnect, compute diff using state vector and send minimal updates.\n- Batch and debounce local changes; apply server acks for backpressure.\n- Expose hooks (useNotesDoc, useMapDoc, useInventoryDoc) for UI.\n- Handle snapshot hydration and late-join using snapshot + incremental updates.",
            "status": "pending",
            "testStrategy": "UI/integration tests: simulate offline edits, then reconnect; verify TC002 convergence and no data loss. Measure latency to satisfy TC005 locally."
          },
          {
            "id": 12,
            "title": "Conflict resolution invariant tests and fuzzing harness",
            "description": "Extend property-based tests to cover edge-case invariants and long sequences with deletes, renames, and counter updates.",
            "dependencies": [
              "20.4",
              "20.8",
              "20.9",
              "20.10"
            ],
            "details": "Add fuzz suites per doc kind:\n- Notes: interleaved title/body edits, deletes, recreates.\n- Map: concurrent move+delete+rename, layer reorder conflicts.\n- Inventory: qty increments/decrements with deletes/moves.\nUse fast-check to generate sequences; verify invariants: convergence, no negative qty, referential integrity (markerId in layer list implies marker exists), and independence of unrelated operations per composition principles.[2][3]",
            "status": "pending",
            "testStrategy": "Run 1k random sequences per suite with deterministic seeds; capture minimal counterexamples on failure. Maps to TC001 and conflict-invariant coverage."
          },
          {
            "id": 13,
            "title": "Performance tuning and load tests with 10+ editors",
            "description": "Profile server/client under simulated load, tune message batching, compression, and apply rate limits.",
            "dependencies": [
              "20.5",
              "20.6",
              "20.11"
            ],
            "details": "Create a load test script spinning 12 clients per doc, performing paced edits. Measure:\n- Update apply latency, CPU, memory, bandwidth.\nTune:\n- Batch updates per 50â€“100ms, coalesce Yjs updates, enable compression on WS frames, snapshot compaction cadence, and rate limit per connection.\nEnsure backpressure and retries interact correctly with crdt-sync-ack.",
            "status": "pending",
            "testStrategy": "Satisfy TC005 thresholds. Record traces and ensure no dropped updates; convergence after bursts within 2s."
          },
          {
            "id": 14,
            "title": "Admin/GM tools for document ACLs and lifecycle",
            "description": "Implement APIs/UI hooks to create/delete docs, manage ACLs, and inspect state for debugging.",
            "dependencies": [
              "20.7",
              "20.6"
            ],
            "details": "Server endpoints or WS messages: createDoc, deleteDoc, setAcl(role matrix), listDocs. Persist ACLs tied to campaign/session. Provide doc inspection (state vector, snapshot size) for debugging.",
            "status": "pending",
            "testStrategy": "Integration tests: GM can create/delete and set ACLs; viewers cannot. Verify persistence restores ACLs correctly (TC003/TC004)."
          },
          {
            "id": 15,
            "title": "Observability and metrics for CRDT subsystem",
            "description": "Add logging and metrics for sync events, errors, snapshot sizes, and convergence timing.",
            "dependencies": [
              "20.5",
              "20.6",
              "20.13"
            ],
            "details": "Emit metrics: updates/sec, bytes sent, snapshot size, compaction frequency, apply latency, reject counts by reason. Structured logs for crdt-sync-error. Dashboards or console summaries for dev.",
            "status": "pending",
            "testStrategy": "Assert metrics counters change as expected during integration/load tests; budgets not exceeded under TC005."
          },
          {
            "id": 16,
            "title": "Security hardening: validation, quotas, and sandboxing",
            "description": "Ensure binary payload limits, schema version gating, and defensive handling against malformed or abusive clients.",
            "dependencies": [
              "20.3",
              "20.5",
              "20.7"
            ],
            "details": "Implement per-connection quotas (messages/sec, bytes/min), max doc size, max update size, and snapshot rate limiting. Schema version checks; reject unknown docKind/docId formats. Sanitize labels/text limits. Kill-switch feature flag to disable CRDT per campaign.",
            "status": "pending",
            "testStrategy": "Negative integration tests: send oversized payloads, invalid schema versions, rapid-fire updates; verify rejections and no server instability (extends TC006)."
          },
          {
            "id": 17,
            "title": "Documentation and developer guide",
            "description": "Produce developer docs detailing document schemas, sync protocol, ACLs, persistence, and testing procedures.",
            "dependencies": [
              "20.2",
              "20.3",
              "20.5",
              "20.6",
              "20.7",
              "20.11",
              "20.12",
              "20.13"
            ],
            "details": "Write docs: rationale for Yjs selection with references to composition and collection patterns, message schemas, example flows, persistence compaction, ACL configuration, and troubleshooting. Include runbooks for tests and load harness.",
            "status": "pending",
            "testStrategy": "Docs linting and example snippets compiled; follow a walkthrough to run TC001â€“TC006 tests successfully."
          }
        ]
      },
      {
        "id": 21,
        "title": "GM Orchestration Loop and Narration Beats",
        "description": "Implement GM loop delivering 2â€“4 sentence beats with high agency, integrating rules, missions, memory, and adapters.",
        "details": "- Prompt templates with tools: rules.check, mission.advance, memory.query, image.request, tts.speak\n- Streaming LLM responses; latency target <3s median via prompt compaction and warmups\n- Tool schema validation with zod; retries on invalid\n- Periodic insert of situation updates",
        "testStrategy": "- Latency benchmarks; synthetic sessions verify median <3s locally\n- Tool invocation unit tests with strict schema validation\n- E2E: players make actions; loop produces beats and advances mission",
        "priority": "high",
        "dependencies": [
          5,
          10,
          11,
          12,
          8,
          6,
          7,
          16,
          14
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write acceptance tests for GM loop, beats, tools, and latency (TC011â€“TC015)",
            "description": "Create a comprehensive test suite that encodes the core acceptance criteria for the GM orchestration loop: produces 2â€“4 sentence narration beats with high agency; integrates rules.check, mission.advance, memory.query, image.request, tts.speak; streams responses; validates tool schemas with zod and retries on invalid; periodically inserts situation updates; and meets a local median latency target <3s under synthetic sessions.",
            "dependencies": [],
            "details": "Implement unit tests and integration tests before any implementation. Include:\n- Unit tests:\n  - TC011: Beat length and agency detection. Assert output is 2â€“4 sentences, imperative/decisive tone tokens present, and no meandering qualifiers.\n  - TC012: Tool invocation schema validation. Mock adapters; validate zod schemas; assert retries on invalid payload; assert backoff policy and max retry cap.\n  - TC013: Prompt compaction logic. Given long memory/missions/rules, assert compactor trims to token budget while preserving priority content.\n  - TC014: Situation updater cadence. Assert periodic inserts occur every N beats or T ms, configurable.\n- Integration/E2E tests:\n  - TC015: Synthetic player actions drive loop; verify mission advances, rules checked, memory queried, optional image.request queued, tts.speak called with produced beat; stream tokens to client; measure local median time-to-first-token and time-to-final <3s across 30 runs.\n- Performance tests:\n  - Harness to simulate LLM with controllable latency distribution and token rate to measure orchestration overhead. Report median and p95.\n- Testing infrastructure:\n  - Jest/Vitest for unit, Playwright for E2E stream verification, a fake WebSocket/feed recorder for streaming assertions, and a mock clock for periodic inserts.\n- Include fixtures: sample rules, missions, memory snapshots, adapter schemas, and long-context samples for compaction tests.",
            "status": "pending",
            "testStrategy": "Run CI job stage `21-tests-acceptance` gating implementation. Fail build if TC011â€“TC015 do not pass. Collect latency metrics artifacts and assert thresholds."
          },
          {
            "id": 2,
            "title": "Define tool adapter interfaces and zod schemas with strict validation",
            "description": "Create typed interfaces and zod schemas for rules.check, mission.advance, memory.query, image.request, tts.speak, plus a common ToolInvocation envelope and result shape with error codes for retries.",
            "dependencies": [
              "21.1"
            ],
            "details": "Implement a tools module:\n- Common types: ToolName, ToolInvocation {id, name, input, correlationId}, ToolResult {ok, output|error}\n- zod schemas per tool with explicit min/max constraints and enums.\n- Validation helpers: validateOrThrow(name, payload) returning typed input.\n- Map tool -> adapter function signature and schema.\n- Add unit tests extending TC012 to check invalid payloads produce schema errors; ensure error messages include jsonPath.\n- Provide a mock-adapters package for tests with controllable success/failure.",
            "status": "pending",
            "testStrategy": "Run all tests; ensure TC012 passes and coverage includes both success and invalid cases."
          },
          {
            "id": 3,
            "title": "Implement retry policy with bounded backoff for invalid/failed tool calls",
            "description": "Add a generic retry wrapper with exponential backoff and jitter specifically for schema-invalid and adapter failure cases, with limits to avoid latency inflation.",
            "dependencies": [
              "21.1",
              "21.2"
            ],
            "details": "Create retryToolCall(toolFn, options) with:\n- Policies: maxRetries (default 2), baseDelay 60â€“120ms jitter, stop on non-retriable errors (e.g., rules violation definitive).\n- On schema invalid: attempt one prompt-side repair (LLM self-correction hint) then retry.\n- Instrumentation: counters for attempts, lastError, totalDelay; expose to metrics.\n- Plug into adapters execution layer used by GM loop.\n- Extend TC012: assert retries occur and stop at cap; measure added overhead <300ms median.",
            "status": "pending",
            "testStrategy": "Unit tests for retry logic, backoff sequence, jitter bounds, and non-retriable passthrough."
          },
          {
            "id": 4,
            "title": "Design prompt templates and compaction strategy with tool affordances",
            "description": "Create modular prompt templates guiding high-agency 2â€“4 sentence beats and enabling tool use affordances; implement prompt compaction and warmup strategies to hit <3s median.",
            "dependencies": [
              "21.1"
            ],
            "details": "Deliver:\n- System and developer templates encoding: role (GM), constraints (2â€“4 sentences, decisive verbs), safety/rules integration, mission context, memory cues, adapters instruction with function calling/tool use, and situation update slots.\n- Compaction pipeline: priority tiers (rules>current mission>recent memory>player last actions>older memory); token budget function; summarizer for older memory; truncation with ellipsis markers.\n- Warmup: pre-load model with priming conversation or cached compiled prompt skeletons; pre-request embeddings/summaries.\n- Unit tests (extends TC011, TC013): ensure compactor reduces tokens while keeping priority content; beats remain 2â€“4 sentences under heavy context.",
            "status": "pending",
            "testStrategy": "Snapshot tests for prompts under different contexts; token counts asserted against model max and target latency budgets."
          },
          {
            "id": 5,
            "title": "Implement GM orchestration state machine",
            "description": "Create the core loop as a finite-state machine handling input ingestion, context assembly, LLM call, tool execution, beat streaming, and cooldown/periodic updates.",
            "dependencies": [
              "21.1",
              "21.2",
              "21.3",
              "21.4"
            ],
            "details": "States: Idle -> AssembleContext -> InvokeLLM -> ExecuteTools (may interleave) -> StreamBeat -> PostBeat (update memory/mission logs, schedule situation updates) -> Idle.\n- Context assembly pulls rules, mission status, recent memory, player actions; passes through compactor.\n- Supports tool function-calling mode: parse tool calls, validate via zod, execute via retry wrapper, feed results back to LLM until final beat.\n- Periodic situation update injection: every K beats or T seconds, insert a lightweight scene delta before or within the beat per config.\n- Configurable knobs: sentence range 2â€“4, cadence, tool timeouts, max tool chain length.\n- Events and metrics emitted at each transition.",
            "status": "pending",
            "testStrategy": "Integration tests driving the FSM with synthetic actions; assert order of states, correct emissions, and that TC014 and TC015 pass."
          },
          {
            "id": 6,
            "title": "Streaming response pipeline with time-to-first-token optimization",
            "description": "Implement streaming from the LLM to clients and to TTS adapter, minimizing orchestration overhead and ensuring backpressure handling.",
            "dependencies": [
              "21.1",
              "21.5"
            ],
            "details": "Add:\n- Stream multiplexer: LLM SSE/WebSocket tokens -> client stream and TTS pre-buffer.\n- Backpressure: bounded queues; drop/collapse slow consumer strategy with notices.\n- Early flush: send header/meta immediately, start tokens as they arrive; compute TTFB.\n- Cancellation: user interrupts cancel current generation and tool chain safely.\n- Metrics: TTFB, tokens/sec, end-to-end time.\n- Ensure beat boundary detection for 2â€“4 sentences; finalize on sentence end or token cap.",
            "status": "pending",
            "testStrategy": "E2E streaming tests using Playwright: assert tokens arrive incrementally, captions/TTF sync hook invoked; verify median TTFB contributes to <3s total (TC015)."
          },
          {
            "id": 7,
            "title": "Integrate tool adapters into loop with strict schema validation",
            "description": "Wire rules.check, mission.advance, memory.query, image.request, and tts.speak into the ExecuteTools stage with validation and retries.",
            "dependencies": [
              "21.2",
              "21.3",
              "21.5"
            ],
            "details": "Implement execution router:\n- On tool call message, validate input via zod; on success, call adapter through retryToolCall; on result, append to tool context and continue LLM function-calling until final content.\n- Enforce max tool depth/chain length to avoid loops; timeouts per tool.\n- For tts.speak, start after first sentence boundary to minimize perceived latency; ensure payload matches TTS task expectations (voice id, text chunking).\n- For image.request, queue async and return placeholder reference for later rendering.",
            "status": "pending",
            "testStrategy": "Unit/integration tests using mocks: ensure invalid schemas are retried; verify tool outputs are surfaced to the LLM and reflected in the final beat; ensure TC012 and TC015 continue to pass."
          },
          {
            "id": 8,
            "title": "High-agency beat generator with sentence control",
            "description": "Enforce 2â€“4 sentence outputs with decisive tone and content validation; implement post-processor to trim/merge sentences and reject low-agency phrasing.",
            "dependencies": [
              "21.4",
              "21.5",
              "21.6"
            ],
            "details": "Add a BeatPostprocessor:\n- Sentence segmentation; enforce limits; if >4, truncate at boundary; if <2, request LLM continuation or synthesize concise closer.\n- Agency heuristics: forbid weak hedges list; require imperative verbs or strong assertions; soft-penalize passive voice; fallback correction prompt if needed.\n- Ensure compatibility with streaming: hold a rolling window to validate and decide early tts.speak triggers.\n- Configuration per campaign for tone/dialect.",
            "status": "pending",
            "testStrategy": "Extend TC011 with adversarial prompts; assert beats remain 2â€“4 sentences and pass agency checks. Add unit tests for sentence segmentation edge cases."
          },
          {
            "id": 9,
            "title": "Situation update scheduler and insertion logic",
            "description": "Implement periodic situation updates injected into the narration flow without breaking pacing.",
            "dependencies": [
              "21.5"
            ],
            "details": "Develop a scheduler tracking beats count and time; when threshold met, prepend or append a concise scene delta (1 sentence) via a lightweight LLM call or templated update using world state deltas. Provide debouncing so updates do not cluster after pauses.",
            "status": "pending",
            "testStrategy": "Validate TC014 with fake clock; ensure updates fire on cadence and are integrated as separate sentences without exceeding 4-sentence cap."
          },
          {
            "id": 10,
            "title": "Latency budgeter, warmups, and prompt token budgeting",
            "description": "Introduce a latency budget manager orchestrating warmup calls, cache hits for prompts, and token budgets to meet <3s median locally.",
            "dependencies": [
              "21.4",
              "21.5",
              "21.6"
            ],
            "details": "Components:\n- Warmup manager: issue tiny priming calls at session start/idle intervals; keep adapter connections warm.\n- Prompt cache: hash of compacted prompt skeleton + context keys; reuse where safe.\n- Token budget calculator: model throughput tokens/sec; aim for output <= 80 tokens for 2â€“4 sentences; adjust stop sequences.\n- Abort long generations at cap and request concise restatement if needed.",
            "status": "pending",
            "testStrategy": "Performance tests: simulate 30 sessions; assert median end-to-end <3s, track improvements when warmups enabled. Ensures TC015 passes consistently."
          },
          {
            "id": 11,
            "title": "Metrics, tracing, and observability for the GM loop",
            "description": "Add structured logging, traces, and counters to measure tool attempts, retries, latency breakdowns, and success rates.",
            "dependencies": [
              "21.5",
              "21.6"
            ],
            "details": "Emit spans for states and tool calls; counters for retries, invalid schemas, tool chain depth; histograms for TTFB, total time; gauges for queue sizes. Provide a debug dashboard or CLI report summarizing last N sessions.",
            "status": "pending",
            "testStrategy": "Add assertions in tests to check metrics are emitted; run perf suite and export a trace to verify spans and timing breakdowns."
          },
          {
            "id": 12,
            "title": "E2E integration with TTS and image adapters",
            "description": "Ensure beats are chunked to TTS with voice context and captions, and image requests are queued and resolved into UI placeholders.",
            "dependencies": [
              "21.6",
              "21.7",
              "21.8"
            ],
            "details": "For TTS: split beat into sentence chunks; send first sentence as soon as stable; include speaker/NPC voice id and captions timestamps hooks. For image: enqueue generation, return handle; when ready, emit event to append visual to scene.",
            "status": "pending",
            "testStrategy": "E2E test: player action -> beat spoken with correct voice and captions; image placeholder appears and resolves. Complements Task 7 tests."
          },
          {
            "id": 13,
            "title": "Error handling, recovery, and user-facing fallbacks",
            "description": "Implement graceful degradation: if tools or LLM fail, produce a concise beat explaining a brief delay and continue; persist minimal state to resume.",
            "dependencies": [
              "21.5",
              "21.6",
              "21.7"
            ],
            "details": "Add categorized errors and fallbacks: switch to minimal-context template on repeated failures; skip optional tools (image) under pressure; revert to cached summaries if memory.query fails; ensure loop does not deadlock.",
            "status": "pending",
            "testStrategy": "Fault injection in integration tests: drop adapter responses, force schema errors; assert a beat still emits within 3s with a fallback message; metrics record the incident."
          },
          {
            "id": 14,
            "title": "Configuration, feature flags, and admin controls",
            "description": "Expose knobs for sentence limits, cadence, max tool depth, timeouts, warmup intervals, and situation update policies with runtime flags.",
            "dependencies": [
              "21.5",
              "21.9",
              "21.10"
            ],
            "details": "Provide config schema and hot-reload; validate with zod; bind to environment and per-campaign overrides; log effective config per session.",
            "status": "pending",
            "testStrategy": "Unit tests ensure invalid configs are rejected; E2E toggles verify behavior changes (e.g., sentence cap from 4 to 3)."
          },
          {
            "id": 15,
            "title": "Documentation and developer guide with examples",
            "description": "Author developer docs showing state machine diagrams, prompt examples, tool schemas, and troubleshooting playbooks.",
            "dependencies": [
              "21.5",
              "21.11",
              "21.14"
            ],
            "details": "Include: sequence diagrams for a typical turn; code samples for adding a new tool; latency optimization checklist; FAQ for schema errors and retries; guidance for writing high-agency styles.",
            "status": "pending",
            "testStrategy": "Doc lints build; examples compiled in CI; runnable snippets as part of tests where feasible."
          }
        ]
      },
      {
        "id": 22,
        "title": "Accessibility and Captioning Compliance",
        "description": "Ensure captions everywhere, adjustable speech rate/volume, color contrast, and keyboard navigation fallback.",
        "details": "- Global caption track toggle; per-channel captions; ARIA roles and landmarks\n- Contrast tokens meet WCAG AA; focus management\n- Keyboard-only flows for critical actions\n- Settings persist per player locally",
        "testStrategy": "- Automated axe tests; manual keyboard nav checklist\n- Contrast checker CI step\n- Verify captions available for all audio sources",
        "priority": "medium",
        "dependencies": [
          4,
          6,
          7
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and write failing tests for accessibility and captioning (TC001â€“TC006)",
            "description": "Capture concrete acceptance criteria and implement initial failing tests covering captions availability, caption toggles, per-channel captions, adjustable speech rate/volume controls, color contrast tokens (WCAG AA), keyboard-only navigation for critical flows, ARIA roles/landmarks, focus management, and per-player local persistence.",
            "dependencies": [],
            "details": "â€¢ Define acceptance criteria mapped to verification IDs:\n  - TC001: Captions available for all audio sources and channels; default off unless globally toggled.\n  - TC002: Global caption track toggle affects all players; per-channel caption toggles override global.\n  - TC003: Adjustable speech rate and volume per channel with defined ranges (rate 0.5â€“2.0x in 0.1 steps; volume 0â€“1.0 in 0.05 steps) and persistence per player in local storage/indexedDB.\n  - TC004: Color contrast tokens meet WCAG 2.1 AA (text â‰¥ 4.5:1; large text â‰¥ 3:1; UI components â‰¥ 3:1) and are enforced via design tokens.\n  - TC005: Keyboard-only flows for critical actions (play/pause, toggle captions, adjust rate/volume, open/close settings, save) with visible focus and logical tab order.\n  - TC006: ARIA roles/landmarks present; focus management returns to invoking control; live regions for captions.\nâ€¢ Unit tests: token contrast calculations, persistence adapter R/W, reducer/state for toggles and controls, ARIA attributes presence, focus trap utilities.\nâ€¢ Integration/UI tests (e.g., Playwright/Cypress + Axe): keyboard-only paths for critical flows, axe automated checks, captions displayed and synced during playback, global vs per-channel precedence, contrast checker step on theme tokens.\nâ€¢ Provide test fixtures: mock audio sources, mock TTS timestamps, seeded theme tokens.\nâ€¢ Ensure tests fail initially to drive implementation.",
            "status": "pending",
            "testStrategy": "Implement Jest/Vitest unit tests and Playwright/Cypress E2E with axe-core. Add CI job: contrast check over tokens and axe run on key pages. Record TC001â€“TC006 mappings in test names."
          },
          {
            "id": 2,
            "title": "Implement caption data model and rendering with ARIA live region",
            "description": "Introduce data structures and UI components to render captions for all audio sources and channels with a live region for assistive tech.",
            "dependencies": [
              "22.1"
            ],
            "details": "â€¢ Add CaptionTrack model: {id, channelId, cues: [{start,end,text}], source: 'tts'|'file'|'manual'}.\nâ€¢ Implement CaptionService: APIs to register tracks per channel, subscribe to playback time, and emit active cues.\nâ€¢ UI: <CaptionsOverlay channelId> reads active cues and renders text with high-contrast styling, role='region' aria-live='polite' aria-atomic='true'.\nâ€¢ Ensure overlay is toggleable and does not trap focus; it should be screen-reader friendly but not interfere with keyboard nav.\nâ€¢ Provide fallback when timestamps unavailable: time-based approximate sync using chunked text.\nâ€¢ Run tests from 22.1 and make TC001 pass.",
            "status": "pending",
            "testStrategy": "Unit: cue selection given currentTime boundaries and edge cases; fallback chunking when timestamps missing. UI: captions appear within 100ms tolerance; axe has no violations for overlay; TC001 integration verifies all audio sources render captions."
          },
          {
            "id": 3,
            "title": "Global and per-channel captions toggle with precedence rules",
            "description": "Add global caption toggle and per-channel toggles with clear precedence logic and persisted state.",
            "dependencies": [
              "22.1",
              "22.2"
            ],
            "details": "â€¢ State: captions: {globalEnabled: boolean, channels: Record<channelId, {enabled?: boolean}>}.\nâ€¢ Precedence: effectiveEnabled(channel) = channels[channel]?.enabled ?? globalEnabled.\nâ€¢ UI: global toggle in settings menu; per-channel toggle in channel controls.\nâ€¢ Connect to CaptionsOverlay visibility by effectiveEnabled.\nâ€¢ Integrate with persistence layer (see 22.6) and emit events for analytics if needed.\nâ€¢ Run tests and ensure TC002 passes.",
            "status": "pending",
            "testStrategy": "Unit: precedence function truth table; reducer actions; persisted hydration. UI: toggling global cascades; per-channel override respected; axe checks on toggle controls."
          },
          {
            "id": 4,
            "title": "Implement speech rate and volume controls per channel with bounds and smoothing",
            "description": "Provide per-channel rate and volume controls with defined ranges, step increments, debounced updates, and immediate audio effect.",
            "dependencies": [
              "22.1",
              "22.2"
            ],
            "details": "â€¢ Expose per-channel AudioController APIs: setRate(rate), setVolume(vol), getState(). Ensure clamped ranges: rate 0.5â€“2.0, volume 0â€“1.0.\nâ€¢ UI controls: slider inputs with keyboard operability (Left/Right/Up/Down/Page keys), aria-valuemin/max/now, labeled by.\nâ€¢ Apply ramping (linRampToValue over 100â€“200ms) to avoid pops.\nâ€¢ Wire to captions timing: adjust caption pacing if derived from TTS timestamps; otherwise do not desync.\nâ€¢ Persist control values per player (22.6).\nâ€¢ Run tests and ensure TC003 passes.",
            "status": "pending",
            "testStrategy": "Unit: clamping, step rounding, ramp scheduling. UI: keyboard adjustment sequences; live updates reflect immediately; E2E verifies persistence reload."
          },
          {
            "id": 5,
            "title": "WCAG AA color contrast tokens and enforcement",
            "description": "Define design tokens for text, large text, and UI components that meet WCAG 2.1 AA and enforce via lint/CI.",
            "dependencies": [
              "22.1"
            ],
            "details": "â€¢ Token set: semantic colors (textPrimary, textSecondary, link, focusRing, background, surface, buttonPrimary, buttonText, disabled, captionBg, captionText).\nâ€¢ Compute contrast ratios programmatically and fail build if below thresholds (text â‰¥ 4.5:1; large text and UI components â‰¥ 3:1).\nâ€¢ Add contrast CI step that checks tokens and common combinations.\nâ€¢ Update themes to use tokens in components including CaptionsOverlay.\nâ€¢ Run tests and ensure TC004 passes.",
            "status": "pending",
            "testStrategy": "Unit: contrastRatio(colorA,colorB) util; snapshot of token ratios. CI: run contrast checker over tokens; fail pipeline on violations. Visual regression optional."
          },
          {
            "id": 6,
            "title": "Per-player local persistence for accessibility settings",
            "description": "Persist caption toggles, rate, and volume per player using local storage/indexedDB with a namespaced key including playerId.",
            "dependencies": [
              "22.1",
              "22.3",
              "22.4"
            ],
            "details": "â€¢ Storage key: accessibility:<playerId> with schema {captionsGlobal, captionsByChannel, rateByChannel, volumeByChannel, lastUpdated}.\nâ€¢ Implement persistence adapter with debounce and versioning/migration.\nâ€¢ Hydrate settings on player session start and broadcast to relevant components.\nâ€¢ Run tests and update previous subtasks to use persistence; ensure TC003/TC002 persistence aspects pass.",
            "status": "pending",
            "testStrategy": "Unit: read/write, migrations, corruption handling. Integration: reload page preserves settings; multi-channel values restored."
          },
          {
            "id": 7,
            "title": "Keyboard-only navigation for critical flows with focus management",
            "description": "Ensure all critical actions are operable via keyboard with logical order, visible focus, ARIA semantics, and proper focus trapping/return.",
            "dependencies": [
              "22.1",
              "22.3",
              "22.4",
              "22.5"
            ],
            "details": "â€¢ Identify critical flows: play/pause, open settings, toggle captions (global/channel), adjust rate/volume, save/close.\nâ€¢ Implement focus styles using tokens (focusRing), ensure tab order follows DOM order; add skip links if needed.\nâ€¢ Dialogs: role='dialog' aria-modal='true', focus trap inside, return focus to opener on close.\nâ€¢ Controls: ensure role, name, value exposed; sliders support Arrow/Page/Home/End keys.\nâ€¢ Add keyboard shortcut hints (tooltips with aria-describedby).\nâ€¢ Run tests to satisfy TC005.",
            "status": "pending",
            "testStrategy": "Playwright with keyboard-only scripts; assert focus movement and action results. Axe automated checks for interactive components. Manual checklist for edge cases."
          },
          {
            "id": 8,
            "title": "ARIA roles, landmarks, and live regions audit and implementation",
            "description": "Add appropriate ARIA roles/landmarks across the player UI and verify announcements for dynamic captions content.",
            "dependencies": [
              "22.1",
              "22.2",
              "22.7"
            ],
            "details": "â€¢ Landmarks: role='banner' for header, 'main' for content, 'complementary' if side panel, 'contentinfo' for footer.\nâ€¢ Controls: ensure native elements or add roles; name via aria-label/aria-labelledby; state via aria-pressed/aria-checked as appropriate.\nâ€¢ Captions: aria-live='polite' with throttled updates; aria-atomic for entire line announcements.\nâ€¢ Ensure no redundant or conflicting roles.\nâ€¢ Run tests to meet TC006.",
            "status": "pending",
            "testStrategy": "Axe audits should pass; screen reader smoke tests (NVDA/VoiceOver) for captions announcements and control labels. Unit snapshot tests for ARIA attributes presence."
          },
          {
            "id": 9,
            "title": "Integration: Caption sync with TTS and audio playback",
            "description": "Wire captions to TTS timestamps when available and fall back gracefully when missing; ensure sync across variable speech rates.",
            "dependencies": [
              "22.2",
              "22.4",
              "22.7"
            ],
            "details": "â€¢ Subscribe to TTS adapter events for word/phrase timestamps if Task 7 provides; map to cues.\nâ€¢ Adjust timing when rate changes by scaling cue windows; if only audio clock available, align via currentTime.\nâ€¢ Ensure channels independently sync.\nâ€¢ Run tests to verify TC001/TC003 end-to-end with TTS integration.",
            "status": "pending",
            "testStrategy": "E2E: simulated TTS stream with timestamps; verify cue highlighting matches audio segments within tolerance. Unit: scaling math for rate changes."
          },
          {
            "id": 10,
            "title": "Automated accessibility testing in CI (axe, contrast checker) and reporting",
            "description": "Add CI jobs to run axe against key player routes and a contrast checker against tokens; publish artifacts and gating rules.",
            "dependencies": [
              "22.5",
              "22.7",
              "22.8"
            ],
            "details": "â€¢ Configure headless browser to load player pages; run axe-core and collect violations.\nâ€¢ Contrast step: run token contrast script; fail on AA violations.\nâ€¢ Output JUnit/HTML reports; annotate PRs with violations; add thresholds to block merges.\nâ€¢ Run test suite to ensure TC004â€“TC006 are enforced automatically.",
            "status": "pending",
            "testStrategy": "CI pipeline dry run with seeded violations to ensure failures are caught; then enforce gating."
          },
          {
            "id": 11,
            "title": "UI polish: caption overlay theming, resizing, and readability controls",
            "description": "Enhance captions overlay with adjustable font size, background opacity, and positioning while maintaining accessibility.",
            "dependencies": [
              "22.2",
              "22.5",
              "22.6"
            ],
            "details": "â€¢ Add per-player settings: caption font size (e.g., 14â€“36px), background opacity (0.3â€“0.85), position (bottom/top).\nâ€¢ Ensure contrast between caption text and overlay background meets AA at all combinations; restrict ranges to guarantee compliance.\nâ€¢ Keyboard-accessible controls; persist values.\nâ€¢ Run tests to ensure no new contrast or keyboard issues.",
            "status": "pending",
            "testStrategy": "Unit: validate setting ranges and contrast checks. UI: keyboard adjustments reflect visually and persist."
          },
          {
            "id": 12,
            "title": "Keyboard-only flows E2E and manual checklist completion",
            "description": "Execute comprehensive keyboard-only E2E tests and finalize manual checklist coverage for edge cases and regressions.",
            "dependencies": [
              "22.7",
              "22.8",
              "22.10"
            ],
            "details": "â€¢ Expand E2E to include error states, modal reopen, multiple channels concurrently, and rapid toggling.\nâ€¢ Validate focus trapping, escape to close, and return focus in all dialogs.\nâ€¢ Document any exceptions and create follow-up defects if needed.\nâ€¢ Run tests and ensure they pass before sign-off.",
            "status": "pending",
            "testStrategy": "Playwright scripts for complex sequences; manual pass with standardized keyboard nav checklist logged in CI artifacts."
          }
        ]
      },
      {
        "id": 23,
        "title": "Performance and Reliability Hardening",
        "description": "Implement retries/backoff for provider calls, WebSocket stability, and caching to meet performance targets.",
        "details": "- Exponential backoff with jitter for adapters\n- Connection monitor and auto-reconnect; offline queueing\n- Image cache hit optimization; token usage tracking and prompt compaction\n- Profiling and flamegraphs; GC tuning hints",
        "testStrategy": "- Load tests simulate burst traffic; verify targets: STT<800ms, GM<3s, TTS<1.2s medians locally\n- Fault injection tests for adapter failures\n- Cache hit rate monitoring >60% for repeated requests",
        "priority": "medium",
        "dependencies": [
          5,
          3,
          8,
          21
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and write unit/integration tests for performance and reliability hardening",
            "description": "Before implementation, codify acceptance criteria and create tests covering retries/backoff with jitter for provider adapters, WebSocket stability (monitoring, auto-reconnect, offline queue), caching effectiveness, and profiling hooks. Include at least one unit test and one integration test. Tag tests with verification IDs: TC016 (retry/backoff), TC017 (WebSocket stability), TC018 (caching hit rate), TC019 (latency targets).",
            "dependencies": [],
            "details": "â€¢ Draft acceptance criteria: \n- Retries: adapter calls use exponential backoff with full jitter; cap max delay; idempotent-safe retries; circuit breaker opens after threshold.\n- WebSocket: connection monitored; auto-reconnect with backoff; offline queue buffers outbound events until connected; no message duplication or reordering beyond at-least-once semantics.\n- Caching: image cache achieves >=60% hit rate on repeated requests; cache keying and eviction strategy defined; token usage tracked; prompt compaction reduces tokens by >=20% on repeated dialog context.\n- Performance targets locally: STT median <800ms, Generation/GM median <3s, TTS median <1.2s under burst traffic.\nâ€¢ Tests to add:\n- Unit: backoff schedule correctness with jitter bounds; retry stops on non-retryable errors; circuit breaker transitions; cache key/hash determinism; LRU eviction; token accounting; prompt compaction length reduction.\n- Integration: fault injection for adapter failures verifying retries and final behavior; simulated WebSocket server that drops/halts to verify reconnect and offline queue flush; load test harness generating burst traffic and measuring latencies; repeated image requests to measure cache hit rate.\n- Include metrics assertions and export hooks used by tests.\nâ€¢ Testing scaffolding: add test helpers for fake time (advance timers), flaky provider stubs (error rates), WS test server, and metrics registry. \nâ€¢ Mark tests with TC016â€“TC019 and wire into CI job `perf-reliability-suite`.",
            "status": "pending",
            "testStrategy": "Run new test suites to see them fail initially: unit (retry/backoff, caching) and integration (WS stability, load/caching). Establish baseline reports for TC016â€“TC019."
          },
          {
            "id": 2,
            "title": "Implement exponential backoff with full jitter utility and integrate into provider adapters",
            "description": "Create a reusable backoff module implementing exponential backoff with full jitter, max attempts, max delay, and per-error retry policies. Integrate into all provider adapters (LLM, STT, TTS, Image). Ensure idempotency and timeouts.",
            "dependencies": [
              "23.1"
            ],
            "details": "â€¢ Backoff utility: function signature like `retry(fn, {base=100ms, factor=2, jitter='full', maxDelay=5s, maxAttempts=6, timeoutPerAttempt, isRetryable(err), onAttempt, signal})`.\nâ€¢ Full jitter: nextDelay = random(0, min(maxDelay, base * factor^n)).\nâ€¢ Respect cancellation and deadlines via AbortSignal.\nâ€¢ Define retryable categories: 429/5xx, network errors, timeouts. Non-retryable: 4xx (except 408/409/429), validation errors.\nâ€¢ Add per-adapter policies (e.g., image generation longer timeouts). \nâ€¢ Instrument attempts, delays, outcomes via metrics (counters and histograms) and logs with structured fields.\nâ€¢ Update adapters to wrap outbound calls with `retry`. Ensure idempotent request keys for safe retries when provider supports it; otherwise guard side-effecting endpoints (no retry on partial success signals).\nâ€¢ Add configuration: env/flags for backoff parameters and max attempts; sane defaults.",
            "status": "pending",
            "testStrategy": "Run unit tests for backoff schedule, jitter bounds, and retry policies (TC016). Run integration fault injection tests to ensure retries occur and stop appropriately."
          },
          {
            "id": 3,
            "title": "Add circuit breaker around provider adapters",
            "description": "Introduce a circuit breaker to prevent cascading failures on persistent errors, with states Closed/Half-Open/Open and rolling error rate calculation.",
            "dependencies": [
              "23.1",
              "23.2"
            ],
            "details": "â€¢ Implement breaker with configurable failure threshold (e.g., >50% over last N requests or consecutive failures), open duration, half-open probe count.\nâ€¢ Expose metrics for state transitions and short-circuits. \nâ€¢ Wrap provider adapter calls: on Open, immediately fail fast with specific error; half-open allows limited trial calls.\nâ€¢ Ensure interoperability with retry: retries operate within Closed/Half-Open; Open should not schedule retries.\nâ€¢ Add config toggles and per-adapter overrides.",
            "status": "pending",
            "testStrategy": "Unit: simulate failure bursts to trigger Open; verify Half-Open probes; ensure reset on success (TC016). Integration: inject provider outage; verify fail-fast after threshold and recovery when provider returns."
          },
          {
            "id": 4,
            "title": "WebSocket connection monitor with auto-reconnect and exponential backoff",
            "description": "Implement a connection monitor for client/server WebSockets that detects disconnects, schedules reconnects with backoff+jitter, and surfaces connection state.",
            "dependencies": [
              "23.1"
            ],
            "details": "â€¢ Monitor responsibilities: heartbeat/ping-pong, idle timeout, detect close/error codes, and reconnect strategy using the backoff utility with jitter and caps.\nâ€¢ Preserve authentication/session context on reconnect; refresh tokens if needed.\nâ€¢ Provide observable state machine: CONNECTING, OPEN, CLOSING, CLOSED, RECONNECTING. Emit events for UI/logic.\nâ€¢ Metrics: connection uptime %, reconnect attempts, time-to-reconnect.\nâ€¢ Configurable policies: max attempts, initial delay, ping interval, idle timeout.",
            "status": "pending",
            "testStrategy": "Integration: WS test server that closes connections randomly; assert reconnect within bounded window and state transitions (TC017). Unit: heartbeat timeout detection logic."
          },
          {
            "id": 5,
            "title": "Offline outbound queue with exactly-once de-duplication on reconnect",
            "description": "Add an offline queue buffering outbound messages/events when WS is disconnected, flushing on reconnect with idempotency keys to prevent duplicates.",
            "dependencies": [
              "23.1",
              "23.4"
            ],
            "details": "â€¢ Queue design: durable (in-memory with optional persistence), ordering preserved; backpressure via size/time caps and drop policies for non-critical messages.\nâ€¢ Each message carries idempotency key and monotonic sequence; server acknowledges processed keys, enabling client to skip duplicates on resend.\nâ€¢ Flush strategy: upon OPEN event, drain queue respecting rate limits; retry with backoff on transient send failures.\nâ€¢ Ensure at-least-once delivery semantics without duplication on server via dedupe cache.\nâ€¢ Metrics: queue length, dropped messages, flush duration.",
            "status": "pending",
            "testStrategy": "Integration: simulate offline period; enqueue messages; reconnect and verify no duplicates and preserved order (TC017). Unit: queue eviction and dedupe logic."
          },
          {
            "id": 6,
            "title": "Image cache with key normalization, LRU eviction, and prewarming",
            "description": "Implement an image cache layer with deterministic keying and LRU eviction to improve hit rate for repeated image generation/fetches; include optional prewarm hooks.",
            "dependencies": [
              "23.1"
            ],
            "details": "â€¢ Cache key: normalize prompts, parameters, model version, seed, size, and post-processing options; hash into stable key.\nâ€¢ Storage: in-memory LRU with size limits (count/bytes) plus optional disk-backed store; respect TTLs.\nâ€¢ Prewarm: allow seeding cache for common assets.\nâ€¢ Expose metrics: hit/miss, evictions, byte hit rate.\nâ€¢ Thread-safety and concurrency: lock per key to prevent thundering herd (single-flight).",
            "status": "pending",
            "testStrategy": "Unit: key normalization determinism; LRU eviction correctness; single-flight prevents duplicate work (TC018). Integration: repeated requests under load achieve >=60% hit rate."
          },
          {
            "id": 7,
            "title": "Token usage tracking and prompt compaction middleware",
            "description": "Add middleware to track token usage across requests and implement prompt compaction to reduce context length while preserving fidelity.",
            "dependencies": [
              "23.1"
            ],
            "details": "â€¢ Token accounting: intercept adapter requests; compute prompt and completion tokens using tokenizer; record per-request metrics and cumulative usage.\nâ€¢ Prompt compaction: rules such as deduplicating repeated instructions, trimming stale turns beyond window, summarizing long histories, and compressing system prompts; target >=20% reduction where applicable.\nâ€¢ Configurable policies per campaign/session. \nâ€¢ Emit metrics and attach compaction summaries for auditing.",
            "status": "pending",
            "testStrategy": "Unit: verify token counts align with tokenizer; compaction reduces tokens >=20% on synthetic long history; idempotency of compaction for repeated runs. Integration: end-to-end run shows reduced token usage without changing required outputs (spot-check)."
          },
          {
            "id": 8,
            "title": "Profiling hooks, flamegraph capture, and GC tuning hints",
            "description": "Integrate profiling instrumentation to capture CPU profiles/flamegraphs and expose memory/GC metrics. Provide guidance knobs for GC tuning.",
            "dependencies": [
              "23.1"
            ],
            "details": "â€¢ Add start/stop profiling endpoints or CLI flags to capture CPU/heap profiles during load tests; export in standard formats (pprof or similar).\nâ€¢ Emit metrics: GC pauses, heap in use, allocation rate, object churn.\nâ€¢ Configurable GC parameters via env flags (e.g., heap growth target, concurrent GC toggles) with safe defaults and documentation.",
            "status": "pending",
            "testStrategy": "Manual/integration: run load test and collect profiles; verify artifacts generated and metrics exposed. Unit: basic sanity on metrics exporters."
          },
          {
            "id": 9,
            "title": "Latency load tests for STT, GM, and TTS with burst traffic",
            "description": "Build a load testing harness to generate burst traffic across STT, generation/GM, and TTS paths, recording latency distributions and asserting medians meet targets.",
            "dependencies": [
              "23.1",
              "23.2",
              "23.3",
              "23.4",
              "23.5",
              "23.6",
              "23.7",
              "23.8"
            ],
            "details": "â€¢ Implement scenarios: concurrent requests with spikes; representative payloads.\nâ€¢ Collect p50/p95 latencies and throughput; export JUnit-like assertions for CI.\nâ€¢ Targets: STT <800ms p50, GM <3s p50, TTS <1.2s p50 on local profile. Gate CI if violated (TC019).\nâ€¢ Integrate with profiling hooks to capture flamegraphs during runs.",
            "status": "pending",
            "testStrategy": "Execute harness repeatedly to stabilize results; verify CI gating and profile artifacts (TC019)."
          },
          {
            "id": 10,
            "title": "Cache effectiveness tests and tuning",
            "description": "Measure and tune cache hit rates under realistic workloads; adjust keying, TTLs, and prewarming to achieve >=60% hit rate for repeated requests.",
            "dependencies": [
              "23.1",
              "23.6",
              "23.9"
            ],
            "details": "â€¢ Design workload with repeated asset requests and variant mixes to avoid overfitting.\nâ€¢ Iterate on TTLs, LRU capacity, and prewarm sets.\nâ€¢ Add dashboard or logs summarizing hit/miss and byte hit rate; assert TC018 threshold.",
            "status": "pending",
            "testStrategy": "Run workload and confirm hit rate >=60% and stable under bursts (TC018)."
          },
          {
            "id": 11,
            "title": "Fault injection scenarios for adapter reliability",
            "description": "Expand fault injection to simulate timeouts, 429s, intermittent 5xx, malformed responses, and slow responses; verify retries/backoff and circuit breaker behavior end-to-end.",
            "dependencies": [
              "23.1",
              "23.2",
              "23.3",
              "23.9"
            ],
            "details": "â€¢ Implement adapter fakes with configurable error rates and latency distributions.\nâ€¢ Scenarios check: retry counts, exponential delays with jitter, breaker open on sustained failures, recovery after cooldown.\nâ€¢ Collect metrics snapshots to confirm behavior matches design (TC016).",
            "status": "pending",
            "testStrategy": "Run each scenario multiple times to cover edge probabilities; assert no request storms and bounded latencies."
          },
          {
            "id": 12,
            "title": "WebSocket soak and chaos tests with offline queue validation",
            "description": "Subject WebSocket layer to long-running and chaotic conditions to validate reconnection, backoff, and offline queue correctness.",
            "dependencies": [
              "23.1",
              "23.4",
              "23.5"
            ],
            "details": "â€¢ Chaos patterns: random disconnects, network partitions, high latency, packet loss.\nâ€¢ Assertions: reconnect within bounded windows, no message loss, no duplicates (idempotency keys), bounded queue growth.\nâ€¢ Collect uptime %, reconnect counts, and flush times (TC017).",
            "status": "pending",
            "testStrategy": "Run soak for several hours in CI nightly; quick chaos smoke in PRs. Use deterministic seeds where possible."
          },
          {
            "id": 13,
            "title": "Documentation and configuration templates for performance and reliability features",
            "description": "Document configuration parameters, operational runbooks, and provide defaults for backoff, breaker, WS, caching, and profiling/GC settings.",
            "dependencies": [
              "23.2",
              "23.3",
              "23.4",
              "23.5",
              "23.6",
              "23.7",
              "23.8",
              "23.9",
              "23.10",
              "23.11",
              "23.12"
            ],
            "details": "â€¢ Write docs covering: settings, recommended defaults, when to tune, and troubleshooting guides.\nâ€¢ Include configuration examples for local, staging, production.\nâ€¢ Add dashboards/alerts suggestions for key metrics.",
            "status": "pending",
            "testStrategy": "Docs lint/build passes; operator walkthrough validated against a staging environment."
          }
        ]
      },
      {
        "id": 24,
        "title": "AI-Generated Video Upgrade (Feature Flag)",
        "description": "Add optional video generation for cutscenes and ambient loops with caching and identity consistency from images/storyboards.",
        "details": "- Feature flag r13VideoEnabled\n- VideoGenAdapter interface; providers: local i2v or cloud (disabled by default)\n- API: /videos request lifecycle similar to images; cache reuse by storyboard hash\n- Identity consistency: reuse character embeddings/prompts from images\n- UI: preview player; ambient loop support",
        "testStrategy": "- TC019: lifecycle, identity/continuity tolerance checks; cache reuse SLA\n- Fallbacks when disabled; ensure no external calls when flag off",
        "priority": "low",
        "dependencies": [
          5,
          8,
          2,
          4
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for video lifecycle, caching, identity consistency, and flag off behavior",
            "description": "Create failing unit and integration/UI tests that capture the core acceptance criteria for AI-generated video under feature flag r13VideoEnabled, including lifecycle parity with images, cache reuse by storyboard hash, identity consistency with images/storyboards, ambient loop handling, and no external calls when the flag is off.",
            "dependencies": [],
            "details": "Implement tests before any production code. Cover:\n- TC019: Video request lifecycle mirrors images: POST /videos creates job, status polling, completion with asset URLs, errors, cancellation. Include SLA assertions for cache reuse path (faster completion) vs cold path.\n- Identity consistency: for the same characters/storyboard, generated videos reuse character embeddings/prompts from images; verify deterministic identity features (e.g., facial embedding cosine similarity threshold) between poster frame of video and source image.\n- Cache reuse by storyboard hash: second request with same storyboardHash returns cached video or immediate reference; ensure idempotency and cache hit markers in response metadata.\n- Ambient loop support: generate loopable short ambient clip; verify auditory track optional and loop points encoded or visual loop seamlessness (frame delta threshold at boundary).\n- Feature flag OFF: with r13VideoEnabled=false, POST /videos returns 403 or 501 with clear error; ensure no provider adapter invocation and no outbound network calls.\n- UI: preview player renders when flag ON and hides when OFF; basic play/pause and loop toggle; integration/UI test to confirm.\n- Provider selection: default disabled; local i2v and cloud adapters behind adapter registry.\nCreate unit tests for API controllers, services, adapter selection, cache service; integration tests hitting in-memory server; UI tests via Playwright/Cypress. Seed test fixtures: sample storyboard JSON, character image embeddings.",
            "status": "pending",
            "testStrategy": "Unit tests: Jest/Vitest for controllers/services; mock adapters. Integration: supertest against in-memory server for /videos lifecycle. Caching: use a temp cache store and measure path selection. Identity: compute CLIP/FaceNet embeddings to assert similarity over threshold. UI: Playwright/Cypress to validate preview visibility, playback, loop toggle, and disabled state when flag OFF. Tag with TC019 in relevant tests."
          },
          {
            "id": 2,
            "title": "Introduce r13VideoEnabled feature flag wiring and guard rails",
            "description": "Add runtime-configurable feature flag r13VideoEnabled across API, services, and UI. Default to false. Ensure all video-related paths are gated to prevent adapter invocation and outbound calls when disabled.",
            "dependencies": [
              "24.1"
            ],
            "details": "Backend: extend config provider (env/remote) with r13VideoEnabled (default false). Add middleware/guard in /videos routes and VideoService that short-circuits with 501 Not Implemented and telemetry event video.flag_disabled. Ensure adapters are not resolved when disabled. Add network guard assertion hook to verify no outbound calls when flag off. Frontend: conditionally render preview player and menu items based on flag fetched from /config. Add feature docs and ops toggle. Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "Run TC019 flag-off tests; assert route returns 501 and no adapter calls using spies; UI test confirms hidden components."
          },
          {
            "id": 3,
            "title": "Define VideoGenAdapter interface and provider registry",
            "description": "Create a provider-agnostic VideoGenAdapter interface and a registry to resolve adapters by name with providers: local i2v and cloud (both disabled by default).",
            "dependencies": [
              "24.1",
              "24.2"
            ],
            "details": "Design interface methods: generate(params), getJobStatus(jobId), cancel(jobId), supports(options), and capabilities metadata (maxDuration, resolutions, loopSupport). Define DTOs: VideoRequest (storyboardHash, prompt, characterRefs, duration, resolution, style, loop), VideoJob (id, status, progress, artifactRef, startedAt, completedAt), VideoArtifact. Implement AdapterRegistry with lazy provider binding and feature flag check. Stub LocalI2VAdapter and CloudAdapter (no real calls yet) returning NotConfigured error by default. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests for interface typing and registry resolution. Verify providers disabled by default. Ensure no calls when flag off."
          },
          {
            "id": 4,
            "title": "Implement /videos API lifecycle aligned with images flow",
            "description": "Add REST endpoints and service orchestration mirroring /images: POST /videos to create jobs, GET /videos/:id for status, DELETE /videos/:id to cancel, and GET /videos for listing by filters.",
            "dependencies": [
              "24.1",
              "24.2",
              "24.3"
            ],
            "details": "Model persistence: videos table/collection with fields (id, storyboardHash, requestJson, status, adapter, jobRef, artifactUrl, cacheHit, meta, createdAt, updatedAt). Controller maps requests to VideoService. Service: validates request, checks cache by storyboardHash, if hit returns cached artifact and marks cacheHit=true; otherwise enqueues job via adapter. Implement polling status mapping to unified statuses (queued, running, completed, failed, canceled). Add idempotency via Idempotency-Key header or storyboardHash+params key. Telemetry for lifecycle events. Ensure parity with /images response shape for client reuse. Run tests.",
            "status": "pending",
            "testStrategy": "Integration tests for lifecycle including creation, polling to completion via mocked adapter progress, cancellation, and cache hit behavior. Validate response schema and parity fields."
          },
          {
            "id": 5,
            "title": "Storyboard hash-based cache service",
            "description": "Create a cache layer keyed by storyboardHash and request parameters to reuse existing generated videos and skip recomputation.",
            "dependencies": [
              "24.1",
              "24.4"
            ],
            "details": "Design CacheService with get(hash, paramsKey), set(hash, paramsKey, artifactRef, meta), markHit(jobId). Store artifact URL, checksum, duration, resolution, loop flag, and identity fingerprint. Implement TTL/pinning policy and invalidation hooks when input changes. Ensure concurrency safety: lock per key to avoid thundering herd. Expose metrics: hit rate, latency delta. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests: concurrent requests deduplicate; subsequent requests return cached artifact with cacheHit=true; integrity check on checksum."
          },
          {
            "id": 6,
            "title": "Identity consistency: character embedding reuse from images",
            "description": "Plumb character identity from image generation into video requests by reusing stored embeddings/prompts to ensure visual continuity.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.5"
            ],
            "details": "Define CharacterIdentityStore interface to fetch embeddings/prompts by characterId or imageAssetId. Extend VideoRequest to accept characterRefs [{characterId, imageAssetId, weight}]. In VideoService, resolve and attach identity payload to adapter call. Implement simple fusion strategy: pass embeddings/prompts to provider as control inputs; for providers without native support, seed with reference frames (first frame generation) or conditioning images. Compute identity fingerprint of output (poster frame embedding) and store in cache meta for later validation. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests to ensure identity payload assembly and adapter call includes identity data. Identity similarity assertions per TC019 using fixtures."
          },
          {
            "id": 7,
            "title": "Ambient loop generation support",
            "description": "Add parameters and processing to support ambient loop clips, including loop flag, duration caps, and seamlessness checks.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.3"
            ],
            "details": "Extend request schema with loop=true, loopDurationSec, and loopTechnique (crossfade, latent-loop if provider supports). Adapter capability check for loopSupport; fallback to post-process with crossfade or ping-pong. Implement LoopPostProcessor to make loop points seamless: match first/last N frames using optical flow or audio crossfade if audio present. Validate loopiness with frame diff threshold metric and store in meta. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests for post-processor producing low boundary deltas; integration test creating a short loop and validating metric threshold."
          },
          {
            "id": 8,
            "title": "Local I2V provider adapter (mocked functional)",
            "description": "Provide a functional LocalI2VAdapter that simulates generation with deterministic outputs for tests, with toggles to later wire real model.",
            "dependencies": [
              "24.1",
              "24.3",
              "24.4",
              "24.6",
              "24.7"
            ],
            "details": "Implement LocalI2VAdapter with job queue, deterministic PRNG seeded by storyboardHash to produce reproducible progress and artifacts (e.g., generate placeholder MP4 with colored frames and optional loop enforcement). Accept identity payload and embed into metadata. Respect cancellation. No external calls. Provide configuration flag to enable this adapter in dev/test. Run tests.",
            "status": "pending",
            "testStrategy": "Integration tests exercising full lifecycle end-to-end with LocalI2VAdapter, ensuring determinism and cache reuse speedup."
          },
          {
            "id": 9,
            "title": "Cloud adapter scaffold with safe disabled default",
            "description": "Implement CloudVideoAdapter skeleton with signed-request preparation and strict disabled-by-default posture; no network calls unless explicitly enabled.",
            "dependencies": [
              "24.1",
              "24.3",
              "24.4"
            ],
            "details": "Create CloudVideoAdapter implementing interface but returning NotConfigured unless env var VIDEO_CLOUD_ENABLED=true and credentials present. Include network allowlist integration from security policy. Stub methods to map to provider job model; add exponential backoff polling when enabled. Ensure redaction of sensitive fields in logs. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests confirm disabled behavior, redaction of config in logs, and adherence to network guard. No actual network calls in CI."
          },
          {
            "id": 10,
            "title": "UI preview player and request form",
            "description": "Add a video preview player component and request form mirroring image generation UI, with controls for play/pause, loop, resolution, duration, and storyboard selection.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.5",
              "24.7",
              "24.8"
            ],
            "details": "Frontend: create VideoPreview component using HTML5 video with loop toggle; show cacheHit badge; display identity continuity indicator (green/yellow/red based on similarity metric). Add VideoRequestForm with fields prompt, storyboard, characters, duration, resolution, loop. Integrate with /videos API and polling hook reused from images. Hide components when r13VideoEnabled=false. Add accessible controls and error states. Run tests.",
            "status": "pending",
            "testStrategy": "UI tests with Playwright/Cypress: render when flag ON, hidden when OFF; submit request, poll to completion, preview plays, loop toggle works, cacheHit badge shows on second request. Snapshot test for UI state."
          },
          {
            "id": 11,
            "title": "Parity schema and validators with /images",
            "description": "Align /videos request/response schemas and validation with /images to enable client reuse and consistent telemetry.",
            "dependencies": [
              "24.1",
              "24.4"
            ],
            "details": "Create zod/ajv schemas for VideoRequest/Response paralleling image schemas: fields for id, status, artifactUrl, meta, cacheHit, error. Validate at controller boundary and on client. Add OpenAPI spec updates. Ensure telemetry fields (latencyMs, adapter, cacheHit) are recorded consistently. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests for schema validation and OpenAPI conformance; integration test comparing keys between image and video responses."
          },
          {
            "id": 12,
            "title": "Asset storage and CDN integration for videos",
            "description": "Wire video artifact storage, checksuming, and CDN URLs consistent with image pipeline, including content-type and range requests support.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.5"
            ],
            "details": "Extend AssetService to handle video mime types (mp4, webm), compute checksum, store poster frame, and return signed or CDN URLs. Support HTTP Range for streaming previews. Generate poster frame on completion for identity checks. Add cleanup policies. Run tests.",
            "status": "pending",
            "testStrategy": "Integration tests: upload/store simulated artifacts, verify URL generation and range requests, poster extraction correctness."
          },
          {
            "id": 13,
            "title": "Caching metrics, SLA checks, and observability",
            "description": "Add metrics for cache hit rate, cold vs warm completion times, adapter latencies, and identity similarity distributions; alert on regressions.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.5",
              "24.6"
            ],
            "details": "Instrument VideoService to emit metrics: video.cache.hit, video.latency.cold/warm, adapter.progress, identity.similarity, loop.seamlessness. Add logs with requestId and storyboardHash. Create dashboards and SLOs (e.g., cached reuse p50 < 1s). Integrate with tracing spans. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests for metrics emission using test sink; integration test simulating cache hit/miss and validating metric values and labels."
          },
          {
            "id": 14,
            "title": "Security, redaction, and compliance for video requests",
            "description": "Ensure sensitive data in prompts and character metadata are redacted in logs and stored according to local-first security policies.",
            "dependencies": [
              "24.1",
              "24.3",
              "24.4"
            ],
            "details": "Reuse redaction middleware to scrub PII in video prompts and metadata. Ensure no plaintext keys in configs; integrate with network allowlist. Mask adapter responses. Add consent flags for using character images for identity conditioning. Update structured logging to include redacted fields only. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests for redaction on video request/response logs. Integration tests ensuring denied outbound when not allowlisted and consent gating behavior."
          },
          {
            "id": 15,
            "title": "Concurrency control and job worker",
            "description": "Introduce a video job worker with bounded concurrency and backpressure, mirroring images pipeline.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.8"
            ],
            "details": "Implement queue (BullMQ/SQS/inproc) with per-adapter concurrency limits, retries, and cancellation. Worker pulls from queue to call adapters, updates status, stores artifacts. Ensure idempotency and deduping by storyboardHash+params. Add graceful shutdown and resume. Run tests.",
            "status": "pending",
            "testStrategy": "Integration tests enqueue multiple jobs, verify ordering, concurrency caps, retries, and cancellation behavior."
          },
          {
            "id": 16,
            "title": "Error handling, retries, and fallback paths",
            "description": "Standardize error taxonomy and retry policies for adapters; fallback to cache or alternative adapter when available.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.9",
              "24.15"
            ],
            "details": "Define errors: Transient, Permanent, NotConfigured, QuotaExceeded. Configure retry with jitter and max attempts per class. On failure with existing cache, return last-known-good artifact with warning meta. If primary adapter unavailable and secondary enabled, route to fallback. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests simulating adapter errors and asserting retry/fallback; integration tests verifying user-facing meta and status codes."
          },
          {
            "id": 17,
            "title": "Documentation and developer ergonomics",
            "description": "Document feature usage, configuration, and extension points for adapters; provide dev scripts for local e2e with LocalI2VAdapter.",
            "dependencies": [
              "24.1",
              "24.3",
              "24.4",
              "24.8",
              "24.10"
            ],
            "details": "Add README with r13VideoEnabled toggle, environment variables, how caching works, identity consistency tips, and UI usage. Provide scripts: yarn dev:video, yarn test:video, and sample requests. Include troubleshooting and FAQ. Run tests to ensure examples align.",
            "status": "pending",
            "testStrategy": "Doc tests: CI step that executes sample curl and validates responses in a mocked environment."
          },
          {
            "id": 18,
            "title": "Performance profiling and memory/disk safeguards",
            "description": "Benchmark video generation path; add limits for duration, resolution, and disk usage to prevent resource exhaustion.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.8",
              "24.12",
              "24.15"
            ],
            "details": "Add guardrails: maxDuration, maxResolution, maxConcurrentJobs; enforce in validators. Implement streaming write to disk and temp file cleanup. Profile CPU/GPU usage with LocalI2VAdapter simulations; record p50/p95 latencies. Run tests.",
            "status": "pending",
            "testStrategy": "Load tests to enqueue multiple jobs; assert limits enforced and no OOM. Metrics assertions for latencies."
          },
          {
            "id": 19,
            "title": "Finalize end-to-end QA and release toggle",
            "description": "Run full suite, verify TC019 across environments, and provide a controlled release plan with feature flag rollout and rollback procedures.",
            "dependencies": [
              "24.1",
              "24.2",
              "24.3",
              "24.4",
              "24.5",
              "24.6",
              "24.7",
              "24.8",
              "24.9",
              "24.10",
              "24.11",
              "24.12",
              "24.13",
              "24.14",
              "24.15",
              "24.16",
              "24.17",
              "24.18"
            ],
            "details": "Execute test matrix: flag OFF/ON, cache MISS/HIT, identity present/missing, loop ON/OFF, adapter local/cloud-disabled, errors and fallbacks. Validate observability dashboards and SLOs. Prepare release notes, migration scripts, and feature flag rollout plan (gradual enable in devâ†’stagingâ†’prod). Ensure safe rollback by disabling flag. Sign off.",
            "status": "pending",
            "testStrategy": "Manual and automated e2e runs; verify TC019 pass criteria; canary in staging; rollback drill."
          }
        ]
      },
      {
        "id": 25,
        "title": "Metrics and Telemetry (Local)",
        "description": "Capture latency and token usage per provider; cache hit rates; campaign retention; fairness metrics.",
        "details": "- Local structured metrics store in SQLite tables metrics_*; no external export by default\n- Dashboards in UI for basic charts\n- Hooks in adapters and GM loop to log timings and counts\n- Opt-in export to CSV",
        "testStrategy": "- Unit tests for metrics aggregation queries\n- E2E: run session and see metrics populate\n- Privacy: verify PII redaction applied before logging",
        "priority": "low",
        "dependencies": [
          5,
          2,
          21,
          8,
          24
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for local metrics capture and dashboards (TC001â€“TC006)",
            "description": "Author unit and integration/UI tests that define the acceptance criteria for local metrics and telemetry. Cover: (1) latency and token usage per provider recorded to SQLite metrics_* tables; (2) cache hit/miss metrics for image/content cache; (3) campaign retention metrics (DAU/WAU/MAU-style session retention, campaign return rate); (4) fairness metrics across providers (latency distribution, error rate, allocation share); (5) hooks in adapters and GM loop emit structured events; (6) opt-in CSV export respects privacy redaction. Include at least one unit test per metrics domain and one end-to-end test that runs a mock session and verifies metrics populate and render basic charts in the UI. Define verification IDs TC001â€“TC006 mapped to these domains.",
            "dependencies": [],
            "details": "Create test scaffolding:\n- DB: Spin up an isolated SQLite database file in tmp with schema migrations applied.\n- Seed: Use seeded time provider to simulate timestamps; use deterministic random.\n- Unit tests:\n  - TC001: Insert/emit provider call start/stop; assert metrics_latency records provider, model, duration p50/p95 aggregate, count.\n  - TC002: Emit token usage events; assert metrics_tokens aggregates by provider and by session; verify total and per-message breakdown.\n  - TC003: Emit cache hits/misses; assert metrics_cache has hit_rate and SLA check (cached <6s median).\n  - TC004: Simulate multi-session campaign re-entries across days; assert metrics_retention with D1/D7 and campaign return rate.\n  - TC005: Simulate multi-provider routing; assert fairness metrics: proportion of calls per provider vs policy target, latency parity (gaps), error rate parity.\n  - TC006: CSV export on with privacy flag: assert PII fields are redacted in export rows.\n- Integration/UI:\n  - Spin up minimal UI with charts fed by metrics endpoints; simulate session; assert charts render non-empty series (smoke test) and correct labels.\n- Mocks: Adapter hooks and GM loop event emitters mocked to generate events into the metrics pipeline.\n- Tooling: Jest/Vitest + Playwright/Cypress; tag tests by TC IDs.",
            "status": "pending",
            "testStrategy": "Unit: validate schema writes and aggregation queries via in-memory/temporary SQLite. Integration: run a short session using mocked providers; verify metrics endpoints and UI charts. Privacy: inject PII in events and assert redaction in logs/exports."
          },
          {
            "id": 2,
            "title": "Define SQLite schema for metrics_* tables and indices",
            "description": "Design and migrate SQLite schema for all local structured metrics tables with necessary indices and foreign keys. Tables: metrics_events (raw), metrics_latency, metrics_tokens, metrics_cache, metrics_retention, metrics_fairness, metrics_exports, and a pii_redaction_audit table. Include views for common aggregations.",
            "dependencies": [
              "25.1"
            ],
            "details": "Implement migration files:\n- metrics_events: id, session_id, campaign_id, provider, model, type, payload_json, ts_ms, redaction_applied BOOLEAN.\n- metrics_latency: id, provider, model, session_id, request_id, duration_ms, success BOOLEAN, ts_ms.\n- metrics_tokens: id, provider, model, session_id, request_id, prompt_tokens, completion_tokens, total_tokens, ts_ms.\n- metrics_cache: id, cache_key, domain (image, text), hit BOOLEAN, latency_ms, ts_ms, campaign_id.\n- metrics_retention: daily aggregates: date_utc, active_campaigns, returning_campaigns_d1, d7, active_sessions.\n- metrics_fairness: window_start, window_end, provider, calls, successes, errors, p50_ms, p95_ms, allocation_share, expected_share.\n- metrics_exports: id, filename, rows, started_at, finished_at, pii_redaction_version, status.\n- pii_redaction_audit: id, source, field, original_hash, mask, ts_ms.\nIndices on ts_ms, provider, model, campaign_id, and composite (provider, ts_ms).\nViews:\n- v_provider_latency_agg (p50/p95/p99 per provider, per model, per day).\n- v_cache_hit_rate (hit_rate per domain and campaign per day).\n- v_tokens_by_provider (sum totals per day).\n- v_fairness_window (allocation vs expected).",
            "status": "pending",
            "testStrategy": "Run migration against temp DB; verify tables and indices exist. Execute sample inserts from tests TC001â€“TC005 to ensure constraints and queries succeed."
          },
          {
            "id": 3,
            "title": "Implement event hooks in adapters and GM loop",
            "description": "Add lightweight, synchronous-safe hooks that emit structured metric events from all providers/adapters and the GM loop. Ensure minimal overhead and no external I/O. Hooks write to metrics_events and specialized tables.",
            "dependencies": [
              "25.1",
              "25.2"
            ],
            "details": "Create MetricsEmitter interface with methods: recordLatency, recordTokens, recordCacheEvent, recordGMEvent, recordError. Implementation writes to SQLite via a buffered queue with batch commits (e.g., every 100ms or max 100 records). Instrument:\n- Provider adapters (LLM, image gen): on request start/finish capture ts, duration, success, tokens.\n- Cache layer: record hit/miss and latency with domain and campaign.\n- GM loop: record turn timings and counts as GM events (optional aggregate only).\n- Ensure PII redaction middleware is invoked before write (use Task 15 redactor when available; inject placeholder deterministic masker until Task 15).\n- Provide noop emitter for tests.\n- Add configuration flag to enable/disable metrics.",
            "status": "pending",
            "testStrategy": "Run TC001â€“TC005 unit tests; they should pass by recording expected events. Validate that emitter batching flushes within test timeouts."
          },
          {
            "id": 4,
            "title": "Metrics aggregation workers and SQL views",
            "description": "Build periodic aggregation jobs that transform raw events into queryable aggregates for dashboards and reports. Jobs compute percentile latencies, token sums, cache hit rates, retention metrics, and fairness windows.",
            "dependencies": [
              "25.1",
              "25.2",
              "25.3"
            ],
            "details": "Implement a background scheduler (node-cron or internal tick) to run aggregations every minute and daily rollups at UTC midnight:\n- Latency: compute p50/p95 per provider/model/day using window functions or approximate percentile if needed.\n- Tokens: sum prompt/completion/total per provider/model/day and per session.\n- Cache: hit_rate = hits/(hits+misses) per campaign and global per domain; SLA check flag cached_median_lt_6s.\n- Retention: compute D1/D7 returning campaigns from sessions_by_day derived table.\n- Fairness: sliding windows (e.g., 1h/24h) compute allocation_share vs expected_share (config) and error/latency parity metrics.\nStore outputs into metrics_* aggregate tables and refresh views.",
            "status": "pending",
            "testStrategy": "Extend TC001â€“TC005 to advance fake clock and trigger workers; assert aggregate rows match expectations, including percentile calculations and hit_rate."
          },
          {
            "id": 5,
            "title": "Privacy redaction integration for metrics pipeline",
            "description": "Integrate PII redaction so that any payloads or identifiers stored in metrics are masked per policy. Ensure opt-in export is redacted and add audit trail.",
            "dependencies": [
              "25.1",
              "25.2",
              "25.3"
            ],
            "details": "Wire existing redaction middleware from Task 15 via an interface. For now, implement a redaction adapter that accepts text fields and returns masked strings plus a hash for audit. Apply to metrics_events.payload_json and any free-text fields. Set redaction_applied flag and write to pii_redaction_audit. Ensure performance by skipping redaction for known numeric/ID fields.",
            "status": "pending",
            "testStrategy": "Run TC006; assert that test PII strings are masked in metrics tables and CSV exports, and audit entries are created."
          },
          {
            "id": 6,
            "title": "Implement local metrics API endpoints",
            "description": "Expose read-only endpoints to power dashboards: /metrics/latency, /metrics/tokens, /metrics/cache, /metrics/retention, /metrics/fairness. Support filters (date range, provider, model, campaign).",
            "dependencies": [
              "25.1",
              "25.2",
              "25.4",
              "25.5"
            ],
            "details": "Create HTTP handlers that query aggregate tables/views with parameterized SQL. Validate inputs; default to last 7 days. Return compact JSON series for charting. Add pagination where result sets can grow. Ensure endpoints do not expose raw PII fields.",
            "status": "pending",
            "testStrategy": "Integration test: call endpoints after seeding events (TC001â€“TC005) and verify JSON schema and values. Security test: ensure PII fields are absent."
          },
          {
            "id": 7,
            "title": "UI dashboards for basic charts",
            "description": "Build simple dashboards to visualize key metrics: latency percentiles per provider/model, token usage trends, cache hit rates/SLA, campaign retention, and fairness indicators.",
            "dependencies": [
              "25.1",
              "25.6"
            ],
            "details": "Implement frontend views:\n- Latency: line/area charts with p50/p95 per provider; model filter.\n- Tokens: stacked area for total tokens by provider.\n- Cache: gauge or line for hit rate; badge for SLA cached <6s median.\n- Retention: cohort/line chart for D1/D7 campaign retention.\n- Fairness: bar charts for allocation share vs expected and error rate by provider.\nUse existing chart library. Add basic empty-state and error handling.",
            "status": "pending",
            "testStrategy": "UI test (Playwright/Cypress): After seeding data, navigate dashboards and assert charts render with expected labels/series (extends initial UI part of TC001â€“TC006)."
          },
          {
            "id": 8,
            "title": "Opt-in CSV export with privacy safeguards",
            "description": "Implement CSV export for selected metrics with explicit opt-in flag. Respect redaction, include export metadata, and write metrics_exports record.",
            "dependencies": [
              "25.1",
              "25.2",
              "25.5",
              "25.6"
            ],
            "details": "Create endpoint /metrics/export?type=latency|tokens|cache|retention|fairness&filters=... requiring export_enabled=true config. Stream CSV rows from aggregate queries. Ensure field set excludes PII and applies masking if any free-text. Persist export job record in metrics_exports with status progression.",
            "status": "pending",
            "testStrategy": "Extend TC006 to request CSV export and verify content headers, row counts, and redaction. Negative test: export disabled returns 403."
          },
          {
            "id": 9,
            "title": "Fairness metrics computation and config",
            "description": "Finalize fairness definitions and computation logic, including expected allocation shares per provider, parity thresholds, and alerts.",
            "dependencies": [
              "25.1",
              "25.3",
              "25.4",
              "25.6"
            ],
            "details": "Add configuration for expected provider shares (e.g., A:50%, B:30%, C:20%). Compute in sliding windows: allocation_share, error_rate, p95 latency. Calculate parity deltas and a fairness_score. Surface via /metrics/fairness and UI badges. Optionally add soft alerts (in-UI warnings) when thresholds exceeded.",
            "status": "pending",
            "testStrategy": "Unit: feed synthetic multi-provider data and assert allocation_share and parity calculations. Integration: endpoints return correct fairness metrics that match UI."
          },
          {
            "id": 10,
            "title": "Campaign retention metrics pipeline",
            "description": "Implement cohort/retention calculations for campaigns returning on D1/D7 and rolling active campaigns, based on session activity.",
            "dependencies": [
              "25.1",
              "25.2",
              "25.4",
              "25.6"
            ],
            "details": "Derive sessions_by_day from events or session table (dependency on existing session source). Compute per-campaign first_seen date and subsequent activity flags for D1/D7. Populate metrics_retention daily. Expose via endpoints and charts.",
            "status": "pending",
            "testStrategy": "Unit: simulate campaigns active across days with fake clock; assert D1/D7 counts. Integration: endpoint returns expected values; UI renders retention chart."
          },
          {
            "id": 11,
            "title": "Cache metrics and SLA checks",
            "description": "Measure cache hit rates and retrieval latency; verify cached retrieval median under 6s for images as SLA. Integrate with Task 8 cache layer.",
            "dependencies": [
              "25.1",
              "25.3",
              "25.4",
              "25.6"
            ],
            "details": "Emit cache events from image generation service (hits/misses, latency). Aggregate hit_rate by campaign and globally. Compute median latency for cached items; flag SLA violations per day and last 1h. Display SLA badge in UI.",
            "status": "pending",
            "testStrategy": "Integration with Task 8 TC003 data: assert hit_rate and SLA median computations. UI shows correct badge state."
          },
          {
            "id": 12,
            "title": "Token usage accounting per provider",
            "description": "Accurately record prompt/completion/total tokens by provider and model; support session and campaign breakdowns.",
            "dependencies": [
              "25.1",
              "25.3",
              "25.4",
              "25.6"
            ],
            "details": "From adapter responses capture token counts; when unavailable, estimate via tokenizer library mapped per model. Aggregate tokens per day, session, and campaign. Provide filters in API/UI.",
            "status": "pending",
            "testStrategy": "Unit: verify estimation matches tokenizer outputs for known prompts. Integration: seed events and assert totals by provider/model/session."
          },
          {
            "id": 13,
            "title": "Latency metrics per provider/model",
            "description": "Collect and aggregate latency distributions per provider and model with percentiles and error segmentation.",
            "dependencies": [
              "25.1",
              "25.3",
              "25.4",
              "25.6"
            ],
            "details": "Instrument timers around provider calls; record success/error states. Aggregations compute p50/p95/p99 and error-rate-weighted stats. Expose separate series for successes vs errors.",
            "status": "pending",
            "testStrategy": "Unit: feed synthetic durations and assert percentile outputs. Integration: endpoint returns correct series; UI renders multiple series."
          },
          {
            "id": 14,
            "title": "End-to-end session metrics smoke test",
            "description": "Create a full E2E test that runs a short session with mixed providers, cache hits/misses, and campaign interactions, then validates that all metrics and dashboards update accordingly.",
            "dependencies": [
              "25.1",
              "25.3",
              "25.4",
              "25.6",
              "25.7",
              "25.8",
              "25.9",
              "25.10",
              "25.11",
              "25.12",
              "25.13"
            ],
            "details": "Use mock adapters to simulate realistic timings, tokens, errors, and cache outcomes. Run aggregations, query endpoints, and open UI routes. Validate presence and correctness of key figures. Tag as E2E and link verification IDs used earlier.",
            "status": "pending",
            "testStrategy": "E2E runner executes headless UI tests plus API assertions. Pass criteria: no 5xx, charts render, metrics values match seeded expectations."
          },
          {
            "id": 15,
            "title": "Performance and backpressure controls",
            "description": "Ensure the metrics pipeline has negligible overhead and cannot overwhelm the app. Add batching, backpressure, and configurable sampling.",
            "dependencies": [
              "25.3",
              "25.4"
            ],
            "details": "Implement: bounded queues, drop-oldest or sample when above thresholds, configurable sampling rate per event type, async batch commits with WAL mode in SQLite, and periodic vacuum. Add health metrics for the metrics system itself.",
            "status": "pending",
            "testStrategy": "Load test with synthetic high-rate events; assert tail latencies for main app unaffected and metrics loss within configured sampling/drop policies."
          },
          {
            "id": 16,
            "title": "Documentation and developer ergonomics",
            "description": "Add README and inline docs describing metrics schema, hooks, APIs, and dashboards; provide examples for emitting events and querying metrics.",
            "dependencies": [
              "25.3",
              "25.6",
              "25.7",
              "25.8"
            ],
            "details": "Write docs with code snippets, SQL examples, and troubleshooting (e.g., WAL settings, locking). Include a quickstart to run tests and view dashboards locally.",
            "status": "pending",
            "testStrategy": "Docs linting/build checks; manual verification that steps reproduce local dashboard with sample data."
          }
        ]
      },
      {
        "id": 26,
        "title": "Verification Plan Mapping and Test Suites TC001â€“TC019",
        "description": "Implement automated tests mapped to each requirementâ€™s test cases ensuring acceptance criteria coverage.",
        "details": "- Test harness tagging by R-xxx/TCxxx\n- Playwright scenarios for voice UI, multi-client sync, images, alliances, mission DSL, memory isolation, resume/branch, providers, ticker, packs, multi-campaign, scheduling, video\n- CI matrix runs smoke for prototype and full for MVP\n- Latency sanity tests as per phases",
        "testStrategy": "- Ensure each TC passes with reports; coverage thresholds >80% lines in core modules\n- Flakiness tracker; retries with artifacts (logs, HAR, screenshots)",
        "priority": "high",
        "dependencies": [
          6,
          8,
          9,
          10,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          24
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Author unit tests for verification harness core (tagging, RTM, coverage gates)",
            "description": "Before implementation, create unit tests that codify acceptance criteria for the verification harness: requirement/test-case tagging by R-xxx/TCxxx, requirements-to-test traceability matrix (RTM) generation, coverage thresholds (>80% lines for core modules), and flakiness tracking metadata presence. These tests should fail initially and define the expected public APIs and artifacts.",
            "dependencies": [],
            "details": "Implement tests using your repoâ€™s unit framework (e.g., Jest/Mocha). Write tests that: 1) Assert a tag parser maps file-level and test-level annotations like @req:R-123 and @tc:TC007 to an internal model; 2) Verify RTM builder emits JSON/CSV with rows: requirement_id, tc_id, file, status; 3) Enforce coverage gate by mocking a coverage report object and asserting that the gate fails below 80% lines on core modules; 4) Validate that a FlakinessTracker API records retries, artifacts paths, and pass/fail deltas; 5) Check that a LatencySanity schema exists for per-phase latency checks with thresholds injected via config.",
            "status": "pending",
            "testStrategy": "Unit only in this subtask. Snapshot RTM output and validate schema. Use fixtures for annotated test files. Mock coverage data sources. Ensure tests fail prior to implementation."
          },
          {
            "id": 2,
            "title": "Implement verification harness core to satisfy unit tests",
            "description": "Build the tagging, RTM, coverage gate, flakiness tracker, and latency sanity schema to make Subtask 26.1 tests pass. Provide CLI hooks to integrate into CI.",
            "dependencies": [
              "26.1"
            ],
            "details": "Implement modules: TagIndexer (glob test files, parse @req and @tc tags), RTMBuilder (emit RTM.json/RTM.csv), CoverageGate (read lcov/istanbul JSON, enforce per-module thresholds configurable, default 80% lines on core), FlakinessTracker (record retry counts, attach logs/HAR/screenshots paths), LatencySanity (YAML schema with phases and thresholds). Provide CLI: verify:build-rtm, verify:coverage, verify:flakiness, verify:latency:validate. Re-run tests and iterate until green.",
            "status": "pending",
            "testStrategy": "Run unit tests from 26.1 and ensure 100% pass. Add minimal integration test invoking the CLI with sample fixtures to produce RTM."
          },
          {
            "id": 3,
            "title": "Author unit and integration tests for CI matrix and reporting",
            "description": "Define tests verifying CI matrix execution plan: smoke for prototype, full for MVP; artifact collection (logs, HAR, screenshots); and publishing RTM and coverage reports.",
            "dependencies": [
              "26.2"
            ],
            "details": "Write unit tests for a MatrixPlanner that, given env TARGET=prototype, selects smoke test set; when TARGET=mvp, selects full suite. Integration tests simulate CI job config generation (e.g., GitHub Actions YAML or equivalent) and assert steps include: build, verify:build-rtm, run smoke/full Playwright sets, collect artifacts, upload reports. Test that report publisher places RTM and coverage under artifacts/verification/ with run metadata.",
            "status": "pending",
            "testStrategy": "Use snapshot tests for generated CI config. Mock filesystem to assert artifact paths. Ensure tests fail before implementation."
          },
          {
            "id": 4,
            "title": "Implement CI matrix planner, report publishing, and artifact wiring",
            "description": "Implement the CI matrix and reporting integrations to satisfy tests, including smoke vs full selection and artifact publication.",
            "dependencies": [
              "26.3"
            ],
            "details": "Create MatrixPlanner with tag expressions (e.g., @smoke) and test selectors for Playwright/Jest. Generate CI config via templates. Implement ReportPublisher to package RTM.json/RTM.csv, coverage, junit.xml, flakiness.json, and Playwright artifacts into versioned paths. Update npm scripts and CI workflows. Re-run tests until passing.",
            "status": "pending",
            "testStrategy": "Run integration tests from 26.3, then perform a dry-run CI locally (act or local runner) to validate steps."
          },
          {
            "id": 5,
            "title": "Write tests for Playwright test scaffolding and tagging (TC001â€“TC019)",
            "description": "Create tests asserting Playwright project config defines scenarios and per-TC tag mapping across voice UI, multi-client sync, images, alliances, mission DSL, memory isolation, resume/branch, providers, ticker, packs, multi-campaign, scheduling, video.",
            "dependencies": [
              "26.2"
            ],
            "details": "Add a meta-test (Node script or unit test) that loads playwright.config and asserts: projects exist for web, video, and latency; testDir includes e2e; expect reporters: list + junit + html; per-test annotations include @tc:TCxxx and @req:R-xxx via file headers. Validate that grep for @smoke slices include the intended minimal tests per area. Ensure initial failure to drive implementation.",
            "status": "pending",
            "testStrategy": "Unit tests over config objects plus a Playwright dry-run (â€”list) parsing to verify presence of TC001â€“TC019 tags."
          },
          {
            "id": 6,
            "title": "Implement Playwright config, base fixtures, and TC tag mapping",
            "description": "Implement Playwright projects, fixtures (multi-client), and test annotations to satisfy the scaffolding tests.",
            "dependencies": [
              "26.5"
            ],
            "details": "Configure multiple projects: chromium, firefox (optional), webkit (optional), video. Implement base fixtures: multiClientContext (2+ pages with shared session), media permissions for mic/camera, websocket HAR capture. Add test annotation helpers to stamp @tc and @req. Ensure smoke.list covers fast sanity paths for prototype. Re-run tests.",
            "status": "pending",
            "testStrategy": "Run Playwright â€”list and meta-tests to confirm TC coverage and tags; execute a sample test to validate fixtures."
          },
          {
            "id": 7,
            "title": "TC001 Voice UI: author failing tests (unit: latency calc; e2e: captions/diarization multi-client)",
            "description": "Create tests for TC001 acceptance: visible transcript/captions in multi-client sessions, diarization by speaker, partial hypotheses streaming, end-to-end latency median <800 ms locally, graceful degradation under packet loss.",
            "dependencies": [
              "26.6",
              "26.2"
            ],
            "details": "Unit: test LatencyEstimator computes median and enforces threshold from LatencySanity config. E2E: Playwright test spins two clients, simulates audio via pre-recorded WAV/Opus, verifies transcript events, caption rendering per speaker, and measures E2E latency (start speaking to caption display). Add a network condition (packet loss 5â€“10%) and assert UI degrades but maintains updates.",
            "status": "pending",
            "testStrategy": "Use synthetic audio fixtures; capture timestamps; assert median <800ms locally; tag @tc:TC001 @smoke for the fastest path."
          },
          {
            "id": 8,
            "title": "Satisfy TC001 tests with minimal adapters and mocks",
            "description": "Implement or mock the STT streaming adapter and client UI hooks in the test app to pass TC001 tests without full production dependencies.",
            "dependencies": [
              "26.7"
            ],
            "details": "Provide a test STT adapter that streams partial/final hypotheses with speaker tags by connection id. Implement caption rendering with timestamps and diarization labels. Add network resilience logic (buffering, backoff). Integrate latency measurement hooks. Rerun TC001 until green.",
            "status": "pending",
            "testStrategy": "Run TC001 unit and E2E repeatedly; collect artifacts (screenshots, HAR) on failure; record flakiness."
          },
          {
            "id": 9,
            "title": "TC002 Multi-client synchronization: tests for shared state coherence",
            "description": "Author tests verifying state sync across multiple clients with consistency under joins/leaves and network jitter.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Two to three clients perform synchronized actions (e.g., room join, event broadcast). Assert delivery order constraints and final state convergence. Unit: test a CRDT/WS sync module for idempotency and dedup.",
            "status": "pending",
            "testStrategy": "Introduce 200â€“500ms artificial jitter; assert no divergence; tag @tc:TC002."
          },
          {
            "id": 10,
            "title": "Implement sync fixtures and pass TC002",
            "description": "Implement the minimal sync mechanisms or mocks to satisfy TC002 tests.",
            "dependencies": [
              "26.9"
            ],
            "details": "Add a test WS gateway and deterministic ordering buffer in test harness. Ensure merge semantics produce convergence. Rerun tests until passing.",
            "status": "pending",
            "testStrategy": "Playwright E2E with 3 clients; verify event logs; capture HAR."
          },
          {
            "id": 11,
            "title": "TC003 Image handling: tests for upload, rendering, and alt/accessibility",
            "description": "Create tests to validate image upload pipeline, caching, rendering, and alt text/accessibility semantics.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Upload image, verify thumbnail and full-resolution render. Unit: test image metadata extraction and cache keying. Accessibility: assert alt text present and announced.",
            "status": "pending",
            "testStrategy": "Use local image fixtures; tag @tc:TC003."
          },
          {
            "id": 12,
            "title": "Implement minimal image pipeline and pass TC003",
            "description": "Provide basic upload/caching/render paths to satisfy TC003.",
            "dependencies": [
              "26.11"
            ],
            "details": "Implement in-memory or tmp-dir storage, thumbnail generator stub, and accessible UI rendering. Rerun tests until green.",
            "status": "pending",
            "testStrategy": "Rerun E2E/UI tests; verify no console errors; collect screenshots."
          },
          {
            "id": 13,
            "title": "TC004â€“TC005 Alliances and leaderboard: author tests",
            "description": "Add API/UI tests for alliance lifecycle and leaderboard updates on scoring events; verify per-campaign separation.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Create alliance, invite/join/leave, assign team; assert visibility in UI. Trigger scoring events; verify leaderboard updates and fairness invariants. Unit: validate data model functions and isolation by campaign.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC004 and @tc:TC005; include smoke subset."
          },
          {
            "id": 14,
            "title": "Implement stubs/mocks to pass TC004â€“TC005",
            "description": "Implement minimal API handlers and UI to satisfy alliance and leaderboard tests within the test app context.",
            "dependencies": [
              "26.13"
            ],
            "details": "Create in-memory tables for alliances, members, and scores; implement endpoints and simple UI views. Ensure per-campaign scoping. Re-run tests until passing.",
            "status": "pending",
            "testStrategy": "Run E2E; verify WS updates for leaderboard where applicable."
          },
          {
            "id": 15,
            "title": "TC006 Mission DSL: tests for parse/execute and rule hooks",
            "description": "Create unit and E2E tests that define a small mission DSL script and verify parsing, rule evaluation, and UI state effects.",
            "dependencies": [
              "26.6"
            ],
            "details": "Unit: parser produces AST; executor evaluates conditions and emits events. E2E: Load mission script, perform actions that trigger state changes; assert UI reflects mission progress.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC006. Include negative test for invalid syntax."
          },
          {
            "id": 16,
            "title": "Implement mission DSL minimal runtime to pass TC006",
            "description": "Provide a small interpreter and hooks into the demo UI to satisfy mission DSL tests.",
            "dependencies": [
              "26.15"
            ],
            "details": "Implement parser (PEG or hand-rolled) for a narrow subset; executor with event bus; bind to UI updates. Rerun tests.",
            "status": "pending",
            "testStrategy": "Unit parser tests + E2E mission progress path."
          },
          {
            "id": 17,
            "title": "TC007 Memory isolation: tests for per-session/campaign boundaries",
            "description": "Author tests that validate no cross-leakage of vector memories or caches between sessions/campaigns.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Run two campaigns in parallel; write memory in A; verify absence in B. Unit: guard middleware blocks cross-campaign queries. Validate file cache uses per-campaign subdirs.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC007; include HAR to verify namespaces."
          },
          {
            "id": 18,
            "title": "Implement isolation guards and cache scoping to pass TC007",
            "description": "Add middleware and storage scoping to satisfy memory isolation tests.",
            "dependencies": [
              "26.17"
            ],
            "details": "Implement context.campaign_id propagation, enforce scoping on DB/Vector/Cache queries, and file cache pathing. Rerun tests.",
            "status": "pending",
            "testStrategy": "Re-run unit/E2E; assert no leakage; check logs for denied access."
          },
          {
            "id": 19,
            "title": "TC008 Resume/branch: tests for session resume and branching history",
            "description": "Write tests that verify a user can resume a session and branch from a prior state with correct history and isolation.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Save checkpoint; resume later; create branch; verify timelines. Unit: serialization/deserialization of state snapshot.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC008; assert deterministic replay."
          },
          {
            "id": 20,
            "title": "Implement resume/branch minimal functionality to pass TC008",
            "description": "Implement checkpoint store and UI controls sufficient for passing resume/branch tests.",
            "dependencies": [
              "26.19"
            ],
            "details": "Add snapshot serializer, storage (in-memory + file fallback), resume loader, and branching identifiers; update UI to list branches.",
            "status": "pending",
            "testStrategy": "Re-run tests; ensure history correctness with assertions."
          },
          {
            "id": 21,
            "title": "TC009 Provider adapters: tests for multiple model providers with fallback",
            "description": "Create tests ensuring provider selection, fallback on error/latency, and consistent interface.",
            "dependencies": [
              "26.6"
            ],
            "details": "Unit: ProviderRegistry chooses best provider by policy. E2E: Force primary failure, verify fallback engages and user flow continues.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC009; include latency thresholds per provider."
          },
          {
            "id": 22,
            "title": "Implement provider registry and fallbacks to pass TC009",
            "description": "Add minimal provider adapters and registry logic to satisfy provider tests.",
            "dependencies": [
              "26.21"
            ],
            "details": "Implement a common interface, policy-based selection, retry/backoff, and circuit breaker flags. Use mock providers for tests.",
            "status": "pending",
            "testStrategy": "Re-run unit and E2E; verify metrics and selection logs."
          },
          {
            "id": 23,
            "title": "TC010 Ticker/notifications: tests for real-time updates",
            "description": "Write tests for ticker stream rendering and reliability (ordering, dedup, persistence).",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Trigger events; assert ticker UI updates in order with no duplicates. Unit: sequence number logic and persistence buffer.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC010; include offline/online toggle test."
          },
          {
            "id": 24,
            "title": "Implement ticker stream to pass TC010",
            "description": "Add sequence-aware ticker stream and UI rendering to satisfy tests.",
            "dependencies": [
              "26.23"
            ],
            "details": "Implement server emitter with seq ids, client dedup buffer, and persistence for last N events; update UI.",
            "status": "pending",
            "testStrategy": "Re-run tests with artificial packet loss."
          },
          {
            "id": 25,
            "title": "TC011 Content packs: tests for pack load/enable and override precedence",
            "description": "Define tests verifying content pack selection, conflict resolution, and hot-reload in dev.",
            "dependencies": [
              "26.6"
            ],
            "details": "Unit: resolver picks highest precedence override. E2E: Enable/disable packs; assert content changes immediately.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC011; negative test for missing pack."
          },
          {
            "id": 26,
            "title": "Implement pack loader/resolver to pass TC011",
            "description": "Implement minimal pack loader and precedence resolver.",
            "dependencies": [
              "26.25"
            ],
            "details": "Add manifest reader, merge strategy, and UI toggle. Support hot-reload in dev using file watchers.",
            "status": "pending",
            "testStrategy": "Re-run tests; validate no UI flicker on toggle."
          },
          {
            "id": 27,
            "title": "TC012 Multi-campaign: author tests for isolation across full stack",
            "description": "Create comprehensive tests that run two concurrent campaigns and verify isolation across DB, caches, WS namespaces, and schedules.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Spin campaigns A and B; perform operations; assert no cross-broadcasts and separate assets. Unit: middleware blocks cross-campaign access.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC012; include stress with parallel actions."
          },
          {
            "id": 28,
            "title": "Implement multi-campaign isolation layer to pass TC012",
            "description": "Wire context propagation and namespacing to pass full-stack isolation tests.",
            "dependencies": [
              "26.27"
            ],
            "details": "Implement per-campaign WS namespaces, DB query scoping, and file cache subdirs. Reuse from Task 18 where available.",
            "status": "pending",
            "testStrategy": "Re-run tests; assert namespace separation via logs/HAR."
          },
          {
            "id": 29,
            "title": "TC013 Scheduling: tests for job creation, execution windows, and per-campaign scoping",
            "description": "Add tests verifying scheduler respects cron/interval windows, dedup, and isolation.",
            "dependencies": [
              "26.6"
            ],
            "details": "Unit: scheduler computes next run accurately. E2E: Create jobs in A and B; ensure no cross-trigger; verify missed-run catch-up rules.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC013; simulate clock with fake timers."
          },
          {
            "id": 30,
            "title": "Implement scheduler minimal features to pass TC013",
            "description": "Provide a lightweight scheduler service with per-campaign queues and dedup keys.",
            "dependencies": [
              "26.29"
            ],
            "details": "Implement cron parsing, next-run calc, queue per campaign, and execution hooks. Ensure isolation by campaign_id.",
            "status": "pending",
            "testStrategy": "Re-run unit/E2E; assert deterministic scheduling with fake timers."
          },
          {
            "id": 31,
            "title": "TC014 Video: tests for playback, streaming join, and caption sync with TTS/STT",
            "description": "Create tests ensuring video sessions initialize, playback controls work, and captions sync with TTS/STT where applicable.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Join a video session, play/pause/seek, verify caption track alignment. Unit: timeline mapper from STT/TTS timestamps to VTT cues.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC014; allow headful CI mode for media."
          },
          {
            "id": 32,
            "title": "Implement video session stubs and caption track to pass TC014",
            "description": "Add minimal video player integration with caption track generation.",
            "dependencies": [
              "26.31"
            ],
            "details": "Use HTML5 video with a mock media source; generate VTT cues from timestamps; expose controls in UI.",
            "status": "pending",
            "testStrategy": "Re-run E2E; verify cues align within tolerance."
          },
          {
            "id": 33,
            "title": "TC015 Providers performance: latency sanity tests per phase",
            "description": "Add latency sanity tests per project phase, asserting configured thresholds for key provider operations.",
            "dependencies": [
              "26.2",
              "26.6"
            ],
            "details": "Unit: read LatencySanity YAML and ensure enforcement logic applies per environment (dev/prototype/mvp). E2E: run representative provider calls and measure median/95th vs thresholds.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC015; skip or relax on CI if env var set."
          },
          {
            "id": 34,
            "title": "Implement latency collectors and metrics to pass TC015",
            "description": "Wire timing hooks and metrics export to satisfy latency sanity tests.",
            "dependencies": [
              "26.33"
            ],
            "details": "Implement timers around provider calls, collect histograms, and expose results to the test harness for assertion. Support JSON export.",
            "status": "pending",
            "testStrategy": "Re-run tests; verify medians below thresholds locally."
          },
          {
            "id": 35,
            "title": "TC016 Images accessibility and performance budgets",
            "description": "Expand image tests to include LCP budget and alt text compliance across views.",
            "dependencies": [
              "26.11"
            ],
            "details": "E2E: Measure LCP for an image-heavy page and assert under budget; ensure alt text present for all images and no empty alts unless decorative.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC016; integrate with Playwright trace for timings."
          },
          {
            "id": 36,
            "title": "Implement image perf budgets and a11y checks to pass TC016",
            "description": "Add lazy-loading, responsive sources, and a11y lint rules to meet budgets and compliance.",
            "dependencies": [
              "26.35"
            ],
            "details": "Implement loading=lazy, srcset/sizes, and an eslint-plugin-jsx-a11y rule gate. Adjust caching headers in dev server.",
            "status": "pending",
            "testStrategy": "Re-run LCP and a11y tests; validate budgets."
          },
          {
            "id": 37,
            "title": "TC017 Full isolation (multi-campaign, DB, cache, WS): tests aligned to Task 18",
            "description": "Mirror Task 18â€™s TC017 acceptance tests in this suite to ensure end-to-end isolation verification.",
            "dependencies": [
              "26.27",
              "26.17"
            ],
            "details": "E2E: Two concurrent campaigns, verify no leakage across DB queries, caches, and WS channels. Unit: middleware denies cross-access.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC017; coordinate with Task 18 artifacts."
          },
          {
            "id": 38,
            "title": "Ensure TC017 passes using Task 18 layer",
            "description": "Integrate Task 18 isolation implementation into the test app to make TC017 green in this suite.",
            "dependencies": [
              "26.37"
            ],
            "details": "Wire context propagation and isolation middleware from Task 18 into the test harness paths used by Playwright tests.",
            "status": "pending",
            "testStrategy": "Re-run TC017; inspect HAR for namespaces; confirm green."
          },
          {
            "id": 39,
            "title": "TC018 Multi-campaign UI management and schedules visibility",
            "description": "Add tests verifying UI controls for switching campaigns, viewing schedules, and ensuring isolation of views and actions.",
            "dependencies": [
              "26.6",
              "26.29"
            ],
            "details": "E2E: Switch campaigns in UI; validate assets, schedules, and leaderboards update to selected campaign only.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC018; include smoke view-switch test."
          },
          {
            "id": 40,
            "title": "Implement UI scaffolding for multi-campaign management to pass TC018",
            "description": "Provide minimal UI for campaign switching and scoped data views.",
            "dependencies": [
              "26.39"
            ],
            "details": "Add a campaign selector component, scope data fetches by campaign_id, and update views (schedules, leaderboard) accordingly.",
            "status": "pending",
            "testStrategy": "Re-run tests; verify no leakage upon switching."
          },
          {
            "id": 41,
            "title": "TC019 End-to-end regression suite assembly and gating",
            "description": "Create a meta-test ensuring all TC001â€“TC019 are included, tagged correctly, and reported in RTM with pass status before release gate passes.",
            "dependencies": [
              "26.4",
              "26.6"
            ],
            "details": "Implement a gate script that reads RTM.json and JUnit results; fails if any TC001â€“TC019 absent or failing. Validate that smoke vs full gates are applied based on TARGET environment.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC019; simulate failing case to ensure gate blocks."
          },
          {
            "id": 42,
            "title": "Docs and traceability: verification plan and RTM publication",
            "description": "Publish the Software Verification and Validation Plan snippets, RTM, and how-to-run docs; ensure CI uploads artifacts for each run.",
            "dependencies": [
              "26.4",
              "26.41"
            ],
            "details": "Add docs/verification/ with SVVP overview, mapping TCs to requirements, run commands, and CI links. Ensure CI step publishes RTM and validation reports to artifacts and, if available, a dashboard.",
            "status": "pending",
            "testStrategy": "Link-check docs; run a full CI dry-run to confirm artifacts present."
          }
        ]
      },
      {
        "id": 27,
        "title": "Implement Subscription/Depth Progression Preset (Default) with Achievements",
        "description": "Add a default campaign preset focused on long-term progression (levels, perks, artifacts, crew achievements, soft-fail credit) with private telemetry points, configurable visibility/leaderboard/fail-forward toggles, full achievements system (definitions, unlocks, rewards, notifications), DB schema, UI (achievements panel + banner, preset settings), tests, and isolation/perf hardening. Feature must be gated behind preset selection and applied to new campaigns.",
        "details": "Scope and architecture\n- Preset definition\n  - Create a CampaignPreset registry keyed by enum: DEFAULT_SUBSCRIPTION_DEPTH.\n  - Preset sets defaults: pointsVisibility=private, leaderboardScope=off, failForward=strict (configurable), progression model=levels+perks+artifacts, crewAchievements=enabled, softFailCredit=enabled.\n  - Hook preset into campaign creation flow so new campaigns default to this preset unless user chooses another.\n\n- Progression mechanics integration\n  - Extend rules/progression module to expose: computeXP(missionOutcome, skillChecks, artifactsFound, allianceFeats), level thresholds, perk point allocation, artifact slots and gating.\n  - Implement fail-forward accounting: on failed missions grant reduced XP and soft credit toward next mission gate. Add tunables in preset for fraction (e.g., 30â€“50%).\n  - Record per-mission private points (telemetry only) separate from public scores table; do not emit leaderboard updates in this preset.\n\n- Achievements system\n  - Definitions: per-player and per-crew achievements with fields: id, scope (player|crew), name, description, rarity, category, unlockConditions (DSL or JSON: missionCompletions>=N, skillChecks[DC>=X] success count, collectArtifact[set], allianceFeat[raidX], time-bounded), rewards (xp, items, titles), icon, enabled, version.\n  - Unlocks: per subject table to store unlocked achievements with timestamps, campaign_id, subject_id, version, reward_granted flag; include progress tracking for incremental achievements.\n  - Evaluators: event-driven evaluators subscribing to rules and mission events; incremental progress updates and final unlock with idempotent reward grant.\n  - Notifications: lightweight in-session banner/toast with accessibility labels; queue dedupe; batch multiple unlocks.\n\n- Campaign-level toggles\n  - Expose settings on campaign model: pointsVisibility (private|friends|public), leaderboardScope (off|friends), failForwardStrictness (off|lenient|strict). Enforce at API and UI. For this preset: default private/off/strict, but allow owner to adjust within allowed bounds (no public leaderboard in this preset).\n\n- Privacy and isolation\n  - Ensure no writes to leaderboard tables when leaderboardScope=off; guard in service layer. Enforce DB constraints or service checks to prevent cross-campaign leakage. Ensure vector memory namespaces remain campaign:<id> and player:<id> only.\n\n- Telemetry\n  - Event schema: achievement_progress, achievement_unlocked, mission_points_recorded, perk_allocated, artifact_acquired. Only stored locally; redact PII; ensure pointsVisibility=private prevents any external export.\n\n- Database schema (migrations)\n  - achievements_definitions(id PK, scope, key UNIQUE, name, description, rarity, category, conditions JSON, rewards JSON, icon, enabled, version, created_at).\n  - achievements_unlocks(id PK, campaign_id, scope, subject_id, def_id FK, progress JSON, unlocked_at NULLABLE, reward_granted BOOL, UNIQUE(campaign_id, scope, subject_id, def_id)).\n  - telemetry_points(id PK, campaign_id, player_id NULLABLE, mission_id, points INT, reason TEXT, created_at).\n  - progression_state(id PK, campaign_id, player_id, level INT, xp INT, perk_points INT, artifacts JSONB).\n  - campaign_settings add: preset enum, points_visibility, leaderboard_scope, fail_forward_strictness.\n\n- API\n  - POST /campaigns with preset selection (applies defaults). PATCH /campaigns/:id/settings for toggles with validation.\n  - GET /achievements/definitions?scope=player|crew, GET /achievements/unlocks/:subject, POST /achievements/claim/:unlockId (idempotent claim if rewards require claim), POST /progression/perk-allocate.\n  - POST /telemetry/mission-points (internal server call) stores private points when missions resolve.\n\n- UI\n  - Achievements panel: filter by All/Unlocked/Locked, categories; show progress bars; claim button when applicable. Respect scope switch between Player and Crew for current campaign.\n  - Lightweight banner/toast for unlocks with small icon, title, reward summary; queue with max display rate; accessible and non-blocking.\n  - Campaign Settings for this preset: radio/selectors for points visibility (private only with info tooltip), leaderboard scope (off or friends-only disabled state note), fail-forward strictness; preset badge and description.\n  - Indicate that leaderboards are disabled in this preset in any leaderboard UI, and suggest switching modes (without enabling here).\n\n- Security & performance\n  - Validate all preset toggle updates server-side; reject public leaderboard in this preset.\n  - Idempotency keys for unlock/reward claims to prevent duplication on retries.\n  - Ensure vector index namespace resolution uses campaign_id guard; add unit tests around it. No external writes for telemetry or achievements.\n\n- Data seeding\n  - Provide initial achievements set: examples â€” First Steps (first mission), Skillful (10 DC15+ successes), Relic Hunter (collect 3 artifacts), United We Stand (crew completes alliance feat), Unstoppable (complete mission after prior fail).\n  - Provide XP curve defaults and sample perks.\n\n- Feature flagging\n  - Gate all UI and API behind preset feature and a server flag to allow staged rollout.\n",
        "testStrategy": "Unit tests\n- Progression math: XP calculation across success/fail-forward paths; level thresholds; perk allocation bounds; artifact slot gating.\n- Achievements logic: incremental progress and unlock for each seeded achievement; idempotent reward grant; evaluator filtering by campaign preset.\n- Privacy/isolation: when leaderboardScope=off, any score submit call is a no-op and logs warning; points written only to telemetry_points; vector namespace isolation enforced on all evaluators.\n- Settings validation: API rejects attempts to set leaderboardScope=public for this preset; pointsVisibility cannot be set to public.\n- Telemetry: events serialized without PII; schema conformance.\n\nIntegration/API tests\n- Create campaign with default preset via /campaigns; verify settings default and preset recorded.\n- Mission resolution posts private points and triggers achievement progress; GET unlocks reflects updates.\n- Toggle failForwardStrictness and verify XP outcomes adjust; verify friends-only leaderboard option is disabled/unavailable in this preset.\n- Idempotent reward claim: POST claim twice returns same state and no duplicate rewards.\n\nUI/End-to-end (Playwright)\n- Achievements panel: filtering, progress bars, unlocked state, claim flow; accessibility checks (axe) pass.\n- Unlock banner displays with correct text/icon and queues when multiple unlocks occur; screen reader announcements present.\n- Campaign settings UI shows preset badge and enforces disabled public leaderboard; changes persist and reflect in API.\n\nSecurity/performance\n- Fuzz tests: no negative XP, no level overflow; unlock spam throttled, banner queue bounded.\n- Verify no external writes when pointsVisibility=private (network inspection/mocking).\n- Vector memory isolation tests to ensure no cross-campaign reads/writes.\n\nAcceptance mapping\n- Ensure scenarios cover R-003/004/005/006/008/009/011 by linking to TC004/TC006/TC007/TC009/TC014/TC015/TC017 in the test harness tags and reports.",
        "status": "pending",
        "dependencies": [
          2,
          4,
          9,
          11,
          21,
          26
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Author test plans and scaffolding mapped to TC004/TC006/TC007/TC009/TC014/TC015/TC017",
            "description": "Create test plans and skeleton test files covering achievements, progression math, preset toggles, privacy/isolation, telemetry, API/UI flows. Tag tests with TC IDs and requirement references. Establish fixtures, factories, and mock event buses required across subsequent tests. This is the foundation for test-first development.",
            "dependencies": [],
            "details": "â€¢ Create test directories: server/tests/progression, server/tests/achievements, server/tests/campaign_preset, server/tests/privacy_isolation, server/tests/api, web/tests/achievements, web/tests/settings, web/tests/notifications.\nâ€¢ Add jest/vitest config with testNamePattern including TC IDs and reporters for CI mapping from Task 26.\nâ€¢ Introduce factories: CampaignFactory (with preset variations), PlayerFactory, MissionFactory, AchievementDefFactory.\nâ€¢ Introduce shared test utilities: mockEventBus, freezeTime helpers, idempotencyKey helper, DB test harness with transactional rollback.\nâ€¢ Define Playwright test project for UI panels and toasts with accessibility assertions.\nâ€¢ Document mapping: TC004 Progression math; TC006 Soft-fail integration; TC007 Preset toggles enforcement; TC009 Privacy/isolation; TC014 Achievements definitions/unlocks; TC015 Notifications; TC017 Feature flag/preset gating.",
            "status": "pending",
            "testStrategy": "Smoke-run empty tests to ensure CI wiring passes; validate tags TC004/6/7/9/14/15/17 appear in reports."
          },
          {
            "id": 2,
            "title": "Write unit tests for progression math and fail-forward (TC004, TC006)",
            "description": "Specify expected behavior for computeXP, level thresholds, perk allocation bounds, artifact slot gating, and fail-forward XP/soft credit fractions tuned by preset.",
            "dependencies": [
              "27.1"
            ],
            "details": "â€¢ Add tests in server/tests/progression/progression_math.test.ts.\nâ€¢ Cases: success mission grants full XP per weights; failure grants 30â€“50% per preset tunable; ensure soft credit accrues toward next mission gate and caps correctly; verify level-ups at thresholds and perk points awarded per level; artifact slots unlock at defined levels; negative or overflow inputs rejected.\nâ€¢ Include boundary tests at threshold edges and multiple missions accumulation; property tests for monotonicity of XP->level.\nâ€¢ Include tests asserting no leaderboard writes when computing or recording points.",
            "status": "pending",
            "testStrategy": "Run tests expecting current code to fail (red) until implementation; snapshot expected curves for regression."
          },
          {
            "id": 3,
            "title": "Write unit tests for achievements definitions, progress, unlocks, idempotent rewards (TC014)",
            "description": "Define tests covering seeded achievements, incremental progress tracking, unlock gating by preset, idempotent reward grants, and versioning.",
            "dependencies": [
              "27.1"
            ],
            "details": "â€¢ Add tests in server/tests/achievements/achievements_engine.test.ts.\nâ€¢ Seed mock definitions: First Steps, Skillful (10 DC15+), Relic Hunter (3 artifacts), United We Stand (crew feat), Unstoppable (win after fail), each with rewards (xp, items, titles).\nâ€¢ Simulate event stream: mission_completed, skill_check_result, artifact_acquired, alliance_feat.\nâ€¢ Assert progress JSON updates, unlock only once; reward_granted toggles idempotently with idempotency key; evaluator respects campaign preset (disabled outside preset).\nâ€¢ Test version bump migration: older unlock with version X remains unlocked; new version creates separate track as per policy.\nâ€¢ Verify per-player vs per-crew scoping and UNIQUE constraint behavior.",
            "status": "pending",
            "testStrategy": "Red tests verifying unlock counts, timestamps, and reward grant calls; include race-condition test by parallel grant attempts."
          },
          {
            "id": 4,
            "title": "Write privacy/isolation tests for telemetry and leaderboard off (TC009)",
            "description": "Ensure private points are stored only in telemetry_points, no writes to leaderboard tables, and namespace isolation guards for vector memory by campaign_id/player_id.",
            "dependencies": [
              "27.1"
            ],
            "details": "â€¢ Add tests in server/tests/privacy_isolation/privacy_isolation.test.ts.\nâ€¢ Simulate mission resolution calling internal POST /telemetry/mission-points; assert row in telemetry_points with redact PII fields, and zero writes to leaderboard tables.\nâ€¢ Validate service layer guards reject any leaderboard write when leaderboardScope=off.\nâ€¢ Add vector index namespace tests: operations require campaign_id guard; ensure cross-campaign access rejects; include unit tests around namespace computation.\nâ€¢ Add DB constraint test or mock to enforce policy where feasible.",
            "status": "pending",
            "testStrategy": "Use DB query counters/spies; simulate malicious call attempting leaderboard write; verify errors and no side effects."
          },
          {
            "id": 5,
            "title": "Write API contract tests for campaigns preset and settings toggles (TC007, TC017)",
            "description": "Define tests for POST /campaigns with preset selection applying defaults, PATCH /campaigns/:id/settings validation, and feature flag/preset gating of related endpoints.",
            "dependencies": [
              "27.1"
            ],
            "details": "â€¢ Create server/tests/api/campaign_preset.api.test.ts.\nâ€¢ Cases: creating campaign without specifying preset defaults to DEFAULT_SUBSCRIPTION_DEPTH; explicit selection applies; response includes settings with private/off/strict defaults.\nâ€¢ PATCH validation: owner can adjust within allowed bounds (no public, leaderboardScope only off or friends); invalid transitions rejected with 4xx.\nâ€¢ Feature gating: achievements/progression endpoints return 404/403 when feature flag off or campaign not using preset; enabled when on.\nâ€¢ Include concurrency tests for toggle updates and ETag/If-Match support if available.",
            "status": "pending",
            "testStrategy": "Supertest or equivalent against in-memory server; verify schema using OpenAPI validators if present."
          },
          {
            "id": 6,
            "title": "Write API tests for achievements and telemetry endpoints (TC014, TC009)",
            "description": "Cover GET definitions, GET unlocks, POST claim, POST telemetry mission-points, and POST progression/perk-allocate including idempotency behavior.",
            "dependencies": [
              "27.1"
            ],
            "details": "â€¢ Create server/tests/api/achievements.api.test.ts.\nâ€¢ GET /achievements/definitions?scope=player|crew: pagination, filtering, enabled=true only.\nâ€¢ GET /achievements/unlocks/:subject: returns progress and unlocked_at; respects campaign.\nâ€¢ POST /achievements/claim/:unlockId: idempotent with idempotency key; reward granted once; returns reward summary.\nâ€¢ POST /telemetry/mission-points: internal auth required; stores telemetry_points with reason.\nâ€¢ POST /progression/perk-allocate: validates available points, bounds, and updates progression_state; emits telemetry event perk_allocated.",
            "status": "pending",
            "testStrategy": "Table-driven tests for success/error codes, auth failures, and boundary conditions."
          },
          {
            "id": 7,
            "title": "Write UI tests for Achievements panel and unlock banner/toast (TC015, TC014)",
            "description": "Add Playwright tests for achievements panel filters, progress bars, claim flow, accessibility, and unlock notification queueing/deduping.",
            "dependencies": [
              "27.1"
            ],
            "details": "â€¢ web/tests/achievements/achievements_panel.spec.ts: verify All/Unlocked/Locked filters, category filters, scope switch Player/Crew, progress bar updates with simulated server progress.\nâ€¢ Claim button flow: after unlock, shows claim CTA if applicable; after claim, CTA disabled and reward shown.\nâ€¢ web/tests/notifications/unlock_toast.spec.ts: enqueue multiple unlocks, ensure batching and max display rate; aria-live polite/roles; dedupe identical unlocks.\nâ€¢ Visual regression baseline screenshots for panel and toasts in light/dark.",
            "status": "pending",
            "testStrategy": "Run Playwright against stubbed API with MSW; assert a11y using axe."
          },
          {
            "id": 8,
            "title": "Write UI tests for Campaign Settings preset controls and leaderboard disabled UX (TC007, TC017)",
            "description": "Ensure preset badge/description renders, toggles limited per preset, and leaderboard UIs show disabled state and guidance.",
            "dependencies": [
              "27.1"
            ],
            "details": "â€¢ web/tests/settings/campaign_preset_settings.spec.ts: verify points visibility shows Private only with info tooltip; leaderboard scope off with friends-only disabled note; fail-forward strictness radio present; badge shows DEFAULT_SUBSCRIPTION_DEPTH.\nâ€¢ Leaderboard page: shows disabled messaging and suggestion to switch modes without enabling here; no network calls to leaderboard APIs.",
            "status": "pending",
            "testStrategy": "Playwright with UI state assertions; network inspection to ensure no leaderboard requests."
          },
          {
            "id": 9,
            "title": "Database migrations for achievements, telemetry, progression, and campaign settings",
            "description": "Implement schema changes: achievements_definitions, achievements_unlocks, telemetry_points, progression_state, and campaign_settings additions for preset and toggles.",
            "dependencies": [
              "27.2",
              "27.3",
              "27.4",
              "27.5",
              "27.6",
              "27.7",
              "27.8"
            ],
            "details": "â€¢ Create migration files with forward/backward steps.\nâ€¢ Tables:\n  - achievements_definitions(id PK, scope, key UNIQUE, name, description, rarity, category, conditions JSON/JSONB, rewards JSON/JSONB, icon, enabled, version, created_at TIMESTAMP).\n  - achievements_unlocks(id PK, campaign_id, scope, subject_id, def_id FK, progress JSONB, unlocked_at TIMESTAMP NULL, reward_granted BOOL, created_at, UNIQUE(campaign_id, scope, subject_id, def_id)).\n  - telemetry_points(id PK, campaign_id, player_id NULL, mission_id, points INT, reason TEXT, created_at TIMESTAMP).\n  - progression_state(id PK, campaign_id, player_id, level INT, xp INT, perk_points INT, artifacts JSONB).\n  - campaign_settings add columns: preset ENUM, points_visibility ENUM, leaderboard_scope ENUM, fail_forward_strictness ENUM.\nâ€¢ Add indices on (campaign_id, subject_id), (campaign_id, mission_id), and partial index for unlocked_at IS NOT NULL.\nâ€¢ Add FK constraints and check constraints where applicable.\nâ€¢ Generate types for ORM.",
            "status": "pending",
            "testStrategy": "Run migration tests on ephemeral DB; verify UNIQUE constraints and rollback integrity."
          },
          {
            "id": 10,
            "title": "Implement CampaignPreset registry and default hook in campaign creation",
            "description": "Add registry keyed by enum DEFAULT_SUBSCRIPTION_DEPTH, define defaults, and integrate into POST /campaigns to apply preset unless overridden.",
            "dependencies": [
              "27.5",
              "27.9"
            ],
            "details": "â€¢ Define enum CampaignPreset { DEFAULT_SUBSCRIPTION_DEPTH, ... } and registry map with config: pointsVisibility=private, leaderboardScope=off, failForward=strict, progressionModel=levels+perks+artifacts, crewAchievements=enabled, softFailCredit=enabled.\nâ€¢ Update campaign creation service to apply preset defaults; expose preset metadata for UI.\nâ€¢ Respect server feature flag; if disabled, reject selection with 403.\nâ€¢ Persist settings into campaign_settings.",
            "status": "pending",
            "testStrategy": "Run API tests from 27.5; ensure defaults match and feature gating enforced."
          },
          {
            "id": 11,
            "title": "Implement progression engine: computeXP, thresholds, perks, artifacts, fail-forward",
            "description": "Extend rules/progression module with XP computation, level thresholds, perk allocation, artifact slot gating, fail-forward accounting with tunables stored in preset.",
            "dependencies": [
              "27.2",
              "27.9",
              "27.10"
            ],
            "details": "â€¢ Add computeXP(missionOutcome, skillChecks, artifactsFound, allianceFeats, presetTunables) returning {xp, softCredit}.\nâ€¢ Define level thresholds curve (e.g., array or function), and helper to compute level from total XP and allocate perk points.\nâ€¢ Implement artifact slot unlock schedule and validation.\nâ€¢ Fail-forward: on failure, grant fraction XP and soft credit toward next mission gate per preset tunable; parametrize 0.3â€“0.5.\nâ€¢ Ensure functions pure, deterministic, and covered with property tests.\nâ€¢ No leaderboard writes; only return values.",
            "status": "pending",
            "testStrategy": "Execute unit tests in 27.2 until green; add fuzz tests for XP monotonicity."
          },
          {
            "id": 12,
            "title": "Implement private telemetry pipeline and service guards for leaderboard=off",
            "description": "Add service to persist mission_points_recorded into telemetry_points and enforce no leaderboard writes when scope is off; redact PII and support internal auth path.",
            "dependencies": [
              "27.4",
              "27.9",
              "27.10"
            ],
            "details": "â€¢ Implement TelemetryService.recordMissionPoints({campaignId, playerId?, missionId, points, reason}).\nâ€¢ Add middleware/guard: when campaign.settings.leaderboardScope===off, block any calls to LeaderboardService and log security event.\nâ€¢ Ensure pointsVisibility=private prevents any external export; add export function returning empty for this preset.\nâ€¢ Redact PII fields; store minimal identifiers.\nâ€¢ Wire POST /telemetry/mission-points to call service behind internal auth.",
            "status": "pending",
            "testStrategy": "Run privacy tests from 27.4 and API tests from 27.6."
          },
          {
            "id": 13,
            "title": "Implement achievements definitions store and seeding",
            "description": "Create repository and seed initial achievements set with categories, conditions JSON/DSL, rewards, icons, enabled flags, and versions.",
            "dependencies": [
              "27.3",
              "27.9"
            ],
            "details": "â€¢ Define AchievementsDefinition model and repository with CRUD (admin), read-only for clients.\nâ€¢ Seed initial set: First Steps, Skillful (10 DC15+), Relic Hunter (3 artifacts), United We Stand (crew feat), Unstoppable (win after fail); include rarity, category, rewards JSON.\nâ€¢ Add scope field (player|crew) and key uniqueness.\nâ€¢ Support versioning and enabled toggles; expose GET /achievements/definitions with filtering by scope, enabled.",
            "status": "pending",
            "testStrategy": "Run API tests for definitions from 27.6 and engine tests from 27.3."
          },
          {
            "id": 14,
            "title": "Implement achievements unlocks repository and event-driven evaluators",
            "description": "Create unlocks table access, progress tracking, event subscribers, and idempotent reward application for per-player and per-crew achievements within a campaign.",
            "dependencies": [
              "27.3",
              "27.9",
              "27.11",
              "27.13"
            ],
            "details": "â€¢ Implement UnlocksRepo: getOrCreate(campaignId, scope, subjectId, defId), updateProgress(progressJSON), markUnlocked(timestamp), setRewardGranted(idempotentKey).\nâ€¢ Event evaluators subscribe to mission and rules events: mission_completed, skill_check_result, artifact_acquired, alliance_feat, mission_failed->next_mission_completed for Unstoppable pattern.\nâ€¢ Evaluators compute incremental progress; emit achievement_progress and achievement_unlocked telemetry events.\nâ€¢ Enforce idempotency via unique constraint and idempotency keys; concurrent unlock attempts race-safe.\nâ€¢ Respect preset gating: evaluators active only when campaign preset is DEFAULT_SUBSCRIPTION_DEPTH and feature flag on.",
            "status": "pending",
            "testStrategy": "Run unit tests from 27.3; add concurrency test using parallel promises to unlock same achievement."
          },
          {
            "id": 15,
            "title": "Implement rewards grant and claim API with idempotency",
            "description": "Provide POST /achievements/claim/:unlockId to finalize reward grants for achievements requiring explicit claim, ensuring idempotent behavior and accurate reward summaries.",
            "dependencies": [
              "27.6",
              "27.14"
            ],
            "details": "â€¢ Add RewardsService.applyRewards(unlock, def) issuing xp/items/titles; update progression_state for xp; record items/titles where applicable.\nâ€¢ Require Idempotency-Key header; store key hash on unlock row; on retry return prior result.\nâ€¢ Validate subject ownership and campaign membership; enforce scope-specific permissions (crew claims by owner/admin).\nâ€¢ Return payload with granted rewards and updated unlock state.",
            "status": "pending",
            "testStrategy": "Run API tests from 27.6 and unit tests verifying idempotency and side-effect counts."
          },
          {
            "id": 16,
            "title": "Implement progression_state persistence and perk allocation API",
            "description": "Persist per-player progression state and expose POST /progression/perk-allocate with validation and telemetry emission.",
            "dependencies": [
              "27.2",
              "27.6",
              "27.9",
              "27.11"
            ],
            "details": "â€¢ Create ProgressionStateRepo with read/update methods; update on XP changes and level-ups including perk_points increments.\nâ€¢ Implement /progression/perk-allocate validating available points and perk bounds/gating; update artifacts/slots and perks state as needed.\nâ€¢ Emit telemetry event perk_allocated; ensure atomic updates with transactions.",
            "status": "pending",
            "testStrategy": "Run API tests from 27.6 and unit tests from 27.2 regarding perk bounds and artifact slot gating."
          },
          {
            "id": 17,
            "title": "Implement UI: Achievements panel (list, filters, progress, claim)",
            "description": "Build the achievements UI with scope switch, filters, progress bars, claim button, and accessibility, wired to API.",
            "dependencies": [
              "27.7",
              "27.13",
              "27.14",
              "27.15"
            ],
            "details": "â€¢ Create AchievementsPanel component with tabs: All, Unlocked, Locked; category filter; scope toggle Player/Crew.\nâ€¢ Render cards with icon, name, description, rarity, progress bar (from unlocks.progress), and claim button when applicable.\nâ€¢ Handle optimistic updates on claim; error states; skeleton loaders.\nâ€¢ Add keyboard navigation and ARIA roles; ensure screen reader labels.\nâ€¢ Integrate with feature flag/preset gating: hide or show disabled state accordingly.",
            "status": "pending",
            "testStrategy": "Run Playwright tests from 27.7; add unit tests for component logic with MSW mocks."
          },
          {
            "id": 18,
            "title": "Implement UI: Unlock banner/toast system with queue and batching",
            "description": "Add lightweight notification component for achievement unlocks that dedupes and rate-limits displays.",
            "dependencies": [
              "27.7",
              "27.14"
            ],
            "details": "â€¢ Create ToastManager with queue; batch multiple unlocks into a summary when threshold exceeded; apply max display rate.\nâ€¢ Subscribe to achievements_unlocked events via websocket or polling; fall back to local event bus.\nâ€¢ Provide accessible aria-live region; ensure non-blocking UX.",
            "status": "pending",
            "testStrategy": "Run Playwright tests from 27.7; unit-test queueing and dedupe logic."
          },
          {
            "id": 19,
            "title": "Implement UI: Campaign Settings for preset toggles and disabled leaderboard UX",
            "description": "Add settings UI for this preset: points visibility (private with tooltip), leaderboard scope (off, friends-only disabled note), fail-forward strictness, preset badge/description.",
            "dependencies": [
              "27.8",
              "27.10"
            ],
            "details": "â€¢ Build SettingsPresetSection component reading campaign settings; radio/selectors constrained per preset.\nâ€¢ Show preset badge DEFAULT_SUBSCRIPTION_DEPTH and description; display info explaining private telemetry and disabled leaderboards.\nâ€¢ Disable friends-only if restricted; show inline help.\nâ€¢ Save via PATCH /campaigns/:id/settings with validation feedback.",
            "status": "pending",
            "testStrategy": "Run Playwright tests from 27.8; verify no leaderboard API calls."
          },
          {
            "id": 20,
            "title": "Security and performance hardening for isolation and event pipeline",
            "description": "Add server-side validation for preset toggle updates, guard vector index namespaces, add idempotency, and micro-benchmarks for event evaluators.",
            "dependencies": [
              "27.12",
              "27.14",
              "27.15",
              "27.16"
            ],
            "details": "â€¢ Validate all preset updates server-side; block public leaderboard when preset is DEFAULT_SUBSCRIPTION_DEPTH.\nâ€¢ Enforce namespace conventions: campaign:<id>, player:<id>; add guards and unit tests; include metrics for rejected cross-campaign attempts.\nâ€¢ Ensure idempotency keys required on claim; retries safe.\nâ€¢ Add simple benchmarks for evaluator throughput under burst of events; ensure O(n) per event bounded by active defs.",
            "status": "pending",
            "testStrategy": "Run privacy tests (27.4); add perf test suite with synthetic 10k events and assert latency bounds."
          },
          {
            "id": 21,
            "title": "Feature flag integration and gating for API/UI",
            "description": "Wire a server flag to enable staged rollout; gate all API endpoints and UI routes/components behind the flag and preset selection.",
            "dependencies": [
              "27.5",
              "27.6",
              "27.10",
              "27.17",
              "27.19"
            ],
            "details": "â€¢ Introduce feature flag SUBSCRIPTION_DEPTH_PRESET enabled per environment.\nâ€¢ Gate evaluators, definitions exposure, claim endpoint, progression endpoints based on campaign preset and flag.\nâ€¢ UI: hide panels when disabled; show rollout tooltip; avoid network calls when gated.",
            "status": "pending",
            "testStrategy": "Run TC017 tests in 27.5, 27.7, 27.8 ensuring correct 403/hidden states."
          },
          {
            "id": 22,
            "title": "End-to-end flow tests for new campaign with preset and achievements",
            "description": "Add E2E tests: create campaign with preset, run missions causing progress/unlocks, ensure UI reflects state and privacy rules are enforced.",
            "dependencies": [
              "27.10",
              "27.11",
              "27.12",
              "27.13",
              "27.14",
              "27.15",
              "27.16",
              "27.17",
              "27.18",
              "27.19",
              "27.21"
            ],
            "details": "â€¢ Script: create campaign (preset default), simulate mission success/fail-forward events; verify telemetry_points entries; computeXP applied; level/perk updates; achievements unlocked and claimable; toasts shown.\nâ€¢ Verify no leaderboard writes; verify settings toggles constrained.\nâ€¢ Validate accessibility and state persistence across refresh.",
            "status": "pending",
            "testStrategy": "Playwright + backend test harness; run in CI with artifacts and HAR captures."
          },
          {
            "id": 23,
            "title": "Documentation and admin tools for achievements and presets",
            "description": "Author developer docs and minimal admin endpoints/tools to manage achievement definitions and preset tunables safely.",
            "dependencies": [
              "27.13",
              "27.14",
              "27.21"
            ],
            "details": "â€¢ Write docs: preset behavior, fail-forward tunables, XP curve, achievements DSL/JSON, event schemas.\nâ€¢ Add admin-safe endpoints behind auth to list/update enabled/version; migration guide for version bumps.\nâ€¢ Provide seed scripts and sample JSON files.",
            "status": "pending",
            "testStrategy": "Docs linting; manual validation using admin tool against staging."
          },
          {
            "id": 24,
            "title": "Run full test suite and stabilize",
            "description": "Execute all unit, API, UI, and E2E tests; fix flakes; ensure coverage thresholds met; prepare change log.",
            "dependencies": [
              "27.22",
              "27.23"
            ],
            "details": "â€¢ Run CI matrix; address flaky tests with retries and deterministic seeds.\nâ€¢ Ensure coverage >80% in core modules.\nâ€¢ Review logs for privacy guard hits; verify no external exports.\nâ€¢ Prepare release notes and changelog entries.",
            "status": "pending",
            "testStrategy": "CI run with reruns for flaky specs; generate coverage and stability report."
          }
        ]
      },
      {
        "id": 28,
        "title": "Implement Viral Scoring Preset (Seasonal Leaderboards & Sharing)",
        "description": "Add a selectable campaign preset that enables public mission scoring, seasonal leaderboards (campaign/global scopes), viral share flows, and weekly featured missions with privacy, anti-griefing, ELO/MMR, and season rewards. Provide full tests (unit/integration/UI/API), rate limiting, and campaign isolation; preset is disabled by default and can be toggled per campaign.",
        "details": "Scope and architecture\n- Preset definition and registry\n  - Extend CampaignPreset registry with enum: VIRAL_SCORING. Preset flags: publicScores=opt-in, leaderboardScope=friends|campaign|global, seasons=enabled, featuredMissions=weekly, allowSharing=opt-in, redactPII=on, storageMode=local-only-compliant, antiGriefing=on, eloEnabled=per-arena, partialCredit=soft-fail enabled. Disabled by default; selectable per campaign in settings UI and during creation wizard.\n  - Add campaign-level toggles: enablePublicScores, leaderboardScope, enableSeasons, shareDefaults (opt-in off), allianceScoreInclusion, seasonSchedule (start, end, grace), and rewardTiers.\n\n- Data model (SQLite)\n  - Tables (new): scores(id, campaign_id, session_id, mission_id, player_id, team_id, scope, metric, value, partial, fail_reason, created_at); seasons(id, campaign_id, name, scope, start_at, end_at, rollover_state, rewards_schema, version); season_entries(id, season_id, player_id, team_id, rank, mmr, division, elo_mu, elo_sigma, last_update); share_artifacts(id, campaign_id, score_id, artifact_type, url_or_blobref, pii_redacted JSON, created_at, consent_at); featured_missions(id, campaign_id, mission_id, week_of, curated_by).\n  - Migrations: create indices on (campaign_id, scope, metric, created_at), (season_id, rank DESC), and composite unique keys to prevent duplicate submissions per mission attempt.\n\n- Scoring formulas and soft-fail\n  - Implement a scoring module keyed by missionType: time-attack, survival, puzzle, social-coop, arena. Each defines base points, bonuses, penalties, and clamps. Support partial credit on soft-fail: grant proportional points based on progress fraction, with anti-exploit caps.\n  - Fair-play checks: validate mission completion evidence, server-side timestamps, min duration thresholds, attempt cooldowns, host consent for social missions, and client signature verification (reuse adapter auth if present). Rate limit score submissions per player and per campaign.\n\n- Anti-griefing and security\n  - Timeouts: enforce max attempt duration; auto-abort stale submissions. Consent gates: for team scores, require majority consent or GM approval. Cross-campaign isolation: all queries filtered by campaign_id and leaderboard scope; add row-level guards in access layer.\n  - Validation: reject out-of-bounds values; detect suspicious streaks; quarantine flagged scores pending review.\n\n- Seasonal leaderboards and rollover\n  - Implement seasonal versioning: active season per campaign/scope; archived seasons are immutable snapshots with view filters. Provide monthly/quarterly schedules and manual admin rollover. Compute standings on event update and via periodic job; freeze during grace period. Support divisions and ranks for large populations; include alliance/crew aggregates.\n\n- ELO/MMR for arenas\n  - Arena matches update MMR per outcome with K-factor scaling by uncertainty; maintain elo_mu/sigma for Bayesian variants. Persist per season. Calibrate initial placement matches; decay on inactivity. Expose API to fetch matchmaking band.\n\n- Rewards and featured missions\n  - Cosmetic season rewards generation based on final rank/percentile and achievement thresholds. Weekly featured missions rotation: auto-select based on engagement signals with manual override.\n\n- Sharing and privacy\n  - Share flows: generate share_artifacts with opt-in consent; render redacted cards (hide PII, show campaign-safe names). Provide copy-link and image export; ensure local-only storage compliance (no external uploads unless configured). Include per-scope badges (friends/global/campaign) in the artifact.\n\n- UI integration\n  - Preset settings pane: toggles, schedule editor, reward tiers editor, privacy controls. Leaderboards views: current season, friends, global (if enabled), past seasons, alliance standings; entry detail with share action. Share dialog with preview and consent checkbox.\n\n- APIs\n  - POST /scores/submit; GET /leaderboards?scope&season; POST /seasons/rollover; GET /seasons/current; POST /share/create; GET /featured-missions; POST /featured-missions/override. Enforce rate limits and schema validation. Contract tests included.\n\n- Performance\n  - Incremental leaderboard updates with upsert + denormalized standings table; background recompute for heavy scopes. Bounded history retention for hot paths; archive to cold tables. Apply submission rate limits (per IP/player) and exponential backoff on abuse.\n\n- Compatibility and toggles\n  - Integrate with alliances/teams so alliance and crew achievements contribute to seasonal standings when enabled. Respect campaign preset defaults; no cross-talk with other presets. Disabled by default for all existing campaigns until explicitly selected.\n\nReferences and rationale\n- Implement seasonal versioning and resets modeled after established practices for seasonal leaderboards to keep competition fresh[3].\n- Apply best practices for leaderboard scopes, reset cycles, and community health to mitigate toxicity and maintain engagement[2][1].\n- Support divisions/ranks concepts akin to league systems to scale competition fairly across skill bands[5].",
        "testStrategy": "Unit tests\n- Scoring math per mission type: deterministic outputs for boundary cases; partial credit proportionality; clamp and cap behaviors. Fuzz against invalid inputs to ensure rejection and quarantine.\n- ELO/MMR updates: verify K-factor scaling, placement matches, win/loss/draw updates, inactivity decay, and season scoping.\n- Season schedule: compute active/archived state, grace period logic, and rollover versioning.\n\nIntegration tests\n- Leaderboard updates: submit scores concurrently; verify standings update correctly, alliance aggregates reflect member contributions, and per-campaign isolation holds. Validate friends vs campaign vs global scopes.\n- Season rollover: run end-of-season; freeze submissions; archive standings; create next season; rewards issuance; verify no mutations to archived season.\n- Rate limiting and anti-griefing: exceed submission thresholds; ensure 429s and quarantine flow; validate consent gates for team submissions; timeouts on stale attempts.\n- Featured missions: weekly rotation triggers; manual override persists; UI surfaces current featured set.\n\nUI tests (Playwright)\n- Preset selection: ensure VIRAL_SCORING appears, is disabled by default, and can be enabled per campaign.\n- Leaderboards views: paginate, filter by scope, switch current/past seasons, view alliance standings, open share dialog, confirm PII redaction and consent requirement.\n- Share flows: create artifact, copy link/image export, verify privacy banner and opt-in remembered per user.\n\nAPI contract tests\n- /scores/submit validation and idempotency; /leaderboards query combinations; /seasons/rollover permissions and effects; /share/create artifact schema; /featured-missions endpoints. Schema versioning and backward compatibility checks.\n\nPerformance and reliability tests\n- Load: burst score submissions maintain SLOs; recompute latency under N concurrent updates; no cross-campaign leakage. Chaos: kill periodic job during rollover; system recovers idempotently.\n\nAcceptance mapping\n- Verify channels and requirements R-001, R-003, R-004, R-010, R-011, R-012 pass via TC004/TC005/TC006/TC016/TC017/TC018 as mapped in Task 26.",
        "status": "pending",
        "dependencies": [
          2,
          4,
          9,
          11,
          21,
          23,
          26,
          27
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 29,
        "title": "Implement Ollama Provider Adapters (LLM + Embeddings) with Streaming, Tools, Safety, and A/B Harness Integration",
        "description": "Add Ollama adapters implementing LLMProvider and EmbeddingProvider with streaming, tool schema/function-calling, safety filters, config, metrics, and full tests; update provider UI and docs.",
        "details": "Scope and architecture\n- Create packages/modules: providers/ollama/llmAdapter.ts and providers/ollama/embeddingAdapter.ts implementing existing LLMProvider and EmbeddingProvider interfaces.\n- Configuration\n  - Env/config keys: OLLAMA_BASE_URL (default http://localhost:11434), OLLAMA_API_KEY (optional for gateway), provider.settings.modelAllowlist = ['llama3','mistral','phi3'] (configurable).\n  - Validate base URL reachability at startup with lightweight /api/tags or /api/version probe and log model availability.\n- LLM adapter\n  - API shape: supports chat completion with messages[], model, temperature, maxTokens, seed (if supported), tools (JSON schema), tool_choice=auto/none, streaming.\n  - Streaming: use server-sent stream from Ollama and emit tokens/chunks in our standard StreamDelta events; handle finish reasons and tool call events.\n  - Tools: convert zod/JSON Schema tool definitions to Ollamaâ€™s function/tool schema; on tool call deltas, aggregate into a function_call struct {name, arguments} and surface via our ToolCall event; validate against schema; on invalid schema, retry with corrected schema once.\n  - Params mapping: temperature->temperature, maxTokens->num_predict, top_p if present in request, seed->seed. Respect stop sequences. Provide fallback when parameter not supported by particular model.\n  - Metrics: capture start/end timestamps, latency, prompt/completion token counts when exposed; if not available, estimate tokens via tokenizer fallback. Cost = 0 for local Ollama. Emit to A/B harness metrics sink.\n  - Retries/backoff: integrate with global adapter retry policy (exponential with jitter); classify retryable errors (429 from gateways, ECONNRESET, timeouts) vs non-retryable (400 schema errors after one correction attempt).\n  - Safety: apply content filters/redaction pipeline pre-send and post-receive. Redact PII/secrets in prompts and tool args; check outputs and mask as configured.\n  - Determinism: if seed provided, pass through and document per-model determinism caveats.\n- Embeddings adapter\n  - Use Ollama embeddings endpoint for selected model; require embedding-capable model in allowlist.\n  - Return Float32Array normalized vectors; include dimensionality discovery on first call and cache.\n  - Batch inputs with size limits; streaming not required.\n- A/B harness integration\n  - Register Ollama as an LLM and Embedding provider in the model matrix; expose provider id, model list (from allowlist intersected with server-available models), and metrics mapping.\n  - Ensure zero cost recorded for this provider.\n- UI and docs\n  - Update Settings > Providers UI to include Ollama provider card with fields: Base URL, API Key (optional), Model allowlist help, connectivity test.\n  - Update providers.md with configuration, supported features, limits, and troubleshooting.\n- Security/ops\n  - Timeouts, circuit breaker guard, and connection pooling. Respect per-campaign isolation and safety settings.\n- Examples\n  - Provide sample code to invoke streaming with tools and embeddings with normalization in docs.\n",
        "testStrategy": "Unit tests\n- Adapter shape: construct OllamaLLMAdapter and OllamaEmbeddingAdapter; verify methods, parameter mapping, defaults, and allowlist enforcement.\n- Streaming: mock Ollama stream; assert ordered StreamDelta emissions, final finish event, and backpressure handling.\n- Tools: validate JSON schema conversion; simulate tool call chunks and ensure aggregated function_call matches schema; invalid schema triggers one retry then fails with tagged error.\n- Retries/backoff: inject transient network errors and verify exponential backoff with jitter and max attempts; non-retryable errors do not retry.\n- Safety: ensure pre-send redaction masks PII and post-receive filters apply; verify redaction does not leak originals to transport layer logs.\n- Embeddings: return type is Float32Array; values normalized to unit length within epsilon; batch processing splits correctly.\n\nIntegration tests\n- Minimal prompt roundtrip against local Ollama (skipped in CI if not available; flag to enable): verify successful completion, streaming order, and metrics capture (latency present, tokens if provided or estimated fallback recorded).\n- Deterministic seed: with same prompt+seed verify identical text for models that support seed; if model lacks determinism, assert at least same first N tokens or mark as conditional skip.\n- Tool-call structure: run prompt that elicits a function call; validate name and JSON arguments parse and zod-validate.\n- Embeddings: compute embeddings for stable inputs; assert dimensionality stable and cosine similarity >0.99 for identical input across runs.\n\nVerification/acceptance\n- Tag tests with TC011 and TC013 where applicable and map in verification plan; ensure R-007 updated requirement satisfied for Ollama.\n- Update providers.md and UI provider list; manual checklist includes connectivity test in UI and A/B harness registration.\n",
        "status": "pending",
        "dependencies": [
          14,
          21,
          23,
          26,
          4
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 30,
        "title": "Implement Group Chat: Global and Adâ€‘Hoc Voice+Text Channels with Invites",
        "description": "Build campaignâ€‘scoped group chat supporting a global Allâ€‘Hands channel and adâ€‘hoc inviteâ€‘based voice+text channels with roles, moderation, audit logging, API/WS, DB schema, and UI; integrate with voice capture/captions and ensure isolation/security.",
        "details": "Scope and architecture\n- Channel model\n  - Channel types: GLOBAL (one per campaign, Allâ€‘Hands) and AD_HOC.\n  - Properties: id, campaign_id, type, name, description, is_invite_only, created_by, created_at, updated_at, archived_at, voice_room_id (nullable), text_retention_days, default_join_muted.\n  - Memberships: id, channel_id, user_id, role (owner|mod|member), mute (self), volume (0â€“100), joined_at, left_at (nullable), is_present_in_voice (derived from voice engine presence).\n  - Invites: id, channel_id, inviter_id, invitee_id, status (pending|accepted|declined|expired|revoked), expires_at, created_at, rate_limit_bucket.\n  - Channel events (audit): id, channel_id, actor_id, event_type (create|update|delete|join|leave|invite_create|invite_accept|invite_decline|role_change|mute|kick), payload (JSON), created_at.\n  - Text messages: reuse existing messages table if present; otherwise define messages(id, channel_id, author_id, content, kind=text|caption|system, ts, ref (optional)). Transcripts store STT captions as messages with kind=caption and diarization metadata.\n\n- API design\n  - REST\n    - POST /channels (create adâ€‘hoc; enforce campaign scope; assign owner)\n    - GET /channels (list by campaign with membership and unread counts)\n    - GET /channels/:id (details, last N messages, membership summary)\n    - PATCH /channels/:id (name, invite_only, description) â€“ owner/mod only\n    - DELETE /channels/:id (archive) â€“ owner only for adâ€‘hoc; GLOBAL cannot be deleted\n    - POST /channels/:id/members/join (join; default muted in voice)\n    - POST /channels/:id/members/leave (leave; owner transfer/constraints)\n    - POST /channels/:id/members/:userId/roles (role transition; auth checks)\n    - POST /channels/:id/moderation/mute (self or modâ€‘enforced target)\n    - POST /channels/:id/moderation/kick (remove from membership; mod/owner)\n    - POST /channels/:id/invites (create; rate limited; invite_only respected)\n    - POST /channels/:id/invites/:inviteId/accept\n    - POST /channels/:id/invites/:inviteId/decline\n  - WebSocket events (namespaced by campaign)\n    - channel.created/updated/archived\n    - channel.member.joined/left/role_changed\n    - channel.invite.created/accepted/declined\n    - channel.moderation.muted/kicked\n    - channel.voice.presence (join/leave/talking/VAD)\n    - channel.text.message (text and caption kinds)\n    - channel.audit.appended\n\n- Voice integration\n  - On channel join, create/ensure voice room mapping (voice_room_id) and attach presence to membership; default join muted; pushâ€‘toâ€‘talk and VAD states reflected in WS presence events.\n  - Perâ€‘channel mute/volume stored in membership; client applies volume locally; server tracks mute for moderation and signaling.\n  - Captions/diarization: consume STT pipeline outputs and emit as channel.text.message with kind=caption, speaker tag (connection/user id), timestamps; store in transcripts/messages.\n\n- Text integration\n  - Message history per channel; pagination by ts+id; captions appear inline with badges; system messages for invites/joins/leaves.\n  - Moderation deletes redact content and append audit event.\n\n- Security and isolation\n  - All endpoints authorize campaign membership; channels cannot cross campaigns; perâ€‘action role checks; enforce invite_only: only invited users can join; global channel membership allowed to all campaign users but can be left/joined.\n  - Rate limit invites per inviter+channel (e.g., 10/min, 100/day) with backoff and 429 responses.\n  - Validate WS subscriptions to campaign and channel membership; no leakage across campaigns.\n\n- Database schema (SQL sketch)\n  - channels(id PK, campaign_id FK, type, name, description, is_invite_only, voice_room_id, default_join_muted, text_retention_days, created_by, created_at, updated_at, archived_at)\n  - channel_memberships(id PK, channel_id FK, user_id FK, role, mute, volume, joined_at, left_at)\n  - channel_invites(id PK, channel_id FK, inviter_id FK, invitee_id FK, status, expires_at, created_at, updated_at)\n  - channel_events(id PK, channel_id FK, actor_id FK, event_type, payload JSONB, created_at)\n  - channel_messages(id PK, channel_id FK, author_id FK NULL for system/captions, kind, content TEXT/JSON, ts, meta JSONB)\n  - Indexes: by campaign_id, (channel_id, ts DESC), unique (channel_id, user_id) active membership, invite dedupe (channel_id, invitee_id, status='pending').\n\n- UI/UX\n  - Channel list/switcher scoped to campaign; global channel pinned/bannered; unread badges; voice presence dots.\n  - Create channel dialog: name, invite_only, initial invites; role shown as owner for creator.\n  - Invite notifications: toast + inbox; accept/decline; deepâ€‘link to channel.\n  - Perâ€‘channel controls: join/leave, pushâ€‘toâ€‘talk toggle, VAD toggle, mute/volume slider; captions pane; message composer.\n  - Accessibility: keyboard PTT, ARIA live for captions, color contrast; localized strings; dark/light.\n\n- Event sourcing and audit\n  - Emit channel_events for all state mutations; include actor_id, reason/message; render minimal audit feed for mods.\n\n- Migration and seeding\n  - On campaign creation, autoâ€‘create GLOBAL Allâ€‘Hands channel with default_join_muted=true and captions on.\n\n- Performance\n  - Backpressure on WS text/caption streams; coalesce presence updates; message send debouncing; pagination size defaults; apply existing WS reconnection policies.\n\n- Error handling and edge cases\n  - Owner leave requires transfer or archive; prevent removing last owner; invite accept autoâ€‘joins channel; decline keeps audit.\n  - Kicks remove from voice and membership; surface reason to target; prevent rejoin if invite_only and no invite.\n\nImplementation notes\n- Backend: TypeScript (Node) services; reuse existing WS hub; zod validation; transactional writes for membership/invite flows; outbox pattern to emit WS after commit.\n- Client: React; state via existing store; optimistic UI for text; reconcile on WS acks; persistent perâ€‘channel audio settings in local storage.\n- Telemetry: log invite rateâ€‘limit hits, moderation actions, errors; redact PII in events.\n",
        "testStrategy": "Unit tests (server)\n- Authorization and role enforcement: create/update/delete channel; role transitions with constraints; moderation mute/kick auth; prevent crossâ€‘campaign access.\n- Invite lifecycle: create (rateâ€‘limited), accept (autoâ€‘join), decline, revoke/expire; dedupe pending invites per user/channel; audit events emitted.\n- Membership: join/leave; default join muted; owner transfer and lastâ€‘owner guard; unique active membership per user/channel.\n- Text routing: messages stored and broadcast to channel members only; captions stored with kind=caption and diarization metadata.\n- Audit logs: verify channel_events appended for all mutations with correct payloads.\n\nIntegration/API tests\n- CRUD: create adâ€‘hoc channel, update props, archive; global channel existence per campaign and nonâ€‘deletable guard.\n- Membership flows: join/leave endpoints; perâ€‘channel mute/volume updates persisted; kick removes voice presence and membership.\n- Invites: create -> invitee receives WS invite; accept -> becomes member; decline -> no membership; rateâ€‘limit returns 429 with reset header.\n- WS sequencing: subscribe to campaign; assert event order and idempotency on reconnect; presence/talking events throttled.\n- Voice/text coupling: join channel -> voice room presence mirrors membership; captions received in text stream; pushâ€‘toâ€‘talk/VAD state reflected in presence events.\n\nUI (Playwright)\n- Global channel banner visible; join/leave/mute and volume work and persist; captions visible with ARIA live.\n- Create adâ€‘hoc channel; invite flow endâ€‘toâ€‘end (create, notify, accept/decline); membership roles displayed; permissions UI enforced.\n- Send/receive text and captions; unread counts and switcher updates; invite notifications actionable.\n\nNonâ€‘functional\n- Rate limits honored under load; invite burst blocked; WS reconnect maintains channel subscriptions and resyncs last cursor.\n- Privacy/isolation: crossâ€‘campaign access attempts denied in API and WS; no events leaked in multiâ€‘campaign test.\n- Persistence: pagination returns stable ordering; retention purger (if configured) removes old messages without breaking pagination.\n",
        "status": "pending",
        "dependencies": [
          4,
          6,
          21,
          23,
          26
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 31,
        "title": "Scaffold React UI per UI Visual Design with Storybook, Theming, and Test Gates",
        "description": "Create the React component library structure in src/ui_frontend matching framework_docs/ui_visual_design.md, implement dark-theme tokens with Tailwind/CSS variables, wire to mocked APIs, and add Storybook/Ladle with accessibility and testing gates (Jest/RTL, Playwright+MSW, visual regression).",
        "details": "Scope and deliverables\n- Create src/ui_frontend/ui with component folders matching the visual layout: TopBar, ChannelsList, PartyPanel, SceneMedia, NPCRoster, QuickIntents, ObjectivesPanel, SituationTicker, AchievementsToasts, TranscriptChat, Modals/ChannelManager, Modals/InviteDialog.\n- For each component:\n  - Files: Component.tsx, Component.stories.tsx, Component.test.tsx, Component.accessibility.test.tsx, index.ts, styles.css (or .module.css if not using Tailwind), and fixtures.mock.ts.\n  - Export public components via src/ui_frontend/ui/index.ts and aggregated src/ui_frontend/index.ts for app consumption.\n  - Add data-testid values exactly as defined in framework_docs/ui_visual_design.md; fail builds if mismatched.\n  - Props: accept minimal props per ASCII wireframes (titles, counts, selected states, lists) and callbacks (onSelectChannel, onToggleMute, onOpenInvite, etc.). No real backend calls.\n- Theming and styles\n  - Default dark theme using CSS variables in :root[data-theme='dark'] and an optional Tailwind config using theme tokens. Define core tokens: color.bg, color.panel, color.text, color.text-muted, color.accent, color.error, elevation.s, elevation.m, radius.s|m, spacing scale, typography tokens.\n  - Support prefers-color-scheme: dark by default; provide a simple ThemeProvider that toggles data-theme on <html>.\n- State management and mocking\n  - Components are primarily presentational; create lightweight container/demo mocks in stories using MSW to simulate API data for: channel list, invites, transcript stream, achievements toasts, ticker items.\n  - Provide a shared mock service worker setup for Storybook and Playwright.\n- Storybook (or Ladle) setup\n  - Configure Storybook with @storybook/addon-a11y, @storybook/addon-interactions, and storybook-addon-msw. Provide stories for happy path and edge states (empty lists, long names, overflow, error banners).\n  - Global decorators for ThemeProvider and MSW.\n- Playwright scaffold\n  - E2E smoke for main layout shell rendering all panels, opening InviteDialog from TopBar/ChannelManager, toggling mute, switching ChannelsList selection. Use MSW to intercept API calls. Add data-testid hooks per design.\n- Visual regression\n  - Capture baseline snapshots for TopBar, ChannelsList, PartyPanel, ObjectivesPanel, SituationTicker, TranscriptChat, AchievementsToasts in both default and edge cases.\n- Accessibility\n  - ARIA roles/labels per component: navigation/menubar for TopBar, list/listitem for ChannelsList, dialog role with labelledby/ describedby for modals, log or feed role for TranscriptChat/Ticker, status for AchievementsToasts, buttons and toggle buttons with aria-pressed for mute.\n- Project wiring\n  - Ensure components are isolated from backend; all data via props or MSW mocks. Provide a mockApi.ts with handlers for channels, invites, presence toggles.\n  - Add npm scripts: ui:storybook, ui:test, ui:e2e, ui:validate-testids.\n- Docs\n  - Add framework_docs/COMPONENTS_README.md describing structure, tokens, test IDs, and story usage.\n\nImplementation notes and examples\n- File structure example\n  - src/ui_frontend/ui/TopBar/TopBar.tsx\n  - src/ui_frontend/ui/TopBar/TopBar.stories.tsx\n  - src/ui_frontend/ui/TopBar/TopBar.test.tsx\n  - src/ui_frontend/ui/TopBar/TopBar.accessibility.test.tsx\n  - src/ui_frontend/ui/TopBar/index.ts\n  - Repeat for all components and Modals/ChannelManager, Modals/InviteDialog.\n- Tailwind option\n  - tailwind.config.ts extends with cssVar-based colors: colors: { bg: 'var(--color-bg)', panel: 'var(--color-panel)', text: 'var(--color-text)', accent: 'var(--color-accent)' }.\n- Data contracts for mocks\n  - Channel {id, name, unreadCount, isMuted, isSelected, type}\n  - Invite {id, channelId, inviter, createdAt, status}\n  - TranscriptItem {id, speaker, text, timestamp}\n  - TickerItem {id, type, message, severity}\n\nNon-goals\n- No backend integration, websockets, or persistence.\n- No provider adapters or voice pipeline wiring here.\n",
        "testStrategy": "Unit tests (Jest + React Testing Library)\n- Props/state rendering: verify labels, counts, selected state, and callbacks fire for TopBar, ChannelsList, PartyPanel, etc.\n- Data-testid presence: assert every element defined in ui_visual_design.md exists with exact IDs; add a test that parses the doc and checks IDs where feasible.\n- Accessibility: axe-core checks per component; roles/labels and keyboard nav: focus trap in dialogs, Escape to close, Tab order, Space/Enter activate.\n\nVisual/regression tests\n- For key panels (TopBar, ChannelsList, PartyPanel, ObjectivesPanel, SituationTicker, TranscriptChat, AchievementsToasts), render deterministic stories and capture baseline images; assert diffs < threshold in CI.\n\nPlaywright E2E smoke (with MSW)\n- Load main layout story/preview; verify all primary regions visible.\n- Open InviteDialog via TopBar/ChannelManager; fill and submit; MSW returns success; dialog closes and toast shows.\n- Toggle mute button (aria-pressed toggles, icon changes).\n- Switch channels: click different list items; selection state and panel header update.\n\nAcceptance checks\n- Visual comparison against ASCII wireframes in ui_visual_design.md passes review.\n- Dark theme tokens applied; components respect tokens.\n- All tests green in CI: lint, typecheck, unit, a11y, visual, and Playwright smoke.",
        "status": "pending",
        "dependencies": [
          1,
          22,
          26,
          30
        ],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-08-12T02:21:02.319Z",
      "updated": "2025-08-12T03:15:29.577Z",
      "description": "Tasks for master context"
    }
  }
}