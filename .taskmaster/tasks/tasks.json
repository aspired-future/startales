{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Monorepo and Project Scaffolding",
        "description": "Initialize local-first monorepo with client and server workspaces, TypeScript configs, linting, testing, and runtime env management.",
        "details": "- Structure:\n  - repo root: pnpm workspaces; packages: server (Node/TS), ui_frontend (React/TS), shared (types, schemas), scripts (CLIs), content (packs)\n- Tooling:\n  - Node 20+, pnpm, TypeScript strict, ESLint+Prettier, Jest+ts-jest, Playwright for E2E\n  - Env: dotenv-safe for local-only, no remote telemetry by default\n- Folder map:\n  - src/server: LLM orchestration, missions, rules, memory, persistence, realtime, images, scheduling, video (flagged)\n  - src/ui_frontend: voice capture, HUD, campaign browser, schedule editor, captions\n  - framework_docs/ (from repo)\n- Scripts: dev (concurrently server+client), build, test, e2e, lint, typecheck\n- Git hooks: pre-commit lint-staged; commitlint conventional commits\n- Security: .env.local in .gitignore; example env file with placeholders; keyring location documented\n- Accessibility baseline: eslint-plugin-jsx-a11y\n- Vite for UI; ts-node/tsx for server dev\n- CRDT lib placeholder (Automerge/Yjs) added as dep for later tasks",
        "testStrategy": "- CI runs lint, typecheck, unit tests on push\n- Playwright scaffold test opens app shell and loads WebSocket handshake stub\n- Verify no external network calls during startup (mock global fetch and assert none)\n- Ensure workspace build succeeds end-to-end with pnpm -r build",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for monorepo scaffolding (TC001–TC006)",
            "description": "Author repository-level tests that codify the core acceptance criteria before any implementation. Cover workspace layout, scripts, TypeScript strictness, linting/formatting, unit/e2e test runners, environment isolation, and absence of external telemetry on startup.",
            "dependencies": [],
            "details": "- Create a temporary sandbox (e.g., scripts/scaffold-tests/setupSandbox.ts) to run CLI scaffolding and assertions.\n- Write Jest tests (root-level) for:\n  - TC001: pnpm -r build succeeds for all workspaces and produces expected dist outputs.\n  - TC002: Workspace graph contains server, ui_frontend, shared, scripts, content with correct package.json config (name, private, type, main/module, scripts).\n  - TC003: TypeScript strict mode enabled across root and packages (tsc --noEmit) and fails on an intentional ts error fixture.\n  - TC004: ESLint + Prettier configured; lint-staged and commitlint configured; pre-commit hook triggers lint on staged files.\n  - TC005: Jest + ts-jest runs unit tests in server and shared; Playwright scaffold can launch dev server and open app shell.\n  - TC006: Startup makes no external network calls: mock global.fetch and node dns/http/https to assert no outbound during dev bootstrap.\n- Write a Playwright spec (e2e/app-smoke.spec.ts) that:\n  - Boots the dev servers via a test harness, visits http://localhost:5173, asserts app shell renders and a WebSocket handshake stub is attempted and intercepted.\n- Add minimal fixtures to assert directory presence and env files exist with placeholders. Do not implement scaffolding yet; tests should fail initially.",
            "status": "in-progress",
            "testStrategy": "Run tests locally: pnpm i; pnpm test; pnpm e2e. Ensure CI job (temporary GitHub Actions in .github/workflows/ci.yml) runs lint, typecheck, unit, and e2e in the sandbox."
          },
          {
            "id": 2,
            "title": "Initialize pnpm workspaces and root configuration",
            "description": "Create the monorepo root with pnpm workspaces, shared engines/pnpm version, base scripts, gitignore, editorconfig, and Node tool versions.",
            "dependencies": [],
            "details": "- Initialize repo: git init.\n- Add package.json at root:\n  - private: true, packageManager: \"pnpm@9.x\", engines: { node: \">=20\" }.\n  - workspaces: [\"packages/*\", \"framework_docs\"].\n  - scripts: dev, build, test, e2e, lint, typecheck, format, prepare (husky install).\n- Add pnpm-workspace.yaml specifying packages/* and excluding framework_docs from publishing.\n- Add .gitignore covering node_modules, dist, coverage, .env.local, .env.*, playwright/.cache.\n- Add .editorconfig with standard settings.\n- Add README with monorepo overview and local-first principles.\n- Commit and run tests from 1; fix workspace discovery failures until TC002 workspace presence checks pass.",
            "status": "done",
            "testStrategy": "Run TC002 partial checks to ensure workspaces resolve. Ensure pnpm -r list shows no packages yet but workspace config loads."
          },
          {
            "id": 3,
            "title": "Scaffold shared package (types and schemas)",
            "description": "Create packages/shared with strict TS config, Jest setup, and initial Zod schema placeholders shared across server and UI.",
            "dependencies": [],
            "details": "- Create packages/shared/package.json with name \"@app/shared\", type: module, main: dist/index.js, types: dist/index.d.ts, files: [\"dist\"], sideEffects: false.\n- Add src/index.ts exporting placeholder zod schemas (e.g., MessageEnvelope, Channel, EnvConfig) and shared types.\n- Add tsconfig.json extending root base with \"strict\": true, composite: true, declaration: true, moduleResolution: bundler, module: ESNext, target: ES2022.\n- Add jest.config.ts with ts-jest preset and transforms for ESM.\n- Add basic unit tests verifying schema parse and type inferences (TC005 unit coverage for shared).\n- Add build script: tsup or tsc build; prefer tsc for simplicity: \"build\": \"tsc -b\".\n- Run tests; ensure TC003 strict mode and TC005 shared unit tests pass.",
            "status": "done",
            "testStrategy": "pnpm --filter @app/shared test; pnpm -r typecheck; verify emitted d.ts and noImplicitAny violations."
          },
          {
            "id": 4,
            "title": "Scaffold server workspace (Node/TS with tsx dev)",
            "description": "Create packages/server with Node 20+ TypeScript, tsx for dev, ts-jest for unit tests, dotenv-safe for local-only env, and baseline runtime.",
            "dependencies": [],
            "details": "- packages/server/package.json: name \"@app/server\", type module, main dist/index.js, scripts: dev: \"tsx src/index.ts\", build: \"tsc -b\", test: jest, lint, typecheck.\n- Add dependencies: dotenv, dotenv-safe, zod; devDeps: tsx, ts-jest, jest, @types/jest, ts-node (if needed), typescript.\n- tsconfig.json extends root, sets NodeNext moduleResolution, strict, outDir dist, rootDir src, skipLibCheck false.\n- src/index.ts: load env via dotenv-safe (require .env.local and .env.example), initialize minimal HTTP server with no outbound calls, log structured startup.\n- src/config/env.ts: zod-validated env loader; export getEnv() used by index.\n- Add jest config and sample unit tests for env validation and startup without external calls (mock http/https/fetch) to satisfy TC006.\n- Document .env.example placeholders and ensure .env.local is gitignored per security baseline.\n- Run tests; ensure TC006 passes for server.",
            "status": "done",
            "testStrategy": "Isolate network modules with jest.mock; assert that startup completes without any http/https requests; assert process.env is validated."
          },
          {
            "id": 5,
            "title": "Scaffold UI workspace with Vite React TypeScript",
            "description": "Create packages/ui_frontend using Vite React TS template, Playwright config, eslint-plugin-jsx-a11y, and strict TypeScript.",
            "dependencies": [],
            "details": "- Initialize Vite app into packages/ui_frontend (no telemetry): pnpm create vite . --template react-ts (run in that dir) and remove analytics.\n- package.json: name \"@app/ui_frontend\", scripts: dev: \"vite\", build: \"tsc -b && vite build\", preview, test (jest for unit), e2e (playwright).\n- Add Playwright config with devServer that runs vite on port 5173; add a smoke spec loading the app shell and intercepting WS handshake stub (TC005 e2e).\n- Add eslint-plugin-jsx-a11y and configure rules; add basic App shell with accessible landmarks and keyboard nav baseline.\n- TypeScript strict: enable in tsconfig.app.json; set moduleResolution bundler.\n- Add a unit test for a small component and a11y attributes.\n- Run e2e and unit tests; ensure TC005 part (UI) passes.",
            "status": "done",
            "testStrategy": "Run pnpm --filter @app/ui_frontend e2e headed and headless; assert title, role=main present; intercept WS URL with Playwright route."
          },
          {
            "id": 6,
            "title": "Root TypeScript project references and strict config",
            "description": "Establish root tsconfig with project references and strictness propagated to all workspaces, enabling tsc -b across repo.",
            "dependencies": [],
            "details": "- Root tsconfig.base.json: compilerOptions strict true, noUncheckedIndexedAccess true, exactOptionalPropertyTypes true, noImplicitOverride true, incremental true.\n- Root tsconfig.json: references to ./packages/shared, ./packages/server, ./packages/ui_frontend where applicable; set exclude for node_modules and dist.\n- Ensure each package tsconfig references shared where imported.\n- Run tsc -b -v at root; fix path aliases if used (via tsconfig paths) and ensure builds to dist.\n- Update root scripts: \"typecheck\": \"tsc -b --pretty false\"; \"build\": \"pnpm -r build\".\n- Run tests; TC003 and TC001 build now should be achievable.",
            "status": "done",
            "testStrategy": "Run pnpm typecheck; intentionally add a failing type in a throwaway test to verify CI fails; remove after verification."
          },
          {
            "id": 7,
            "title": "ESLint, Prettier, and a11y linting baseline",
            "description": "Configure ESLint with TypeScript, import/order, monorepo-aware overrides, Prettier integration, and jsx-a11y for UI.",
            "dependencies": [],
            "details": "- Add .eslintrc.cjs at root with parser @typescript-eslint, plugins: @typescript-eslint, import, unused-imports, jsx-a11y (scoped to UI), jest.\n- Add eslint-configs per workspace via overrides: server (node, commonjs globals), ui (browser, react), shared (lib rules).\n- Add .prettierrc with standard formatting; setup lint-staged to run eslint --fix and prettier --write on staged files.\n- Add scripts: lint, format in root and packages; ensure pnpm -r lint works.\n- Add minimal violations to ensure rules work, then fix them.\n- Ensure TC004 passes including pre-commit hook behavior.",
            "status": "done",
            "testStrategy": "Run eslint on changed files via lint-staged simulation; commit a change to confirm pre-commit hook runs and blocks on errors."
          },
          {
            "id": 8,
            "title": "Husky, lint-staged, and commitlint hooks",
            "description": "Install and configure Git hooks: pre-commit for lint-staged and commit-msg for conventional commits with commitlint.",
            "dependencies": [],
            "details": "- Install husky, lint-staged, @commitlint/config-conventional, @commitlint/cli.\n- Add prepare script to root package.json and run pnpm prepare to generate .husky/.\n- Create .husky/pre-commit with: pnpm lint-staged.\n- Configure lint-staged in package.json or .lintstagedrc to run eslint and prettier on staged ts/tsx/json/yaml.\n- Create .husky/commit-msg with: pnpm commitlint --edit \"$1\".\n- Add commitlint.config.cjs extending @commitlint/config-conventional.\n- Verify TC004 hook behavior.",
            "status": "done",
            "testStrategy": "Attempt a non-conforming commit message; expect failure. Attempt conforming message; expect success. Ensure staged lint fixes are applied."
          },
          {
            "id": 9,
            "title": "Jest configuration across monorepo",
            "description": "Unify Jest config to support ESM TypeScript in all packages with ts-jest, coverage reports, and isolated test envs.",
            "dependencies": [],
            "details": "- Create jest.preset.ts at root exporting common config: preset ts-jest, testEnvironment node/jsdom by package, extensionsToTreatAsEsm, transform for ts with useESM, moduleNameMapper for TS paths.\n- Update each package jest.config.ts to extend from root preset.\n- Add coverage thresholds and collectCoverageFrom per package.\n- Ensure server and shared unit tests run; for UI, keep component tests minimal if Playwright covers UI e2e.\n- Run tests; confirm TC005 unit test coverage across packages.",
            "status": "done",
            "testStrategy": "pnpm -r test with --coverage; verify that ESM interop works and no Babel needed."
          },
          {
            "id": 10,
            "title": "Playwright e2e setup and devServer orchestration",
            "description": "Finalize Playwright project with devServer orchestration to spin up both server and UI concurrently for e2e smoke.",
            "dependencies": [],
            "details": "- In e2e/playwright.config.ts at root, define projects: ui. Configure webServer to start: pnpm --filter @app/server dev and pnpm --filter @app/ui_frontend dev via a wrapper script using concurrently or a custom node launcher.\n- Implement scripts/dev.ts in repo root to spawn both processes, wait for ports (server e.g., 4000, UI 5173), and expose readiness.\n- Add Playwright route interception to stub WS handshake to localhost without touching network.\n- Ensure TC005 end-to-end smoke passes reliably in CI.",
            "status": "done",
            "testStrategy": "Run pnpm e2e locally and in CI; add retry and timeout settings; capture traces on failure."
          },
          {
            "id": 11,
            "title": "Runtime environment management with dotenv-safe",
            "description": "Standardize environment variable management, examples, and documentation; enforce local-only defaults and no telemetry.",
            "dependencies": [],
            "details": "- Create .env.example at repo root with placeholders and comments for all required variables for server and UI (prefixed VITE_ for UI if needed). Include OFFLINE=true default.\n- Ensure .env.local is in .gitignore and referenced in docs.\n- Update server env loader to respect OFFLINE flag and explicitly deny outbound by default (but do not implement network guard policy yet; just set flags).\n- Document keyring location expectations (future tasks) and environment conventions in README.\n- Update tests to check presence of example env and that startup honors OFFLINE in logs (no network).",
            "status": "done",
            "testStrategy": "Run server startup under OFFLINE=true and assert logs reflect offline mode; ensure TC006 remains passing."
          },
          {
            "id": 12,
            "title": "Dev, build, test, e2e, lint, typecheck scripts wiring",
            "description": "Wire root and per-package scripts and concurrently-based dev script to run server+client together.",
            "dependencies": [],
            "details": "- Add root scripts:\n  - dev: \"node scripts/dev.js\" (or ts-node/tsx if TypeScript) to run both workspaces.\n  - build: \"pnpm -r build\".\n  - test: \"pnpm -r test\".\n  - e2e: \"playwright test\".\n  - lint: \"pnpm -r lint\"; format: \"pnpm -r format\"; typecheck: \"tsc -b\".\n- Ensure package-level scripts align and dev servers bind to non-conflicting ports.\n- Validate TC001: pnpm -r build passes and produces outputs for server and shared; UI build produces dist.\n- Ensure CI uses these scripts.",
            "status": "done",
            "testStrategy": "Run pnpm build and verify artifacts; run pnpm dev and access UI; ensure e2e passes."
          },
          {
            "id": 13,
            "title": "CI pipeline: lint, typecheck, unit, and e2e on push",
            "description": "Add GitHub Actions workflow to run lint, typecheck, unit tests, and Playwright e2e on pushes/PRs; cache pnpm and Playwright browsers.",
            "dependencies": [],
            "details": "- .github/workflows/ci.yml:\n  - Use actions/setup-node@v4 with Node 20.x; setup pnpm; cache pnpm store.\n  - Jobs: lint+typecheck, unit, e2e with matrix for OS if needed (start with ubuntu-latest).\n  - Install Playwright browsers with npx playwright install --with-deps.\n  - Artifacts: upload playwright traces on failure and coverage reports.\n- Gate merges by requiring CI pass (docs; optional branch protection).",
            "status": "done",
            "testStrategy": "Open a PR to trigger CI; ensure all TC001–TC006 checks run and are green."
          },
          {
            "id": 14,
            "title": "Security and git hygiene baselines",
            "description": "Ensure sensitive files are ignored, add CODEOWNERS, basic security policy, and configure minimal access boundaries.",
            "dependencies": [],
            "details": "- Verify .gitignore covers .env.local and any keys; add .env.* patterns as needed.\n- Add SECURITY.md and CONTRIBUTING.md describing local-first, no telemetry defaults.\n- Add CODEOWNERS to declare ownership for packages/server, packages/ui_frontend, packages/shared, scripts, content.\n- Add npmrc/pnpm config to avoid sending telemetry if any and lock registry to npmjs.\n- Add a simple script to scan for accidental keys in commits using a regex pre-commit optional step.",
            "status": "done",
            "testStrategy": "Run a simulated commit containing a dummy API key and confirm the scanner flags it; verify TC006 still passes."
          },
          {
            "id": 15,
            "title": "Content and scripts workspaces scaffolding",
            "description": "Create packages/content and packages/scripts workspaces with minimal structure and testing harness.",
            "dependencies": [],
            "details": "- packages/content: package.json name \"@app/content\", type module; src/ with placeholder pack JSON and loader types referencing @app/shared.\n- packages/scripts: package.json name \"@app/scripts\", bin entries for future CLIs; tsconfig; jest config; sample CLI that prints workspace graph safely (no network).\n- Add unit tests for scripts CLI and content schema validation.\n- Ensure build and tests integrate into pnpm -r build/test.",
            "status": "done",
            "testStrategy": "Run pnpm --filter @app/scripts test and build; ensure TC001 still green."
          },
          {
            "id": 16,
            "title": "CRDT library placeholder dependencies",
            "description": "Add CRDT dependency placeholders (Automerge/Yjs) without implementation; verify build integrity and tree-shaking.",
            "dependencies": [],
            "details": "- Add dependencies to shared or server where appropriate as optionalDependencies to avoid inflating builds prematurely.\n- Provide minimal type exports that wrap these libs behind an interface stub (no runtime usage yet).\n- Ensure optional import paths are type-safe but not executed in dev smoke.\n- Document future integration points in shared README.",
            "status": "done",
            "testStrategy": "Run pnpm -r build to confirm no bundling issues; ensure e2e smoke unaffected."
          },
          {
            "id": 17,
            "title": "Finalize folder map and docs import",
            "description": "Lay out src/server subfolders (llm orchestration, missions, rules, memory, persistence, realtime, images, scheduling, video-flagged) and src/ui_frontend features (voice capture, HUD, campaign browser, schedule editor, captions), plus framework_docs/.",
            "dependencies": [],
            "details": "- Create empty folder structure with README.md in each domain describing purpose and boundaries.\n- Add index.ts placeholders exporting nothing to keep TS project references valid.\n- Add a feature flag for video areas in server and UI (simple boolean in env types) and ensure excluded from builds when false.\n- Ensure imports do not create circular deps.\n- Import existing framework_docs/ if provided and exclude from build.",
            "status": "done",
            "testStrategy": "Run pnpm typecheck to ensure no stray imports; run pnpm -r build; ensure TC001 remains green."
          },
          {
            "id": 18,
            "title": "Verification sweep and harden tests (TC001–TC006)",
            "description": "Run and harden all tests, improve flake resistance, and ensure acceptance criteria fully met before closing task.",
            "dependencies": [],
            "details": "- Stabilize Playwright devServer startup with wait-on and retry.\n- Ensure no external network calls by stubbing DNS lookups and setting env OFFLINE in e2e.\n- Validate pnpm -r build works from a clean clone; test incremental builds.\n- Ensure lint-staged and commitlint enforce policies consistently.\n- Update docs with setup steps and troubleshooting.",
            "status": "done",
            "testStrategy": "Cold CI run in a fresh environment; collect traces; run tests twice to detect flakes; ensure all TC001–TC006 pass consistently."
          }
        ]
      },
      {
        "id": 2,
        "title": "Local SQLite and Vector Index Setup",
        "description": "Implement local-first persistence with SQLite and pluggable vector index (FAISS or SQLite-VSS), schema migrations, and access layer.",
        "details": "- Use better-sqlite3 for sync local db; drizzle-orm or Kysely for typed queries\n- Vector: prefer sqlite-vss (if available for platform) with fallback FAISS via node bindings; abstraction interface VectorIndex with namespaces campaign:<id>, player:<id>\n- Migrations: drizzle-kit or Knex; seed script for dev\n- Tables: players, characters, campaigns, sessions, world_states, events, memories, missions, mission_progress, inventory, items, images, videos (featureFlag), llm_messages, settings, schedules\n- Indices: events(session_id, seq), memories(namespace, ts), images(hash/style), schedules(campaign_id, next_fire_at)\n- Snapshots table for periodic snapshots\n- Local asset cache dirs: cache/images, cache/video, logs/\n- Encryption at rest for provider keys: OS keychain via keytar; settings table stores key ids not secrets",
        "testStrategy": "- Unit tests: CRUD for core tables, migrations up/down idempotency\n- Vector tests: insert/query cosine similarity, namespace isolation\n- Performance smoke: simple benchmark ensures typical inserts >2k/s, vector query <50ms on small set\n- Verify keys never stored in plaintext in DB by scanning settings table",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and write tests first (DB + Vector + Security + Perf)",
            "description": "Create a comprehensive test suite that encodes the core acceptance criteria for local-first persistence, migrations, vector index behavior (sqlite-vss and FAISS fallback), access layer, encryption-at-rest via keytar, and basic performance smoke checks. No production code beyond test scaffolding should be implemented here.",
            "dependencies": [],
            "details": "• Set up test harness with Node.js + TypeScript: vitest/jest, ts-node/ts-jest, and a temporary filesystem sandbox per test.\n• Define TC IDs and coverage mapping:\n  - TC001: Migrations up/down idempotency and versioning.\n  - TC002: CRUD for core tables (players, campaigns, sessions, events, memories) covering inserts, updates, deletes, and queries with indices.\n  - TC003: Vector index insert and cosine similarity search returns expected order; validate namespace isolation (campaign:<id>, player:<id>).\n  - TC004: Fallback from sqlite-vss to FAISS when vss extension unavailable.\n  - TC005: Keys are not stored in plaintext in DB; settings table stores key IDs only; keytar used for secret retrieval.\n  - TC006: Seed script populates dev data deterministically and re-runnable without duplication.\n  - TC007: Indices exist and are used (events(session_id, seq), memories(namespace, ts), images(hash, style), schedules(campaign_id, next_fire_at)).\n  - TC008: Snapshots table creation and periodic write/read integrity.\n  - TC009: Performance smoke: typical inserts >2000 rows/s; vector top-k query <50ms on small set.\n  - TC010: Feature flag toggles videos table creation and access layer exposure.\n• Create fixtures for sample entities and small vector sets.\n• Provide mock/shim for keytar in tests to simulate OS keychain.\n• Stub FAISS bindings with simple in-memory vector store behind the same interface for unit tests if native module is not available in CI.\n• Set up test database paths in a temp directory; ensure cleanup.\n• Do not implement production modules; write tests that reference planned module contracts and interfaces.",
            "status": "pending",
            "testStrategy": "Run the test suite; all tests expected to fail initially (red). Ensure CI runs on push and PR."
          },
          {
            "id": 2,
            "title": "Project scaffolding and package setup",
            "description": "Initialize packages, TypeScript config, testing framework, scripts, and environment scaffolding for local-first SQLite and vector index development.",
            "dependencies": [
              "2.1"
            ],
            "details": "• Add dependencies: better-sqlite3, drizzle-orm or kysely (choose one), drizzle-kit or knex, keytar, zod, dotenv, fast-glob, and optionally sqlite-vss package/loader; add FAISS node bindings dependency (optional peer) and a lightweight fallback dev stub.\n• Add dev dependencies: vitest/jest, ts-node/tsx, types for node, eslint, prettier, tsup/tsc build.\n• Configure tsconfig for ES2020 target and NodeNext module resolution.\n• Add NPM scripts: test, test:watch, db:migrate, db:seed, db:reset, build, lint, typecheck, perf:smoke.\n• Create environment loader: .env schema with DB_FILE, FEATURE_VIDEOS, VSS_EXTENSION_PATH, FAISS_ENABLED, APP_ENV.\n• Provide platform notes for loading sqlite-vss (dlopen) and FAISS optional load.",
            "status": "pending",
            "testStrategy": "Run test suite; ensure it executes and fails only on unimplemented features, not on environment issues."
          },
          {
            "id": 3,
            "title": "Database connection and lifecycle module (better-sqlite3)",
            "description": "Implement a robust SQLite connection factory using better-sqlite3 with safe open, WAL mode, PRAGMA defaults, and a standardized path layout for local-first storage.",
            "dependencies": [
              "2.2"
            ],
            "details": "• Implement db/connection.ts: create or open DB at DB_FILE; set PRAGMAs: journal_mode=WAL, synchronous=NORMAL, foreign_keys=ON, cache_size=-20000, temp_store=MEMORY; busy_timeout=5000.\n• Ensure directories exist: ./cache/images, ./cache/video, ./logs.\n• Expose a singleton getDb() and a withTransaction<T>(fn) helper using db.transaction.\n• Implement graceful shutdown hook; close DB on process exit.\n• Export a lightweight query interface if using better-sqlite3 prepared statements.\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "Unit tests: open/close DB, PRAGMAs set, WAL file appears after write, concurrent prepared statements work. Map to TC002 partial infra."
          },
          {
            "id": 4,
            "title": "Schema definition with ORM and migrations baseline",
            "description": "Define schemas for all required tables and generate initial migration files using drizzle-orm (or Kysely) with drizzle-kit (or Knex).",
            "dependencies": [
              "2.3"
            ],
            "details": "• Choose ORM: drizzle-orm recommended for typed queries; set up schema folder with table definitions for: players, characters, campaigns, sessions, world_states, events, memories, missions, mission_progress, inventory, items, images, videos (featureFlag), llm_messages, settings, schedules, snapshots.\n• Define indices:\n  - events: composite index (session_id, seq).\n  - memories: (namespace, ts).\n  - images: (hash), (style) or composite depending on query plan.\n  - schedules: (campaign_id, next_fire_at).\n• Add foreign keys and ON DELETE/UPDATE behaviors; add created_at/updated_at defaults.\n• Implement conditional DDL for videos table controlled by FEATURE_VIDEOS env at migration time.\n• Generate initial migration SQL and a migration runner script (db/migrate.ts) with up/down and idempotency guards.\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC001 (idempotent up/down), TC007 (indices exist), and part of TC010 (videos flag) should pass."
          },
          {
            "id": 5,
            "title": "Seed script for development data",
            "description": "Create a repeatable, idempotent seed script to populate core entities and sample data for development and tests.",
            "dependencies": [
              "2.4"
            ],
            "details": "• Implement db/seed.ts: insert sample players, campaigns, sessions, items, and minimal vectors for memories.\n• Use upsert patterns (INSERT ... ON CONFLICT DO UPDATE/NOTHING) keyed by stable IDs to ensure re-runnable seeds.\n• Provide small deterministic corpus for vector tests (fixed random seed, small embeddings arrays).\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC006 should pass; verify rows count stable across repeated seeding; ensure referential integrity."
          },
          {
            "id": 6,
            "title": "VectorIndex interface and adapter contracts",
            "description": "Design a pluggable VectorIndex TypeScript interface with namespace support and define contracts for sqlite-vss and FAISS adapters.",
            "dependencies": [
              "2.4"
            ],
            "details": "• Define types in vector/index.ts:\n  - interface VectorIndex { init(): Promise<void>|void; upsert(vecs: {id:string, namespace:string, embedding:number[], metadata?:Record<string,any>}[]): Promise<void>; delete(ids: string[], namespace: string): Promise<void>; query(opts:{namespace:string, embedding:number[], topK:number, filter?:Record<string,any>, metric?:'cosine'|'l2'}): Promise<{id:string, score:number, metadata?:Record<string,any>}[]>; purgeNamespace(namespace:string): Promise<void>; close(): Promise<void>|void }\n• Enforce namespace forms: campaign:<id>, player:<id> via zod refinements.\n• Define error classes and feature detection helpers for sqlite-vss availability and FAISS bindings.\n• Run tests and make them pass for interface existence and validation utilities.",
            "status": "pending",
            "testStrategy": "Unit tests validate input schemas, namespace regex, and adapter selection logic stubs."
          },
          {
            "id": 7,
            "title": "SQLite-VSS adapter implementation",
            "description": "Implement VectorIndex using sqlite-vss extension when available, with table creation, indexing, and cosine similarity queries per namespace.",
            "dependencies": [
              "2.6",
              "2.3",
              "2.4"
            ],
            "details": "• Load sqlite-vss extension via db.loadExtension(VSS_EXTENSION_PATH) or compile-time bundled load; guard per-platform.\n• Create vss embeddings table: vss_embeddings(dim INTEGER, namespace TEXT, id TEXT PRIMARY KEY, embedding BLOB, metadata JSON, created_at/updated_at). Create a VSS index over embedding; store embeddings as FLOAT32 array in BLOB.\n• Implement upsert: use replace/insert with parameter binding; maintain updated_at.\n• Implement query: compute topK via vss_search using cosine distance; translate to similarity score (1 - distance if needed). Apply namespace filter and optional metadata JSON filter via JSON_EXTRACT.\n• Implement delete and purgeNamespace.\n• Ensure transactions for batch upserts.\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC003 (sqlite-vss path) and TC004 partial (availability detection) pass on environments with extension."
          },
          {
            "id": 8,
            "title": "FAISS adapter implementation (fallback)",
            "description": "Implement FAISS-based VectorIndex adapter loaded optionally via node bindings, used when sqlite-vss is unavailable.",
            "dependencies": [
              "2.6"
            ],
            "details": "• Attempt to import FAISS; if unavailable, provide a minimal in-memory cosine index fallback for dev to satisfy tests.\n• Implement index management: maintain per-namespace index (IndexFlatIP or L2 as configured). Persist index shards to files under ./cache/vector/<namespace>.faiss when possible; else memory-only with warning.\n• Implement upsert by re-building or adding vectors; delete by re-indexing namespace excluding IDs; maintain an aux mapping {id->position, metadata} in JSON file per namespace.\n• Implement query with topK; return scores normalized to cosine similarity.\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC004 (fallback works) and TC003 (namespace isolation and similarity order) pass with FAISS or in-memory fallback."
          },
          {
            "id": 9,
            "title": "Vector adapter selection and factory",
            "description": "Implement a factory that selects sqlite-vss when available, else FAISS adapter, exposing a single VectorIndex instance.",
            "dependencies": [
              "2.7",
              "2.8"
            ],
            "details": "• Implement vector/factory.ts: detect sqlite-vss by trying to load extension or probing PRAGMA module_list; if successful, return SQLiteVSS adapter, else try FAISS; if both fail, throw descriptive error with remediation.\n• Ensure init() sets up necessary tables or files; ensure close() cleans up handles.\n• Integrate with env flags to force a particular backend for testing.\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC004 should fully pass across environments; add unit tests for forced selection via env."
          },
          {
            "id": 10,
            "title": "Access layer (repositories) with typed queries",
            "description": "Implement repositories for core tables using the ORM: CRUD operations, common queries, and transaction-safe methods.",
            "dependencies": [
              "2.4",
              "2.3"
            ],
            "details": "• Implement repositories: PlayersRepo, CampaignsRepo, SessionsRepo, EventsRepo, MemoriesRepo, ItemsRepo, InventoryRepo, MissionsRepo, MissionProgressRepo, WorldStatesRepo, ImagesRepo, LlmMessagesRepo, SettingsRepo, SchedulesRepo, SnapshotsRepo.\n• Provide methods: create/get/update/delete, list by foreign key, and domain-specific methods (e.g., EventsRepo.appendEvent(sessionId, seq, payload) enforcing seq index; MemoriesRepo.listByNamespace with ts ordering; SchedulesRepo.nextDue(campaignId)).\n• Use prepared statements or ORM queries; ensure consistent error handling and result typing.\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC002 and TC007 should pass for CRUD and indexed queries."
          },
          {
            "id": 11,
            "title": "Security: key management via keytar and settings indirection",
            "description": "Store provider secrets in OS keychain using keytar; persist only key IDs in settings; add helper to set/get/delete secrets safely.",
            "dependencies": [
              "2.10"
            ],
            "details": "• Implement security/secrets.ts with functions: saveSecret(id, value), getSecret(id), deleteSecret(id). Use keytar with service name from env/app name.\n• Implement SettingsRepo helpers: setProviderKey(provider, keyId), getProviderKeyId(provider). Ensure no plaintext keys stored in DB; add validation checks scanning settings rows for secret-like content.\n• Provide migration safeguard ensuring settings columns are string ids, not secret blobs.\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC005 passes, including scanning DB to ensure no secrets present."
          },
          {
            "id": 12,
            "title": "Snapshots table and periodic snapshot writer",
            "description": "Add snapshotting support to persist periodic world state and session metadata for recovery and audits.",
            "dependencies": [
              "2.10"
            ],
            "details": "• Confirm snapshots schema (id, scope, ref_id, ts, payload JSON, hash) and indices on (scope, ref_id, ts DESC).\n• Implement snapshots service: takeSnapshot(scope, refId, payload) computes content hash, stores row; listSnapshots(scope, refId, limit); getLatest.\n• Integrate with withTransaction and repositories where appropriate.\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC008 passes with write/read integrity and hash validation."
          },
          {
            "id": 13,
            "title": "Feature flagged videos table and repository",
            "description": "Conditionally expose videos repository and DDL based on FEATURE_VIDEOS flag without breaking other modules.",
            "dependencies": [
              "2.4",
              "2.10"
            ],
            "details": "• Ensure migrations respect FEATURE_VIDEOS at runtime; add guard that if disabled, VideosRepo throws a controlled error on use.\n• If enabled, implement CRUD and indexing per schema; store files in cache/video directory with hashed filenames.\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC010 passes for both enabled and disabled states."
          },
          {
            "id": 14,
            "title": "Integration: vector memory flows with repositories",
            "description": "Wire the VectorIndex with MemoriesRepo to support write/query operations with strict namespace handling.",
            "dependencies": [
              "2.9",
              "2.10"
            ],
            "details": "• Implement memoryService with methods: writeMemory(namespace, text, embedding, metadata), retrieve(namespace, embedding, topK, filter), delete(ids, namespace), promote hooks (stub for Task 12).\n• Ensure transactional write: insert memory row then upsert embedding; on failure, rollback.\n• Validate namespace format before execution.\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "Covers TC003 end-to-end with repo + vector query; add integration test using seed corpus."
          },
          {
            "id": 15,
            "title": "Performance smoke tests and tuning",
            "description": "Implement automated performance smoke benchmarks for inserts and vector queries; tune PRAGMAs and batch sizes to meet targets.",
            "dependencies": [
              "2.14"
            ],
            "details": "• Implement perf tests: bulk insert 10k events using prepared statements and transactions; capture rows/s; assert >2000 rows/s on typical dev machine.\n• Vector query perf: index 1k embeddings and run topK=5 cosine query; assert <50ms median for warm cache.\n• Tune: batch upserts (500-1000), PRAGMAs set earlier, WAL checkpointing as needed.\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "TC009 passes; report metrics in test output for observability."
          },
          {
            "id": 16,
            "title": "Tooling: DB reset, migration verify, and lint rules",
            "description": "Add utility scripts to reset DB, verify migration integrity, and enforce SQL/ORM lint rules.",
            "dependencies": [
              "2.4"
            ],
            "details": "• db:reset script drops DB file, runs migrations up, and runs seed.\n• db:verify script runs down/up cycle in a temp DB and checks schema checksum to ensure idempotency.\n• ESLint rules for no raw secrets in code; forbid direct INSERT into settings.secret columns (not present) via custom lint pattern.\n• Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "Re-run TC001 and TC006 in a fresh environment; ensure pass."
          },
          {
            "id": 17,
            "title": "Documentation and examples",
            "description": "Provide README and example snippets for developers to use the access layer and vector index correctly.",
            "dependencies": [
              "2.14",
              "2.11",
              "2.13"
            ],
            "details": "• Add docs explaining environment variables, how to run migrations and seed, how vector backend is selected, and how to store secrets with keytar.\n• Provide example scripts: examples/demo-seed-and-query.ts demonstrating end-to-end insert and retrieval across namespaces.\n• Ensure examples run under CI as part of tests.",
            "status": "pending",
            "testStrategy": "Run examples in CI; basic assertions that outputs contain expected IDs and scores."
          }
        ]
      },
      {
        "id": 3,
        "title": "Realtime WebSocket Gateway",
        "description": "Create WebSocket server for multiplayer messaging, presence, and pub/sub channels underpinning voice/text synchronization.",
        "details": "- Library: ws or uWebSockets.js; Node/TS\n- Auth: local session token per client (simple dev auth); campaign+session scoping\n- Channels: 1:1, room/proximity, team/line, party/alliance topics; server enforces membership\n- Message types: join, leave, voice-meta, caption, action, ticker-update, crdt-sync\n- Backpressure and retries with exponential backoff; heartbeat pings; reconnect tokens\n- Serialize with zod schemas in shared package for strict validation\n- Rate limit per connection; structured logs to logs/",
        "testStrategy": "- Integration tests with superwstest/ws mocking multiple clients joining/leaving\n- TC002 mapping: verify channel membership and audio routing metadata distribution\n- Chaos test: drop packets, ensure reconnect restores subscriptions\n- Performance: sustain 100 concurrent clients locally without error",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for WebSocket gateway (unit + integration)",
            "description": "Before implementation, author a comprehensive test suite capturing the core acceptance criteria for the realtime gateway covering connection lifecycle, auth, channel membership enforcement, message routing per type, rate limiting, backpressure handling, heartbeat/reconnect, and basic performance envelopes.",
            "dependencies": [],
            "details": "Create tests in packages/server/src/realtime/__tests__ with Jest + ts-jest and superwstest or ws test utilities. Add:\n- Unit tests for validators (zod schemas), rate limiter, backoff utility, token parsing, and channel authorization rules.\n- Integration tests spinning up an ephemeral ws server on a random port with multiple simulated clients using ws or superwstest.\n- Tag relevant cases with IDs TC002 (channel membership and audio metadata routing) and reserve TC010–TC014 for lifecycle, resilience, and rate-limit cases.",
            "status": "pending",
            "testStrategy": "- Unit: zod schema validation for message types join, leave, voice-meta, caption, action, ticker-update, crdt-sync. Expect parse success/failure on fixtures (TC010).\n- Unit: rate limiter blocks excess messages per connection with reset window (TC011).\n- Unit: exponential backoff function yields expected sequence with jitter (TC012).\n- Integration: auth required—unauthorized handshake rejected; authorized connects succeed (TC013).\n- Integration: channel membership enforced—publish blocked if not a member; allowed after join; distribution only to members (TC002).\n- Integration: presence events broadcast join/leave to relevant channels (TC014).\n- Integration: heartbeat—server pings, client must pong; idle disconnect; reconnect token restores subscriptions (TC015).\n- Integration: backpressure—server buffers capped; slow consumer triggers pause/drop policy with signal; retries with backoff from client harness (TC016).\n- Integration: sustain 100 concurrent local clients for 30s without error and with <1% message loss for best-effort channels (TC017)."
          },
          {
            "id": 2,
            "title": "Scaffold realtime server module and configuration",
            "description": "Create the realtime WebSocket gateway package structure, environment config, and process bootstrap to run tests.",
            "dependencies": [
              "3.1"
            ],
            "details": "In packages/server/src/realtime: add index.ts (server entry), server.ts (gateway class), config.ts (env: PORT, RATE_LIMIT, HEARTBEAT_MS, BACKPRESSURE_LIMIT, RECONNECT_TTL, DEV_AUTH), logs/ directory for structured logs. Use ws or uWebSockets.js; start with ws for portability. Wire pnpm scripts: server:dev, server:test. Ensure Jest spins ephemeral server for integration tests.",
            "status": "pending",
            "testStrategy": "Run all tests from 3.1 and ensure the harness boots a server per test and tears down cleanly."
          },
          {
            "id": 3,
            "title": "Implement Zod schemas and shared message types",
            "description": "Define strict Zod schemas for all message types and envelopes in the shared package; export TS types for server and client.",
            "dependencies": [
              "3.1",
              "3.2"
            ],
            "details": "In packages/shared/src/realtime/schemas.ts define: Envelope {type, ts, sessionId, campaignId, channel?, payload}, and payload schemas for join, leave, voice-meta, caption, action, ticker-update, crdt-sync. Add parse/serialize helpers and discriminated unions. Version messages with v field for forward compatibility. Include error schema for server errors.",
            "status": "pending",
            "testStrategy": "Run unit tests from 3.1 TC010 validating success/failure paths and round-trip serialization."
          },
          {
            "id": 4,
            "title": "Authentication and scoping middleware",
            "description": "Implement connection authentication using local session tokens and enforce campaign+session scoping for each client.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.3"
            ],
            "details": "On connection upgrade, parse token from query/header; validate format and map to {userId, campaignId, sessionId, roles} via a dev in-memory verifier. Attach auth context to ws. Reject unauthenticated with close code 4001. Maintain a connection registry keyed by sessionId/userId. Ensure all incoming messages are checked against the connection's campaign/session scope.",
            "status": "pending",
            "testStrategy": "Run TC013 integration: unauthorized rejected, authorized succeeds; unit test token parsing including malformed tokens."
          },
          {
            "id": 5,
            "title": "Channel model and membership enforcement",
            "description": "Add server-side channel registry for 1:1, room/proximity, team/line, party/alliance topics with membership rules.",
            "dependencies": [
              "3.1",
              "3.4"
            ],
            "details": "Design ChannelId type {kind, key} where kind ∈ {direct, room, team, party}. Implement membership service: direct = {a,b}; room/proximity based on session state map; team and party via role/team assignments. Provide join/leave handlers updating membership and presence state. Enforce on publish: block if not a member. Maintain indexes: channel->connections and connection->channels.",
            "status": "pending",
            "testStrategy": "Run TC002: attempts to publish without membership fail; after join, messages fan out only to members; presence events sent on join/leave."
          },
          {
            "id": 6,
            "title": "Message routing and handlers per type",
            "description": "Implement dispatch loop validating messages with zod and routing to appropriate channels with structured logs.",
            "dependencies": [
              "3.1",
              "3.3",
              "3.5"
            ],
            "details": "On message, parse Envelope with zod; reject invalid with error envelope. Route: voice-meta and caption to channel members; action to channel or targeted users; ticker-update broadcast to session scope; crdt-sync enqueue to CRDT module hook (stub for Task 20). Add tracing context (requestId) in logs. Prevent echo to sender when not desired.",
            "status": "pending",
            "testStrategy": "Extend TC002 and add cases for each type to ensure correct targeting and schema validation errors."
          },
          {
            "id": 7,
            "title": "Heartbeat, idle detection, and reconnect tokens",
            "description": "Add pings at configured interval, close idle connections, and implement reconnect tokens to restore subscriptions.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.4",
              "3.5",
              "3.6"
            ],
            "details": "Implement server ping loop; mark connection alive on pong; if missed N pings, close with 4002. On close, persist a reconnect token mapping to prior subscriptions and presence for RECONNECT_TTL in memory. On reconnect with token and same auth, restore channel memberships and emit presence restored events.",
            "status": "pending",
            "testStrategy": "Run TC015: simulate dropped client; verify disconnect then reconnect with token restores subscriptions and presence notifications."
          },
          {
            "id": 8,
            "title": "Backpressure control and send queue",
            "description": "Implement per-connection buffered send queues with size caps and policies for slow consumers.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.6"
            ],
            "details": "Wrap ws.send with a queue. If socket bufferedAmount exceeds BACKPRESSURE_LIMIT or queue length exceeds limit, apply policy: drop oldest non-critical messages (e.g., voice-meta, ticker-update) marked best-effort; retain critical (join/leave, action, crdt-sync). Expose metrics. Notify sender of drops via control messages.",
            "status": "pending",
            "testStrategy": "Run TC016: create artificial slow consumer; assert queue caps are enforced and best-effort drops occur with notifications; ensure no process crash."
          },
          {
            "id": 9,
            "title": "Client retry strategy and exponential backoff utilities",
            "description": "Provide a reusable backoff utility and document client-side retry expectations; include server hints in close reasons.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.7",
              "3.8"
            ],
            "details": "Implement backoff.ts with base, cap, jitter. Include recommended retry-after hints in close frames for 4002/overload conditions. Provide sample client harness in tests using the utility to validate retries and eventual reconnect with token.",
            "status": "pending",
            "testStrategy": "Run TC012 for utility sequence; integration verifies retries escalate and reconnect succeeds without storming the server."
          },
          {
            "id": 10,
            "title": "Per-connection rate limiting",
            "description": "Add token-bucket or leaky-bucket rate limiting per connection with burst allowance and penalty close on abuse.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.6"
            ],
            "details": "Implement a token bucket with configurable tokens/sec and burst. Apply per incoming message before parsing heavy payloads. On exceed, send error envelope and optionally temporarily mute or close with 4003 on sustained abuse. Exempt heartbeat pings/pongs.",
            "status": "pending",
            "testStrategy": "Run TC011: flood messages and assert throttling kicks in, errors returned, and optional close on persistent violation."
          },
          {
            "id": 11,
            "title": "Structured logging and diagnostics",
            "description": "Produce structured JSON logs for key events to logs/ with rotation hooks and redaction of sensitive fields.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.4",
              "3.6"
            ],
            "details": "Use pino or winston to log events: connect, auth, join/leave, publish, drops, rate-limit, heartbeat, errors. Include fields: ts, level, connId, userId, sessionId, channelId, event, metrics. Redact tokens. Configure test logger to memory to assert log entries in tests.",
            "status": "pending",
            "testStrategy": "Add assertions in existing integration tests to verify presence of required log fields for representative flows."
          },
          {
            "id": 12,
            "title": "Integration with CRDT sync hook (Task 20 preparation)",
            "description": "Provide a typed hook for crdt-sync messages so Task 20 can plug in Yjs/Automerge syncing without changing the gateway.",
            "dependencies": [
              "3.1",
              "3.3",
              "3.6"
            ],
            "details": "Define CrdtSyncAdapter interface in shared: onMessage(connCtx, payload), getDocsForSession(sessionId), and broadcast helper. In server, on crdt-sync route to adapter if present; otherwise acknowledge with stub response. Guard permissions via roles from auth context.",
            "status": "pending",
            "testStrategy": "Integration test sends crdt-sync; verify adapter stub invoked and messages contained within session scope; permission denied when role missing."
          },
          {
            "id": 13,
            "title": "Presence service and roster queries",
            "description": "Maintain presence state per session/channel and support roster queries and updates on join/leave.",
            "dependencies": [
              "3.1",
              "3.5",
              "3.6"
            ],
            "details": "Track online users and their channels; on join/leave, send presence events to relevant members. Add a query message type or action to request roster snapshot for a channel which returns list of userIds and metadata.",
            "status": "pending",
            "testStrategy": "Extend TC014: verify presence roster updates across joins/leaves and that roster query returns accurate membership."
          },
          {
            "id": 14,
            "title": "Performance and load test scaffold (100 clients)",
            "description": "Add a local load test to spin up 100 ws clients, join channels, and exchange messages for 30s to validate stability.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.5",
              "3.6",
              "3.7",
              "3.8",
              "3.10",
              "3.11"
            ],
            "details": "Create scripts/perf/realtime.load.test.ts using Jest with increased timeout. Launch 100 clients with staggered connects and randomized publishes within rate limits. Collect metrics: connect success, message throughput, error count, dropped messages percentage.",
            "status": "pending",
            "testStrategy": "Run TC017: assert zero crashes, >95% delivery for reliable messages, and best-effort within acceptable loss; max memory within threshold."
          },
          {
            "id": 15,
            "title": "Security hardening and close codes",
            "description": "Standardize WebSocket close codes and sanitize inputs; guard against oversized frames and JSON bombs.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.6",
              "3.10"
            ],
            "details": "Configure ws maxPayload. Validate message size before parse. Define close codes: 4000 generic, 4001 auth, 4002 idle, 4003 rate limit, 4004 membership, 4005 schema. Strip unknown fields in zod. Deny unknown message types.",
            "status": "pending",
            "testStrategy": "Integration tests sending oversized or malformed frames should be rejected with appropriate close/error envelopes; fuzz a few random payloads."
          },
          {
            "id": 16,
            "title": "Admin and observability endpoints (dev)",
            "description": "Expose dev-only HTTP endpoints to inspect sessions, channels, and metrics for debugging.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.5",
              "3.11"
            ],
            "details": "Attach a minimal HTTP server to expose /health, /metrics (Prom-like counters for connections, messages, drops), /sessions/:id, /channels/:id members. Guard behind DEV_AUTH and not enabled in production.",
            "status": "pending",
            "testStrategy": "Integration test fetches endpoints while gateway runs; verify JSON structure and that metrics increase during test traffic."
          },
          {
            "id": 17,
            "title": "Sample client harness and docs",
            "description": "Provide a TypeScript sample client demonstrating auth, join, publish, heartbeat handling, and reconnect workflow.",
            "dependencies": [
              "3.1",
              "3.3",
              "3.4",
              "3.7",
              "3.9"
            ],
            "details": "In scripts/clients/sample-client.ts implement flows using the shared schemas and backoff utility. Document configuration and how to run load tests and integration tests in README within realtime folder.",
            "status": "pending",
            "testStrategy": "Manual run during CI or as part of integration tests to ensure interoperability; verify it can reconnect and restore channels."
          }
        ]
      },
      {
        "id": 4,
        "title": "React UI Shell and Campaign Browser",
        "description": "Implement UI shell with campaign list/create/clone/archive and basic session lobby.",
        "details": "- React + Vite; state with Zustand or Redux Toolkit; React Router\n- Views: Campaigns (list/create/clone/archive), Sessions (list/join), Settings (providers), Assets viewer (images cache)\n- Use accessible components; keyboard nav; color contrast tokens\n- API routes: /campaigns CRUD/clone/archive\n- Localized strings scaffold; dark/light themes\n- Display isolation indicators per campaign",
        "testStrategy": "- Playwright: create campaign, clone, archive; verify isolation in UI\n- Accessibility: axe-core scan passes for pages\n- Snapshot tests for key components",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and write initial tests (TDD scaffolding)",
            "description": "Create test plans and implement the first round of unit, integration, and accessibility/UI tests that encode the core acceptance criteria for the UI shell, campaign browser (list/create/clone/archive), sessions lobby (list/join), settings, and assets viewer. Establish testing utilities and fixtures.",
            "dependencies": [],
            "details": "• Document acceptance criteria mapped to verification IDs: TC001 (UI shell nav), TC003 (Campaign list CRUD/clone/archive), TC004 (Session join flow), TC005 (Settings providers persistence), TC006 (Assets viewer loads and caches images), TC007 (Accessibility axe checks), TC008 (Dark/Light theme switch), TC009 (Isolation indicator display), TC010 (i18n string rendering). \n• Set up testing stack: Vitest + React Testing Library for unit/component tests; Playwright for E2E; axe-core/axe-playwright for accessibility; MSW for API mocking; Storybook optional for snapshots. \n• Create base test utilities: renderWithProviders (Router + Zustand/Redux store + Theme + I18n), mock server handlers for /campaigns CRUD/clone/archive and /sessions, i18n test config with en locale. \n• Author initial tests (failing by design): \n  - Unit: NavBar renders links and keyboard focus order (TC001). \n  - Component: CampaignList renders items from API and supports pagination/filter basics (TC003). \n  - Component: CampaignForm validates required fields (TC003). \n  - Integration: Create→Clone→Archive happy path via UI using Playwright with MSW (TC003). \n  - Integration: Session list and Join button route to session lobby (TC004). \n  - Accessibility: axe passes for Campaigns, Sessions, Settings, Assets pages (TC007). \n  - Theming: toggling theme updates tokens and contrast snapshots (TC008). \n  - i18n: strings come from locale files; fallback works (TC010). \n  - Isolation indicator: per-campaign badge visible and labeled (TC009).",
            "status": "pending",
            "testStrategy": "Run: vitest for unit/component; playwright test for E2E; axe scans within tests. Ensure all tests fail initially to drive implementation."
          },
          {
            "id": 2,
            "title": "Project setup: Vite React app, routing, state, testing and tooling",
            "description": "Initialize React + Vite project, configure TypeScript, React Router, state management (Zustand or Redux Toolkit), testing frameworks, linting, formatting, and CI workflows.",
            "dependencies": [
              "4.1"
            ],
            "details": "• Create Vite React TS app; add React Router v6+. \n• Choose state: Redux Toolkit (RTK) with RTK Query or Zustand. Prefer RTK for API caching and normalized lists. \n• Install packages: react-router-dom, @reduxjs/toolkit, react-redux or zustand; vitest, @testing-library/react, @testing-library/user-event, msw, playwright, axe-core, @axe-core/playwright, i18next, react-i18next, i18next-browser-languagedetector, tailwind or CSS variables for tokens. \n• Configure Vitest setup file to include RTL and i18n. \n• Configure MSW service worker and test server. \n• Set up Playwright project with MSW integration or test server mocks, CI scripts, and npm scripts: test, test:e2e, test:a11y, lint, format. \n• Add absolute import aliases. \n• Add GitHub Actions workflow to run unit and Playwright tests. \n• Run tests from 4.1 and verify they execute (still failing by design).",
            "status": "pending",
            "testStrategy": "Run all tests; ensure environment resolves and reporters show failures. Fix only environment/test runner issues, keep feature tests failing."
          },
          {
            "id": 3,
            "title": "UI shell layout, routing structure, and accessible navigation",
            "description": "Implement the application shell: header, sidebar/top-nav, main content area, skip links, focus management, and React Router routes for Campaigns, Sessions, Settings, Assets.",
            "dependencies": [
              "4.1",
              "4.2"
            ],
            "details": "• Create Layout components: AppShell (Header with app title and theme toggle; Nav with links to Campaigns, Sessions, Settings, Assets), Main with landmark roles. \n• Add skip-to-content link, aria-current on active nav links, keyboard navigable menu, and focus ring styles. \n• Define routes: /campaigns, /campaigns/new, /campaigns/:id, /sessions, /settings, /assets. \n• Implement basic placeholders for pages with test IDs and i18n keys. \n• Ensure color contrast tokens applied to shell. \n• Run tests from 4.1 and make TC001 pass; keep others pending.",
            "status": "pending",
            "testStrategy": "Unit/component tests for NavBar rendering and keyboard nav; axe check on shell; routing tests using MemoryRouter."
          },
          {
            "id": 4,
            "title": "Theming system: dark/light tokens and contrast",
            "description": "Add theme provider with dark/light mode, CSS variables tokens, and accessible color contrast compliance.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "• Define design tokens as CSS variables (colors, spacing, typography) with data-theme attribute on html. \n• Implement ThemeContext or use CSS prefers-color-scheme with toggle persisted to localStorage. \n• Ensure minimum contrast ratios (4.5:1 body text); adjust palette accordingly. \n• Update AppShell to use tokens. \n• Run tests to satisfy TC008 and axe color contrast snapshots.",
            "status": "pending",
            "testStrategy": "Unit test for theme toggle state; visual snapshot tests for key components in both themes; axe contrast rules."
          },
          {
            "id": 5,
            "title": "i18n scaffold and localized strings",
            "description": "Set up i18next with language detector, resource bundles for en (and placeholder for others), and translation hooks across shell and pages.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "• Initialize i18next with react-i18next provider; create locales/en/common.json with all UI strings keys. \n• Wire t() into AppShell, page titles, buttons, forms, empty states, and validation messages. \n• Add language switcher in Settings page (scaffold). \n• Run tests to satisfy TC010.",
            "status": "pending",
            "testStrategy": "Unit tests rendering strings via keys; snapshot comparing translated text; ensure fallback works when key missing."
          },
          {
            "id": 6,
            "title": "API client layer and state slices for campaigns and sessions",
            "description": "Implement API client with fetch wrappers, error handling, and RTK Query or Zustand selectors for campaigns and sessions endpoints.",
            "dependencies": [
              "4.1",
              "4.2"
            ],
            "details": "• Create api/base with fetchJson, error normalization, retry policy for idempotent GETs. \n• Define types: Campaign, CampaignInput, Session, SessionJoinPayload. \n• Implement endpoints: /campaigns (GET list, POST create), /campaigns/:id (GET, PUT), /campaigns/:id/clone (POST), /campaigns/:id/archive (POST or PATCH), /sessions (GET), /sessions/:id/join (POST). \n• If using RTK Query: createApi with endpoints and cache tags; otherwise build Zustand store with async actions and status flags. \n• Integrate MSW handlers mirroring server routes for tests and dev. \n• Run tests and ensure service hooks/stores are testable.",
            "status": "pending",
            "testStrategy": "Unit tests for API functions with MSW mocking: happy path and error cases; ensure correct payloads and state updates."
          },
          {
            "id": 7,
            "title": "Campaigns page: list with accessible actions and isolation indicators",
            "description": "Build Campaigns list UI: fetch and render campaigns, show per-campaign isolation indicator, and provide actions (create, clone, archive) with confirmation modals.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.6"
            ],
            "details": "• Implement CampaignList component: table or list with columns Name, Updated, Status, Isolation badge (e.g., shield icon with aria-label including campaign ID), Actions menu. \n• Keyboard-accessible action buttons; proper aria-labels. \n• Empty state with Create button. \n• Wire to API state for loading/error/empty. \n• Ensure isolation indicator visible and testable (data-testid). \n• Run tests to satisfy parts of TC003 and TC009.",
            "status": "pending",
            "testStrategy": "Component tests rendering list from MSW; axe checks; verify isolation badge content; snapshot in dark/light."
          },
          {
            "id": 8,
            "title": "Campaign create/clone/archive flows",
            "description": "Implement modal or page for creating campaigns, clone flow from selected campaign, and archive action with confirmation and optimistic updates.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.6",
              "4.7"
            ],
            "details": "• Create CampaignForm with fields: name (required), description (optional), provider preset selection (optional). \n• Create route /campaigns/new with form validation and submit to POST /campaigns. \n• Implement Clone action: opens dialog prefilled from source; POST /campaigns/:id/clone; navigate to detail or back to list. \n• Implement Archive action: confirmation dialog; POST/PATCH archive; show archived status and hide from default view if needed. \n• Toast notifications for success/error via ARIA live region. \n• Run tests to make remaining TC003 pass (unit form validation + Playwright create→clone→archive).",
            "status": "pending",
            "testStrategy": "RTL tests for validation errors; integration tests for full flow; axe on dialogs."
          },
          {
            "id": 9,
            "title": "Sessions lobby: list and join",
            "description": "Create Sessions page that lists active sessions per campaign context and supports joining a session with proper routing and state.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.6"
            ],
            "details": "• Implement SessionsList fetching /sessions with campaign filter (if applicable). \n• Display session name, participants, status; keyboard navigable list. \n• Join button triggers POST /sessions/:id/join, then navigate to /sessions/:id (basic lobby placeholder). \n• Handle errors and loading states with ARIA live. \n• Run tests to satisfy TC004.",
            "status": "pending",
            "testStrategy": "Component tests with MSW: list and join; Playwright test navigating and verifying lobby route; axe checks."
          },
          {
            "id": 10,
            "title": "Settings view: provider configuration and preferences",
            "description": "Implement Settings page for provider selections and user preferences including theme and language.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.4",
              "4.5"
            ],
            "details": "• Sections: Providers (placeholder controls), Appearance (theme toggle), Language (i18n switch). \n• Persist selections to localStorage or state store; reflect changes immediately. \n• Ensure controls accessible with labels and descriptions. \n• Run tests to validate persistence and UI updates (TC005, TC008, TC010).",
            "status": "pending",
            "testStrategy": "Unit tests for persistence and immediate application; axe scan on Settings."
          },
          {
            "id": 11,
            "title": "Assets viewer: images list with caching indicators",
            "description": "Create Assets page to browse images with basic client-side caching indicators and lazy loading.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "• Implement grid/list of images from mock endpoint; use IntersectionObserver to lazy load. \n• Show cache state badge (e.g., from a simple in-memory or IndexedDB cache) and loading skeletons. \n• Keyboard navigation and focus management for thumbnails; alt text from metadata. \n• Run tests to satisfy TC006 and accessibility.",
            "status": "pending",
            "testStrategy": "Component tests verifying cache hits after second load; Playwright scroll/lazy-load; axe scan."
          },
          {
            "id": 12,
            "title": "Accessibility pass and keyboard navigation enhancements",
            "description": "Ensure WCAG-focused fixes across pages: roles, labels, focus traps in dialogs, skip links, and tab order.",
            "dependencies": [
              "4.1",
              "4.3",
              "4.7",
              "4.8",
              "4.9",
              "4.10",
              "4.11"
            ],
            "details": "• Validate landmarks and headings hierarchy. \n• Ensure dialog traps and escape to close; ARIA labels for all interactive elements. \n• Improve tab order and visible focus states. \n• Re-run axe on all pages and fix violations. \n• Run tests to satisfy TC007 comprehensively.",
            "status": "pending",
            "testStrategy": "Automated axe tests + manual keyboard-only walkthroughs; snapshots after fixes."
          },
          {
            "id": 13,
            "title": "Isolation indicator consistency and campaign context propagation",
            "description": "Standardize how campaign isolation indicators are displayed and ensure campaign_id context is propagated to Sessions and Assets views.",
            "dependencies": [
              "4.1",
              "4.6",
              "4.7",
              "4.9",
              "4.11"
            ],
            "details": "• Create CampaignContext provider carrying current campaign_id when navigating from Campaigns. \n• Ensure Sessions and Assets read campaign_id and reflect isolation badge and scoping hints. \n• Add breadcrumb with campaign label and isolation icon. \n• Run tests to reaffirm TC009 across pages.",
            "status": "pending",
            "testStrategy": "Component/integration tests verifying context propagation and indicator presence on child routes."
          },
          {
            "id": 14,
            "title": "Error boundaries and loading states",
            "description": "Add error boundaries around route segments and graceful loading skeletons for data fetches.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.6"
            ],
            "details": "• Implement ErrorBoundary components per route with retry buttons and accessible error messages. \n• Add Suspense-like loading placeholders/skeletons for lists and forms. \n• Wire API errors to user-friendly toasts and ARIA live regions. \n• Update tests expecting stable error handling.",
            "status": "pending",
            "testStrategy": "Unit tests for ErrorBoundary catching thrown errors; component tests for retry behavior; axe checks for alerts."
          },
          {
            "id": 15,
            "title": "Snapshots and visual regression for key components",
            "description": "Add snapshot tests for NavBar, CampaignList, CampaignForm, SessionsList in both themes and locale.",
            "dependencies": [
              "4.1",
              "4.4",
              "4.5",
              "4.7",
              "4.8",
              "4.9"
            ],
            "details": "• Create deterministic renders with mocked dates and data. \n• Generate snapshots per theme (light/dark) and locale (en). \n• Integrate into CI and gate on changes. \n• Ensure no flakiness.",
            "status": "pending",
            "testStrategy": "Vitest snapshot tests; optional Playwright visual diffs for pages."
          },
          {
            "id": 16,
            "title": "Finalize Playwright E2E flows for campaigns and sessions",
            "description": "Harden E2E scenarios for create/clone/archive and join session; add retries and network idle waits with MSW to reduce flakiness.",
            "dependencies": [
              "4.1",
              "4.7",
              "4.8",
              "4.9"
            ],
            "details": "• Write comprehensive specs: \n  - Campaigns: create new, clone, archive; verify list updates and isolation badges (TC003, TC009). \n  - Sessions: join and navigate to lobby; verify breadcrumb and context (TC004). \n• Add axe scans within flows to validate TC007. \n• Tag tests with TC IDs in titles.",
            "status": "pending",
            "testStrategy": "Playwright headed and headless runs; CI parallelism; record traces on failure."
          },
          {
            "id": 17,
            "title": "Documentation and developer experience polish",
            "description": "Provide README instructions, scripts, and Storybook (optional) for components; ensure contributors can run tests and develop efficiently.",
            "dependencies": [
              "4.2",
              "4.3",
              "4.6",
              "4.7",
              "4.8",
              "4.9",
              "4.10",
              "4.11",
              "4.12",
              "4.16"
            ],
            "details": "• Update README with setup, scripts, environment, and testing instructions. \n• Add component stories for key UI pieces with accessibility notes. \n• Provide example .env and MSW handlers docs. \n• Ensure pre-commit hooks for lint/test run.",
            "status": "pending",
            "testStrategy": "Manual validation following README; ensure newcomer can clone, install, run tests, and open app."
          }
        ]
      },
      {
        "id": 5,
        "title": "Provider Adapter Framework (LLM/STT/TTS/Image/Video/Embeddings)",
        "description": "Design provider-agnostic adapter interfaces selectable at runtime, with registry and config UI.",
        "details": "- Define interfaces in shared: LLMAdapter, STTAdapter, TTSAdapter, ImageGenAdapter, VideoGenAdapter (flag), EmbeddingsAdapter\n- Adapter capabilities describe models, cost, token limits, streaming support\n- Registry loads adapters via config; hot-switch per campaign/session\n- Initial implementations (MVP):\n  - LLM: OpenAI-compatible, local Ollama; STT: Vosk/Whisper local; TTS: Coqui XTTS or system; Image: Stable Diffusion (Automatic1111 or ComfyUI HTTP); Embeddings: text-embedding via local model\n  - Video placeholder adapter disabled by flag\n- A/B harness scaffold: route % traffic or paired eval; capture latency/tokens to llm_messages",
        "testStrategy": "- Unit tests ensure each adapter conforms to interface and error handling\n- TC011–TC013 partial: conformance checks and metrics capture\n- Config UI allows switching providers; persistence in settings without storing raw keys",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and unit/integration tests (TC011–TC013, UI config switching)",
            "description": "Before implementation, author test suites that define core acceptance criteria for the provider-agnostic adapter framework, registry selection, runtime hot-switching, capability metadata, metrics capture, and config UI switching. Include at least: unit tests for each adapter interface conformance and error handling, integration tests for registry loading and hot-switch per campaign/session, and a UI test for provider switching persistence without storing raw API keys.",
            "dependencies": [],
            "details": "Create test plan mapping: TC011 – adapter conformance and capability reporting; TC012 – metrics capture (latency/tokens) into llm_messages; TC013 – runtime switching via registry/config. Add a UI test case for switching providers and persisting selection. Set up test scaffolding in repo: - shared/tests/adapters/*.spec.ts for interface conformance. - services/registry/*.spec.ts for registry resolution and hot-switch. - db/tests/llm_messages_metrics.spec.ts for metrics capture. - webapp/e2e/config-provider-switch.spec.ts for UI switching. Stub provider mocks for: OpenAI-compatible LLM, Ollama LLM, Whisper local STT, Vosk STT, Coqui XTTS TTS, system TTS, Stable Diffusion (A1111/ComfyUI HTTP), local embeddings. Define fixtures for campaign/session contexts. Define redaction expectations for secrets. Do not implement framework yet; tests should initially fail.",
            "status": "pending",
            "testStrategy": "Use Jest/Vitest for unit/integration, Playwright/Cypress for UI. Create mocks for network calls. Seed sqlite/test DB for llm_messages. Verify: - Each adapter implements required methods and capability descriptors. - Consistent error mapping across adapters. - Registry loads adapters from config and supports per-campaign and per-session overrides. - Hot-switching does not require process restart. - A/B harness routes by percentage and paired eval mode. - Metrics recorded with latency and token counts. - Config UI switching persists provider keys via secrets manager reference, not raw key."
          },
          {
            "id": 2,
            "title": "Define shared adapter interfaces and capability descriptors",
            "description": "Implement TypeScript interfaces in shared module: LLMAdapter, STTAdapter, TTSAdapter, ImageGenAdapter, VideoGenAdapter (gated by feature flag), EmbeddingsAdapter. Include standardized request/response shapes, streaming support, and capability descriptors for models, token/context limits, cost, and features.",
            "dependencies": [
              "5.1"
            ],
            "details": "In packages/shared/adapters/: define base types. Common: AdapterId, ProviderName, Capability { models: string[], cost: { inputPer1K?: number; outputPer1K?: number; unit?: 'tokens'|'sec'|'image' }, maxTokens?: number, contextWindow?: number, streaming?: boolean, languages?: string[], notes?: string }. Add result/error types and standardized error codes (AdapterErrorCode: 'RATE_LIMIT'|'AUTH'|'UNAVAILABLE'|'TIMEOUT'|'VALIDATION'|'UNKNOWN'). - LLMAdapter: methods: chat(options: { messages: ChatMessage[]; model?: string; temperature?: number; maxTokens?: number; stream?: boolean; tools?: ToolDef[] }): Promise<LLMResult> | AsyncIterable<LLMDelta>; embed(texts: string[]): Promise<number[][]> optional? keep separate in EmbeddingsAdapter per spec. - STTAdapter: transcribe(input: AudioInput, options?): Promise<STTResult>; supports streaming? add streamTranscribe(inputStream, options?): AsyncIterable<STTDelta>. - TTSAdapter: synthesize(input: { text: string; voiceId?: string; rate?: number; volume?: number; format?: 'wav'|'mp3' }, options?): Promise<TTSResult>; streamSynthesize? AsyncIterable<AudioChunk & Timestamps?>. - ImageGenAdapter: generate(input: { prompt: string; negativePrompt?: string; width?: number; height?: number; style?: Record<string, any>; seed?: number }, options?): Promise<ImageResult>; getStatus?(id): Promise<ImageStatus>. - VideoGenAdapter: behind feature flag; define interface similar to Image with disabled default implementation. - EmbeddingsAdapter: embed(texts: string[], options?): Promise<{ vectors: number[][]; model: string }>. Export Capability descriptors in each adapter via getCapabilities(): Promise<Capability>. Include type guards and zod schemas for validation.",
            "status": "pending",
            "testStrategy": "Run tests from 5.1. Ensure type conformance tests compile and fail until implementations; then update tests to import interfaces and validate shape using runtime zod schemas. Verify capability schemas validation and error code enums."
          },
          {
            "id": 3,
            "title": "Implement adapter error normalization and metrics hooks",
            "description": "Create shared error normalization utility and metrics hook contracts used by all adapters to map provider-specific errors to standardized codes and to capture latency, token counts, and payload sizes.",
            "dependencies": [
              "5.1",
              "5.2"
            ],
            "details": "Add packages/shared/adapters/errors.ts with AdapterError extends Error { code: AdapterErrorCode; provider?: string; raw?: unknown; httpStatus?: number }. Provide normalizeError(provider, rawError): AdapterError with mappings for common HTTP codes/timeouts. Add metrics interface: AdapterMetricsSink { onRequestStart(ctx), onRequestEnd(ctx, metrics), onRequestError(ctx, err) }. Define Metrics types: { latencyMs, inputTokens?, outputTokens?, bytesIn?, bytesOut?, model }. Implement default no-op sink and allow dependency injection via adapter constructors. Provide helper timers and token estimation hooks for OpenAI/Ollama models using encoding libs when exact not available.",
            "status": "pending",
            "testStrategy": "Unit tests assert mapping of simulated provider errors to AdapterError codes (TC011/TC012). Verify metrics hooks invoked and capture latency; assert token estimation fallback triggers when providers don't return counts."
          },
          {
            "id": 4,
            "title": "Build Adapter Registry with runtime selection and hot-switching",
            "description": "Implement a registry that loads adapter instances from configuration, supports per-campaign and per-session overrides, and allows hot-switching without restart.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3"
            ],
            "details": "Create packages/core/registry/AdapterRegistry.ts. Expose: register(type: 'llm'|'stt'|'tts'|'image'|'video'|'embeddings', id: string, factory: (cfg, deps)=>Adapter); get(type, context: { campaignId?: string; sessionId?: string }): Adapter; list(type): AdapterInfo[]. Load config from settings service (Task 2/4 deps) with schema: providers: { llm: { default: 'openai', perCampaign: { [id]: 'ollama' }, perSession: { [id]: 'openai' } }, ... } and providerConfigs: { openai: { apiKeyRef: 'secret://openai' , baseUrl? }, ollama: { host }, ... }. Implement watcher on config changes to recreate instances lazily. Support hot-switch by context: registry resolves provider id by session override > campaign override > default. Ensure secrets resolved via secrets manager refs (no raw keys kept).",
            "status": "pending",
            "testStrategy": "Integration tests from 5.1 should now pass for registry resolution and hot-switch (TC013). Add additional tests for config change triggering provider replacement between calls without process restart."
          },
          {
            "id": 5,
            "title": "MVP LLM adapters: OpenAI-compatible and local Ollama",
            "description": "Implement two LLMAdapter providers: OpenAI-compatible (chat/completions APIs) and Ollama local. Support streaming and token metrics capture.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "Create packages/providers/llm/openaiAdapter.ts supporting baseUrl override and model listing via /models when available. Streaming via SSE chunks -> AsyncIterable<LLMDelta>. Capture input/output tokens from response if present; else estimate. Implement tool/function call mapping. Create packages/providers/llm/ollamaAdapter.ts using ollama HTTP API (/api/chat, /api/generate) with stream support; map responses to LLMResult/LLMDelta. Provide getCapabilities() with models, contextWindow if known, streaming true, cost unknown or zero for local. Use metrics sink injection and error normalization.",
            "status": "pending",
            "testStrategy": "Unit tests per adapter: conformance, streaming emits deltas, errors normalized (TC011). Integration: registry returns correct adapter by config, A/B routing harness scaffolding can call both and capture metrics (TC012/TC013)."
          },
          {
            "id": 6,
            "title": "MVP STT adapters: Whisper local and Vosk",
            "description": "Implement STTAdapter providers for local Whisper and Vosk engines, with optional streaming if supported, unified timestamps output when available.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "Implement providers/stt/whisperLocalAdapter.ts wrapping local whisper CLI/server; providers/stt/voskAdapter.ts wrapping Vosk model via node binding or HTTP microservice. Normalize outputs to STTResult { text, words?: [{ start, end, word }], language? }. Support streamTranscribe when engine supports partials. Integrate error normalization and metrics (latency).",
            "status": "pending",
            "testStrategy": "Unit tests: adapter conformance, error paths, timestamp presence/absence handled. Integration: registry selection and switching. Performance smoke test optional."
          },
          {
            "id": 7,
            "title": "MVP TTS adapters: Coqui XTTS and System TTS",
            "description": "Implement TTSAdapter providers for Coqui XTTS (local/server) and a basic System TTS fallback. Provide optional timestamp/captions when available.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "providers/tts/coquiXttsAdapter.ts: call local XTTS server; support voiceId; streamSynthesize if API supports chunks; map viseme/phoneme timestamps if available. providers/tts/systemAdapter.ts: use OS TTS or simple offline engine; no timestamps by default. Both emit audio format metadata and integrate metrics.",
            "status": "pending",
            "testStrategy": "Unit: conformance, voice params mapping, error normalization. Integration: registry switching; verify absence of timestamps triggers documented fallback behavior."
          },
          {
            "id": 8,
            "title": "MVP Image generation adapters: Stable Diffusion (A1111 and ComfyUI HTTP)",
            "description": "Implement ImageGenAdapter providers for Stable Diffusion via Automatic1111 and ComfyUI HTTP APIs, with job status polling and seed/style controls.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "providers/image/sdA1111Adapter.ts calling /sdapi/v1/txt2img/img2img; handle negative prompts, width/height, seed, steps. providers/image/comfyUiAdapter.ts building graph payload; submit, poll status, retrieve image. Normalize outputs to ImageResult { id, images: [Buffer|assetRef], seed?, metadata }. Add getStatus(id) for long jobs. Integrate metrics and error normalization.",
            "status": "pending",
            "testStrategy": "Unit: payload building and parameter mapping; error cases. Integration: registry selection; ensure long-running job status works. These adapters will be used by Task 8 tests (TC003)."
          },
          {
            "id": 9,
            "title": "MVP Embeddings adapter: local model",
            "description": "Implement EmbeddingsAdapter for a local text-embedding model (e.g., sentence-transformers or llama.cpp embeddings), returning float vectors and model name.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "providers/embeddings/localAdapter.ts: wrap local service or on-device library; batch inputs; return consistent vector length; include model id in result. Add capability descriptor with cost=0 and supported languages.",
            "status": "pending",
            "testStrategy": "Unit: vector length consistency, batching, error normalization. Integration: registry selection."
          },
          {
            "id": 10,
            "title": "Feature-flagged VideoGenAdapter placeholder",
            "description": "Create a disabled-by-default VideoGenAdapter placeholder behind a feature flag, returning a clear NotEnabled error on invocation.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "Define FeatureFlag 'video.gen.enabled'. Implement providers/video/placeholderAdapter.ts that implements interface but throws AdapterError{ code:'UNAVAILABLE', message:'Video generation disabled by feature flag' }. Register only when flag true; otherwise registry returns placeholder for clarity.",
            "status": "pending",
            "testStrategy": "Unit: when flag off, calls throw UNAVAILABLE; when flag on with placeholder, ensure methods exist. Registry test: type 'video' returns placeholder."
          },
          {
            "id": 11,
            "title": "A/B harness scaffold and paired evaluation",
            "description": "Implement routing harness to send a percentage of traffic to alternate provider or perform paired evaluations, capturing metrics and persisting to llm_messages.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4",
              "5.5"
            ],
            "details": "Create core/ab/AbHarness.ts supporting modes: percentageSplit{ controlId, variantId, percent }, pairedEval{ aId, bId }. For percentage, randomly route per request using stable hash of session to meet target percent. For paired, call both adapters, store both outputs with linkage id. Integrate metrics sink to write latency/token counts into db.llm_messages with columns: request_id, provider_id, latency_ms, input_tokens, output_tokens, mode, paired_group_id. Provide API to configure per campaign/session.",
            "status": "pending",
            "testStrategy": "Integration tests (TC012/TC013): verify distribution within tolerance over N requests; paired eval stores two records linked by group id; metrics captured. Property tests for stable routing by session hash."
          },
          {
            "id": 12,
            "title": "Config UI for provider selection and secret references",
            "description": "Build a settings UI to switch providers per capability type (LLM/STT/TTS/Image/Embeddings), with per-campaign and per-session overrides. Persist selections using secret references instead of raw keys.",
            "dependencies": [
              "5.1",
              "5.4"
            ],
            "details": "In webapp: Add Settings > Providers page. Components: ProviderTypeSelector, ProviderList (from registry list()), ProviderConfigForm (fields depend on provider schema), OverrideScopes (global/campaign/session). Persist via settings API: provider selection and providerConfigs with secretRef fields (secret://...). Implement validation UI to test connection without revealing secrets. Ensure hot-switch reflected immediately by querying registry on apply.",
            "status": "pending",
            "testStrategy": "E2E UI test from 5.1 validates that switching providers updates active adapter and persists across reload; secrets are not exposed in DOM or network logs. Integration test asserts registry picks overrides after UI save."
          },
          {
            "id": 13,
            "title": "llm_messages metrics persistence and schema updates",
            "description": "Extend database schema and data-access layer to store latency and token metrics for LLM calls; provide generic metrics write for other adapters where applicable.",
            "dependencies": [
              "5.1",
              "5.3"
            ],
            "details": "Migrate db: alter llm_messages add columns: provider_id, model, latency_ms, input_tokens, output_tokens, bytes_in, bytes_out, mode, paired_group_id, created_at. Add DAO functions logLLMCallMetrics(ctx, data). Wire metrics sink default implementation to call DAO when type='llm'. Prepare views or queries for analytics.",
            "status": "pending",
            "testStrategy": "Unit tests (TC012): inserting and reading metrics; migration reversible; DAO validates constraints. Integration: verify entries appear after LLM calls via adapters and A/B harness."
          },
          {
            "id": 14,
            "title": "Security: secrets handling and redaction",
            "description": "Implement secrets manager references and ensure no raw API keys are persisted in settings, logs, or metrics. Add redaction utilities.",
            "dependencies": [
              "5.1",
              "5.4",
              "5.12"
            ],
            "details": "Create secrets module to resolve secret:// refs at runtime from OS keyring/env/VAULT. Inject resolved keys into adapter factories only in-memory. Implement redact(obj) utility to filter keys matching patterns (apiKey, token, Authorization) from logs and errors. Add interceptors to strip secrets from error.raw. Update config UI to only store secretRef strings.",
            "status": "pending",
            "testStrategy": "Unit: secrets resolution mock; verify no raw secret stored in settings DB; log snapshot tests confirm redaction. E2E: change secret, confirm adapters continue to work after refresh."
          },
          {
            "id": 15,
            "title": "Documentation and developer guide",
            "description": "Document adapter interfaces, registry usage, adding new providers, error codes, metrics, A/B harness, and config UI operations.",
            "dependencies": [
              "5.2",
              "5.4",
              "5.5",
              "5.6",
              "5.7",
              "5.8",
              "5.9",
              "5.10",
              "5.11",
              "5.12",
              "5.13",
              "5.14"
            ],
            "details": "Create docs in /docs/adapters/: overview, architecture diagrams, code samples, step-by-step guide to build a new adapter, capability descriptor reference, registry config examples, secrets handling, and troubleshooting. Add ADR for choosing Adapter pattern and registry design.",
            "status": "pending",
            "testStrategy": "Doc linting, example code snippets compiled in CI. Optional link checks."
          }
        ]
      },
      {
        "id": 6,
        "title": "Voice Capture, VAD, STT Pipeline with Captions and Diarization",
        "description": "Implement client voice capture with VAD, push-to-talk fallback, streaming STT, captions rendering, and speaker diarization.",
        "details": "- Web Audio API + MediaStream; VAD via webrtcvad-wasm; PTT UI toggle\n- Stream opus/pcm chunks over WebSocket to server; server forwards to STT adapter\n- Diarization: simple client-side speaker tagging by connection id; optional pyannote server bridge later\n- Captions: render per speaker with timestamps; adjustable rate/volume controls; accessibility semantics\n- Latency target: STT < 800 ms median; use partial hypotheses streaming",
        "testStrategy": "- TC001: join/voice/action: verify transcript and captions visible in multi-client session\n- Measure end-to-end latency with synthetic audio and assert median <800ms locally\n- Packet loss simulation to ensure graceful degradation",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for voice→captions pipeline (unit + integration)",
            "description": "Write automated tests that codify the core acceptance criteria: capture mic audio, VAD-driven start/stop with push-to-talk fallback, stream to STT over WebSocket, receive partial/final transcripts, render captions per speaker with timestamps, and basic diarization tags. Include latency and packet loss scenarios.",
            "dependencies": [],
            "details": "Create a test plan and scaffolding before implementation.\n- Unit tests:\n  - TC001-U1: VAD state machine transitions (silence→speech→silence) with synthetic PCM frames.\n  - TC001-U2: Audio chunker frames at configured size (e.g., 20 ms or 100 ms) and encodes PCM/Opus correctly.\n  - TC001-U3: STT adapter client merges partial hypotheses into stable final transcripts.\n  - TC001-U4: Caption formatting includes timestamps and speaker tag.\n  - TC001-U5: PTT toggle enforces capture-on-hold behavior and bypasses VAD.\n- Integration/UI tests:\n  - TC001-I1 (maps to TC001): Two simulated clients join a session via WS gateway, stream synthetic audio, verify captions appear for both with correct speaker tags and ordering.\n  - TC001-I2: Latency measurement harness injects prerecorded audio and asserts median end-to-end STT latency under 800 ms locally.\n  - TC001-I3: Packet loss simulator drops 5–10% WS frames; verify graceful degradation (no crash, captions may have gaps but UI stable).\nArtifacts: test utilities to synthesize sinewave/speech-like PCM; a mock STT server emitting partial/final hypotheses; DOM testing for captions region with ARIA roles.",
            "status": "pending",
            "testStrategy": "Implement with Jest/Vitest + Playwright. Provide a WS mock server, a fake STT adapter, and a clock/HRTime probe for latency. Ensure tests run headless and record metrics."
          },
          {
            "id": 2,
            "title": "Audio capture module with Web Audio API and permissions",
            "description": "Implement microphone capture using MediaDevices.getUserMedia and Web Audio API, exposing a readable stream of mono PCM frames with configurable sample rate and frame size.",
            "dependencies": [
              "6.1"
            ],
            "details": "Build an AudioCapture class:\n- Request mic: navigator.mediaDevices.getUserMedia({ audio: { channelCount: 1, echoCancellation: false, noiseSuppression: false, autoGainControl: false, sampleRate: 16000 } }).\n- Use AudioWorklet (preferred) or ScriptProcessor fallback to pull Float32 audio.\n- Resample to 16 kHz mono if necessary (polyphase or linear with anti-aliasing).\n- Convert Float32 [-1,1] to 16-bit PCM Int16Array frames of N ms (start with 20 ms frames; allow config up to 100 ms for efficiency/latency tradeoff).\n- Expose events: onStart, onStop, onFrame(Int16Array, timestamp).\n- Handle permission errors and device changes; provide start/stop/dispose methods.\n- Disable AGC/noise suppression per provider best practices.",
            "status": "pending",
            "testStrategy": "Run tests from 6.1; add unit tests to validate resampler correctness (RMS/energy preserved within tolerance), frame sizing, and error handling. Mock getUserMedia and AudioWorklet."
          },
          {
            "id": 3,
            "title": "Voice Activity Detection (VAD) integration with webrtcvad-wasm",
            "description": "Wire up VAD to gate audio frames into speech segments with configurable aggressiveness and hangover time, emitting start/stop speech events.",
            "dependencies": [
              "6.1",
              "6.2"
            ],
            "details": "Implement VADController:\n- Load webrtcvad-wasm module; initialize with mode (0–3) aggressiveness.\n- Feed 10/20/30 ms 16 kHz PCM frames as required by WebRTC VAD.\n- Maintain ring buffer to smooth decisions; parameters: pre-roll (e.g., 200 ms), hangover (e.g., 300 ms).\n- Emit events: onSpeechStart, onSpeechEnd, onSpeechFrame.\n- Provide thresholds to avoid choppy toggling; expose metrics (speech ratio, decisions/sec).",
            "status": "pending",
            "testStrategy": "Unit tests (from 6.1 TC001-U1) with synthetic voiced/unvoiced signals; verify transitions and pre-roll/hangover behavior. Property tests to ensure decisions deterministic."
          },
          {
            "id": 4,
            "title": "Push-to-talk (PTT) UI and control flow",
            "description": "Create a UI toggle/button to enable push-to-talk, bypassing VAD when pressed/held and muting capture when released, with full keyboard accessibility.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3"
            ],
            "details": "Implement a PTTButton component:\n- States: idle, pressed, locked (toggle mode), disabled.\n- Keyboard: Space/Enter to press/hold; toggle via T; ARIA role='button', aria-pressed.\n- Integrate with capture pipeline: when PTT active, forward frames regardless of VAD; when inactive, rely on VAD.\n- Visual feedback (recording indicator) and tooltip. Persist user preference for VAD/PTT mode.\n- Debounce to avoid flapping on quick taps.",
            "status": "pending",
            "testStrategy": "UI tests: simulate keyboard/mouse; verify state changes and that frames are forwarded while held. Map to TC001-U5 and TC001-I1 checks for accessibility attributes."
          },
          {
            "id": 5,
            "title": "Opus/PCM framing and WebSocket client streaming",
            "description": "Implement audio chunker and WS client to send PCM or Opus-encoded frames to server with metadata for session and speaker.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3",
              "6.4"
            ],
            "details": "Build StreamSender:\n- Config: encoding=PCM16 or Opus; frameDurationMs (20/40/60/100); maxBufferedFrames; reconnect/backoff.\n- For Opus, integrate encoder (e.g., opus-recorder/opus-media-recorder or wasm opus) at 16 kHz mono, bitrate ~16–24 kbps, complexity tuned for latency.\n- Package messages: { type: 'audio-chunk', ts, seq, encoding, sampleRate, speakerId, sessionId, channelId, payload }.\n- Handle backpressure: if WS bufferedAmount exceeds threshold, drop or downsample per policy and mark with loss hints.\n- Heartbeat pings and resume with seq continuity; include reconnect token.\n- Security: do not include PII; use session token from Task 3 auth.",
            "status": "pending",
            "testStrategy": "Unit tests: encode/decode sanity, framing correctness, seq monotonicity, backpressure behavior. Integration: echo server validates schema and ordering; packet loss injection for TC001-I3."
          },
          {
            "id": 6,
            "title": "STT adapter client with partial/final hypothesis handling",
            "description": "Implement client-side STT stream handler that receives partial and final transcripts from the server and assembles utterances with timestamps.",
            "dependencies": [
              "6.1",
              "6.5"
            ],
            "details": "STTClient:\n- WS message types: stt-partial, stt-final, stt-error; include seq, speakerId, startTs, endTs, text, confidence.\n- Maintain per-speaker utterance buffer: update partial text in place; finalize on stt-final.\n- Emit events: onPartial(utterance), onFinal(utterance), onError.\n- Track timings for latency: first-partial latency, final latency.\n- Handle out-of-order messages via seq; merge corrections.\n- Configurable provider hints (languageCode, punctuation, interimResults=true).",
            "status": "pending",
            "testStrategy": "Unit tests (TC001-U3): merging logic, corrections, and event emission. Integration: with mock STT server producing partials/finals; record latency for TC001-I2."
          },
          {
            "id": 7,
            "title": "Client-side diarization tagging by connection/session",
            "description": "Assign a stable speakerId per client connection and attach it to audio and caption events; prepare hook for future server-side diarization bridge.",
            "dependencies": [
              "6.1",
              "6.5"
            ],
            "details": "Implement SpeakerTagger:\n- Derive speakerId from WS connection id or assigned session user id from gateway.\n- Provide map of speakerId→displayName/color; persist locally.\n- Attach speakerId to outgoing audio chunks and consume on incoming captions.\n- Define interface for optional server diarization (pyannote) later: accept speaker change events and remap segments post-hoc.",
            "status": "pending",
            "testStrategy": "Unit: verify stable speakerId across reconnects using reconnect token; ensure mapping applied to messages. Integration (TC001-I1): two clients produce distinct speaker tags."
          },
          {
            "id": 8,
            "title": "Captions rendering component with accessibility semantics",
            "description": "Render streaming captions per speaker with timestamps, interim updates, and ARIA-compliant semantics and controls for rate/volume.",
            "dependencies": [
              "6.1",
              "6.6",
              "6.7"
            ],
            "details": "Implement CaptionsPanel:\n- Regions per speaker with color tokens; show partial text updating in place; finalize into scrollback with start–end timestamps.\n- Keyboard navigable; ARIA live region='polite' for partials; role='log' for history.\n- Controls: caption visibility toggle, adjustable TTS speech rate/volume sliders tied to settings; WCAG AA contrast tokens.\n- Virtualized list for performance; time formatting; copy/export transcript.",
            "status": "pending",
            "testStrategy": "UI tests: verify live updates, finalization, keyboard focus order, ARIA roles. Integration (TC001-I1): captions visible in multi-client session and per-speaker segregation."
          },
          {
            "id": 9,
            "title": "Latency optimization and measurement hooks",
            "description": "Implement measurement probes and tune frame sizes, buffering, and encoder settings to achieve <800 ms median STT partial latency locally.",
            "dependencies": [
              "6.1",
              "6.5",
              "6.6",
              "6.8"
            ],
            "details": "Add high-resolution timers around pipeline stages: capture→chunk→send→server→partial→render. Expose metrics to console/overlay. Tune defaults: 20–40 ms frame size, immediate send on frame, Nagle disabled, Opus lookahead minimized, interimResults enabled. Provide config to trade efficiency vs latency.",
            "status": "pending",
            "testStrategy": "Run TC001-I2: feed synthetic audio, record latencies, assert median under 800 ms. Regression test to fail if exceeded."
          },
          {
            "id": 10,
            "title": "Packet loss tolerance and reconnection handling",
            "description": "Ensure graceful behavior under dropped audio or STT messages with retries/backoff and UI resilience.",
            "dependencies": [
              "6.1",
              "6.5",
              "6.6",
              "6.8"
            ],
            "details": "Implement loss handling:\n- Audio chunks include seq; gaps are tolerated and flagged.\n- Partial timeout fallback: if partials stall, finalize best-effort segment.\n- Reconnect WS with exponential backoff; resubscribe to channels; restore speaker mapping.\n- UI shows subtle loss indicator but continues rendering.\n- Backpressure policy: drop oldest non-sent frames when buffer high.",
            "status": "pending",
            "testStrategy": "Execute TC001-I3 with 5–10% drop; verify no crashes, reconnect works, captions continue. Unit tests for backoff schedule and timeout finalization."
          },
          {
            "id": 11,
            "title": "Server gateway interop and schema validation",
            "description": "Validate integration with Realtime WebSocket Gateway schemas and message types, using shared zod schemas for strict validation.",
            "dependencies": [
              "6.1",
              "6.5"
            ],
            "details": "Import shared schema package; validate outbound audio-chunk and inbound stt-* messages. Ensure channel scoping (room/team/etc.) obeys membership. Include rate limiting hints and heartbeat compatibility. Map to Task 3 message types: voice-meta, caption, action as needed.",
            "status": "pending",
            "testStrategy": "Integration tests with gateway test harness (from Task 3): multi-client join/leave, audio routing metadata distribution per TC002 mapping, and schema conformance."
          },
          {
            "id": 12,
            "title": "Settings persistence and controls (rate/volume, caption toggle)",
            "description": "Persist user preferences for captions visibility, speech rate, and volume locally and apply on load.",
            "dependencies": [
              "6.1",
              "6.8"
            ],
            "details": "Implement SettingsStore (localStorage/indexedDB): keys for captionsEnabled, speechRate, speechVolume, PTT/VAD mode. Provide hooks/context to read/write. Ensure defaults sane and synced to UI controls.",
            "status": "pending",
            "testStrategy": "Unit/UI tests: change settings, reload app, confirm persistence and application. Axe checks for controls accessibility."
          },
          {
            "id": 13,
            "title": "Security, privacy, and consent prompts for recording",
            "description": "Add explicit user consent UI for recording and transmitting audio; ensure no PII in telemetry and secure handling of media streams.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.5"
            ],
            "details": "Consent modal/banner before first capture with clear language; store consent flag. Redact PII in logs; avoid storing raw audio locally. Use secure WS (wss) and session tokens. Provide quick mic mute control and indicator.",
            "status": "pending",
            "testStrategy": "UI tests: consent required before capture begins; verify logs contain no audio payloads or PII. Negative tests: decline consent prevents capture."
          },
          {
            "id": 14,
            "title": "Optional server-side diarization bridge hook (pyannote-ready)",
            "description": "Prepare client to accept server diarization segments and remap displayed speakers post-hoc without breaking UX.",
            "dependencies": [
              "6.1",
              "6.6",
              "6.7",
              "6.8"
            ],
            "details": "Define WS message type 'diarization-update' with segments [{start,end,speakerLabel,confidence}]. Implement reconciler to reassign captions in time ranges; maintain mapping and update colors/labels smoothly. Conflict resolution: client tag vs server diarization preference toggle.",
            "status": "pending",
            "testStrategy": "Integration test: feed diarization updates after initial captions; verify UI remaps segments and preserves ordering without flicker."
          },
          {
            "id": 15,
            "title": "End-to-end scenario tests and documentation",
            "description": "Finalize E2E tests covering common flows and document setup, configs, and troubleshooting for the pipeline.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3",
              "6.4",
              "6.5",
              "6.6",
              "6.7",
              "6.8",
              "6.9",
              "6.10",
              "6.11",
              "6.12",
              "6.13",
              "6.14"
            ],
            "details": "Add Playwright E2E covering: VAD-only session, PTT session, multi-client captions, reconnect scenario, settings persistence, and diarization updates. Write README with architecture diagram, configuration options (frame size, encoding), and performance tuning tips.",
            "status": "pending",
            "testStrategy": "Run full suite including TC001, latency goal, and packet loss. Ensure green before marking task complete."
          }
        ]
      },
      {
        "id": 7,
        "title": "TTS Synthesis per NPC with Controls",
        "description": "Add TTS playback per speaker/NPC with adjustable rate/volume and caption sync.",
        "details": "- TTS adapter streaming; audioWorklet playback; queue per channel\n- Voice identity map per NPC; cache synthesized clips by text+voice hash in cache\n- Controls: rate, volume, mute per channel; caption sync from TTS timestamps if available",
        "testStrategy": "- Unit: caching key correctness; fallbacks when timestamps unavailable\n- UX test: adjust rate/volume; ensure captions track\n- Performance: TTS <1.2s for ~150 chars median using local model settings",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for per-NPC TTS playback, controls, caching, and caption sync (TC001, TC002, TC005)",
            "description": "Author unit and integration/UI tests that define acceptance criteria for TTS playback per NPC channel with adjustable rate/volume/mute, queueing, caching by text+voice hash, and caption synchronization using timestamps or graceful fallback.",
            "dependencies": [],
            "details": "Implement test suites before any production code:\n- Unit tests:\n  - TC001: Cache key stability and correctness. Given same text and voice identity, expect cache hit; different text or voice → miss. Include Unicode and punctuation normalization cases.\n  - TC002: Channel queue behavior. Enqueue multiple utterances per NPC; ensure FIFO playback order and non-blocking behavior across different NPC channels.\n  - TC005: Caption mapping. Given TTS word/phoneme timestamps, verify caption segments align to ranges and produce correct text highlighting indices; when timestamps absent, verify fallback to timed chunks proportional to text length.\n  - Control application: Verify rate/volume/mute conversions map from UI model to adapter parameters; ensure mute overrides volume.\n  - Voice identity map: Ensure NPC->voice mapping persists and is read for synthesis; missing mapping falls back to default.\n  - Performance harness stub: Measure mocked adapter end-to-end promise resolution under 1.2s median for ~150 chars with local mock.\n- Integration/UI tests (Playwright):\n  - Render multi-NPC chat; trigger TTS for two NPCs concurrently; verify independent channel state and no cross-audio bleed; UI sliders for rate/volume update live; mute toggles silence while captions continue.\n  - Caption sync: During playback, verify active caption word/segment highlights track synthesized timestamps.\n  - Offline/latency tolerance: With adapter providing no timestamps, verify fallback captions progress smoothly.\n- Mocks/fakes:\n  - TTSAdapterFake supports: streaming chunks, optional timestamps, controllable latency, and emits per-chunk events.\n  - AudioWorkletMock/AudioContextMock to assert parameter changes and buffer scheduling.\n- Tag tests with TC labels and map to requirements. Establish coverage thresholds ≥80% for TTS module.\n- Define fixtures: sample texts (ASCII, Unicode/emoji, punctuation), voices, NPC IDs, campaign IDs.",
            "status": "pending",
            "testStrategy": "Run unit tests in Jest with fake timers for playback scheduling; use Playwright for UI scenarios with WebAudio and Worklet mocks. Add performance assertions with soft thresholds and artifacts on failure."
          },
          {
            "id": 2,
            "title": "Design TTS channel architecture and interfaces",
            "description": "Define core interfaces and data models for TTS channels per NPC, adapter abstraction, queue items, controls state, and caption events.",
            "dependencies": [
              "7.1"
            ],
            "details": "Create TypeScript interfaces:\n- TTSAdapter { synthesizeStream(text, voice, rate, volume): AsyncIterable<TTSChunk>; supportsTimestamps: boolean }\n- TTSChunk { audioBuffer: ArrayBuffer | Float32Array; timestamps?: WordTimestamp[]; isFinal: boolean }\n- WordTimestamp { startMs: number; endMs: number; text: string; charStart: number; charEnd: number }\n- NPCChannel { id: string; voiceId: string; queue: Utterance[]; state: 'idle'|'playing'|'paused'|'muted'; controls: { rate: number; volume: number; mute: boolean } }\n- Utterance { id: string; npcId: string; text: string; voiceId: string; hashKey: string; requestMeta: { createdAt: number } }\n- CaptionEvent { utteranceId: string; current: { startMs: number; endMs: number; text: string; index: number }; source: 'timestamps'|'fallback' }\nDefine service boundaries:\n- TTSService: manages NPC channels, enqueues utterances, resolves cache, calls adapter, emits playback and caption events.\n- AudioEngine: wraps AudioContext/AudioWorkletNode per channel, applies rate/volume/mute, schedules buffers.\n- Cache: clip store by (text+voice hash) mapping to decoded PCM and timestamps if present.\n- VoiceRegistry: NPC→voice mapping with default.\nEvents bus signature for UI subscription: onPlaybackStart, onPlaybackEnd, onCaptionUpdate, onControlChange.\nHashing: stable normalized key build: normalize text (NFC), collapse whitespaces, trim, lowercase optional flag, include voiceId and rate-independent; include locale if applicable.",
            "status": "pending",
            "testStrategy": "Validate interface types compile; add minimal smoke unit tests for hash builder and model invariants. Run tests from 7.1 and ensure compile passes."
          },
          {
            "id": 3,
            "title": "Implement voice identity map per NPC",
            "description": "Create a persistent mapping from NPC IDs to voice identities with defaults and overrides, including loading/saving.",
            "dependencies": [
              "7.1",
              "7.2"
            ],
            "details": "Build VoiceRegistry module:\n- API: getVoice(npcId): voiceId; setVoice(npcId, voiceId); getDefault(): voiceId; setDefault(voiceId).\n- Persistence: store in project settings or per-campaign config; namespace by campaign_id if available; provide migration-safe schema.\n- Validation: ensure voiceId exists in supported voices list from adapter; fallback to default on invalid.\n- Events: emit 'voiceChanged' for UI to refresh.\n- Tie into TTSService so enqueue uses VoiceRegistry.getVoice(npcId) unless explicit override provided.",
            "status": "pending",
            "testStrategy": "Unit tests: set/get, default fallback, invalid voiceId handling, campaign scoping. Run existing tests; ensure no regressions."
          },
          {
            "id": 4,
            "title": "Implement text+voice hash-based clip cache",
            "description": "Add an in-memory + on-disk cache keyed by stable hash of text and voice identity to reuse synthesized audio and timestamps.",
            "dependencies": [
              "7.1",
              "7.2"
            ],
            "details": "Cache module:\n- Key builder: hash = SHA-256(JSON.stringify({text: normalize(text), voiceId})) returning hex; ensure deterministic order.\n- Store: LRU in-memory (e.g., 128 entries) and persistent file cache per-campaign subdir; index mapping key→metadata (durationMs, hasTimestamps, createdAt, version).\n- Values: PCM data (Float32Array) or encoded (Opus/PCM WAV) plus optional timestamps.\n- API: get(key)→{audio, timestamps}?; put(key, value); has(key).\n- Serialization: use chunked file format or simple JSON+binary split; checksum for corruption.\n- Invalidate on version bump or voice change.\n- Thread-safety: guard concurrent puts; de-dupe concurrent inflight requests via promise memoization.",
            "status": "pending",
            "testStrategy": "Unit tests from TC001 validate key stability and hit/miss. Add tests for persistence roundtrip and invalidation. Run full suite; fix failing cases."
          },
          {
            "id": 5,
            "title": "Build per-NPC channel queue and dispatcher",
            "description": "Create TTSService to manage independent queues per NPC, ensuring FIFO playback within a channel and concurrency across channels.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.3",
              "7.4"
            ],
            "details": "Implement TTSService:\n- Data: Map<npcId, NPCChannel> with queue array and state.\n- API: enqueue(npcId, text, options?): returns utteranceId; clear(npcId); skipCurrent(npcId); pause/resume.\n- Dispatcher: one async loop per channel processes queue items; resolves from cache or synthesizes via adapter; emits events; ensures errors do not break loop.\n- Concurrency: channels run independently via separate tasks.\n- Backpressure: cap queue length per channel; drop or merge policy configurable.\n- Cancellation: abort controller per utterance; skip should stop current synthesis and playback gracefully.\n- Telemetry: timings for synthesis, cache hit ratio, latency.",
            "status": "pending",
            "testStrategy": "Unit tests from TC002 cover FIFO and independence; add tests for skip/pause/resume. Run tests; ensure deterministic with fake timers."
          },
          {
            "id": 6,
            "title": "Integrate streaming TTS adapter and fallback",
            "description": "Wire a streaming TTSAdapter that yields audio chunks and optional timestamps; include a no-timestamps fallback adapter for offline/local model.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.5"
            ],
            "details": "Adapter layer:\n- Define StreamingAdapter implementation using existing provider integration (or local model). It should respect rate and volume parameters where supported, else adjust in AudioEngine.\n- Provide feature flag for timestamps availability (supportsTimestamps).\n- Normalize timestamps to WordTimestamp[] aligned to original text; map phoneme/viseme if provider returns them.\n- Error handling: retries with jitter; surface structured errors to TTSService.\n- FallbackAdapter: returns audio without timestamps; set supportsTimestamps=false.\n- Ensure adapters are swappable via DI to support tests/mocks.",
            "status": "pending",
            "testStrategy": "Extend adapter unit tests with mocked provider responses. Ensure TC005 caption tests pass with both adapters. Run full suite."
          },
          {
            "id": 7,
            "title": "Implement AudioWorklet-based playback engine per channel",
            "description": "Create AudioEngine with an AudioContext and an AudioWorkletNode per NPC channel, supporting buffer scheduling, rate, volume, and mute.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.5"
            ],
            "details": "AudioEngine design:\n- One shared AudioContext; per-channel WorkletNode instance with parameters: gain (volume), playbackRate, mute flag.\n- Buffer queue: accept PCM Float32 buffers from TTSService; schedule via ring buffer in Worklet; low-latency streaming.\n- Controls: setRate(npcId, rate), setVolume(npcId, volume), setMute(npcId, boolean); clamp ranges and smooth changes (ramps) to avoid clicks.\n- End-of-stream and underflow handling; pause/resume map to context suspend/resume or per-channel gating.\n- Clock: expose currentTime mapping to ms for caption alignment.\n- Platform fallback: if Worklet unsupported, use ScriptProcessor as fallback with a feature flag.",
            "status": "pending",
            "testStrategy": "Unit tests with AudioWorkletMock verify parameter changes propagate and buffers consumed. UI tests adjust sliders and observe audible changes via analyser-node metrics or mock assertions. Run all tests."
          },
          {
            "id": 8,
            "title": "Caption synchronization and highlighting",
            "description": "Translate TTS timestamps into caption events and provide fallback time-based segmentation when timestamps are unavailable.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.5",
              "7.6",
              "7.7"
            ],
            "details": "CaptionSync module:\n- If timestamps present: build segments/word-level map; emit CaptionEvent updates on audio clock progression; support per-word highlight.\n- If absent: estimate duration from audio buffer length; segment text into words/phrases; assign proportional timings; update on clock.\n- Handle punctuation and Unicode graphemes with Intl.Segmenter; keep char indices consistent with normalized text used in cache key.\n- Provide API: subscribe(utteranceId, listener), unsubscribe; and getCurrent(utteranceId).\n- Edge cases: fast/slow rate changes in-flight adjust mapping; seeking unsupported; pause/resume maintain indices.",
            "status": "pending",
            "testStrategy": "Leverage TC005 tests to verify alignment under both modes. Add unit tests for segmentation with emojis/RTL scripts. Run suite."
          },
          {
            "id": 9,
            "title": "User controls UI and state management for per-channel rate/volume/mute",
            "description": "Add UI controls per NPC channel to adjust rate, volume, and mute in real time, reflecting state from the TTSService and AudioEngine.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.5",
              "7.7",
              "7.8"
            ],
            "details": "UI implementation:\n- For each NPC panel, render sliders: rate (0.5x–2.0x), volume (0–1), and a mute toggle.\n- Bind to TTSService control APIs; debounce updates and apply smooth ramps.\n- Display current voice name; allow change via dropdown to update VoiceRegistry.\n- Show live caption highlight under the current utterance.\n- Accessibility: keyboard operable, ARIA labels, focus order.\n- Persist last-used controls per NPC in state store; reset on campaign switch.",
            "status": "pending",
            "testStrategy": "Playwright tests: adjust controls and verify AudioEngine parameter changes and audible output (via mock metrics). Verify captions follow. Ensure multi-NPC independence. Run all tests and fix failures."
          },
          {
            "id": 10,
            "title": "Performance optimization and latency budget enforcement",
            "description": "Ensure median time-to-first-audio under 1.2s for ~150 chars using local settings; optimize buffering, caching, and concurrency.",
            "dependencies": [
              "7.1",
              "7.5",
              "7.6",
              "7.7"
            ],
            "details": "Optimizations:\n- Start playback on first buffered chunk threshold (e.g., 100–200ms) while continuing to stream.\n- Decode/convert audio off main thread (Worklet/Worker).\n- Pre-warm adapter connections; memoize inflight synthesis by identical key.\n- Measure TTFB and total synthesis durations; log to telemetry.\n- Cache fast-path: on hit, schedule immediately.\n- Rate/volume applied in Worklet avoids re-synthesis.\n- Configurable chunk size to balance latency vs. stability.",
            "status": "pending",
            "testStrategy": "Add performance tests using mock adapter timing and real AudioContext in headless mode where possible. Assert median <1.2s across 20 runs. Keep artifacts on failures. Run full suite."
          },
          {
            "id": 11,
            "title": "Error handling, fallbacks, and resilience",
            "description": "Harden the system to handle synthesis errors, audio underflow, unsupported features, and cancellation without crashing channels.",
            "dependencies": [
              "7.5",
              "7.6",
              "7.7",
              "7.8"
            ],
            "details": "Implement:\n- Retry with exponential backoff for transient adapter failures; circuit-breaker to avoid thrashing.\n- Graceful underflow handling: insert short silence buffers; keep captions paused.\n- Provider capability detection to switch to fallback adapter.\n- Timeouts for synthesis; propagate user-visible error to UI toast and event bus.\n- Ensure skip/pause/resume/cancel consistently clean resources; avoid memory leaks.",
            "status": "pending",
            "testStrategy": "Unit tests simulate adapter failures and timeouts; verify retries and UI error surfacing. Integration tests skip/cancel mid-utterance. Run whole suite."
          },
          {
            "id": 12,
            "title": "Wire campaign isolation for TTS assets and channels",
            "description": "Scope caches, voice mappings, and realtime events by campaign_id to avoid cross-campaign leakage.",
            "dependencies": [
              "7.3",
              "7.4",
              "7.5"
            ],
            "details": "Integrate with campaign context:\n- Namespaced cache directories per campaign.\n- VoiceRegistry keyed by campaign_id; default can be campaign-specific.\n- Event bus namespaces so captions/audio events do not cross campaigns.\n- Validate channel IDs encode campaign_id.",
            "status": "pending",
            "testStrategy": "Add isolation unit tests mirroring TC017 patterns for TTS context: two campaigns active, ensure no cache or event leakage. Run suite."
          },
          {
            "id": 13,
            "title": "Documentation and developer ergonomics",
            "description": "Provide usage docs, API examples, and troubleshooting for TTS per NPC with controls and captions.",
            "dependencies": [
              "7.5",
              "7.6",
              "7.7",
              "7.8",
              "7.9",
              "7.11",
              "7.12"
            ],
            "details": "Write README with:\n- Quickstart: enqueue, set controls, subscribe to captions.\n- Adapter configuration and swapping.\n- Cache behavior and invalidation.\n- Performance tuning tips.\n- Known limitations and fallback behavior.\n- Mapping to TC001/TC002/TC005.\nAdd TypeDoc comments and example snippets for common flows.",
            "status": "pending",
            "testStrategy": "Doc lints pass; run code snippets in docs as tests where possible. Re-run full test suite."
          },
          {
            "id": 14,
            "title": "Final end-to-end validation and readiness gate (TC001, TC002, TC005)",
            "description": "Execute the complete test plan, verify acceptance criteria across unit and UI layers, and ensure CI integration.",
            "dependencies": [
              "7.2",
              "7.3",
              "7.4",
              "7.5",
              "7.6",
              "7.7",
              "7.8",
              "7.9",
              "7.10",
              "7.11",
              "7.12",
              "7.13"
            ],
            "details": "Actions:\n- Run full CI matrix including Playwright UI and performance suites; ensure coverage >80% in TTS modules.\n- Verify cache key correctness (TC001), FIFO and per-channel isolation (TC002), and caption synchronization with and without timestamps (TC005) are green.\n- Export artifacts: coverage, screenshots, logs.\n- Resolve any flakiness and document waivers if any non-critical issues remain.",
            "status": "pending",
            "testStrategy": "CI run with retries and artifact collection; manual spot-check in a dev environment for audio quality and caption feel before sign-off."
          }
        ]
      },
      {
        "id": 8,
        "title": "Image Generation Service with Campaign Style Profiles and Cache",
        "description": "Generate scene/portrait/item images using prompt templates and style profiles; manage lifecycle placeholder→final and caching.",
        "details": "- ImageGenAdapter usage; prompt templates with variables (scene, character, item)\n- Campaign style profile: seed, artists/tags, aspect\n- API: POST /images request returns placeholder id → polls/streams to final; store in images table with hash\n- Cache reuse by prompt+style hash; SLA: cached <6s median\n- UI: show placeholder then swap to final; local asset storage\n- Dedup across campaigns only if allowed; default isolate per campaign",
        "testStrategy": "- TC003: verify lifecycle and cache reuse; measure cached retrieval latency\n- Unit: prompt rendering correctness and hash stability\n- Failure tests: provider error → fallback placeholder",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for image lifecycle, caching, and style profiles (TC003, Unit + Integration + UI)",
            "description": "Before implementation, define unit, integration, and UI tests covering core acceptance criteria: prompt rendering correctness, prompt+style hash stability, lifecycle placeholder→final, cache reuse with SLA (<6s median for cached hits), provider error fallback placeholder, and campaign isolation defaults with opt-in dedup.",
            "dependencies": [],
            "details": "• Create test plan mapping: TC003 covers lifecycle, cache reuse, latency; Unit tests for prompt template rendering and hash stability; Integration tests for API lifecycle and cache hits; UI test for placeholder-to-final swap.\n• Define fixtures: sample prompt templates for scene/portrait/item with variables {scene, character, item}; sample campaign style profiles (seed, artists/tags, aspect); campaign A and campaign B contexts.\n• Unit tests:\n  - PromptTemplateRenderer renders variables correctly; missing variables error; deterministic output for same inputs.\n  - StyleProfile normalization (seed, tags ordering, aspect normalization) and hash stability across processes.\n  - Hash function includes prompt, style profile, and campaign scoping flag; identical inputs produce identical hashes; different campaign IDs do not collide unless dedup allowed.\n• Integration tests (API):\n  - POST /images returns 202 with placeholder id, placeholder status, and polling endpoint; subsequent poll transitions to final with URL and metadata.\n  - Cached request (same prompt+style, same campaign) returns final within SLA when cache is warm; record latency and assert median <6s for cached runs.\n  - Provider error simulation -> placeholder remains with error state and retry guidelines; fallback placeholder asset returned.\n  - Dedup across campaigns only when allow_cross_campaign_dedup=true; otherwise separate cache keys.\n• UI/e2e tests:\n  - Render component shows placeholder asset immediately, then swaps to final URL when status=final.\n  - Local asset storage path correctness; image tag updates without layout shift.\n• Performance test harness: warm the cache, then issue N=50 cached requests and compute median latency; assert <6s.\n• Tag tests with IDs: TC003-LIFECYCLE, TC003-CACHE, TC003-SLA, TC003-ERROR, TC003-ISOLATION, TC003-UI.\n• Define mocks for ImageGenAdapter and clock controls for deterministic timing.",
            "status": "pending",
            "testStrategy": "Run unit tests first; then integration tests with in-memory DB and file store; UI tests via headless browser. Add a perf test stage gated for TC003-SLA. All subsequent subtasks must run and keep these tests passing."
          },
          {
            "id": 2,
            "title": "Design data model and migrations for images, cache indices, and campaign scoping",
            "description": "Define the schema for images table and related indices to support lifecycle states, hashing, and campaign isolation with optional cross-campaign dedup.",
            "dependencies": [
              "8.1"
            ],
            "details": "• Table images: id (uuid), campaign_id (uuid), request_hash (string, indexed), prompt (text), style_profile (jsonb), type (enum: scene|portrait|item), status (enum: placeholder|processing|final|error), placeholder_url (string), final_url (string), provider (string), provider_job_id (string), error_code (string), error_message (text), allow_cross_campaign_dedup (bool, default false), created_at, updated_at.\n• Unique constraint for (campaign_id, request_hash) when allow_cross_campaign_dedup=false; alternative global unique index on (request_hash) for dedup=true entries; implement via partial indices.\n• Secondary table image_cache_index (optional) mapping request_hash -> images.id for fast lookups; consider materialized view or rely on images index.\n• Add latency metrics table image_metrics: id, image_id, is_cached (bool), duration_ms, measured_at to support SLA validation.\n• Local asset storage registry table (optional) or embed in images as asset_paths jsonb for variants and thumbnails.\n• Migrations written idempotently; rollbacks provided.\n• Update ORM models and repository interfaces.",
            "status": "pending",
            "testStrategy": "Run migration tests in a fresh DB; ensure indices exist; verify unique/partial index behavior for dedup and isolation. Re-run TC003-ISOLATION integration tests to ensure DB errors do not occur."
          },
          {
            "id": 3,
            "title": "Implement PromptTemplateRenderer and StyleProfile normalization + hashing",
            "description": "Create renderer for prompt templates and canonicalization for style profiles; implement stable request hash that powers caching and dedup behavior.",
            "dependencies": [
              "8.1",
              "8.2"
            ],
            "details": "• PromptTemplateRenderer: supports variables {scene, character, item, extras}; strict mode requiring all variables present; escape rules; deterministic whitespace normalization.\n• StyleProfile: schema {seed:number, artists: string[], tags: string[], aspect: string | {w,h}}; normalization steps: sort artists/tags, lowercase trimmed tokens, normalize aspect to {w,h} canonical form (e.g., 16:9-> {w:16,h:9}).\n• RequestHash: H = SHA256(canonical_json({prompt: rendered, style: normalized, type, model_version?, guidance?, steps?, seed, allow_cross_campaign_dedup, campaign_scope: allow_cross_campaign_dedup? 'global':'campaign:'+campaign_id}))\n• Ensure stable JSON stringify: sorted keys; numeric normalization; remove non-deterministic fields.\n• Expose: renderAndHash(input, style, type, campaign_id, flags) -> {renderedPrompt, hash}.\n• Add unit tests from 8.1 to verify correctness and stability.",
            "status": "pending",
            "testStrategy": "Run unit tests for rendering, normalization, and hashing from 8.1. Add fuzz tests for key order variations leading to same hash."
          },
          {
            "id": 4,
            "title": "Define ImageGenAdapter interface and provider error contracts",
            "description": "Specify adapter interface and common error model to abstract providers; include retry and fallback semantics compatible with future hardening.",
            "dependencies": [
              "8.1"
            ],
            "details": "• Interface generateImage(request): input includes renderedPrompt, styleProfile, type, seed, aspect, size; returns {provider_job_id, eta_ms?, placeholder_url?} and a poll(job_id) -> {status: processing|final|error, final_url?, error_code?, error_message?}.\n• Standardize error codes: TIMEOUT, RATE_LIMIT, PROVIDER_DOWN, INVALID_PROMPT, CONTENT_BLOCKED.\n• Include ability to stream partial updates in future; for now polling.\n• Provide a mock adapter for tests; wire fault injection hooks.\n• Document retry hints but leave implementation for Task 23.",
            "status": "pending",
            "testStrategy": "Adapter unit tests with mocks; simulate errors and verify mapping to unified error codes used by API and lifecycle tests (TC003-ERROR)."
          },
          {
            "id": 5,
            "title": "Implement /images POST API: create placeholder and enqueue generation job",
            "description": "Build API to accept image generation requests, render prompt, compute hash, check cache, and return placeholder resource with polling link.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.4"
            ],
            "details": "• Request body: {campaign_id, type, template_id or inline_template, variables, style_profile, allow_cross_campaign_dedup?:bool}.\n• Steps:\n  - Validate campaign context and isolation (default isolate per campaign; only allow dedup if flag true).\n  - Render prompt and compute request_hash via 8.3.\n  - Cache lookup: if existing final image for scope found, return existing image resource (status final) and mark as cached in metrics.\n  - If miss: create images row with status=placeholder, placeholder_url (local placeholder asset by type), return 202 + {id, status: placeholder} and enqueue async worker job with request_hash.\n• Response includes poll URL GET /images/{id} and optional SSE endpoint for future streaming.\n• Store initial latency start time for metrics.",
            "status": "pending",
            "testStrategy": "Integration tests: POST returns placeholder when cache miss; returns final when cache hit; respects allow_cross_campaign_dedup; records metrics. Run TC003-LIFECYCLE and TC003-CACHE partials."
          },
          {
            "id": 6,
            "title": "Background worker: generation lifecycle and persistence",
            "description": "Implement worker that consumes generation jobs, invokes ImageGenAdapter, handles polling to final, updates DB, stores assets locally, and records metrics.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.4",
              "8.5"
            ],
            "details": "• Worker flow:\n  - Idempotency: lock by request_hash to prevent duplicate provider calls; coalesce concurrent requests.\n  - On start, update images row to processing.\n  - Call adapter.generateImage(); poll until final or error; configurable max timeouts.\n  - On success: download/store final asset to local storage (per-campaign subdir), write final_url, status=final, provider metadata.\n  - On error: status=error; keep placeholder_url; error codes/messages saved.\n  - Metrics: record elapsed duration; mark is_cached=false for first final; subsequent cache hits bypass worker.\n• Local storage layout: /assets/{campaign_id}/images/{yyyy}/{mm}/{dd}/{image_id}.png; ensure atomic writes.",
            "status": "pending",
            "testStrategy": "Integration tests simulate provider success and failure; verify DB state transitions and asset files exist; TC003-ERROR passes."
          },
          {
            "id": 7,
            "title": "GET /images/{id} API and optional polling stream",
            "description": "Expose retrieval endpoint to poll image status and metadata; include cache headers and minimal payload for UI updates.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.5",
              "8.6"
            ],
            "details": "• GET returns: {id, status, placeholder_url, final_url, type, campaign_id, created_at, updated_at, error?} with 200; 404 if not in campaign scope.\n• Add ETag/Last-Modified for client caching.\n• Optionally provide SSE at /images/{id}/events for status updates (queued, processing, final, error).",
            "status": "pending",
            "testStrategy": "Integration tests: poll transitions to final; 404 on cross-campaign access; UI tests use this endpoint for swap."
          },
          {
            "id": 8,
            "title": "UI component: ImagePlaceholderSwap with local asset storage",
            "description": "Implement front-end component that shows placeholder immediately and swaps to final when available; ensure smooth UX and correct local asset usage.",
            "dependencies": [
              "8.1",
              "8.7"
            ],
            "details": "• Props: imageId. On mount, fetch GET /images/{id}; display placeholder_url; start polling every 1s or use SSE; when status=final, swap img src to final_url.\n• Avoid layout shift: reserve aspect ratio box from style_profile.aspect or metadata.\n• Handle error state by keeping placeholder and showing tooltip.\n• Ensure URLs point to local asset server paths.\n• Accessibility: alt text from prompt summary.",
            "status": "pending",
            "testStrategy": "UI test: renders placeholder then swaps to final; verifies no layout shift and correct src changes; covers TC003-UI."
          },
          {
            "id": 9,
            "title": "Cache reuse logic with SLA measurement and optimization",
            "description": "Finalize cache hit path to meet <6s median for cached results; ensure fast DB and file access and precomputed metadata.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.5",
              "8.6",
              "8.7",
              "8.8"
            ],
            "details": "• On cache hit in POST /images: immediately return existing final image without spawning worker; mark metric is_cached=true and capture end-to-end latency.\n• Optimize indices for request_hash lookup; add read-through in-memory cache (LRU) keyed by request_hash -> {image_id, final_url} with TTL.\n• Warm-path benchmarks and micro-optimizations (avoid JSON parsing in hot path; select only needed columns).\n• Store pre-generated thumbnails if needed to speed UI.\n• Add API fast path testing hooks.",
            "status": "pending",
            "testStrategy": "Run performance test harness from 8.1 with warmed cache; verify median latency <6s (target much lower). Capture flamegraphs if regressions."
          },
          {
            "id": 10,
            "title": "Cross-campaign dedup controls and isolation enforcement",
            "description": "Implement strict default isolation with optional explicit dedup across campaigns, including cache key scoping and access controls.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.5",
              "8.7"
            ],
            "details": "• Enforce campaign scoping on all queries via middleware; GET /images/{id} must verify campaign_id.\n• In POST, if allow_cross_campaign_dedup=true, use global cache index for request_hash; otherwise use campaign-scoped index.\n• Ensure returned assets always reference correct campaign directories even if dedup is global (store final once, reference many via soft links or metadata pointers).\n• Add audit logs when cross-campaign dedup is used.",
            "status": "pending",
            "testStrategy": "Integration tests: two campaigns issuing same request; verify no reuse by default; with flag true, reuse occurs; GET access blocked across campaigns."
          },
          {
            "id": 11,
            "title": "Failure handling and fallback placeholder policy",
            "description": "Define and implement robust error mapping, retry hints (without retries), and consistent fallback behavior on provider errors.",
            "dependencies": [
              "8.1",
              "8.4",
              "8.6",
              "8.7"
            ],
            "details": "• Map provider errors to standardized codes (from 8.4). On error, keep status=error, placeholder visible, and include user-safe message.\n• Provide next-step guidance: retry_after_s suggestion or manual retry endpoint.\n• Ensure no partial assets leak; clean temp files.\n• Log correlation IDs across API and worker for observability.",
            "status": "pending",
            "testStrategy": "Run TC003-ERROR and additional unit tests verifying error payloads; simulate each standardized error and verify consistent responses."
          },
          {
            "id": 12,
            "title": "Security, validation, and content safety gates",
            "description": "Add input validation, rate limits, and content safety checks to prevent invalid prompts and unsafe outputs.",
            "dependencies": [
              "8.1",
              "8.5"
            ],
            "details": "• Validate template and variables; limit prompt size and tag lists; sanitize strings.\n• Rate limiting per campaign and per IP.\n• Optional content policy check prior to generation; map violations to CONTENT_BLOCKED.\n• Sign asset URLs if needed; ensure local path traversal protections.",
            "status": "pending",
            "testStrategy": "Unit/integration tests for validation failures; ensure CONTENT_BLOCKED surfaces as error and placeholder remains."
          }
        ]
      },
      {
        "id": 9,
        "title": "Alliances/Teams and Leaderboards",
        "description": "Implement alliances/teams data model, membership flows, shared mechanics hooks, and basic leaderboards for competitive modes.",
        "details": "- Tables: alliances (id, campaign_id, name), alliance_members, scores (campaign_id, team_id, metric, value)\n- API: create/delete alliance, invite/join/leave, assign team/line\n- Leaderboard: compute on event updates or periodic job\n- Hooks into mission/rules to award points\n- UI: manage team membership and view leaderboard",
        "testStrategy": "- TC004: team/alliance setup flows verified via API/UI tests\n- TC005: leaderboard updates on scoring events; fairness invariants\n- Isolation: ensure per-campaign separation",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for alliances, membership, scoring, and leaderboards (TC004, TC005, Isolation)",
            "description": "Author unit and integration/UI tests that encode core acceptance criteria before implementation: alliance CRUD and membership flows (invite/join/leave/assign team-line), scoring hooks and leaderboard updates on events/cron, and per-campaign isolation. Include negative cases and fairness invariants. No production code changes here.",
            "dependencies": [],
            "details": "• Create test plans and fixtures:\n  - Campaign fixtures: campaignA, campaignB\n  - Users: owner, member1, member2, outsider\n  - Missions/rules stubs: emits scoring events\n  - Metrics: kills, objectives, time\n• Unit tests (Jest/TS):\n  - alliances model validation and constraints\n  - scoring aggregation functions\n  - leaderboard ranking logic (ties, stable sort, pagination)\n  - permissions matrix for endpoints\n• API integration tests (Supertest):\n  - Create/delete alliance; invite -> accept/decline -> join; leave; assign team/line\n  - Membership enforcement and errors (outsider cannot invite; non-owner deletion forbidden)\n  - Per-campaign isolation: alliances and scores do not leak across campaigns (TC004 Isolation)\n• Event-driven tests:\n  - Emit scoring events -> verify scores table updated and leaderboard recalculated (TC005)\n  - Periodic job computes leaderboard when no live events\n• WebSocket gateway (Task 3) interop stub: team/alliance topic auth enforced (reference only, no dependency)\n• UI e2e tests (Playwright):\n  - Manage team membership UI: create alliance, invite, accept, leave (TC004)\n  - View leaderboard: reflects scoring updates in near-real-time and after cron (TC005)\n• Fairness invariants:\n  - Scores cannot be negative (unless metric allows); only whitelisted metrics accepted\n  - Idempotent event processing; at-least-once delivery safety with dedupe keys\n• Map tests to IDs: TC004 (setup flows via API/UI), TC005 (leaderboard updates and fairness), Isolation checks.\n• CI wiring to run tests with seeded DB and mocked mission/rules.",
            "status": "pending",
            "testStrategy": "This subtask is the test definition. Output: failing tests that encode acceptance criteria."
          },
          {
            "id": 2,
            "title": "Design relational schema and migrations for alliances, membership, and scores",
            "description": "Create normalized tables with constraints, indexes, and audit columns for alliances, alliance_members, and scores; add supportive tables for invites and deduplication of scoring events.",
            "dependencies": [
              "9.1"
            ],
            "details": "• Tables:\n  - alliances(id UUID PK, campaign_id UUID FK campaigns(id) ON DELETE CASCADE, name TEXT NOT NULL, slug TEXT UNIQUE per campaign, created_by, created_at, updated_at, UNIQUE(campaign_id, name))\n  - alliance_members(id UUID PK, alliance_id FK alliances(id) ON DELETE CASCADE, user_id UUID FK users(id), role ENUM('owner','admin','member'), team_line JSONB nullable (or columns team, line), joined_at, UNIQUE(alliance_id, user_id))\n  - alliance_invites(id UUID PK, alliance_id FK, invited_user_email TEXT or user_id, token TEXT UNIQUE, expires_at, invited_by, status ENUM('pending','accepted','declined','expired'), UNIQUE(alliance_id, invited_user_email or user_id, status='pending'))\n  - scores(id UUID PK, campaign_id FK, team_id UUID FK alliances(id), metric TEXT, value BIGINT NOT NULL DEFAULT 0, updated_at, UNIQUE(campaign_id, team_id, metric))\n  - score_events(id UUID PK, campaign_id FK, team_id FK alliances(id), metric TEXT, delta INT, source TEXT, event_idempotency_key TEXT UNIQUE, occurred_at, processed_at, status ENUM('pending','applied','rejected'), metadata JSONB)\n  - leaderboards(id UUID PK, campaign_id FK, metric TEXT, computed_at, entries JSONB, UNIQUE(campaign_id, metric))\n• Indexing:\n  - alliances(campaign_id, name), alliance_members(alliance_id, user_id), scores(campaign_id, metric DESC, value DESC), score_events(event_idempotency_key), leaderboards(campaign_id, metric)\n• Constraints:\n  - Enforce per-campaign isolation via FKs\n  - Check: value >= 0 for non-negative metrics (use metric policy table later if needed)\n• Migrations and rollback scripts.\n• Seed data for tests.",
            "status": "pending",
            "testStrategy": "Run unit tests for model validation and isolation from 9.1; ensure schema supports required flows and uniqueness constraints cause expected failures."
          },
          {
            "id": 3,
            "title": "Implement data access layer and domain models with validation",
            "description": "Add repositories/services for alliances, membership, invites, scores, score_events, and leaderboards with input validation and error semantics.",
            "dependencies": [
              "9.1",
              "9.2"
            ],
            "details": "• Tech: Node/TS, Prisma/Knex/TypeORM per project standard; zod schemas in shared package.\n• Implement:\n  - AlliancesService: create(campaignId,name,creator), delete(id, byUser), getById, listByCampaign\n  - MembershipService: invite(allianceId, target), accept(token or inviteId, byUser), decline, join(byUser via open policy), leave, assignTeamLine(memberId, team, line), setRole\n  - ScoresService: applyDelta({campaignId, teamId, metric, delta, idempotencyKey, source, metadata}) with upsert to scores and persistence to score_events\n  - LeaderboardService: compute({campaignId, metric, limit, tieBreakers}) returns ordered list and persists to leaderboards\n  - Policy enforcement: only owners/admins can invite/delete; members can leave; outsiders blocked\n• Validation:\n  - zod schemas for names, metrics whitelist, delta range, team/line format\n  - Idempotency: reject or no-op duplicates via score_events unique key\n• Transactions for atomic score updates\n• Error mapping to HTTP codes later used by API.",
            "status": "pending",
            "testStrategy": "Run unit tests from 9.1 for model/logic; add service-level tests for idempotency, transactions, and permissions."
          },
          {
            "id": 4,
            "title": "Build REST APIs for alliances CRUD and membership flows",
            "description": "Expose endpoints: create/delete alliance; invite/accept/decline; join/leave; assign team/line; list alliances and members. Secure per-campaign and role-based access.",
            "dependencies": [
              "9.1",
              "9.3"
            ],
            "details": "• Routes (prefix /campaigns/:campaignId):\n  - POST /alliances {name}\n  - DELETE /alliances/:allianceId\n  - GET /alliances\n  - GET /alliances/:allianceId/members\n  - POST /alliances/:allianceId/invites {userId|email}\n  - POST /invites/:inviteId/accept\n  - POST /invites/:inviteId/decline\n  - POST /alliances/:allianceId/join\n  - POST /alliances/:allianceId/leave\n  - PATCH /alliances/:allianceId/members/:memberId {role?, team?, line?}\n• Middleware:\n  - Auth session -> user; campaign scope check; role checks (owner/admin)\n• Responses follow zod schemas; errors standardized.\n• OpenAPI/Swagger annotations for UI integration.",
            "status": "pending",
            "testStrategy": "Run API tests from 9.1 TC004 and isolation cases. Add negative tests for unauthorized access and invalid payloads."
          },
          {
            "id": 5,
            "title": "Implement scoring hooks integration with missions/rules",
            "description": "Create an event handler that listens to mission/rules events and applies scoring deltas per alliance/team according to configured metrics.",
            "dependencies": [
              "9.1",
              "9.3"
            ],
            "details": "• Event bus: subscribe to mission events (e.g., mission.completed, kill.registered, objective.captured)\n• Mapping config: metric map per campaign (e.g., mission.completed -> objectives +10)\n• Handler flow:\n  - Resolve player/user -> alliance/team within campaign\n  - Derive metric and delta from event payload\n  - Call ScoresService.applyDelta with idempotency key event.id\n  - Optionally emit leaderboard.updated notification\n• Error handling: drop or quarantine events with missing mappings; maintain dead-letter queue for review.\n• Ensure at-least-once safety and idempotent updates.",
            "status": "pending",
            "testStrategy": "Extend tests to emit mock events and assert scores and leaderboard recompute (TC005). Include idempotency duplicate event test."
          },
          {
            "id": 6,
            "title": "Create leaderboard computation job and on-event updater",
            "description": "Provide two paths to keep leaderboards fresh: immediate recompute on scoring events (throttled/debounced) and a periodic job (cron/queue) to backfill and correct.",
            "dependencies": [
              "9.1",
              "9.3",
              "9.5"
            ],
            "details": "• On-event updater:\n  - Debounce per campaign+metric (e.g., 500ms window) to recompute after bursts\n  - Compute top N (configurable), ties handled by stable sort on value desc then earliest achieved or name\n  - Persist to leaderboards table and publish cache invalidation\n• Periodic job:\n  - Runs every N minutes; recompute for active campaigns and all metrics\n  - Metrics coverage discovered from scores table\n• Performance: aggregate via SQL (SUM value from scores) or read from scores table directly if it stores totals\n• Expose admin endpoint to trigger recompute for tests.",
            "status": "pending",
            "testStrategy": "API/integration tests validate leaderboard reflects events and cron; test tie cases, pagination, and stability (TC005)."
          },
          {
            "id": 7,
            "title": "Enforce team/alliance topic permissions in WebSocket gateway",
            "description": "Integrate with Task 3 gateway to ensure server-side enforcement for team/line and alliance topics based on membership.",
            "dependencies": [
              "9.1",
              "9.3"
            ],
            "details": "• Provide membership lookup module usable by gateway\n• On join(topic): verify user belongs to alliance/team in campaign; reject otherwise\n• On membership change: push subscription updates (kick or grant)\n• Rate limiting and schema validation reuse from gateway\n• Emit ticker-update for leaderboard changes if subscribed.",
            "status": "pending",
            "testStrategy": "Gateway integration tests (superwstest) verifying channel authorization (maps to TC002 in Task 3) and alliance membership updates eject unauthorized clients."
          },
          {
            "id": 8,
            "title": "Build UI: Team/Alliance management screens",
            "description": "Implement React views to manage alliances and membership within campaign context: list, create, invite, accept, leave, assign team/line; respect roles and accessibility.",
            "dependencies": [
              "9.1",
              "9.4"
            ],
            "details": "• Pages/Components:\n  - AlliancesList: fetch and display alliances; create form modal\n  - AllianceDetail: members table; invite by email/user; role dropdown; team/line editor\n  - InviteAcceptFlow: handle token link and success/failure\n• State: use existing store; optimistic updates with rollback on error\n• Accessibility: keyboard, focus management, proper labels; i18n strings\n• Error toasts and empty states.",
            "status": "pending",
            "testStrategy": "Playwright UI tests for TC004: create alliance, invite member, accept, leave; snapshot tests for components; axe-core scan passes."
          },
          {
            "id": 9,
            "title": "Build UI: Leaderboard views with live updates",
            "description": "Create leaderboard UI for competitive modes: per metric tabs, sorting, pagination, and live updates via WebSocket and periodic polling fallback.",
            "dependencies": [
              "9.1",
              "9.6",
              "9.7"
            ],
            "details": "• Components:\n  - LeaderboardWidget: shows top N with rank, alliance name, score, delta indicators\n  - MetricTabs: switch metrics\n• Data:\n  - REST fetch current leaderboard; subscribe to ticker-update for changes\n  - Debounced re-render; handle tie display\n• UX: loading/skeletons; empty states; accessible table semantics.",
            "status": "pending",
            "testStrategy": "Playwright test for TC005: on scoring event simulation, UI reflects updated leaderboard; verify tie rendering and pagination."
          },
          {
            "id": 10,
            "title": "Security, isolation, and permissions hardening",
            "description": "Add comprehensive checks to ensure per-campaign isolation, least-privilege access, and safe inputs across API, services, and UI.",
            "dependencies": [
              "9.4",
              "9.5",
              "9.6",
              "9.8",
              "9.9"
            ],
            "details": "• Server:\n  - Verify campaign_id scoping on all queries\n  - Ensure delete alliance requires owner; admin limits\n  - Input sanitization; rate limit sensitive endpoints\n• DB:\n  - Row-level policies if using Postgres RLS\n  - Additional indexes for isolation queries\n• UI:\n  - Hide actions the user lacks permissions for\n• Logging and audit trails for membership and score changes.",
            "status": "pending",
            "testStrategy": "Negative tests: cross-campaign access attempts; privilege escalation attempts; fuzz invalid inputs. Validate isolation checks from TC004/TC005."
          },
          {
            "id": 11,
            "title": "Observability and admin tooling for scoring and leaderboards",
            "description": "Add metrics, logs, and minimal admin endpoints to inspect score events, recompute leaderboards, and quarantine bad events.",
            "dependencies": [
              "9.5",
              "9.6"
            ],
            "details": "• Metrics: counters for events processed, dedup hits, recompute latency\n• Logs: structured logs with event ids and outcomes\n• Admin endpoints:\n  - GET /admin/campaigns/:id/score-events?status=...\n  - POST /admin/campaigns/:id/leaderboards/:metric/recompute\n  - POST /admin/score-events/:id/quarantine\n• Protect admin routes via role/feature flag.",
            "status": "pending",
            "testStrategy": "Integration tests for admin endpoints; ensure no exposure to non-admins; verify recompute path correctness."
          },
          {
            "id": 12,
            "title": "Finalize documentation and OpenAPI contracts",
            "description": "Deliver developer docs, API reference (OpenAPI), event mappings, and UI usage guides for alliances and leaderboards.",
            "dependencies": [
              "9.4",
              "9.5",
              "9.6",
              "9.8",
              "9.9",
              "9.10",
              "9.11"
            ],
            "details": "• OpenAPI specs for all endpoints; schemas for requests/responses\n• Event mapping docs for missions -> metrics\n• Usage examples and error codes\n• UI handbook: flows for admins and members\n• Add ADR for schema and idempotency decisions.",
            "status": "pending",
            "testStrategy": "Lint OpenAPI; link checks; run example requests in CI against mock server."
          }
        ]
      },
      {
        "id": 10,
        "title": "Mission Template DSL and Executor",
        "description": "Create objective-graph DSL with twists and soft-fail states; executor to advance graph based on events and player actions.",
        "details": "- DSL: JSON schema in shared; nodes (objective, twist, soft_fail), edges with conditions; validators with zod/ajv\n- Executor: deterministic state machine; inputs: events stream; outputs: mission_progress updates and prompts for GM LLM\n- API: load mission from content packs; start/advance/end\n- Soft-fail handling transitions without ending mission; twist activation by predicates",
        "testStrategy": "- TC006: graph advancement correctness; activation of twists; soft-fail behavior under unit tests with seeded events\n- Property tests: no dead nodes; reachability\n- Snapshot tests for executor determinism",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for Mission DSL and Executor (TC006 + determinism)",
            "description": "Create a comprehensive test suite that encodes the core acceptance criteria before implementation. Cover graph advancement correctness, twist activation via predicates, soft-fail transitions that do not end the mission, and deterministic executor behavior with snapshot testing. Include property tests for reachability (no dead-end from start to at least one terminal state) and seed-based determinism tests.",
            "dependencies": [],
            "details": "Set up a tests package in the monorepo (e.g., packages/mission/__tests__) using Jest + ts-jest or Vitest. Define fixtures for minimal mission graphs in JSON with nodes: objective, twist, soft_fail; edges with conditions; and seeded event streams. Write tests:\n- TC006-Unit: Given events, executor advances objective nodes in order; twist nodes activate when their predicate becomes true; soft_fail transitions occur without ending the mission.\n- TC006-Integration: Load a mission from a mock content pack and drive executor with a sequence of events, assert mission_progress updates and prompts queued for GM LLM.\n- Determinism Snapshot: For a seeded event stream, executor produces identical state snapshots across runs.\n- Property: For each mission fixture, verify start node has a path to at least one terminal objective (goal) and that no edge references missing nodes.\n- Error handling: Invalid schema missions fail validation with readable errors.\nTag tests with IDs: TC006-U1/U2, TC006-I1, TC006-P1, TC006-D1.",
            "status": "pending",
            "testStrategy": "Execute tests locally and in CI across Node LTS. Use fixed seeds for random behavior. Include golden JSON snapshots for executor state after each step."
          },
          {
            "id": 2,
            "title": "Design Mission Graph JSON Schema (nodes, edges, metadata)",
            "description": "Specify the DSL as a JSON Schema defining mission graphs with node types (objective, twist, soft_fail), edges with conditions/predicates, metadata, and terminal states. Include versioning and compatibility fields.",
            "dependencies": [
              "10.1"
            ],
            "details": "In shared package, add schema v1: mission.schema.json with types: Mission, Node, Edge, Condition. Fields:\n- Mission: id, version, title, description, start_node_id, nodes[], edges[], variables (initial), metadata.\n- Node: id, type ('objective' | 'twist' | 'soft_fail'), title, description, payload (objective-specific fields like success_predicate, failure_predicate, completion_mode), prompts (for GM LLM), on_enter/on_exit actions, soft_fail_recovery (for soft_fail nodes), tags.\n- Edge: id, from, to, guard (predicate expression or predicate config), priority, kind ('normal' | 'soft_fail' | 'twist'), side_effects (declarative action ids), reentrant (bool).\n- Condition/Predicate: allow two forms: (a) declarative operator tree (left/op/right) referencing events and variables, (b) named predicate id with parameters.\n- Terminal designation: objective nodes may have terminal=true.\nInclude $defs for predicates, actions, and expressions. Provide examples section and $schema, $id. Add semver in mission.version.",
            "status": "pending",
            "testStrategy": "Run schema validation tests from TC006-U1 against fixtures; ensure invalid graphs (missing nodes, cycles without exit, invalid edge references) fail with descriptive errors."
          },
          {
            "id": 3,
            "title": "Implement Zod types and AJV validators for Mission DSL",
            "description": "Create Zod type definitions mirroring the JSON Schema and compile an AJV validator for runtime validation. Provide a unified validateMissionGraph API returning typed results and rich errors.",
            "dependencies": [
              "10.2",
              "10.1"
            ],
            "details": "In shared/mission-dsl: \n- Define zod types: ZMission, ZNode, ZObjectiveNode, ZTwistNode, ZSoftFailNode, ZEdge, ZPredicate, ZExpression.\n- Generate TypeScript types from Zod. Configure AJV with allErrors, strict, formats. Add ajv instance and precompiled validate function from mission.schema.json.\n- Export: parseMission(zod), validateMissionAjv(json): { ok, errors }, and assertMission(json): Mission.\n- Add custom validators: ensure start_node_id exists; all edges from/to exist; no duplicate ids; edge kind matches node types (e.g., soft_fail edges allowed from objectives); terminal reachability check optional at load time.",
            "status": "pending",
            "testStrategy": "Wire TC006-U1 invalid schema tests to ensure both Zod parsing and AJV validation produce consistent failures. Add unit tests for custom validations."
          },
          {
            "id": 4,
            "title": "Define predicate and condition evaluation engine",
            "description": "Implement a pure, deterministic evaluator for declarative predicates over events and variables to drive edge guards and node success/failure conditions.",
            "dependencies": [
              "10.3",
              "10.1"
            ],
            "details": "Create a module evaluator.ts with:\n- Expression AST: literals, variable refs (vars.morale, event.type), comparison ops, logical ops, temporal operators (within_ms, count_of, since), and event pattern matching (match {type, actor, target}).\n- Context: { variables, recentEvents (deque with timestamps), now, seed }.\n- Evaluate functions: evalPredicate(predicate, context), evalExpression(expr, context) with no dynamic code eval. Support named predicate registry with pluggable functions (e.g., 'player_action_equals', 'inventory_contains', 'roll_ge').\n- Determinism: ensure stable ordering, no Date.now direct calls—use provided now.\n- Performance: pre-compile predicates to executable closures when loading the mission.",
            "status": "pending",
            "testStrategy": "Unit tests: truth tables for logical ops; temporal windows with seeded event streams; named predicate registry resolution; snapshot of compiled predicates for equality; TC006-U2 twist activation using predicate evaluation."
          },
          {
            "id": 5,
            "title": "Executor state machine core (advance loop and transitions)",
            "description": "Build a deterministic executor that maintains mission state, ingests events, evaluates node conditions, and advances along edges with priorities while handling twists and soft-fail states.",
            "dependencies": [
              "10.4",
              "10.3",
              "10.1"
            ],
            "details": "Create executor.ts with:\n- Types: ExecutorState { currentNodeIds[], variables, history, activeTwists[], softFailActive?, rngSeed, now }, Event, Output { mission_progress, prompts }.\n- APIs: start(mission, seed, now) -> ExecutorState; step(state, events[]) -> { state, outputs }; end(state) -> summary.\n- Logic: For each step, update context with events, evaluate node-level success/failure predicates, choose edges whose guards are true, select by highest priority and deterministic tie-break (edge id sort). Allow parallel objectives if mission allows (flag). Twists: if guard true and not active, activate and push to activeTwists; may modify variables or inject prompts. Soft-fail: if triggered (node failure or soft_fail edge), transition to soft_fail node while mission remains ongoing; support recovery via soft_fail_recovery and edges back to objectives.\n- Determinism: order evaluations by stable id sort; avoid non-deterministic iteration; RNG via seeded PRNG injected.\n- Snapshotting: produce a compact state snapshot after each step for tests.",
            "status": "pending",
            "testStrategy": "Use TC006-D1 determinism snapshot with fixed seed and event sequence; TC006-U1 advancement cases; add edge-priority tie tests; soft-fail entry and recovery tests."
          },
          {
            "id": 6,
            "title": "Mission progress and GM LLM prompt generation",
            "description": "Define mission_progress structure and generate GM-facing prompts based on node transitions, twist activations, and soft-fail events.",
            "dependencies": [
              "10.5",
              "10.3"
            ],
            "details": "Design mission_progress: { missionId, timestamp, activeObjectives[], completedObjectives[], failedObjectives[], activeTwists[], softFail?: { nodeId, since }, variablesDelta, log[] }. Implement promptBuilder that consumes transition events to produce concise prompts: on_enter objective, on_complete, on_twist_activate, on_soft_fail_enter/exit. Allow templates in node.payload.prompts with variable interpolation. Ensure outputs are deterministic and idempotent.",
            "status": "pending",
            "testStrategy": "Integration test TC006-I1: run executor over a mission with twists and soft-fail; assert mission_progress updates and that generated prompts match expected snapshots."
          },
          {
            "id": 7,
            "title": "Content pack loader and repository API",
            "description": "Implement APIs to load mission graphs from content packs, list missions, and fetch by id with validation and pre-compilation.",
            "dependencies": [
              "10.3",
              "10.2"
            ],
            "details": "Create module contentRepo.ts: loadContentPack(dirOrZip), index missions by id, run validation and precompile predicates/guards, cache compiled missions. Export getMission(id), listMissions(), and unload/reload. Support version gating and schema migration hooks.",
            "status": "pending",
            "testStrategy": "Integration test: load a mock content pack with two missions, ensure invalid mission is rejected; verify compiled predicate cache is used and consistent across loads."
          },
          {
            "id": 8,
            "title": "Public Mission API: start/advance/end with event stream input",
            "description": "Expose a stable API surface for external systems to manage mission lifecycles and feed events.",
            "dependencies": [
              "10.5",
              "10.7",
              "10.6"
            ],
            "details": "In a missions module, export:\n- startMission(missionId, seed, now): loads compiled mission, initializes ExecutorState, persists initial mission_progress.\n- advanceMission(stateOrId, events[], now): applies step, persists updated mission_progress and returns outputs.\n- endMission(stateOrId, reason): finalizes and returns summary.\nIntegrate with persistence interfaces (from Task 2) behind an adapter so this task compiles without DB if Task 2 not yet ready. Provide in-memory repository fallback. Ensure all calls run validation and respect determinism.",
            "status": "pending",
            "testStrategy": "Integration test: simulate a mission lifecycle with in-memory repo, asserting stored mission_progress history and idempotent advance on empty events."
          },
          {
            "id": 9,
            "title": "Soft-fail mechanics and recovery policies",
            "description": "Finalize semantics for soft-fail handling: entry triggers, variable penalties, cooldowns, and recovery transitions without mission termination.",
            "dependencies": [
              "10.5",
              "10.4"
            ],
            "details": "Extend executor to support:\n- soft_fail node entry via edge or objective failure; set state.softFailActive with nodeId and since timestamp; apply penalties from node.payload (e.g., reduce morale var, add complication tags) and cooldown until recovery condition met.\n- Recovery: evaluate recovery predicates/edges to return to previous or specified objective(s). Ensure multiple soft-fail cycles do not cause infinite loops using visit counters or cooldown tokens.\n- Logging: append log entries for entry/exit.",
            "status": "pending",
            "testStrategy": "Unit tests: repeated soft-fail entries respect cooldown; recovery edges activate only when predicates satisfied; ensure mission not ended accidentally. Extend TC006-U1 with soft-fail loop prevention assertions."
          },
          {
            "id": 10,
            "title": "Property-based tests for graph invariants and executor safety",
            "description": "Add fast-check property tests to ensure invariants: no dead nodes reachable from start without exit, all transitions preserve determinism, and executor never throws on unknown events.",
            "dependencies": [
              "10.5",
              "10.4",
              "10.1"
            ],
            "details": "Use fast-check to generate small mission graphs within schema constraints and random event streams. Properties:\n- Reachability: every active node has at least one possible outgoing edge or is terminal.\n- Determinism: same seed+events => same state snapshots.\n- Safety: executor handles unknown event types by ignoring or routing to default predicates.\n- No edge to non-existent node.\nLimit generation to avoid exponential explosions; cap sizes and depth.",
            "status": "pending",
            "testStrategy": "Add TC006-P1 property test suite. Run multiple seeds in CI with a time budget. Persist failing counterexamples as fixtures."
          },
          {
            "id": 11,
            "title": "Persistence integration for mission and progress (adapter for Task 2)",
            "description": "Integrate with the local SQLite access layer when available, with a clean adapter that can be swapped for in-memory during tests.",
            "dependencies": [
              "10.8"
            ],
            "details": "Define IMissionStore interface: getMissionState(id), saveMissionState(state, progress), appendLog(entry), listMissionProgress(missionId). Provide two implementations: InMemoryMissionStore (default) and SqliteMissionStore (thin wrapper expecting Task 2 tables missions, mission_progress). Use dependency injection in Public Mission API.",
            "status": "pending",
            "testStrategy": "Integration tests: run lifecycle tests with both InMemory and a mocked Sqlite implementation (using sqlite in tmp). Verify idempotent saves and transactional updates."
          },
          {
            "id": 12,
            "title": "Executor performance and backpressure handling",
            "description": "Optimize executor step throughput and add safeguards for large event batches.",
            "dependencies": [
              "10.5",
              "10.8"
            ],
            "details": "Batch events by time windows; short-circuit evaluation when terminal reached; pre-index edges by from node. Add maxStepsPerAdvance and maxEventsPerStep configs; if exceeded, return a backpressure signal in outputs. Include metrics counters (steps, evals) for diagnostics. Ensure performance optimizations keep determinism intact.",
            "status": "pending",
            "testStrategy": "Benchmark test: synthetic mission with 1k edges, event batches of 1k; assert step time under threshold locally. Unit tests: backpressure triggers and preserves correctness."
          },
          {
            "id": 13,
            "title": "API error handling, diagnostics, and logging",
            "description": "Provide structured errors and diagnostic logs for validation failures, illegal transitions, and predicate errors with redaction-friendly fields.",
            "dependencies": [
              "10.8",
              "10.6",
              "10.3"
            ],
            "details": "Create Error types: ValidationError, TransitionError, PredicateError with codes and details (nodeId, edgeId). Diagnostics: debug traces of evaluation decisions (edge considered -> accepted/rejected) gated by a flag. Logs structured as objects with no PII; integrate with project logging interfaces. Ensure error messages are stable for tests.",
            "status": "pending",
            "testStrategy": "Unit tests: simulate predicate exceptions and ensure they are caught and wrapped. Integration tests: invalid mission load produces ValidationError with path hints. Snapshot logs for a step under diagnostics mode."
          },
          {
            "id": 14,
            "title": "GM LLM prompt channel integration points",
            "description": "Define extensible hook points for emitting prompts to the GM LLM pipeline without taking a hard dependency.",
            "dependencies": [
              "10.6",
              "10.8"
            ],
            "details": "Define IPromptSink interface with method emit(prompt: Prompt). In executor outputs, include prompts[]. Provide default NoopPromptSink and a test sink collecting prompts. Allow prompt templates to include structured context (current objectives, twists, variables).",
            "status": "pending",
            "testStrategy": "Integration test: provide a test sink and assert received prompts correspond to transitions in TC006-I1."
          },
          {
            "id": 15,
            "title": "Versioning and migration strategy for DSL",
            "description": "Establish semver policy and migration utilities for mission schema changes.",
            "dependencies": [
              "10.2",
              "10.7"
            ],
            "details": "Add version field and $id to schema. Create migrateMission(missionJson, fromVersion, toVersion) with a registry of transforms. Provide a linter command to report deprecated fields and auto-fix where safe. Document backward-compat flags in validator.",
            "status": "pending",
            "testStrategy": "Unit tests: migrate from v1 to v1.x with added fields; ensure strict mode rejects incompatible versions; integration test: content pack loader auto-migrates minor versions."
          },
          {
            "id": 16,
            "title": "CLI tooling for validate, simulate, and visualize",
            "description": "Provide a developer CLI to validate missions, run simulations over event traces, and output a DOT/JSON suitable for visualization.",
            "dependencies": [
              "10.8",
              "10.7",
              "10.5"
            ],
            "details": "Create bin/mission-cli.ts with commands:\n- validate <file>\n- simulate <file> --events <trace.json> --seed <n>\n- visualize <file> -> outputs DOT and JSON including reachable subgraph and edge labels with guard summaries.\nUse shared validator and executor. Ensure deterministic outputs for CI.",
            "status": "pending",
            "testStrategy": "Integration tests: run CLI against fixtures in a temp workspace and compare outputs with snapshots."
          },
          {
            "id": 17,
            "title": "Cross-package integration test with WebSocket Gateway (Task 3)",
            "description": "Add an integration proving that mission executor outputs (ticker-update/action prompts) can be sent via the realtime gateway topics without tight coupling.",
            "dependencies": [
              "10.8",
              "10.6"
            ],
            "details": "Spin up a mocked WebSocket server or reuse Task 3 test harness. Wire a thin bridge that listens to executor outputs and publishes ticker-update and action messages on a session channel. Verify channel membership and payload schemas from shared package.",
            "status": "pending",
            "testStrategy": "Integration test mapping to TC002: multiple clients subscribe, advance mission, and receive expected updates. Ensure reconnect preserves subscriptions and resumes updates."
          },
          {
            "id": 18,
            "title": "Security and redaction hooks alignment (Task 15)",
            "description": "Ensure logs, prompts, and mission content pass through redaction middleware and no secrets or PII are persisted.",
            "dependencies": [
              "10.13"
            ],
            "details": "Introduce IRedactor interface and optional middleware in Mission API. Apply redaction to mission_progress.log entries and prompts before persistence or emission. Audit for outbound network calls (none).",
            "status": "pending",
            "testStrategy": "Integration tests aligned with TC014: scan persisted mission_progress for unredacted PII tokens from a test corpus; verify redaction happens deterministically."
          },
          {
            "id": 19,
            "title": "Finalize documentation and developer examples",
            "description": "Write reference docs and example missions demonstrating twists and soft-fails with event-driven progression.",
            "dependencies": [
              "10.16",
              "10.8",
              "10.6"
            ],
            "details": "Add README with schema overview, executor lifecycle, and sample missions. Provide example content pack and simulation traces. Include troubleshooting for validation errors and determinism pitfalls.",
            "status": "pending",
            "testStrategy": "Docs lint and build. Run examples through CLI simulate in CI to ensure they remain valid."
          }
        ]
      },
      {
        "id": 11,
        "title": "Rules Engine for d20 and Progression",
        "description": "Implement rules for d20 checks, DCs, advantage/disadvantage, conditions, XP/levels, and loot distribution.",
        "details": "- Pure TS module in shared; deterministic, side-effect free\n- Dice roller with seed; advantage/disadvantage; DC compare\n- Conditions state and effects; XP curves; loot tables\n- Hooks for alliances/team modifiers",
        "testStrategy": "- Unit tests for dice distributions and edge cases\n- Golden tests for progression and loot outcomes\n- Fuzz tests to ensure invariants (no negative XP, etc.)",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write acceptance tests for d20 rules, progression, and loot (TC006–TC010)",
            "description": "Before implementation, author unit and integration tests that codify the core acceptance criteria for the d20 rules engine, including seeded dice behavior and advantage/disadvantage, DC comparisons, conditions effects, XP and level progression curves, loot distribution with deterministic seeding, and alliance/team modifier hooks. Include golden tests for XP curves and loot tables, fuzz tests for invariants (no negative XP, bounded probabilities), and at least one integration test simulating a full check-to-reward flow.",
            "dependencies": [],
            "details": "Create a new test suite in shared module (pure TS, deterministic). Use Jest/Vitest with seedable RNG stub. Tests:\n- TC006: Dice roller determinism with seed; uniform distribution sanity; advantage/disadvantage selects max/min correctly; tie handling defined.\n- TC007: DC compare: success/critical success/critical failure rules; modifiers stacking order; bounded final results.\n- TC008: Conditions: apply/remove; stacking policy; turn-based tick; effects on checks (e.g., disadvantage from Blinded), immunity handling; serialization round-trip.\n- TC009: XP/Levels: define XP curve; level-up thresholds; gained XP cannot be negative; level computation pure/idempotent; golden snapshot for levels 1–20.\n- TC010: Loot: seeded drop tables; rarity weights; pity/guarantees if applicable; quantity ranges; team/alliance modifiers hook applied; golden snapshot for representative seeds.\n- Integration: Given character with conditions + modifiers, perform check vs DC, award XP and loot deterministically for a given seed; verify outputs stable.\n- Fuzz: Randomized seeds across 10k trials validate invariants (no negative XP, loot weights sum, probabilities within tolerance).\nInclude coverage thresholds >80% lines for this module. Tag tests with TC IDs and map into Task 26 harness.",
            "status": "pending",
            "testStrategy": "Run unit + integration tests locally and in CI. Use golden files for XP/loot outcomes. Statistical assertions use confidence bounds; seed fixed for reproducibility. Ensure at least one integration test exercises full pipeline."
          },
          {
            "id": 2,
            "title": "Implement deterministic seedable RNG and dice roller with advantage/disadvantage",
            "description": "Create a pure, side-effect-free dice module supporting d20 rolls with seedable RNG, advantage/disadvantage, and roll metadata for auditing.",
            "dependencies": [
              "11.1"
            ],
            "details": "Implement RNG: xoshiro128** or Mulberry32 with explicit seed input and next() returning [0,1). Interfaces:\n- RNG { next(): number, fork(label:string): RNG } to derive independent streams deterministically via hash(seed,label).\nDice API:\n- rollD20(rng, options:{adv?:boolean, dis?:boolean}) -> {value:number, detail:{rolls:number[], mode:'normal'|'adv'|'dis', seedTrace:string[]}}\n- roll(n,sides,rng, sum|keepHighest/keepLowest k) for reuse.\nRules: advantage = max of two d20; disadvantage = min of two; if both provided, resolve precedence as config (default: they cancel to normal). Ensure no global state; all functions pure.\nInclude distribution helpers for tests.",
            "status": "pending",
            "testStrategy": "Run TC006. Verify deterministic outputs for fixed seeds; validate advantage/disadvantage semantics and tie handling; basic chi-square sanity within tolerance over many trials."
          },
          {
            "id": 3,
            "title": "Implement DC comparison and result grading",
            "description": "Provide pure functions to compute final check result given a d20 roll, modifiers, and DC, returning success tiers and critical rules.",
            "dependencies": [
              "11.1",
              "11.2"
            ],
            "details": "API:\n- computeCheck({baseRoll:number, modifiers:number[], dc:number, critRange?:{nat1CritFail?:boolean,nat20CritSuccess?:boolean, margin?:number}}, options?:{capTotal?:{min?:number,max?:number}}) -> {total:number, degree:'crit-fail'|'fail'|'success'|'crit-success', breakdown}\nRules: total = baseRoll + sum(modifiers). Degree: compare total vs DC with configurable margin for crit thresholds (e.g., ≥DC+10 crit success, ≤DC-10 crit fail). Natural 1/20 overrides if enabled. Provide breakdown object listing contributions. No mutation.",
            "status": "pending",
            "testStrategy": "Run TC007. Unit tests cover edges: DC equal, large modifiers, caps, natural 1/20 overrides, conflicting margins."
          },
          {
            "id": 4,
            "title": "Model conditions and effects framework",
            "description": "Define a condition state model and effect application pipeline that can modify dice behavior and modifiers (e.g., impose disadvantage, grant bonuses), with deterministic serialization.",
            "dependencies": [
              "11.1",
              "11.2",
              "11.3"
            ],
            "details": "Data:\n- Condition { id, name, stacks:boolean, maxStacks?:number, duration?:{turns?:number, expiresAt?:number}, tags:string[], effects: Effect[] }\n- Effect types: {type:'modifier', value:number, scope:'check'|'skill'|'attack'|'save'} | {type:'dice-mode', mode:'adv'|'dis'} | {type:'immunity', tag:string} | {type:'restriction', ruleId}\nState:\n- CharacterState { conditions: AppliedCondition[] }\nPure API:\n- applyCondition(state, condition, now)->state; removeCondition(state,id)->state; tick(state)->state; resolveCheckContext(state, checkInput)-> {modifiers:number[], dice:{adv?:boolean, dis?:boolean}, immunities:string[]}\nStacking policy: if stacks=false, refresh duration; if stacks=true, increment up to maxStacks and scale modifier if defined per stack.\nSerialization: toJSON/fromJSON stable and versioned.",
            "status": "pending",
            "testStrategy": "Run TC008. Unit tests for apply/remove, stacking, duration tick, dice-mode effect precedence, immunity preventing effects, and serialization round-trip."
          },
          {
            "id": 5,
            "title": "Implement XP curve and level computation",
            "description": "Provide deterministic, pure functions to compute XP required per level, accumulate XP, and derive level from total XP with golden curve support.",
            "dependencies": [
              "11.1"
            ],
            "details": "API:\n- xpForLevel(level:number, scheme:'linear'|'quadratic'|'custom', custom?:number[]) -> number\n- levelForXp(xp:number, scheme, custom?) -> number\n- grantXp(currentXp:number, gained:number)->number ensuring gained>=0 by clamping and guarding overflow.\nInclude default curve for levels 1–20 (configurable). Provide table generation utility for golden snapshot testing.",
            "status": "pending",
            "testStrategy": "Run TC009. Verify monotonic xpForLevel, levelForXp inverses on table points, no negative XP, golden snapshot for default 1–20."
          },
          {
            "id": 6,
            "title": "Implement loot tables and deterministic distribution",
            "description": "Create loot table structures with weighted choices, quantity ranges, rarity categories, and seeded deterministic sampling, plus team/alliance modifier hooks.",
            "dependencies": [
              "11.1",
              "11.2",
              "11.4"
            ],
            "details": "Data:\n- LootTable { id, entries: LootEntry[], pity?:{counterKey:string, threshold:number, reward:LootEntry} }\n- LootEntry { id, itemId, weight:number, qty:{min:number,max:number}, tags:string[], modifiers?:{teamBonus?:number, allianceBonus?:number} }\nAPI:\n- rollLoot(table:LootTable, rng, context:{teamId?:string, allianceId?:string, hooks?:HookFns}) -> LootResult\n- weightedPick deterministic via cumulative weights; quantity via RNG; apply hooks from alliances module via provided hook functions (no import dependency): e.g., hooks.getTeamModifier(teamId) returns multiplier.\n- Support multi-drop and pity: maintain counters via caller-provided state object; engine remains pure by returning updated counters as part of result.",
            "status": "pending",
            "testStrategy": "Run TC010. Golden tests for specific seeds; verify weights respected over many trials; verify team/alliance modifiers applied; pity triggers at threshold deterministically."
          },
          {
            "id": 7,
            "title": "Compose check pipeline: state -> roll -> compare -> rewards",
            "description": "Provide a high-level pure function that, given character state, DC, and RNG, produces a full check outcome including applied conditions, d20 roll with (dis)advantage, DC result, and reward hooks (XP and loot) without side effects.",
            "dependencies": [
              "11.2",
              "11.3",
              "11.4",
              "11.5",
              "11.6"
            ],
            "details": "API:\n- performCheck(input:{state:CharacterState, baseModifiers:number[], dc:number, rng:RNG, xpReward:number, lootTable?:LootTable, lootContext?:{}, options?:{critMargin?:number}}) -> {roll:{value, detail}, result:{total, degree}, rewards:{xp:number, loot?:LootResult}, stateUpdates:{conditions?:AppliedCondition[]}, audit:{seedTrace, breakdown}}\nFlow:\n1) resolveCheckContext -> merge base modifiers with condition-derived modifiers; compute dice mode.\n2) rollD20 with mode.\n3) computeCheck to determine degree.\n4) award XP: grantXp(currentXp, xpReward adjusted by degree if rules specify multipliers).\n5) optional rollLoot with provided table and context hooks.\nNo external state written; return all data and any updated counters via result.",
            "status": "pending",
            "testStrategy": "Extend integration test to call performCheck and assert deterministic full pipeline outputs for fixed seeds; verify invariants (no negative XP, loot deterministic)."
          },
          {
            "id": 8,
            "title": "Define alliance/team modifier hook interfaces",
            "description": "Publish minimal hook interfaces in shared module that the alliances/teams feature can implement to adjust modifiers, XP, or loot without creating a hard dependency.",
            "dependencies": [
              "11.1",
              "11.6",
              "11.7"
            ],
            "details": "Define types:\n- HookFns { getTeamModifier?(teamId:string, context:any): number, getAllianceModifier?(allianceId:string, context:any): number, adjustXp?(xp:number, context:any): number }\nAll rule engine public APIs accept an optional hooks:HookFns parameter and must apply these adjustments in a documented, deterministic order (team then alliance then cap). Provide no-op defaults. Ensure that serialization of context excludes functions.",
            "status": "pending",
            "testStrategy": "Unit tests verify that when hooks are provided, outputs are scaled accordingly and order-of-operations is respected. Extend integration test to include mock hooks and validate results."
          },
          {
            "id": 9,
            "title": "Golden data generators and snapshot fixtures",
            "description": "Implement utilities to generate golden fixtures for XP curves and loot outcomes, and wire snapshot testing helpers to prevent regressions.",
            "dependencies": [
              "11.1",
              "11.5",
              "11.6"
            ],
            "details": "Create generator functions:\n- generateXpTable(levels:number, scheme) -> number[]\n- generateLootOutcomes(table, seeds:string[], context) -> LootResult[]\nStore snapshots under tests/__golden__/ with stable JSON serialization (sorted keys). Provide compare helper that pretty-diffs deviations and suggests update via explicit flag.",
            "status": "pending",
            "testStrategy": "Run golden tests in TC009/TC010 to verify snapshots. Manual review required on intended changes."
          },
          {
            "id": 10,
            "title": "Fuzz and property-based tests for invariants",
            "description": "Add property-based tests across dice, DC grading, conditions, XP, and loot to ensure invariants hold and detect edge cases.",
            "dependencies": [
              "11.1",
              "11.2",
              "11.3",
              "11.4",
              "11.5",
              "11.6",
              "11.7"
            ],
            "details": "Use fast-check (or similar) to generate random seeds, modifiers, DCs, and condition sets. Properties:\n- Dice: values in [1,20], advantage >= normal, disadvantage <= normal.\n- DC grading: monotonic w.r.t increasing modifiers; crit-success implies success; crit-fail implies fail.\n- Conditions: serialization round-trip; stacking never exceeds max; dice-mode resolution deterministic.\n- XP: non-negative, non-decreasing with gains; levelForXp(xpForLevel(n)) == n.\n- Loot: weights normalized; probabilities approximate weights over large N; pity triggers within threshold.\nKeep tests deterministic with seeded generators.",
            "status": "pending",
            "testStrategy": "Execute property tests in CI as part of this module’s suite with time budget controls. Fail on counterexamples with minimized cases saved."
          },
          {
            "id": 11,
            "title": "Documentation and examples for the rules engine APIs",
            "description": "Provide concise API docs and example usage covering common flows: rolling checks with conditions, computing levels, and generating loot, emphasizing purity and determinism.",
            "dependencies": [
              "11.2",
              "11.3",
              "11.4",
              "11.5",
              "11.6",
              "11.7",
              "11.8",
              "11.9",
              "11.10"
            ],
            "details": "Add TSDoc comments to all public types/functions. Write examples in a docs/examples folder demonstrating: seeded roll with advantage; applying a condition; performing a check with hooks; generating XP table; rolling loot with team modifier. Include guidance on seeding, forking RNGs, and integrating hooks from alliances. Note no side effects and no global state.",
            "status": "pending",
            "testStrategy": "Run examples in a small doc-test harness to ensure they compile and produce expected outputs with fixed seeds."
          }
        ]
      },
      {
        "id": 12,
        "title": "Vector Memory with Per-Player Privacy and Campaign Memory",
        "description": "Provide vector memory supporting episodic/semantic/declarative/procedural types with strict per-player isolation and shared campaign memory.",
        "details": "- Namespaces: campaign:<id>, player:<id>\n- Hybrid retrieval: BM25 (sqlite fts5) + vector; rerank with small local model or LLM if available\n- Summarization pipeline promotes memories to campaign memory per policy\n- Redaction of PII before storage; policies configurable\n- API: write_memory, retrieve(query, scope), promote",
        "testStrategy": "- TC007: enforce per-player isolation in queries\n- TC008: recall relevance tests with seeded corpus and summarization correctness checks\n- Bench: retrieval latency under target",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Acceptance Tests for Vector Memory, Privacy, and Promotion (TC007, TC008, Perf)",
            "description": "Write unit and integration tests that capture the core acceptance criteria before implementation. Cover per-player isolation (TC007), hybrid retrieval relevance and summarization/promotion correctness (TC008), namespace scoping, PII redaction policies, and performance benchmarks for retrieval latency. Stub/mock embeddings and reranker to make tests deterministic.",
            "dependencies": [],
            "details": "Implement tests in two layers: (a) unit tests for API surface and policy logic, (b) integration tests over SQLite+FTS5 and a pluggable vector index with in-memory dataset. Seed a small corpus with memories across namespaces campaign:42, player:101, player:202, with types episodic/semantic/declarative/procedural and metadata. Add a seeded query set with expected relevant IDs. Provide a mock EmbeddingsProvider returning fixed vectors; provide a stub Reranker that returns input order unless score margins enforce swaps. Include PII samples (email, phone, address) to verify redaction pre-storage and retrieval. Define tests: - TC007: retrieve(scope=\"player\", playerId=101) never returns data from player:202 or other campaigns; retrieve(scope=\"campaign\", campaignId=42) may return campaign namespace but not any other campaign or players from other campaigns. - TC008a: Hybrid retrieval returns top-k containing at least N of expected relevant items given seeded BM25+vector mix; assert reranker improves MRR@k over unreranked baseline on seeded set. - TC008b: Summarization pipeline produces concise summary and promotion to campaign memory obeys policy (e.g., if item meets threshold and not PII-blocked). - Policy Redaction: verify PII is removed or masked in stored memory content and summaries; raw input never stored. - API contract: write_memory, retrieve(query, scope), promote. - Latency bench: vector+BM25 end-to-end under target (e.g., p50 < 60 ms local, adjustable via env). - Determinism: snapshot tests for summary schema and metadata fields. Provide fixtures and helpers to reset DB between tests.",
            "status": "pending",
            "testStrategy": "Use Jest/Vitest (Node) with sqlite3/better-sqlite3 in temp files. Seed DB in beforeAll, clean in afterEach. For performance, run 100 queries and compute p50/p95; mark as skipped in CI if no perf env. Add property-based tests for namespace isolation. Use data-driven table tests to cover types and scopes."
          },
          {
            "id": 2,
            "title": "Design Memory Schema, Namespaces, and Index Abstractions",
            "description": "Define DB schema for memories and supporting tables, and the abstraction interfaces for vector index and reranking to support campaign:<id> and player:<id> namespaces.",
            "dependencies": [
              "12.1"
            ],
            "details": "Add/extend tables: memories(id PK, namespace TEXT, campaign_id INTEGER, player_id INTEGER NULL, type TEXT CHECK IN('episodic','semantic','declarative','procedural'), content TEXT, content_redacted TEXT, metadata JSON, created_at, updated_at, embedding BLOB/VSS column if using sqlite-vss, bm25_doc TEXT for FTS). memory_summaries(id PK, source_memory_id FK, namespace TEXT, summary TEXT, metadata JSON, created_at). memory_promotions(id PK, source_memory_id, target_namespace TEXT, policy_id TEXT, reason TEXT, created_at). pii_redaction_logs(id, memory_id, fields JSON, policy_version). Create FTS5 virtual table memories_fts(content_redacted, metadata) with content='memories', content_rowid='id'. Define VectorIndex interface: upsert(vector, id, namespace, metadata), query(vector, namespace, k, filter), delete(id, namespace), flush. Provide namespace as exact match partition key. Define HybridRetriever composing: - BM25 via FTS5 MATCH query scoped by namespace - Vector via VectorIndex.query - Fusion mechanism (e.g., reciprocal rank fusion) before rerank. Define Reranker interface with rerank(query, docs) supporting local small model or no-op. Document scope: 'player' resolves to namespace=player:<id>, 'campaign' to campaign:<id>. Ensure columns to enforce campaign_id consistency with namespace.",
            "status": "pending",
            "testStrategy": "Run existing tests; verify schema migration runs and tables exist. Add unit tests for namespace parsing and validation."
          },
          {
            "id": 3,
            "title": "Implement PII Redaction Policy Engine and Transformers",
            "description": "Create a configurable PII redaction pipeline applied before storage that supports masking/removal of emails, phones, addresses, and custom regexes; store redacted content separately and log redaction metadata.",
            "dependencies": [
              "12.1",
              "12.2"
            ],
            "details": "Implement RedactionPolicy with config: { strategies: ['mask','remove'], rules: [builtin.email, builtin.phone, builtin.ssn, builtin.address], customRules: [{name, regex, action}], preserveHints: boolean }. Build redact(text, policy) -> { redactedText, findings:[{type, start,end, original?, replacement}], policyVersion }. Ensure redact is idempotent. Integrate with write_memory transformer chain: normalize whitespace, truncate overly long inputs (configurable), redact according to policy, compute bm25_doc and embedding from redactedText only. Store content as original input? For privacy, do not store original PII: either discard original or store only redacted version; reflect in config to forbid keeping raw. Persist pii_redaction_logs. Provide utility to scrub metadata fields too.",
            "status": "pending",
            "testStrategy": "Unit tests on diverse PII samples verifying matches and replacements; ensure no PII remnants remain by negative regex checks. Verify logs written. Run TC008 policy redaction tests."
          },
          {
            "id": 4,
            "title": "Implement Embeddings Provider and VectorIndex Adapter with Namespaces",
            "description": "Provide an EmbeddingsProvider abstraction with a default local/small model or stub and implement a VectorIndex adapter for sqlite-vss with FAISS fallback, enforcing namespace partitioning.",
            "dependencies": [
              "12.1",
              "12.2"
            ],
            "details": "EmbeddingsProvider: interface embed(text|texts[], dim), deterministic mode for tests (hash-based vector) and real mode (pluggable). VectorIndexSqliteVSS: create vss0 table per memories or a single table with namespace column; ensure index supports cosine similarity. Implement upsert/query/delete using namespace WHERE clause and optional metadata filters (e.g., type). FAISS fallback behind same interface stored in files per namespace directory. Ensure migrations create vss indexes and FTS5 view. Implement health checks and graceful no-vector mode where hybrid falls back to BM25 only.",
            "status": "pending",
            "testStrategy": "Vector unit tests for insert/query cosine similarity, namespace isolation, and deletion. Run TC007 isolation with vector path active and inactive."
          },
          {
            "id": 5,
            "title": "Build Hybrid Retrieval (BM25 + Vector) with Fusion and Optional Reranking",
            "description": "Compose BM25 via FTS5 and VectorIndex results into a unified ranked list using reciprocal rank fusion, then optionally rerank with a local model or pass-through fallback.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.4"
            ],
            "details": "Implement HybridRetriever.retrieve(query, scope, k, filters) -> results[]. Steps: - Resolve namespaces from scope. - Generate query embedding. - Query FTS5 with MATCH across content_redacted and metadata fields, constrained by namespace and filters; collect top N_bm25 with scores. - Query VectorIndex for top N_vec. - Normalize scores and apply Reciprocal Rank Fusion (RRF) with tunable k parameter; de-duplicate by id. - If Reranker available, rerank top M with query and snippets. - Fetch full records, include highlights from FTS5 offsets. Ensure deterministic behavior in tests. Provide configs for weights. Handle missing vector index or embeddings gracefully.",
            "status": "pending",
            "testStrategy": "Integration tests from TC008a check recall and MRR improvement. Unit tests for fusion correctness on synthetic lists. Run latency bench to ensure under target for small corpora."
          },
          {
            "id": 6,
            "title": "Implement Memory Types, Write Path, and API: write_memory",
            "description": "Create the write_memory API to accept memory entries with types, apply redaction, compute embeddings, and index into FTS and vector stores within namespaces.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.3",
              "12.4"
            ],
            "details": "API write_memory(input): { campaignId, playerId?, type, content, metadata } -> returns memoryId, namespace, redactionSummary. Steps: - Validate type in allowed set; require campaignId; playerId optional; derive namespace. - Apply redaction policy; compute embedding on redacted text. - Insert into memories with content_redacted as stored content; bm25_doc mirrors content_redacted. - Upsert into VectorIndex with namespace and metadata filters. - Index into FTS5. - Return identifiers and redaction findings. Ensure transactional integrity across DB and vector index; rollback on failure.",
            "status": "pending",
            "testStrategy": "Unit tests verifying insert success, redaction applied, correct namespace, and index calls. Integration tests that subsequent retrieval finds the item in correct scope. Run existing tests."
          },
          {
            "id": 7,
            "title": "Implement Retrieval API: retrieve(query, scope)",
            "description": "Expose retrieve API that accepts query and scope (player or campaign), resolves namespaces, executes hybrid retrieval, and returns ranked results with snippets and metadata.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.5"
            ],
            "details": "API retrieve({query, scope: {type:'player'|'campaign', campaignId, playerId?}, k, filters, rerank:boolean}). Validate scope; map to one or more namespaces (player maps to a single player:<id>, campaign maps to campaign:<id>). Use HybridRetriever to fetch results. Return: [{id, type, namespace, score, snippet, metadata}]. Enforce per-player isolation by never including other players' namespaces when scope=player. Ensure campaign scope includes only campaign:<id> namespace, not players' private memories unless policy allows (default: exclude).",
            "status": "pending",
            "testStrategy": "Integration tests for TC007 and TC008 run through public API. Add negative tests ensuring cross-campaign leakage does not occur. Run tests."
          },
          {
            "id": 8,
            "title": "Summarization and Promotion Pipeline",
            "description": "Implement a pipeline that summarizes selected memories and promotes them to campaign memory according to configurable policies.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.3",
              "12.6",
              "12.7"
            ],
            "details": "Define PromotionPolicy: thresholds (e.g., frequency, recency, access count, type whitelist), size limits, and PII gate (block if findings present). Implement summarize(memory|batch) using a pluggable Summarizer interface: default rule-based/LLM adapter; operate only on redacted content. Promotion flow: evaluate candidates (e.g., after N accesses or explicit promote call), generate summary, write to campaign:<campaignId> namespace via write_memory with type=semantic or declarative per policy, record in memory_promotions with policy_id and reason. Ensure deduplication (hash summaries), and link back with source_memory_id.",
            "status": "pending",
            "testStrategy": "TC008b: verify summary created, meets schema, and promotion stored only when policy passes; ensure blocked when PII present. Snapshot test for summary fields. Run tests."
          },
          {
            "id": 9,
            "title": "Implement promote API and Policy Enforcement",
            "description": "Expose promote API to allow explicit promotion of player memories to campaign memory while enforcing policy and privacy gates.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.6",
              "12.8"
            ],
            "details": "API promote({memoryId, campaignId, policyOverride?}). Steps: - Fetch memory; verify it belongs to the same campaign as target. - Check policy (type whitelist, PII gate, dedupe). - Summarize if required; write to campaign namespace via write_memory; record promotion entry. - Return promoted record reference. Log decision outcomes.",
            "status": "pending",
            "testStrategy": "Unit tests for policy branches (allow, block, dedupe). Integration test that promotion results are retrievable in campaign scope but not in other campaigns. Run tests."
          },
          {
            "id": 10,
            "title": "Reranker Integration with Local Model or LLM Fallback",
            "description": "Plug in an optional reranker component to reorder the fused results using a small local model when available, otherwise no-op or LLM API when configured.",
            "dependencies": [
              "12.1",
              "12.5"
            ],
            "details": "Implement Reranker interface adapters: LocalCrossEncoderReranker (if packaged) and LLMBasedReranker (budget-guarded). Add capability detection and configuration. Ensure deterministic behavior in tests by using a mock reranker. Provide timeouts and graceful degradation to baseline fusion if reranker unavailable.",
            "status": "pending",
            "testStrategy": "Unit tests for adapter selection and no-op fallback. Integration test showing improved ordering on synthetic dataset. Run tests."
          },
          {
            "id": 11,
            "title": "Access Control and Namespace Enforcement Middleware",
            "description": "Add a guard layer ensuring APIs only access allowed namespaces derived from input scope and session context, preventing cross-player data access.",
            "dependencies": [
              "12.1",
              "12.7"
            ],
            "details": "Implement a middleware/utility that derives allowedNamespaces from {campaignId, playerId, scope.type}. Validate every request: - write_memory requires campaignId and optional playerId; verify caller has rights. - retrieve restricts namespace list strictly. - promote checks campaign match and policy gate. Provide audit logging on denials.",
            "status": "pending",
            "testStrategy": "Unit tests stubbing session context to verify denials on mismatched IDs and allowed paths for correct scopes. Re-run TC007 to ensure isolation still holds."
          },
          {
            "id": 12,
            "title": "Observability, Telemetry, and Latency Bench Hooks",
            "description": "Instrument memory operations with timings, counters, and tracing to support latency acceptance and debugging.",
            "dependencies": [
              "12.1",
              "12.5",
              "12.7"
            ],
            "details": "Add metrics: write_memory duration, retrieve total, FTS5 time, vector time, rerank time, fusion time, promotions count, policy blocks. Add histograms and p50/p95. Integrate simple tracing spans. Expose a diagnostics endpoint to dump recent metrics (redaction-safe). Wire benchmarks used by tests.",
            "status": "pending",
            "testStrategy": "Perf tests from TC008 and bench run read metrics to assert p50 target. Unit tests for metrics emission using a test sink."
          },
          {
            "id": 13,
            "title": "Data Migration and Backfill Utilities",
            "description": "Provide scripts to migrate existing memories to include redacted content, embeddings, and to populate vector/FTS indexes with namespaces.",
            "dependencies": [
              "12.2",
              "12.3",
              "12.4",
              "12.6"
            ],
            "details": "Write CLI: mem-migrate --reindex --redact --namespace-fix. Steps: scan memories, apply redaction if missing, compute embeddings, upsert into vector index, update FTS5. Support dry-run and progress logging. Handle large batches with pagination.",
            "status": "pending",
            "testStrategy": "Integration test on a temp DB populated with legacy-like rows; after migration, retrieval works and PII absent. Run tests."
          },
          {
            "id": 14,
            "title": "Configuration, Policies, and Feature Flags",
            "description": "Centralize configuration for redaction, retrieval fusion weights, reranker toggle, promotion policy, and fallback behaviors with safe defaults.",
            "dependencies": [
              "12.3",
              "12.5",
              "12.8",
              "12.10"
            ],
            "details": "Implement config loader supporting env and file-based overrides. Keys: MEMORY_REDACTION_POLICY, HYBRID_WEIGHTS, RERANKER_MODE, PROMOTION_POLICY, NAMESPACE_RULES, LATENCY_TARGETS. Add validation and config hot-reload if supported. Tie into A/B harness later.",
            "status": "pending",
            "testStrategy": "Unit tests for config parsing and defaulting; integration smoke where toggling reranker changes behavior. Re-run test suite with different configs."
          },
          {
            "id": 15,
            "title": "Security Review: No Raw PII Storage and Audit",
            "description": "Ensure that raw PII is never persisted, secrets are not leaked in logs, and access paths are audited.",
            "dependencies": [
              "12.3",
              "12.6",
              "12.11"
            ],
            "details": "Add safeguards: prohibit storing original content when policy forbids; scrub logs; add DB scan utility to assert no PII patterns exist. Implement audit events for cross-namespace access attempts and promotions. Document threat model and controls.",
            "status": "pending",
            "testStrategy": "Run DB scan test to confirm absence of PII patterns in stored fields. Unit tests for logger scrub. Negative tests triggering audit on denied access."
          },
          {
            "id": 16,
            "title": "Documentation and Developer Examples",
            "description": "Provide developer docs and runnable examples demonstrating write, retrieve by scope, and promotion flow, including configuration of policies.",
            "dependencies": [
              "12.6",
              "12.7",
              "12.8",
              "12.9",
              "12.14"
            ],
            "details": "Write README with API contracts, scope semantics, memory types, and examples. Include a sample script that seeds memories for two players in one campaign, runs queries, shows isolation, and promotes a memory to campaign. Document performance tips and limitations.",
            "status": "pending",
            "testStrategy": "Execute examples as part of CI to ensure they run without errors. Validate outputs contain expected IDs and namespaces."
          }
        ]
      },
      {
        "id": 13,
        "title": "Event Sourcing and Snapshots with Resume/Branch",
        "description": "Persist event-sourced state with periodic snapshots; allow resume and branching timelines from any snapshot.",
        "details": "- Event store: append-only events table (session_id, seq, type, payload, ts)\n- Snapshot service: periodic every N events/time; store snapshot blob and hash\n- Replay engine reconstructs state; branch creates new session from snapshot with pointer to parent\n- UI: branch action in session history",
        "testStrategy": "- TC009: snapshot+replay deterministic state vs live\n- TC010: branch creation yields isolated new session; no leakage\n- Corruption tests: invalid snapshot hash triggers fallback replay",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write acceptance tests for snapshots, replay determinism, branching, and corruption handling",
            "description": "Create unit and integration/UI tests that define the acceptance criteria for event sourcing with snapshots, resume, and branching. Include tests for deterministic replay from events vs snapshot+delta (TC009), branch creation isolation (TC010), and corruption handling where invalid snapshot hash triggers full replay fallback. Add UI test for branch action in session history. No implementation yet; tests should initially fail.",
            "dependencies": [],
            "details": "• Tech stack: TypeScript/Node, Jest (unit), Playwright (UI), and a lightweight in-memory SQLite or better-sqlite3 for integration tests.\n• Define fixtures: sample event types (type, payload), sessions, and snapshot blobs. Use seeded timestamps and sequences.\n• Unit tests:\n  - TC009-UNIT: Given a session with N events and snapshots every k events, reconstruct state via: (a) full replay; (b) latest snapshot + replay of subsequent events; assert deep equality of states and version.\n  - TC010-UNIT: Branch from snapshot S to new session B; append events to B; assert no changes in parent session events or state; ensure branch has parent pointer.\n  - Corruption-UNIT: Tamper snapshot blob or stored hash; assert engine detects hash mismatch and falls back to full replay; log/metric is emitted.\n  - Sequencing: Ensure seq strictly increases per session; inserting out-of-order should be rejected.\n  - Idempotency: Re-applying same event seq should be no-op and duplicates with same seq rejected.\n• Integration tests (Jest with real sqlite):\n  - TC009-INT: Populate events table; run snapshot service policy (every N events); verify read path boots from snapshot and only queries deltas.\n  - TC010-INT: Create branch from snapshot; write subsequent events to branch; query both sessions and verify isolation at DB-level.\n  - Corruption-INT: Manually flip snapshot hash; ensure read falls back to full replay and records an audit entry.\n• UI test (Playwright):\n  - TC010-UI: In session history page, click Branch on a snapshot row; verify new session appears with parent pointer and timeline starts at branched state.\n• Add verification ID tags in test names/comments: [TC009], [TC010].",
            "status": "pending",
            "testStrategy": "Run Jest unit/integration suites and Playwright UI tests in CI. Expect tests to fail until implementation exists."
          },
          {
            "id": 2,
            "title": "Design and migrate relational schema for events, snapshots, and branches",
            "description": "Create or migrate the database schema to support append-only events, snapshots with integrity hashes, and session branching pointers. Ensure constraints enforce sequencing, immutability, and referential integrity.",
            "dependencies": [
              "13.1"
            ],
            "details": "• Tables:\n  - sessions(id PK, parent_session_id NULL FK->sessions(id), created_at, metadata JSON)\n  - events(id PK, session_id FK->sessions(id), seq INTEGER, type TEXT, payload JSON, ts INTEGER, UNIQUE(session_id, seq)) with CHECK(seq>0)\n  - snapshots(id PK, session_id FK->sessions(id), upto_seq INTEGER, blob BLOB, hash TEXT, created_at, UNIQUE(session_id, upto_seq))\n• Indexes: events(session_id, seq), snapshots(session_id, upto_seq DESC), sessions(parent_session_id).\n• Triggers/constraints:\n  - Prevent DELETE/UPDATE on events.type/payload/seq/ts after insert (soft enforcement via application + optional DB trigger).\n  - Ensure snapshots.upto_seq corresponds to an existing event seq per session (FK-like via deferred trigger).\n• Migration scripts: up/down SQL; seed dev data.\n• Data size: ensure blob column uses efficient storage (e.g., SQLite BLOB; Postgres bytea if applicable).",
            "status": "pending",
            "testStrategy": "Integration tests from 13.1 run migrations in test DB and validate constraints by attempting invalid inserts (e.g., duplicate seq, missing parent) and expecting failures."
          },
          {
            "id": 3,
            "title": "Implement append-only EventStore with optimistic concurrency",
            "description": "Build a repository/service to append and read ordered events per session with sequence guarantees, and to guard against duplicates and race conditions using expected sequence checks.",
            "dependencies": [
              "13.1",
              "13.2"
            ],
            "details": "• API (TypeScript):\n  - appendEvents(sessionId, expectedLastSeq, events: {type, payload, ts}[]): returns {lastSeq}\n  - readEvents(sessionId, fromSeqInclusive): returns ordered array\n  - createSession(parentSessionId?, metadata?): returns sessionId\n• Implementation:\n  - Use a transaction to compute next seq = COALESCE(MAX(seq),0)+1, compare against expectedLastSeq+1 for first event; assign increasing seq for batch.\n  - Enforce immutability: no updates to stored events; only inserts allowed.\n  - Validate payload JSON schema per event type (pluggable validators).\n• Telemetry: counters for appends, rejects, latency.",
            "status": "pending",
            "testStrategy": "Run tests: sequencing and idempotency tests from 13.1 should now pass for EventStore behaviors. Add race test using parallel appends expecting one to fail with concurrency error."
          },
          {
            "id": 4,
            "title": "Implement SnapshotStore with hash integrity and retention policy",
            "description": "Create service to persist and fetch latest snapshot per session, compute and verify hashes, and enforce retention (keep last M or by age).",
            "dependencies": [
              "13.1",
              "13.2"
            ],
            "details": "• API:\n  - saveSnapshot(sessionId, uptoSeq, stateBlob: Uint8Array): returns {id, hash}\n  - getLatestSnapshot(sessionId): returns {uptoSeq, blob, hash} | null\n  - verifySnapshot({blob, hash}): boolean\n• Hashing: SHA-256 over canonicalized blob bytes. Include sessionId and uptoSeq in the hash preimage to prevent cross-session substitution.\n• Retention: configurable M and TTL; delete older snapshots beyond policy in a background job.\n• Store blob as compressed (e.g., gzip) for size; record encoding in metadata if needed.",
            "status": "pending",
            "testStrategy": "From 13.1 corruption tests: tamper hash to force verifySnapshot=false and assert the replay engine falls back. Add unit tests to ensure save and retrieval round-trip with matching hash."
          },
          {
            "id": 5,
            "title": "Build SnapshotPolicy scheduler (periodic every N events and/or time)",
            "description": "Implement policy engine to decide when to snapshot a session based on thresholds: every K events, and/or every T minutes since last snapshot or since session start.",
            "dependencies": [
              "13.1",
              "13.3",
              "13.4"
            ],
            "details": "• Inputs: thresholds {eventsEveryK, timeEveryTms}. Track last snapshot seq and timestamp per session.\n• On each appendEvents success, evaluate policy: if events since last snapshot >= K or time since last snapshot >= T, enqueue snapshot job for that session.\n• Use job queue (in-memory or lightweight queue) to decouple from write path; batchable.\n• Provide dry-run mode for testing to snapshot synchronously.",
            "status": "pending",
            "testStrategy": "Integration tests seed sessions and append events crossing thresholds; assert snapshot jobs were produced and snapshots saved at expected uptoSeq values. Ensure no duplicate snapshots for same uptoSeq."
          },
          {
            "id": 6,
            "title": "Implement deterministic Reducer and ReplayEngine",
            "description": "Create a pure, deterministic reducer to apply events to state and a replay engine that loads from latest snapshot when present, validates hash, and applies remaining events. On hash failure, fall back to full replay and flag snapshot as corrupted.",
            "dependencies": [
              "13.1",
              "13.3",
              "13.4"
            ],
            "details": "• Reducer signature: reduce(currentState, event) -> nextState, with serialization-stable state.\n• ReplayEngine API:\n  - loadState(sessionId): returns {state, uptoSeq}\n  - rebuildFromSnapshot(snapshot): verify hash; if invalid, mark corrupted and rebuild from seq=0; else apply events from uptoSeq+1.\n• Determinism:\n  - No wall-clock usage during reduce; use event.ts exclusively.\n  - Ensure stable ordering by seq; guard against gaps or duplicates.\n• Corruption handling:\n  - If hash mismatch, record incident row (snapshots_corrupted) and emit metric.\n  - Optionally re-create a fresh snapshot after full replay.",
            "status": "pending",
            "testStrategy": "Run TC009 unit/integration tests. Add unit test where reducer is applied across two paths (full vs snapshot+delta) and yields identical state object structure and checksum."
          },
          {
            "id": 7,
            "title": "Implement Branching: create new session from snapshot",
            "description": "Enable branching a session timeline from any snapshot. The branch starts with the state of the chosen snapshot and references the parent session.",
            "dependencies": [
              "13.1",
              "13.2",
              "13.4",
              "13.6"
            ],
            "details": "• API:\n  - createBranch(parentSessionId, snapshotSeq, metadata?): returns newSessionId\n• Steps:\n  - Load snapshot at or before snapshotSeq (exact preferred; else pick latest <= snapshotSeq), verify hash; if invalid, rebuild to snapshotSeq and produce a fresh branch base state.\n  - Create new session row with parent_session_id=parentSessionId and metadata including branchOriginSeq.\n  - Option A (no initial events in branch): Store an initial branch snapshot blob representing state at snapshotSeq with uptoSeq=0 for branch, or store origin metadata and compute state via parent snapshot when first read.\n  - Ensure subsequent events appended to branch are isolated under new session_id and start seq at 1.\n• Permissions/hooks: check access if needed.",
            "status": "pending",
            "testStrategy": "Run TC010 unit/integration tests to validate isolation: appending to branch must not change parent state or events. Verify parent pointer and branch origin metadata are persisted."
          },
          {
            "id": 8,
            "title": "Expose Resume/Read API with snapshot-aware fast path",
            "description": "Provide a high-level API for clients to resume a session by reconstructing current state using snapshot+delta and to read session timelines efficiently.",
            "dependencies": [
              "13.6",
              "13.3",
              "13.4"
            ],
            "details": "• API:\n  - resume(sessionId): returns {state, lastSeq}\n  - getTimeline(sessionId, {fromSeq, limit}): returns events page\n• Implementation:\n  - resume delegates to ReplayEngine.loadState.\n  - getTimeline streams events with pagination sorted by seq.\n• Caching: optional in-memory cache keyed by (sessionId, uptoSeq) to avoid repeated replays within a request scope.",
            "status": "pending",
            "testStrategy": "Integration tests calling resume on sessions with/without snapshots, ensuring correctness and performance (fewer queries when snapshots exist)."
          },
          {
            "id": 9,
            "title": "Add UI: session history with Branch action and branch visualization",
            "description": "Implement UI elements to show session history with snapshots and provide a Branch action to create a new session from a selected snapshot. Visualize parent-child relationship.",
            "dependencies": [
              "13.1",
              "13.7",
              "13.8"
            ],
            "details": "• UI components:\n  - SessionHistory list showing events and snapshot markers.\n  - For each snapshot row, a Branch button opens a dialog to confirm and enter metadata; on confirm, call createBranch.\n  - After creation, navigate to new session view; display parent pointer and branch origin info.\n• Visualization: simple tree or breadcrumb indicating branch hierarchy.\n• Accessibility and error handling: display hash corruption warnings if snapshot invalidated and fallback occurred.",
            "status": "pending",
            "testStrategy": "Playwright test (TC010-UI) clicks Branch and verifies new session appears with correct parent and isolated timeline."
          },
          {
            "id": 10,
            "title": "Implement snapshot compaction and housekeeping jobs",
            "description": "Background jobs to prune old snapshots per retention, rehydrate and re-snapshot hot sessions, and mark corrupted snapshots for re-creation.",
            "dependencies": [
              "13.4",
              "13.5",
              "13.6"
            ],
            "details": "• Jobs:\n  - RetentionPruner: enforce keep-last-M and TTL per session.\n  - Rehasher: periodically verify hashes of latest snapshots.\n  - Resnapshotter: for sessions with large deltas since last snapshot, generate a fresh snapshot.\n• Scheduling: cron-like scheduler or reuse existing job framework.",
            "status": "pending",
            "testStrategy": "Integration tests create multiple snapshots and verify pruning rules; simulate corruption and ensure re-snapshotting occurs."
          },
          {
            "id": 11,
            "title": "Observability: metrics, logging, and audit for snapshot/replay/branch",
            "description": "Add structured logs, metrics, and audit trails for key operations: appends, snapshot saves, replay paths, branch creation, and corruption events.",
            "dependencies": [
              "13.3",
              "13.4",
              "13.6",
              "13.7",
              "13.8"
            ],
            "details": "• Metrics: counts and latencies for appendEvents, saveSnapshot, loadState (full vs snapshot path), createBranch; gauge for snapshots per session; corruption count.\n• Logs: include session_id, upto_seq, hash, parent_session_id, outcome fields; redact payloads per security policy.\n• Audit table: audits(id, ts, actor, action, session_id, details JSON).",
            "status": "pending",
            "testStrategy": "Add assertions in integration tests that specific metrics/log lines/audit rows are emitted for operations (use test logger/sink)."
          },
          {
            "id": 12,
            "title": "Hardening: concurrency, integrity, and failure scenarios",
            "description": "Handle edge cases like concurrent snapshot creation, out-of-order reads, partial writes, and ensure idempotency and retries.",
            "dependencies": [
              "13.3",
              "13.4",
              "13.5",
              "13.6",
              "13.7"
            ],
            "details": "• Concurrency control: use DB transactions at SERIALIZABLE or REPEATABLE READ; unique (session_id, upto_seq) prevents duplicate snapshots.\n• Snapshot races: only one snapshot per uptoSeq; use INSERT ... ON CONFLICT DO NOTHING.\n• Retry policy for transient DB errors; exponential backoff.\n• Validation: detect gaps in seq during replay; if gaps, error and require maintenance.\n• Large payloads: stream snapshot blob to DB to avoid memory spikes.",
            "status": "pending",
            "testStrategy": "Stress tests with parallel appends and snapshot jobs; assert no duplicate snapshots and no lost events. Fault injection to simulate transient failures and ensure retries succeed."
          },
          {
            "id": 13,
            "title": "Documentation and developer tooling",
            "description": "Provide README and API docs for EventStore, SnapshotStore, ReplayEngine, and Branch API. Add CLI tooling to inspect sessions, list snapshots, verify hashes, and create branches.",
            "dependencies": [
              "13.3",
              "13.4",
              "13.6",
              "13.7",
              "13.8",
              "13.11"
            ],
            "details": "• Docs: architecture overview, data model diagrams, sequence charts for snapshotting and branching, configuration of policies, and how to run tests [TC009, TC010].\n• CLI commands: events:list, snapshots:list, snapshot:verify, branch:create.\n• Examples: sample reducers and state schemas.",
            "status": "pending",
            "testStrategy": "Manual verification by running CLI against test DB; lint docs build."
          }
        ]
      },
      {
        "id": 14,
        "title": "A/B Harness for Model Comparison",
        "description": "Implement A/B evaluation harness across LLM/STT/TTS/Image adapters with metrics capture and toggle per campaign.",
        "details": "- Experiment config: variant allocation, paired or split traffic\n- Capture latency, token usage, quality tags; store in llm_messages/metrics\n- UI: enable per-campaign; view basic charts\n- Safe rollbacks; guardrails for budget limits",
        "testStrategy": "- TC013: structural checks and metrics correctness under simulated runs\n- Unit: allocation reproducibility with seed\n- Load: run concurrent experiments without cross-talk",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for A/B harness acceptance criteria (TC013, unit, integration, UI, load)",
            "description": "Create a comprehensive automated test suite defining acceptance criteria for the A/B evaluation harness across LLM/STT/TTS/Image adapters. Cover configuration, allocation determinism, metrics capture, per-campaign toggles, charts visibility, budget guardrails, and safe rollback behavior. Include at least one unit test and one integration/UI test, plus a load test skeleton for concurrent experiments without cross-talk.",
            "dependencies": [],
            "details": "Implement tests first using your project's chosen stack (e.g., Jest + TS for unit/integration, Playwright for UI, k6 or node worker-based script for load). Scope:\n- TC013 Structural/metrics correctness: simulate experiment runs and verify metrics persistence into llm_messages and metrics tables, including latency, token usage, and quality tags.\n- Unit tests:\n  - Allocation reproducibility with a seed: given an experiment id, user/session id, and seed, the same subject is assigned to the same variant for split traffic; for paired mode both variants are run and linked.\n  - Budget guardrail: when spend or token budget threshold is reached per campaign, new traffic allocation halts or routes to control as configured.\n  - Config validation: invalid variant allocation sums, missing adapters, or negative budgets are rejected.\n- Integration tests:\n  - Run harness across mock adapters implementing LLM/STT/TTS/Image interfaces; ensure per-adapter metrics captured and aggregated.\n  - Concurrent experiments on different campaigns do not interfere (namespace isolation).\n  - Safe rollback: toggling off experiment reverts to prior provider settings.\n- UI tests (Playwright):\n  - Enable A/B per campaign; configure variants, allocation, mode (paired/split), budgets; verify charts render basic metrics.\n  - Verify guardrail banner/notice appears when budget hit and new allocations stop.\n- Load test skeleton: spin N concurrent simulated sessions across two campaigns and two experiments; assert no cross-talk and acceptable latency aggregation.\nProduce fixtures: mock adapters that return deterministic outputs with configurable latency and token usage. Seeded RNG helper for allocation.",
            "status": "pending",
            "testStrategy": "Map assertions to IDs: TC013 for structural and metrics checks; add TC014-UI for per-campaign toggle and charts; TC015-Load for concurrency isolation; TC016-Budget for guardrails; TC017-AllocationSeed for reproducibility. Tests must fail initially and be run in CI."
          },
          {
            "id": 2,
            "title": "Design experiment configuration schema and validation",
            "description": "Define the A/B experiment domain model and validation rules to support variant allocation, paired vs split traffic, per-campaign enablement, budgets, and rollback strategy.",
            "dependencies": [
              "14.1"
            ],
            "details": "Add a versioned schema (Zod or io-ts) for ExperimentConfig with fields: id, campaignId, name, status (draft|running|paused|archived), mode (paired|split), allocation [{variantId, adapterKind (LLM|STT|TTS|Image), providerKey, model, weight 0..1}], seed (optional), trafficFilter (optional), startAt/stopAt (optional), guardrails {maxTokens, maxCost, maxRequests, actionOnExceed: halt|route_control|pause}, rollback {toProviderConfigSnapshotId}, metricsConfig {captureLatency: boolean, captureTokens: boolean, qualityTags: string[]}, createdBy, createdAt, updatedAt.\nValidation rules:\n- Sum of weights per adapterKind equals 1.0 for split mode.\n- Paired mode requires exactly 2 variants per adapterKind or explicit pairing rules; allocation ignored.\n- providerKey/model must exist in Provider Adapter Registry (Task 5 dependency).\n- Budget values >= 0; at least one guardrail enabled or explicitly disabled.\n- status transitions allowed: draft->running->paused/archived; paused->running.\nPersist schema type in shared package. Implement validateExperimentConfig(config) that returns typed config or throws detailed errors.",
            "status": "pending",
            "testStrategy": "Run tests from 14.1; ensure invalid configs are rejected and valid pass. Add unit tests for edge cases: rounding of weights, missing variants, unknown providerKey."
          },
          {
            "id": 3,
            "title": "Extend database schema for experiments and metrics storage",
            "description": "Add migrations and data access for experiments, allocations, runs, and metrics, integrating with existing llm_messages and a new metrics table.",
            "dependencies": [
              "14.1",
              "14.2"
            ],
            "details": "Using existing DB stack (Task 2), add:\n- Tables:\n  - experiments: id, campaign_id, name, status, mode, seed, guardrails JSON, rollback_snapshot_id, created_at, updated_at.\n  - experiment_variants: id, experiment_id, adapter_kind, provider_key, model, weight, metadata JSON.\n  - experiment_runs: id, experiment_id, campaign_id, subject_key (user/session/message id), adapter_kind, mode, variant_a_id, variant_b_id (nullable), assigned_variant_id (nullable for paired), paired_group_id (for paired linking), started_at, completed_at, status, error.\n  - metrics: id, experiment_run_id, adapter_kind, latency_ms, input_tokens, output_tokens, cost_micro, quality_tags TEXT[]/JSON, created_at.\n- Augment existing llm_messages: add experiment_run_id nullable FK; ensure indices on campaign_id, created_at.\n- Indices: experiments(campaign_id,status), experiment_runs(experiment_id,subject_key), metrics(experiment_run_id), and partial index for status='running'.\n- Data access layer (repository functions) with transaction-safe inserts for run + metrics.\n- Seed script updates for dev examples.\nHandle SQLite compatibility (arrays via JSON). Ensure foreign keys and cascade deletes for archiving experiments.",
            "status": "pending",
            "testStrategy": "Execute migration tests for up/down idempotency and CRUD. From 14.1 tests, verify metrics persist correctly and link to runs and llm_messages. Add performance smoke: insert >2k metrics/s on small batch locally if feasible."
          },
          {
            "id": 4,
            "title": "Implement allocation engine with seeded determinism and paired/split modes",
            "description": "Create the runtime allocator that assigns variants per request/session with deterministic results under a given seed and subject key, supporting split and paired traffic.",
            "dependencies": [
              "14.1",
              "14.2",
              "14.3"
            ],
            "details": "Implement module allocateVariant({experiment, adapterKind, subjectKey}):\n- For split mode: use a stable hash (e.g., murmurhash) seeded by experiment.seed to map subjectKey to [0,1) and select variant by cumulative weights. Ensure consistent across processes.\n- For paired mode: return both variants (A and B) and generate a paired_group_id; executor will run both in sequence or parallel depending on adapter capability.\n- Support traffic filtering and sticky assignment per subjectKey stored in experiment_runs to maintain consistency.\n- Handle multiple adapter kinds by independent allocations per kind.\nAdd reproducibility options for test replays. Implement small PRNG utility to avoid platform differences.",
            "status": "pending",
            "testStrategy": "Use tests from 14.1 (TC017-AllocationSeed). Add unit tests verifying boundary conditions (exact weight edges), stability across process restarts, and paired linking."
          },
          {
            "id": 5,
            "title": "Execution harness integrating Provider Adapter Framework",
            "description": "Build the execution layer that takes allocations and invokes the correct adapter variant(s), captures timings, tokens, costs, and stores messages and metrics atomically.",
            "dependencies": [
              "14.1",
              "14.2",
              "14.3",
              "14.4"
            ],
            "details": "Create AbHarness.execute(request) where request includes campaignId, adapterKind, payload (prompt/audio/text/image spec), subjectKey, experimentId (optional). Steps:\n- Resolve active experiment for campaign+adapterKind; if multiple, support single active per adapterKind or fail fast.\n- Allocate variant(s) using allocation engine.\n- For split: run selected adapter; for paired: run both variants; for LLM paired, optionally run A then B with same prompt and context; for STT/TTS/Image ensure same input.\n- Capture timing via high-resolution timers; gather token usage/cost from adapter responses or estimate via tokenizer if needed.\n- Begin transaction: insert experiment_run, store adapter outputs into llm_messages (link run id), write metrics row(s) with latency_ms, tokens, cost, quality_tags (initially empty).\n- Return unified response with metadata {experimentRunId, variant info}.\n- Provide hooks for post-run quality tagging and custom metrics enrichment.\nImplement error handling: if variant call fails, record status=error, fallback to control variant if configured, and continue according to guardrails.",
            "status": "pending",
            "testStrategy": "Run integration tests from 14.1 for multi-adapter execution and metrics correctness. Add unit tests with mock adapters to simulate latency and token outputs and verify atomic writes."
          },
          {
            "id": 6,
            "title": "Budget guardrails and enforcement with safe rollback",
            "description": "Implement budget tracking (tokens, cost, requests) per campaign/experiment with enforcement actions and automatic rollback to prior provider settings when configured.",
            "dependencies": [
              "14.1",
              "14.3",
              "14.5"
            ],
            "details": "Implement GuardrailService:\n- Maintain counters aggregated from metrics table per experiment and campaign.\n- On each new allocation/execution, check thresholds {maxTokens, maxCost, maxRequests}; if exceeded, apply actionOnExceed:\n  - halt: reject new allocations for experiment and log event.\n  - route_control: bypass experiment and use baseline provider config.\n  - pause: set experiment.status=paused.\n- Safe rollback: if rollback.toProviderConfigSnapshotId provided, restore provider settings atomically. Capture a pre-experiment snapshot when enabling experiment.\n- Expose events for UI notifications and audit log entries.\nEnsure concurrency-safety with DB transactions and last-write-wins guards.",
            "status": "pending",
            "testStrategy": "Use TC016-Budget and relevant integration tests from 14.1. Add unit tests for threshold boundary behavior and rollback idempotency. Simulate concurrent increments to ensure no double counting."
          },
          {
            "id": 7,
            "title": "Per-campaign experiment toggle and settings plumbing (backend API)",
            "description": "Expose REST/IPC endpoints to create, validate, enable, pause, and archive experiments per campaign and snapshot provider settings for rollback.",
            "dependencies": [
              "14.1",
              "14.2",
              "14.3",
              "14.6"
            ],
            "details": "Add API routes:\n- POST /campaigns/:id/experiments (create+validate config)\n- POST /campaigns/:id/experiments/:expId/enable (snapshot provider config, set running)\n- POST /campaigns/:id/experiments/:expId/pause\n- POST /campaigns/:id/experiments/:expId/archive\n- GET /campaigns/:id/experiments (list with status and guardrail state)\n- GET /experiments/:expId/metrics/summary (latency p50/p95, tokens, cost, by variant)\nAuth/permissions per existing model. Wire to GuardrailService and Allocation/Execution layers. Emit events for UI. Ensure idempotency and proper status transitions.",
            "status": "pending",
            "testStrategy": "Run integration tests to enable experiment and execute mock runs. Verify rollback snapshot existence. Add contract tests for each endpoint response shape and error codes."
          },
          {
            "id": 8,
            "title": "Metrics aggregation and basic charts backend",
            "description": "Implement metrics aggregation queries and DTOs powering UI charts for latency, token usage, cost, and quality tags by variant over time.",
            "dependencies": [
              "14.1",
              "14.3",
              "14.5",
              "14.7"
            ],
            "details": "Create aggregation service:\n- Time-bucketed summaries (e.g., 5m/1h/day) per experimentId, adapterKind, variantId: count, avg, p50, p95 latency, total input/output tokens, total cost, tag counts.\n- Comparative snapshot for A vs B deltas.\n- Budget utilization percentages vs guardrails.\nOptimize with SQL views or materialized summaries if needed; otherwise compute on demand with indexes. Define DTOs for UI: Series points and legend metadata.",
            "status": "pending",
            "testStrategy": "Extend TC013 to validate aggregated values against known fixtures. Unit test percentile calcs and tag aggregation. Performance test aggregation on sample dataset."
          },
          {
            "id": 9,
            "title": "React UI: per-campaign A/B toggle and configuration form",
            "description": "Add UI to enable/disable experiments per campaign, configure variants, allocation, mode, budgets, and seed; ensure accessibility and validation feedback.",
            "dependencies": [
              "14.1",
              "14.2",
              "14.7"
            ],
            "details": "Within Campaign Settings, add an Experiments panel:\n- List experiments with status chips.\n- Create/Edit form: adapter kind, mode, variants (provider/model selection via Provider Registry), allocation sliders with sum-to-100 indicator, budgets, seed, guardrail action, rollback option.\n- Client-side validation mirroring schema; surface backend errors.\n- Actions: Enable, Pause, Archive with confirmations.\n- Accessibility: keyboard, labels, ARIA, color contrast. Localized strings.\nPersist via backend API. Capture snapshot confirmation on enable.",
            "status": "pending",
            "testStrategy": "Playwright UI tests from 14.1 (TC014-UI). Snapshot tests for form. Axe-core accessibility scan must pass. Verify validation errors and successful enable flows."
          },
          {
            "id": 10,
            "title": "React UI: basic charts and experiment status indicators",
            "description": "Create a metrics dashboard per experiment showing latency, tokens, cost, and tag distributions with variant comparison and budget guardrail status.",
            "dependencies": [
              "14.1",
              "14.8",
              "14.9"
            ],
            "details": "Add an Experiment Dashboard page:\n- Charts: time series for latency (p50/p95), stacked bars for tokens, cost trend, and a tag distribution pie/bar by variant.\n- Controls: time range, adapter kind filter, paired/split mode indicator.\n- Badges/alerts when guardrails engaged (halt/route_control/pause) and budget utilization bars.\n- Empty states and loading skeletons.\nUse a lightweight charting lib. Fetch data from aggregation endpoints, poll at intervals.",
            "status": "pending",
            "testStrategy": "Playwright tests to verify charts render with mock data and reflect state changes (e.g., budget exceeded banner). Visual snapshot tests for charts with deterministic fixtures."
          },
          {
            "id": 11,
            "title": "Quality tagging workflow and APIs",
            "description": "Enable attaching quality tags to experiment runs/messages (manual or automated), and include tags in aggregation.",
            "dependencies": [
              "14.1",
              "14.5",
              "14.8",
              "14.7"
            ],
            "details": "Add API to POST tags to an experiment_run or llm_message (e.g., ['helpful','off-topic','hallucination']). Provide batch tagging endpoint for evaluator jobs. Update aggregation to include tag counts by variant. Optionally, add a small UI control to tag recent runs from dashboard.",
            "status": "pending",
            "testStrategy": "Unit tests for tag validation and persistence. Integration test that tags affect aggregation counts. UI test for tagging control if implemented."
          },
          {
            "id": 12,
            "title": "Safe rollback executor and provider snapshot manager",
            "description": "Implement provider configuration snapshotting per campaign and reliable rollback application when experiments are paused/archived or guardrails trigger route to control.",
            "dependencies": [
              "14.1",
              "14.6",
              "14.7"
            ],
            "details": "Create SnapshotService capturing current provider settings for a campaign at enable-time. Store snapshots in settings table with diff metadata. On rollback action: apply snapshot atomically, verify with post-apply read-back, and record audit event. Ensure idempotency and handle partial failures with retry and compensating actions.",
            "status": "pending",
            "testStrategy": "Integration tests: enable experiment -> mutate providers -> trigger rollback -> verify providers restored exactly. Unit tests for diff/apply logic and idempotency."
          },
          {
            "id": 13,
            "title": "Concurrency isolation and cross-talk prevention",
            "description": "Ensure experiments across campaigns and adapter kinds are isolated in allocation, execution, metrics, and guardrails under concurrent load.",
            "dependencies": [
              "14.1",
              "14.4",
              "14.5",
              "14.6",
              "14.8"
            ],
            "details": "Audit code paths to include campaignId and experimentId scoping in queries and caches. Namespaces for any in-memory caches keyed by campaign+experiment+adapterKind. Add advisory locks or compare-and-swap on run creation to avoid duplicate runs for the same subjectKey. Verify queue/executor isolation if present.",
            "status": "pending",
            "testStrategy": "Use TC015-Load from 14.1 to run concurrent experiments and assert no cross-talk (e.g., variant assignment leakage, metric aggregation mixing). Add race-condition unit tests with fake timers and parallel tasks."
          },
          {
            "id": 14,
            "title": "Documentation and operational playbooks",
            "description": "Add developer and operator docs describing configuration, running experiments, interpreting charts, budgets, and rollback procedures.",
            "dependencies": [
              "14.2",
              "14.5",
              "14.6",
              "14.7",
              "14.8",
              "14.10"
            ],
            "details": "Write README and runbooks: schema reference, API usage, UI flows, how to add new adapters, seeding/replay for reproducibility, troubleshooting guardrails, and safe rollback steps. Include examples for paired and split experiments and metrics interpretation.",
            "status": "pending",
            "testStrategy": "Validate examples by running them as part of an examples test script. Link docs in UI help."
          },
          {
            "id": 15,
            "title": "Release toggle and feature flagging",
            "description": "Gate the A/B harness behind a feature flag and provide a kill switch to disable experiments globally in case of issues.",
            "dependencies": [
              "14.1",
              "14.5",
              "14.7"
            ],
            "details": "Introduce feature flag abHarnessEnabled with remote/local override. Wrap API routes and UI panels. Add global kill switch that pauses all running experiments and routes traffic to control, emitting alerts and audit entries.",
            "status": "pending",
            "testStrategy": "Unit tests for flag evaluation and route guarding. Integration test toggling flag disables allocations and hides UI, ensuring safe behavior."
          }
        ]
      },
      {
        "id": 15,
        "title": "Local-First Security and PII Redaction",
        "description": "Enforce local-only data, encrypted provider keys at rest, and PII redaction on logs and transcripts per policy.",
        "details": "- Network guard: deny outbound except explicit provider hosts; config flag to fully offline\n- Key storage via keytar; never write plaintext keys to DB or logs\n- Redaction middleware for transcripts/logs using deterministic masking; consent flags for PvP interactions\n- Structured logging with redacted fields",
        "testStrategy": "- TC014: assert no unintended external writes via network interceptor tests\n- Verify key encryption by attempting to read DB and finding no keys\n- Redaction test corpus covering emails, names, locations",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for network guard, key storage, and PII redaction (TC014, TC015–TC017)",
            "description": "Create unit, integration, and E2E tests capturing acceptance criteria for local-only networking, encrypted-at-rest provider keys, and deterministic PII redaction across logs/transcripts. Include offline mode behavior and consent flags for PvP interactions. No production code changes yet.",
            "dependencies": [],
            "details": "• Network guard tests (TC014):\n  - Unit: mock HTTP client/interceptor; assert outbound requests are blocked by default and only allowed to explicit allowlist hosts; assert DNS/IP literal requests to non-allowed hosts are denied; assert protocol restrictions (http/https only) and port allow rules; assert environment variable proxy is ignored unless allowlisted.\n  - Integration: spin a local test server and a disallowed remote host (use nock or msw). Verify attempts to call disallowed hosts fail with specific error code and are logged as security events without leaking request bodies. Verify offline flag denies even allowlisted hosts.\n  - E2E: run a minimal app boot flow with offline flag true and ensure no outbound sockets are established (capture with a socket/sniffing helper) and that functionality relying on local cache works.\n• Key storage tests (TC015):\n  - Unit: mock key storage adapter; ensure plaintext keys are never returned from persistence layer; verify encryption/decryption boundaries; attempt to log keys and assert structured logger redacts.\n  - Integration: write provider keys via API; inspect DB/files to verify no plaintext keys or decryptable material without OS keystore; simulate corrupted store; assert safe failures and no logs with secrets.\n• PII redaction tests (TC016):\n  - Unit: provide corpus with emails, names, phones, SSNs, addresses, coordinates, IPs, credit card numbers; assert deterministic masking (same token -> same mask), irreversible format; preserve structure for analytics fields; ensure Unicode and locale variations.\n  - Snapshot: redact sample transcripts and logs; assert snapshots contain masked tokens and required structured fields remain.\n• Consent flags for PvP tests (TC017):\n  - Unit: when consent=false, redact or drop personally identifying speaker tags; when consent=true, allow pseudonymous identifiers; verify consent toggling mid-session re-redacts past messages where policy requires.\n• Logging structure tests:\n  - Unit: logger enforces redacted fields schema; disallows emitting objects with forbidden keys (e.g., apiKey, token) and auto-redacts.\n",
            "status": "pending",
            "testStrategy": "Map tests to TC IDs: TC014 (network egress policy), TC015 (keys never plaintext), TC016 (PII redaction determinism/coverage), TC017 (PvP consent). Include CI jobs running unit, integration, and an E2E smoke with offline flag. Use seeded randomness for deterministic masking and snapshots."
          },
          {
            "id": 2,
            "title": "Implement network guard with outbound deny-by-default and offline mode",
            "description": "Add a process-wide network guard that intercepts all HTTP(S) egress and denies by default except explicit provider allowlist. Provide a config flag to force fully offline operation.",
            "dependencies": [
              "15.1"
            ],
            "details": "• Interception layer:\n  - Node: wrap globalAgent/undici/axios/fetch with a policy interceptor; optionally use net.connect monkeypatch to enforce at socket level. In Electron, also register protocol interceptors.\n  - Policy: default deny; allowlist of hostnames and pinned ports; support SNI/hostname verification; resolve DNS and verify final destination IP matches expected CIDR ranges if specified; block plain IP unless explicitly allowlisted; block non-TCP schemes.\n  - Offline flag: config.local.offline=true short-circuits all outbound attempts with a typed error (ERR_OFFLINE_BLOCKED) and increments a metric.\n  - Observability: structured security log event on block with: timestamp, dest_host (redacted if contains PII), reason, rule_id; no request body logged; include correlationId.\n  - Configuration: load allowlist from signed config or environment; hot-reloadable; include explicit provider hosts (e.g., openai.com, anthropic.com) as examples in config only, not hardcoded.\n  - Tests: run and fix failing tests from 15.1; add integration harness using nock/msw; validate no regressions.",
            "status": "pending",
            "testStrategy": "Run TC014 tests. Add additional tests: proxy bypass attempts, IPv6 literals, redirect chains where initial host is allowed but redirect to disallowed host must be blocked."
          },
          {
            "id": 3,
            "title": "Add configuration management for allowlist and offline toggle",
            "description": "Introduce secure configuration sources for network allowlist and an offline toggle with environment and file-based overrides, including validation and hot-reload.",
            "dependencies": [
              "15.1",
              "15.2"
            ],
            "details": "• Config schema: define zod/ajv schema: { offline: boolean, allowlist: [{ host, ports, cidrs?, protocols? }] } with defaults to safest settings.\n• Load order: env vars -> signed config file -> runtime admin API; validate and reject unsafe values.\n• Hot-reload: watch config file; if changes, update the network guard rules atomically with versioning; emit audit log entry.\n• Admin API (local-only): read-only endpoint to display current policy for UI; ensure not exposed over network in offline mode.\n• Tests: re-run 15.1; add hot-reload tests ensuring in-flight connections are unaffected and new connections apply new policy.",
            "status": "pending",
            "testStrategy": "Property tests for schema validation; mutation tests for unsafe config (e.g., allowlist '*')."
          },
          {
            "id": 4,
            "title": "Implement key storage using OS keychain via keytar",
            "description": "Store provider API keys using OS keystore (keytar). Ensure keys are never written in plaintext to DB, files, or logs. Provide typed adapter APIs.",
            "dependencies": [
              "15.1"
            ],
            "details": "• Adapter design: KeyVault interface: setKey(provider, accountId, secret), getKey(provider, accountId), deleteKey, listEntries(). Implement KeytarKeyVault using keytar.\n• Persistence: DB stores only references (provider, accountId, keyRefId), not secrets. Migrations to remove any legacy plaintext fields and replace with nullable references.\n• Logging: redact on toString/inspect; structured logger sanitizer strips fields named apiKey/token/secret by path.\n• Error handling: map keytar errors to domain errors; fallback behavior disabled by default (no plaintext fallback). Provide dev-only mock vault behind explicit ALLOW_INSECURE_DEV_VAULT.\n• Tests: execute TC015; simulate DB reads to confirm absence of plaintext; attempt to log secrets and verify redaction.",
            "status": "pending",
            "testStrategy": "Integration tests across supported OSs via CI matrix (macOS, Windows, Linux) with keytar. If unavailable in CI, use container images with libsecret/gnome-keyring for Linux."
          },
          {
            "id": 5,
            "title": "Add secure key ingestion and rotation APIs",
            "description": "Expose local-only APIs/UI flows to add, rotate, and delete provider keys, enforcing validation and audit logging while keeping secrets only in keytar.",
            "dependencies": [
              "15.1",
              "15.4"
            ],
            "details": "• API: POST /secrets/:provider (validate format via regex/luhn where applicable), POST /secrets/:provider/rotate, DELETE /secrets/:provider/:accountId.\n• Transport: local IPC or localhost-only with mTLS disabled in offline mode; never send secrets over outbound network.\n• Audit log: structured event with provider, accountId hash, action, initiator, result; no secret content.\n• Rotation: dual-write window with old/new keyRefs, automatic cutover after validation ping (if offline, defer until connectivity resumes or manual confirm).\n• UI: minimal modal that never echoes back full secret; show last4 and createdAt only.\n• Tests: update TC015 integration; add negative tests for invalid formats and ensure no secret appears in any log.",
            "status": "pending",
            "testStrategy": "Contract tests for API; UI test for modal masking and copy-to-clipboard behavior without exposing full value."
          },
          {
            "id": 6,
            "title": "Build deterministic PII redaction engine and policy config",
            "description": "Create a streaming-capable redaction engine with deterministic masking for PII types (emails, names, phones, SSNs, addresses, IPs, GPS, credit cards) and policy-driven controls.",
            "dependencies": [
              "15.1"
            ],
            "details": "• Engine: tokenization + pattern/rule-based detectors (regex + locale-aware libs) with optional ML hook later; map tokens to stable pseudonyms using HMAC(key, token) -> stable ID, format-preserving masks.\n• Policy: config defines which entities to redact vs hash vs drop; include context-aware exceptions (e.g., system usernames). Seed key stored in keytar as RedactionSalt; rotate with versioning.\n• Streaming: support incremental masking for transcripts/logs.\n• Determinism: same input maps to same mask within a policy version; changing salt/version invalidates mapping.\n• Performance: compile regexes; apply trie for known names list; limit backtracking; process UTF-8 safely.\n• Tests: run TC016 corpus and snapshot tests; add property tests for determinism and irreversibility.",
            "status": "pending",
            "testStrategy": "Fuzz tests over random PII-like strings; performance benchmark to ensure under 5 ms/KB typical."
          },
          {
            "id": 7,
            "title": "Integrate redaction middleware into logging pipeline",
            "description": "Introduce middleware that enforces redaction on all structured logs before emission with schema enforcement and forbidden fields auto-redaction.",
            "dependencies": [
              "15.1",
              "15.6"
            ],
            "details": "• Logger wrapper: before write, pass message through redaction engine; drop or mask fields per policy; enforce schema shape (level, msg, eventId, fields).\n• Field guards: recursively scan object keys for sensitive names (apiKey, token, secret, password, Authorization) and replace with [REDACTED].\n• Metadata: attach redaction_version and policy_id; allow safe list of fields for observability.\n• Sinks: console, file, and in-app viewer; ensure file sink uses append-only permissions.\n• Tests: extend TC016 snapshots; ensure any attempt to log secret values gets masked; check performance overhead.",
            "status": "pending",
            "testStrategy": "Golden tests for representative log events; mutation tests ensuring no bypass when nested."
          },
          {
            "id": 8,
            "title": "Add transcript redaction middleware with consent-aware PvP handling",
            "description": "Apply redaction to chat/transcript streams, honoring consent flags for player-vs-player interactions and pseudonymous identifiers.",
            "dependencies": [
              "15.1",
              "15.6"
            ],
            "details": "• Middleware placement: before persistence and before any UI rendering/export.\n• Consent: per-participant consent flag; if false, strip PII and replace speaker identifiers with pseudonyms; if true, allow pseudonymous ID but still redact sensitive PII; changes propagate historically if policy demands.\n• Deterministic pseudonyms: use HMAC(seed, userId) to generate stable alias per campaign/session.\n• Exports: ensure exported transcripts apply same policy; include redaction metadata.\n• Tests: run TC017; regression tests for toggling consent mid-session; verify deterministic aliasing.",
            "status": "pending",
            "testStrategy": "Integration tests simulating multi-user chat with mixed consent; UI snapshot to verify masked display."
          },
          {
            "id": 9,
            "title": "Implement structured security and audit logging",
            "description": "Standardize structured logging with redacted fields, security events taxonomy, and audit trail for key and policy operations.",
            "dependencies": [
              "15.1",
              "15.7",
              "15.8"
            ],
            "details": "• Event taxonomy: SECURITY_BLOCK, POLICY_CHANGE, SECRET_WRITE, SECRET_ROTATE, SECRET_DELETE, CONSENT_UPDATE.\n• Schema: include actor (pseudonymous), action, objectRef, outcome, correlationId; ensure all payloads pass redaction middleware.\n• Storage: append-only local file with rotation; protect with file permissions; optional local SQLite table with checksum.\n• Query API: local-only read interface for UI.\n• Tests: validate schema; verify no PII leakage; ensure events written for key ops and policy changes.",
            "status": "pending",
            "testStrategy": "E2E test where key rotation and policy change generate correct audit entries with no secrets."
          },
          {
            "id": 10,
            "title": "Add admin UI for security settings, keys, and redaction policy",
            "description": "Provide a local-only admin UI to manage offline toggle, allowlist, keys, and redaction policy with safe UX that avoids exposing secrets.",
            "dependencies": [
              "15.3",
              "15.5",
              "15.6",
              "15.9"
            ],
            "details": "• UI sections: Network (offline, allowlist), Keys (add/rotate/delete with masked display), Redaction Policy (entity toggles), Audit Log viewer.\n• Security: ensure UI reads via local IPC; no external calls; copy-to-clipboard uses masked preview; confirm dialogs for destructive actions.\n• Accessibility: clear labels and warnings when offline mode blocks providers.\n• Tests: UI integration test to ensure no secret text nodes; snapshot for masked outputs; flow tests for key rotation and policy toggle updating runtime.",
            "status": "pending",
            "testStrategy": "Automated UI tests (Playwright) running locally; enforce no network requests during UI suite."
          },
          {
            "id": 11,
            "title": "Introduce policy versioning, rotation, and redaction salt management",
            "description": "Manage redaction policy versions and rotation of the HMAC salt stored in keytar with safe reprocessing of stored logs/transcripts when required.",
            "dependencies": [
              "15.4",
              "15.6",
              "15.8",
              "15.9"
            ],
            "details": "• Versioning: policy_id and salt_version; store in config and audit on change.\n• Rotation: generate new salt, store in keytar; fromVersion -> toVersion migrator to re-redact stored artifacts or mark as legacy with compatibility view.\n• Backfill job: batch reprocess transcripts/logs; track progress; throttle IO.\n• Tests: simulate rotation; assert determinism changes; ensure old artifacts are either reprocessed or labeled; ensure audit entries created.",
            "status": "pending",
            "testStrategy": "Long-running integration test with dataset; verify no PII regression during rotation."
          },
          {
            "id": 12,
            "title": "Harden transports and dependency surfaces against leaks",
            "description": "Ensure no unintended external writes via SDKs, telemetry, crash reporters, or dependency defaults. Disable or stub all third-party telemetry by default.",
            "dependencies": [
              "15.2",
              "15.3"
            ],
            "details": "• Survey dependencies for telemetry; set env flags (e.g., ELECTRON_DISABLE_SECURITY_WARNINGS does not emit data; disable Sentry/Crashpad unless opt-in local-only).\n• Replace global fetch/WS with guarded implementations; block WebSocket egress via the same network guard.\n• Ensure DNS prefetching and auto-update are disabled.\n• Tests: extend TC014 to include WebSocket and DNS prefetch attempts; verify blocks.",
            "status": "pending",
            "testStrategy": "Static analysis to search for known telemetry endpoints; runtime hooks to detect unexpected sockets."
          },
          {
            "id": 13,
            "title": "Implement data retention and secure deletion for redacted artifacts",
            "description": "Define retention policies for logs/transcripts and implement secure deletion routines with index updates and audit logging.",
            "dependencies": [
              "15.7",
              "15.8",
              "15.9",
              "15.11"
            ],
            "details": "• Retention config: max days/size; per-campaign overrides.\n• Deletion: secure overwrite for files; for DB rows, wipe blob content and remove indexes; write AUDIT events.\n• Compaction: rotate log files; prune old snapshots.\n• Tests: ensure deletion removes PII even if policy rotates; verify audit entries and no dangling references.",
            "status": "pending",
            "testStrategy": "E2E retention expiry test with fake clock; validate disk usage before/after."
          },
          {
            "id": 14,
            "title": "Documentation and developer tooling for local-first security",
            "description": "Provide clear docs, code owners, and pre-commit hooks that prevent accidental logging of secrets and enforce offline-safe patterns.",
            "dependencies": [
              "15.2",
              "15.4",
              "15.6",
              "15.7"
            ],
            "details": "• Docs: threat model, network guard rules, redaction policy, key storage design, operational runbooks.\n• Tooling: eslint rule to forbid logging certain keys; commit hook scanning for secrets; template examples for using redaction and key vault APIs.\n• Onboarding: short guide for running in offline mode and testing flows.\n• Tests: verify lint rules catch samples; ensure pre-commit hook blocks sample secrets.",
            "status": "pending",
            "testStrategy": "CI checks for docs presence; unit tests for custom ESLint rules."
          }
        ]
      },
      {
        "id": 16,
        "title": "Periodic Situation Updates (Ticker)",
        "description": "Broadcast periodic situation updates by time or event cadence to keep clients synchronized.",
        "details": "- Ticker service: cron-like and event-driven triggers\n- Compose updates from world state, mission progress, alliances status\n- WebSocket broadcast on channels; throttle to avoid spam\n- Configurable cadence per campaign",
        "testStrategy": "- TC015: validate cadence and content fidelity vs true state\n- Load test: ensure ticker doesn’t starve main loop\n- Client receives without duplication",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for ticker cadence, content fidelity, throttling, and client delivery",
            "description": "Author unit and integration tests that define the acceptance criteria for the Periodic Situation Updates (Ticker), covering time-based cadence, event-driven triggers, content composition from world/mission/alliance state, per-campaign configurable cadence, throttling to prevent spam, WebSocket broadcast on channels, no-duplication guarantees, and non-starvation under load.",
            "dependencies": [],
            "details": "Create test skeletons and assertions before implementation. Map to verification IDs: TC015 (cadence and content fidelity), plus additional internal cases for load and deduplication. Define fixtures to simulate world state, mission progress, and alliance status. Include: 1) Unit tests for scheduler cadence: cron-like spec parsing, jitter, per-campaign overrides; 2) Unit tests for event-driven triggers firing on state changes; 3) Unit tests for composer correctness: assembling situation updates from supplied state snapshots; 4) Unit tests for throttler behavior and backoff; 5) Integration tests: WebSocket broadcast on named channels, multi-client receipt without duplicates, correct routing by campaign; 6) Load test stub to ensure ticker loop does not starve the main loop under configured QPS. Tag tests with TC015 where applicable.",
            "status": "pending",
            "testStrategy": "- Unit: schedule parsing, next-run computation, event trigger debounce, content composer correctness against fixtures (TC015). - Integration: WebSocket broadcast delivery to multiple clients with deduplication and channel routing; verify receipt order/time within tolerance. - Load: simulate N campaigns and M clients; assert main loop metrics remain within thresholds; ensure throttling engages. - Negative: invalid cadence config falls back to default with warning; malformed events don't crash."
          },
          {
            "id": 2,
            "title": "Define ticker domain model and configuration schema",
            "description": "Create data models and configuration schema for ticker, including per-campaign cadence, event trigger specs, channel mapping, throttling parameters, and content template configuration.",
            "dependencies": [
              "16.1"
            ],
            "details": "Implement types/interfaces: TickerConfig { campaignId, cadence: { cron?: string, intervalMs?: number, jitterPct?: number }, events: { enabled: boolean, topics: string[], debounceMs: number }, channels: { updates: string }, throttle: { minIntervalMs: number, burst: number, windowMs: number }, payload: { include: { world: boolean, mission: boolean, alliances: boolean }, redact?: string[] } }. Provide JSON Schema/Zod validation with descriptive errors and defaults (e.g., intervalMs default 30000, jitterPct 0.1, debounceMs 500, throttle.minIntervalMs 2000). Add config loader resolving campaign-level overrides and env defaults. Run tests from 16.1 and fix any schema-related test failures.",
            "status": "pending",
            "testStrategy": "Unit: schema validates good configs, rejects invalid; defaulting behavior; override precedence (global -> campaign)."
          },
          {
            "id": 3,
            "title": "Implement cron-like and interval scheduler with jitter",
            "description": "Create scheduling engine to compute next tick times from cron expressions or fixed intervals, including jitter support and pause/resume hooks.",
            "dependencies": [
              "16.1",
              "16.2"
            ],
            "details": "Implement Scheduler service with APIs: scheduleInterval(campaignId, intervalMs, jitterPct), scheduleCron(campaignId, cronExpr), cancel(campaignId), pause/resume. Use a priority timer wheel or min-heap of next-run timestamps. Ensure drift-correct scheduling (compute next based on previous scheduled time, not actual fire time). Add clock abstraction for testability. Integrate per-campaign instances via TickerConfig. Run the cadence unit tests; adjust to meet time tolerance (e.g., ±5%).",
            "status": "pending",
            "testStrategy": "Unit: next-run computation for various crons, jitter bounds, pause/resume, cancellation; fake timers for deterministic checks (TC015 cadence aspect)."
          },
          {
            "id": 4,
            "title": "Implement event-driven trigger subsystem with debounce",
            "description": "Build event listeners for world, mission, and alliance state topics that can trigger updates based on configured topics with debouncing and deduplication.",
            "dependencies": [
              "16.1",
              "16.2"
            ],
            "details": "Create EventTrigger service that subscribes to message bus topics (e.g., world.updated, mission.progressed, alliances.changed). Implement debounce per campaign/topic using timers keyed by campaignId+topic with debounceMs from config. Coalesce multiple events during debounce window into one trigger with merged context (e.g., union of changed entity IDs). Provide backpressure: cap pending triggers and drop oldest with metrics logging. Run tests for event trigger firing and debounce behavior.",
            "status": "pending",
            "testStrategy": "Unit: fires once per debounce window; multiple topics produce separate triggers; disabled events do not fire; malformed events handled safely."
          },
          {
            "id": 5,
            "title": "Implement situation update composer",
            "description": "Create a deterministic composer that assembles an update payload from world state, mission progress, and alliance status, with optional redaction and templated summary text.",
            "dependencies": [
              "16.1",
              "16.2"
            ],
            "details": "Design Composer with interface compose(campaignId, snapshot): returns { campaignId, ts, seq, summary, world, mission, alliances, version }. Pull snapshot from provided state accessors. Apply payload.include flags and redact fields listed in config.redact. Implement summary templates with i18n-ready tokens and length guard (e.g., 140–280 chars). Increment a per-campaign monotonic sequence number for deduplication. Ensure stable field ordering for test assertions. Run content fidelity tests from 16.1.",
            "status": "pending",
            "testStrategy": "Unit: given seeded fixtures, composer matches expected payload (TC015 content fidelity); redaction removes configured paths; sequence increments correctly."
          },
          {
            "id": 6,
            "title": "Build throttling and rate control",
            "description": "Implement per-campaign throttle to prevent spam from time and event bursts, enforcing minimum intervals and token-bucket style burst limits.",
            "dependencies": [
              "16.1",
              "16.2",
              "16.3",
              "16.4",
              "16.5"
            ],
            "details": "Introduce Throttler with config throttle: { minIntervalMs, burst, windowMs }. Use a token bucket per campaign: tokens refill at burst/windowMs, capped at burst. Allow pass if lastSentAt older than minIntervalMs and tokens available; else queue last-update-only or drop with metric depending on policy. Integrate with Scheduler and EventTrigger so both routes pass through Throttler before publish. Run throttling unit tests and integration tests to confirm reduced spam without starving.",
            "status": "pending",
            "testStrategy": "Unit: respects minInterval and burst semantics; boundary conditions around window refill. Integration: burst of events results in <= allowed publishes; ensures last event eventually published."
          },
          {
            "id": 7,
            "title": "Implement WebSocket channel broadcasting with deduplication",
            "description": "Broadcast updates on per-campaign channels over WebSocket, ensuring no duplicates and correct client routing.",
            "dependencies": [
              "16.1",
              "16.2",
              "16.5",
              "16.6"
            ],
            "details": "Create TickerPublisher using existing WebSocket gateway. Channel name from config.channels.updates (e.g., campaign:{id}:ticker). Include payload with seq and hash (e.g., SHA-256 of normalized payload) to support deduplication. Maintain per-campaign lastHash/lastSeq to avoid sending identical payloads twice. Set message type 'ticker.update'. Implement idempotent publish and retry on transient failures with exponential backoff. Run integration tests from 16.1 to verify multi-client receipt and no duplication.",
            "status": "pending",
            "testStrategy": "Integration: multiple clients subscribe and receive exactly one message per update; order preserved by seq. Negative: simulated network retries do not produce duplicates."
          },
          {
            "id": 8,
            "title": "Wire ticker orchestration loop",
            "description": "Compose scheduler, event triggers, composer, throttler, and publisher into a cohesive ticker service managing multiple campaigns.",
            "dependencies": [
              "16.1",
              "16.2",
              "16.3",
              "16.4",
              "16.5",
              "16.6",
              "16.7"
            ],
            "details": "Implement TickerService managing CampaignTicker instances. Each instance registers interval/cron schedules and event subscriptions. On trigger: fetch snapshot, build payload via Composer, pass through Throttler, then publish via Publisher. Ensure isolation per campaign. Add lifecycle methods start(campaignId), stop(campaignId), reloadConfig(campaignId). Provide metrics: ticks_scheduled, triggers_received, composed_ok, throttled, published, dropped_duplicate, errors. Run all existing tests; adjust orchestration to satisfy them.",
            "status": "pending",
            "testStrategy": "Integration: end-to-end trigger to client flow works for multiple campaigns concurrently; stop() halts emits; reloadConfig applies new cadence without restart."
          },
          {
            "id": 9,
            "title": "Add configurable cadence per campaign and admin controls",
            "description": "Expose configuration entry points and admin APIs to set and update cadence and event settings per campaign at runtime.",
            "dependencies": [
              "16.1",
              "16.2",
              "16.8"
            ],
            "details": "Implement Admin API endpoints or CLI: GET/PUT /campaigns/{id}/ticker-config. Validate via schema; persist to config store. On update, call TickerService.reloadConfig(campaignId). Add RBAC checks. Provide audit logs of changes. Update tests to exercise dynamic cadence change and confirm scheduler reconfigures without message loss.",
            "status": "pending",
            "testStrategy": "Integration: change cadence from 30s interval to cron spec and verify emission timing transitions cleanly; permissions enforced; invalid config rejected with clear errors."
          },
          {
            "id": 10,
            "title": "Ensure ticker does not starve main loop under load",
            "description": "Introduce resource isolation and backpressure so ticker work cannot starve the main game loop under heavy load.",
            "dependencies": [
              "16.1",
              "16.8"
            ],
            "details": "Run ticker tasks on a bounded worker pool or queue with priority lower than the main loop. Use asynchronous snapshot retrieval with timeouts and cancellation. Set per-campaign in-flight cap. Add metrics and configurable limits. Execute load tests from 16.1 and tune parameters to meet CPU and latency budgets.",
            "status": "pending",
            "testStrategy": "Load: simulate high event rates across campaigns; assert main loop tick time and GC metrics remain within target; ticker publishes may be throttled but not block main loop."
          },
          {
            "id": 11,
            "title": "Implement persistence for sequence and last-hash state",
            "description": "Persist per-campaign sequence counters and last-hash to survive restarts and avoid duplicates or regressions.",
            "dependencies": [
              "16.1",
              "16.7",
              "16.8"
            ],
            "details": "Add lightweight storage (e.g., Redis or DB table) keyed by campaignId: { seq, lastHash, lastSentAt }. Initialize CampaignTicker from persisted state; flush updates atomically after publish. Handle migration defaults. Update tests to restart service and ensure continuity of seq and dedup behavior.",
            "status": "pending",
            "testStrategy": "Integration: after restart, next seq increments correctly; duplicate suppression still works; no replays unless explicitly requested."
          },
          {
            "id": 12,
            "title": "Observability: metrics, logs, and alerts",
            "description": "Provide comprehensive instrumentation and alerting for ticker performance and correctness.",
            "dependencies": [
              "16.8",
              "16.10",
              "16.11"
            ],
            "details": "Emit Prometheus metrics for scheduling, queue sizes, throttle events, publish counts, errors, and latencies (compose, publish). Structured logs include campaignId, triggerType, seq. Add SLOs and alerts (e.g., zero publishes over 5m during active hours, error rate >1%). Integrate tracing spans across components. Ensure tests assert presence of key metrics in integration runs.",
            "status": "pending",
            "testStrategy": "Integration: verify metrics endpoints expose expected series after simulated activity; log lines include correlation IDs."
          },
          {
            "id": 13,
            "title": "Security and validation hardening",
            "description": "Harden inputs and outputs: validate snapshots, sanitize payloads, enforce channel authorization, and prevent information leakage.",
            "dependencies": [
              "16.2",
              "16.5",
              "16.7",
              "16.8"
            ],
            "details": "Add strict schema validation for composed payloads; enforce max payload size; redact configured fields; verify only authorized clients can subscribe to campaign channels. Fuzz tests for snapshot anomalies. Ensure PII is not broadcast if marked for redaction. Run full test suite.",
            "status": "pending",
            "testStrategy": "Integration: unauthorized client cannot subscribe; payloads pass schema; redaction verified by golden tests."
          },
          {
            "id": 14,
            "title": "Client-side subscription and UI validation tests",
            "description": "Add UI/integration tests ensuring clients subscribe to ticker channels, display updates without duplication, and handle throttled bursts gracefully.",
            "dependencies": [
              "16.7",
              "16.8"
            ],
            "details": "Using Playwright or equivalent, spin up two clients in the same campaign. Subscribe to ticker channel; trigger updates via test hooks. Assert both clients render exactly one card/toast per update, in order, with correct summary. Simulate burst and ensure UI shows latest state without flicker. Tag with TC015 client receipt aspect.",
            "status": "pending",
            "testStrategy": "UI/Integration: subscription success, render correctness, dedup on client, resilience to reconnects."
          },
          {
            "id": 15,
            "title": "Operational runbooks and configuration examples",
            "description": "Document runbooks for configuring ticker cadence, troubleshooting, and capacity planning; provide sample configs per campaign archetype.",
            "dependencies": [
              "16.8",
              "16.9",
              "16.12"
            ],
            "details": "Create docs covering: enabling ticker, cadence options, event topics, throttling tuning, metrics to watch, common errors, and rollback. Provide YAML/JSON examples for slow/medium/fast campaigns. Include procedures for safe config changes during live operations.",
            "status": "pending",
            "testStrategy": "Doc linting and example schema validation in CI; manual review checklist."
          }
        ]
      },
      {
        "id": 17,
        "title": "Content Packs: Import/Export with Signing and Validation",
        "description": "Support signed JSON content packs for worlds, missions, items with schema and signature validation.",
        "details": "- Pack format: manifest.json, assets/, signatures\n- Sign/verify with ed25519 local keys; store public keys whitelist\n- Validate JSON schema; write to content/packs/\n- Import UI flow; export existing campaign content\n- Safe sandbox: no code execution",
        "testStrategy": "- TC016: import/export flows; reject invalid signatures/schemas\n- Unit: schema validation and asset linking\n- Security: path traversal prevention tests",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for signed content pack import/export (TC016, security, schema, UI)",
            "description": "Create comprehensive unit, integration, and UI tests that define the acceptance criteria for content pack import/export with schema and signature validation, asset handling, and sandbox safety. Include negative tests for signature and schema failures, and path traversal prevention.",
            "dependencies": [],
            "details": "Implement tests first. Cover: 1) Unit tests: a) Schema validation for worlds, missions, items manifests/manifests.json using JSON Schema; b) Ed25519 signature verify success/failure with key whitelist; c) Asset linking rules and missing asset rejection; d) Safe extraction prevents path traversal and symlink escapes; e) No code execution within packs (e.g., .js/.sh ignored); f) Writing to content/packs/ only; g) Public key whitelist CRUD persistence. 2) Integration tests (TC016): a) End-to-end import of a valid signed .zip pack with manifest.json and assets/; b) Export existing campaign content to a pack, sign it, then import back and assert equivalence; c) Reject packs with invalid/unknown signatures; d) Reject invalid schema; e) Clean rollback on partial failures. 3) UI tests: a) Import flow prompts file selection and displays validation summary; b) Export flow allows selecting campaign scope and shows success; c) Error banners for invalid signature/schema. 4) Security tests: path traversal attempts in zip (../, absolute paths), zip bombs (huge zip central directory vs uncompressed), and signature replay with modified payload.",
            "status": "pending",
            "testStrategy": "Use Jest/Vitest for unit tests, Playwright/Cypress for UI, and a temporary filesystem sandbox for integration. Tag key cases as TC016-UT-001.., TC016-IT-001.., TC016-UI-001..; include Security: TC016-SEC-001.. for traversal/zip bomb. Use deterministic fixtures for ed25519 keys and sample packs."
          },
          {
            "id": 2,
            "title": "Design content pack specification and JSON Schemas",
            "description": "Define the content pack structure and JSON Schemas for manifest and domain objects (worlds, missions, items). Document the format, required fields, and constraints.",
            "dependencies": [
              "17.1"
            ],
            "details": "Specify pack layout: root contains manifest.json, assets/ directory with referenced files, signatures/ directory containing detached signatures. Manifest fields: packId (UUID), name, version (semver), type(s) [world|mission|item], createdAt, toolVersion, entries array with per-object metadata {id, kind, schemaVersion, path (JSON file path in pack), assets: [relative asset paths], integrity: SHA256 of object JSON}. Signatures: signatures/manifest.json.sig (ed25519 detached over canonicalized manifest.json), signatures/entries/<entry-id>.sig (optional per-entry). Define JSON Schemas (Draft 2020-12): a) manifest.json; b) world.json; c) mission.json; d) item.json. Include $id and schemaVersion. Add constraints: disallow absolute paths; paths must be normalized and under pack root; asset filenames whitelist (png,jpg,jpeg,webp,ogg,mp3,wav,json). Document signature canonicalization (UTF-8, JSON canonical serializer e.g., RFC8785 or deterministic stable stringify).",
            "status": "pending",
            "testStrategy": "Validate schemas against fixtures in tests from 17.1. Ensure examples pass and counterexamples fail. Version schemas and include backwards compatibility notes."
          },
          {
            "id": 3,
            "title": "Implement Ed25519 key management with whitelist persistence",
            "description": "Create services to generate/import/export local ed25519 keys and maintain a whitelist of trusted public keys for verification.",
            "dependencies": [
              "17.1",
              "17.2"
            ],
            "details": "Implement KeyStore: a) Generate local ed25519 keypair using libsodium/tweetnacl; b) Store private key securely (OS keychain if available, else encrypted at rest); c) Persist public key whitelist with metadata (keyId, label, createdAt, fingerprint) in app config store; d) CRUD operations: add/remove/list; e) Provide sign(data) and verify(data, signature, pubkey) methods; f) Fingerprint: SHA256(pubkey) hex. Expose API for UI to manage whitelist.",
            "status": "pending",
            "testStrategy": "Unit tests: key generation determinism not required but verify key lengths, fingerprint formation, sign/verify roundtrip, whitelist add/remove/list persistence, and rejection when pubkey not in whitelist (TC016-UT-key-001..)."
          },
          {
            "id": 4,
            "title": "Implement JSON canonicalization and signing/verification utilities",
            "description": "Build utilities to canonicalize JSON and perform detached ed25519 signing and verification for manifest and entries.",
            "dependencies": [
              "17.1",
              "17.2",
              "17.3"
            ],
            "details": "Implement canonicalizer using RFC8785 or stable stringify: sort object keys, normalize numbers/booleans/strings, UTF-8 encoding. Create functions: canonicalizeJson(obj) -> Uint8Array; signJson(obj, privateKey) -> signature; verifyJson(obj, signature, publicKey) -> boolean. For entries with integrity hash, ensure signing covers the canonicalized JSON exactly as stored. For manifest, sign the canonicalized manifest.json. Provide file helpers to read JSON, canonicalize, and compute SHA-256 integrity to compare with manifest entries.",
            "status": "pending",
            "testStrategy": "Unit tests: canonicalization stability across equivalent objects, signature ver/invalid with mutated fields, mismatch when whitespace differs but canonical content same passes, integrity hash changes upon mutation (TC016-UT-sig-001..)."
          },
          {
            "id": 5,
            "title": "Safe ZIP reader and extractor with sandboxing",
            "description": "Create a secure ZIP processing module that parses and extracts packs into a temp sandbox, preventing path traversal, symlink escapes, and zip bombs. No code execution.",
            "dependencies": [
              "17.1"
            ],
            "details": "Implement zip reading using a streaming parser. Before extraction, scan entries: reject entries with absolute paths, .. segments, backslashes on non-Windows normalized outside root, or symlinks. Enforce size limits: total uncompressed bytes cap (configurable), per-file cap, entry count cap; detect zip bombs via compression ratio thresholds. Extract to a temporary directory under app cache. Disallow executing any files; ignore executable bits; filter only allowed filetypes. After validation & verification, move into content/packs/<packId-version>/ atomically.",
            "status": "pending",
            "testStrategy": "Security tests from 17.1 should pass: path traversal (../evil), absolute path (/etc/passwd), symlink entries, zip bomb heuristic. Add unit tests for normalization logic across OS path separators (TC016-SEC-001..)."
          },
          {
            "id": 6,
            "title": "Schema validation engine and domain validators",
            "description": "Implement JSON Schema validation for manifest and domain objects with helpful error reporting and version handling.",
            "dependencies": [
              "17.1",
              "17.2"
            ],
            "details": "Use Ajv (Draft 2020-12) with formats and strict mode. Precompile schemas for manifest, world, mission, item. Implement validateManifest(json) and validateEntry(kind, json). Include schemaVersion checks and migrations stub for future versions. Produce user-friendly error messages for UI. Integrate integrity check: compute SHA256 of entry JSON and compare to manifest.integrity.",
            "status": "pending",
            "testStrategy": "Unit tests: valid fixtures pass, invalid required fields/type mismatches fail with clear messages; integrity mismatch rejects; version bump behavior verified (TC016-UT-schema-001..)."
          },
          {
            "id": 7,
            "title": "Content repository writer with atomic install to content/packs/",
            "description": "Implement writing imported packs to the content repository with atomic moves and rollback on failure.",
            "dependencies": [
              "17.1",
              "17.5",
              "17.6"
            ],
            "details": "Create ContentRepo service: a) Staging directory for validated packs; b) Atomic move to content/packs/<packId>/<version>/ with lockfile to prevent races; c) Index file updating a registry of installed packs (packId, version, keys used, install date); d) On failure, clean staging and do not leave partial state; e) Ensure file permissions safe and no executables marked.",
            "status": "pending",
            "testStrategy": "Integration tests: simulate mid-operation failure to assert rollback; verify final layout matches spec; concurrency test with two imports of same pack to ensure one wins and the other reports duplicate (TC016-IT-repo-001..)."
          },
          {
            "id": 8,
            "title": "Import pipeline: verify, validate, and install",
            "description": "Build the end-to-end import pipeline that consumes a .zip, performs all security and validity checks, and installs the pack.",
            "dependencies": [
              "17.1",
              "17.3",
              "17.4",
              "17.5",
              "17.6",
              "17.7"
            ],
            "details": "Pipeline steps: 1) Open zip in sandbox; 2) Locate required files (manifest.json, signatures/manifest.json.sig); 3) Parse manifest; 4) Verify signature against a public key present in whitelist; 5) For each entry, load JSON, validate schema by kind, verify integrity hash; optionally verify per-entry signatures if provided; 6) Validate asset files exist and are within assets/ and match referenced paths; 7) Enforce safe sandbox rules; 8) If all checks pass, install via ContentRepo; 9) Emit structured result with warnings and errors.",
            "status": "pending",
            "testStrategy": "Integration tests (TC016): valid pack imports successfully; invalid signature/schema rejected with clear errors; missing asset rejection; ensure no writes outside content/packs/. UI tests will consume messages."
          },
          {
            "id": 9,
            "title": "Export pipeline: serialize, hash, and sign existing content",
            "description": "Implement export of selected campaign/world/mission/item data into a signed content pack zip with correct layout.",
            "dependencies": [
              "17.1",
              "17.2",
              "17.3",
              "17.4"
            ],
            "details": "Steps: 1) Select objects to export via API filters; 2) Serialize domain objects to stable JSON; 3) Build manifest.json with entries and SHA-256 integrity for each JSON file; 4) Collect referenced assets from repository into assets/; 5) Canonicalize manifest and create detached ed25519 signature using local private key; 6) Optionally include per-entry signatures; 7) Package into .zip with safe paths; 8) Output file named <packId>-<version>.zip.",
            "status": "pending",
            "testStrategy": "Integration tests: export then import round-trip preserves data equivalence; signature verifies; tamper with zip and expect import failure (TC016-IT-export-001..)."
          },
          {
            "id": 10,
            "title": "UI: Import flow with validation summary",
            "description": "Build UI to select a pack file, run import pipeline, and present a clear validation summary, errors, and installed pack details.",
            "dependencies": [
              "17.1",
              "17.8"
            ],
            "details": "UI components: file picker; progress display (parsing, verifying, validating, installing); results panel listing entries, asset counts, signer fingerprint and label, and any warnings/errors. Provide actions: view manifest, view errors, open installed location. Handle large packs with streaming progress updates. Respect safe sandbox (disable execution).",
            "status": "pending",
            "testStrategy": "UI tests (Playwright/Cypress): happy path shows success with details; invalid signature shows error banner and no installation occurs; schema errors surfaced per entry (TC016-UI-import-001..)."
          },
          {
            "id": 11,
            "title": "UI: Export flow with scope selection and signer choice",
            "description": "Build UI to export existing campaign content with selection of scope and signer key, then run export pipeline and offer download.",
            "dependencies": [
              "17.1",
              "17.9"
            ],
            "details": "UI allows: selecting campaign/worlds/missions/items; choose version and pack metadata; pick signer key from local key store; run export; show result including manifest preview, signature fingerprint, counts, and file size; provide Save As dialog. Persist last-used options.",
            "status": "pending",
            "testStrategy": "UI tests: select scope, export completes, file downloaded; invalid configuration (no key) blocks export with guidance; round-trip test pairs with 17.8 (TC016-UI-export-001..)."
          },
          {
            "id": 12,
            "title": "Public key whitelist management UI",
            "description": "Provide UI for managing trusted public keys used to verify content pack signatures.",
            "dependencies": [
              "17.1",
              "17.3"
            ],
            "details": "Implement list/add/remove UI: display key label, fingerprint, createdAt; import public key from file/paste; validate format; prevent duplicates; allow revoke/disable. Expose integration for import pipeline to display which key verified the pack.",
            "status": "pending",
            "testStrategy": "UI tests: add valid key, reject malformed, remove key, verify that import of a pack signed by removed key now fails (TC016-UI-keys-001..)."
          },
          {
            "id": 13,
            "title": "Security hardening: filetype filtering, PII-safe logs, and no code execution",
            "description": "Finalize security controls ensuring only allowed file types are processed, logs are redacted, and no code is executed from packs.",
            "dependencies": [
              "17.1",
              "17.5",
              "17.8"
            ],
            "details": "Implement allowlist-based MIME detection (magic numbers) for assets; block scripts/binaries; ensure logs redact sensitive fields (file paths, key material) and avoid printing JSON secrets; enforce read-only handling of pack contents until installation; disable any dynamic code loading on import; integrate with existing redaction middleware from Task 15 if available.",
            "status": "pending",
            "testStrategy": "Security tests: attempt to include .js/.sh/.exe assets and ensure they are rejected; confirm logs contain redacted fields and no secrets; attempt to trigger code execution via crafted manifest and verify none occurs (TC016-SEC-filetype-001..)."
          },
          {
            "id": 14,
            "title": "Repository indexing and query APIs",
            "description": "Expose APIs to list installed packs, query by kind/version, and fetch entries/assets for use by other modules.",
            "dependencies": [
              "17.1",
              "17.7"
            ],
            "details": "Implement read APIs over the content repo registry: listPacks(), getPack(packId, version), listEntries(packId), getEntryJson(packId, entryId), getAssetStream(packId, path). Enforce read paths within repo root. Provide pagination for large collections.",
            "status": "pending",
            "testStrategy": "Unit/integration tests: install sample pack and ensure query APIs return correct metadata and content; path traversal attempts on getters rejected (TC016-IT-repoapi-001..)."
          },
          {
            "id": 15,
            "title": "Error handling, rollback, and user-facing messages",
            "description": "Standardize error codes, rollback behavior, and user-visible messages for all import/export operations.",
            "dependencies": [
              "17.1",
              "17.8",
              "17.9",
              "17.10"
            ],
            "details": "Define error taxonomy: SIGNATURE_INVALID, SIGNER_UNTRUSTED, SCHEMA_INVALID, INTEGRITY_MISMATCH, ASSET_MISSING, ZIP_UNSAFE, REPO_CONFLICT, EXPORT_FAILED. Map internal exceptions to codes and localized messages. Ensure partial states are rolled back and temporary files cleaned. Surface actionable guidance in UI.",
            "status": "pending",
            "testStrategy": "Integration/UI tests: simulate each error and verify correct code/message shown; inspect filesystem to confirm no partial installs remain (TC016-IT-errors-001..)."
          },
          {
            "id": 16,
            "title": "Performance and scalability tuning",
            "description": "Optimize import/export for large packs with many entries and assets.",
            "dependencies": [
              "17.1",
              "17.8",
              "17.9"
            ],
            "details": "Add streaming hashing and verification; parallelize schema validation with a worker pool; throttle I/O to avoid UI stalls; progress events with percentage and ETA. Add config for size limits and timeouts. Ensure memory usage stays bounded.",
            "status": "pending",
            "testStrategy": "Bench tests: import 1–5 GB packs with thousands of assets in a controlled environment; ensure throughput targets and no timeouts; verify correctness not affected (TC016-PERF-001..)."
          },
          {
            "id": 17,
            "title": "Documentation and developer guide",
            "description": "Write developer and user documentation for content pack format, signing, verification, and UI flows.",
            "dependencies": [
              "17.2",
              "17.8",
              "17.9",
              "17.10",
              "17.11",
              "17.12",
              "17.15"
            ],
            "details": "Provide spec docs for pack structure and schemas; CLI/API examples for signing and verifying; screenshots of UI flows; troubleshooting guide mapping errors to fixes; security notes on safe packaging and allowed file types. Include versioning policy and migration guidance.",
            "status": "pending",
            "testStrategy": "Docs linting and example validation: run schema examples through validators; run CLI examples as part of CI to ensure they work (TC016-DOC-001..)."
          }
        ]
      },
      {
        "id": 18,
        "title": "Multi-Campaign Isolation Layer",
        "description": "Ensure full data, assets, vector memories, and schedules isolation for parallel campaigns.",
        "details": "- Context object carries campaign_id; middleware enforces scoping on all queries\n- File cache per-campaign subdirs\n- Realtime namespace per campaign; no cross-broadcasts\n- Clone/Archive flows implemented in APIs",
        "testStrategy": "- TC017: run two concurrent campaigns and verify no leakage across DB queries, caches, WS channels\n- Unit: guard middleware blocks cross-campaign access\n- E2E: clone and archive then verify isolation",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and unit/integration tests for isolation (TC017, TC018, TC019)",
            "description": "Author tests that codify multi-campaign isolation across data queries, file cache, realtime namespaces, vector memories, and schedules. Include: (a) unit tests for middleware scoping by campaign_id and guard rails blocking cross-campaign access; (b) integration/E2E tests that run two concurrent campaigns and verify no leakage across DB queries, caches, and WebSocket channels; (c) API tests for Clone and Archive flows to ensure isolation is preserved post-operation. Map cases to TC017 (parallel isolation), TC018 (clone/archive isolation), and TC019 (schedule/job isolation).",
            "dependencies": [],
            "details": "Create a top-level test plan and scaffolding:\n- Test IDs: TC017: end-to-end isolation across DB, cache, WS; TC018: clone/archive isolation; TC019: schedule/job isolation.\n- Unit tests (server):\n  - Middleware: rejects/filters queries where request context campaign_id does not match resource campaign_id.\n  - Repository layer: all queries require campaign scope; verify parameterized campaign_id use; fail without scope.\n  - File cache helper: resolves paths under campaign-specific subdirs and forbids path traversal between campaigns.\n  - Realtime broker: publishes to `realtime:<campaign_id>` namespace only; verify no cross-broadcasts when subscribed to different namespaces.\n  - Vector memory store: namespaces `campaign:<id>` and `player:<id>` enforced; cross-campaign retrieval returns empty.\n  - Scheduler: jobs tagged with campaign_id; dispatch filters by campaign; ensure no cross-trigger.\n- Integration tests:\n  - Spin up two campaigns A and B with seeded users, assets, vector memories, schedules.\n  - Verify querying A cannot access B records, assets, vectors, or WS messages.\n  - File cache writes in A are not visible in B and vice versa.\n  - WebSocket: two clients subscribe to different namespaces; verify messages do not leak.\n  - Clone A→A2: verify A2 receives only cloned artifacts under new IDs/namespaces; A remains unaffected; no reference pointers back to A.\n  - Archive B: verify archived campaign becomes read-only; no broadcasts; schedules disabled; no effect on A.\n- Data fixtures: factories for Campaign, Player, Memory, Asset, Schedule; utilities to create WS clients bound to campaign namespace.\n- CI configuration: mark TC017/TC018/TC019; parallelize tests to simulate concurrent campaigns.",
            "status": "pending",
            "testStrategy": "Execute unit tests first to lock guard behavior; then run integration tests bringing up minimal services (DB, cache, WS broker, scheduler). Use coverage thresholds on guard modules (>90%)."
          },
          {
            "id": 2,
            "title": "Implement and enforce context propagation of campaign_id across request lifecycle",
            "description": "Ensure campaign_id from the authenticated principal or request parameters is propagated deterministically through all layers (HTTP, jobs, WS, repositories, file cache, vector memory, and scheduler). Block processing if campaign_id is missing or ambiguous.",
            "dependencies": [
              "18.1"
            ],
            "details": "Implementation guidance:\n- Context object: define `RequestContext { campaignId: string; userId?: string; roles?: string[]; }`.\n- HTTP middleware: extract campaign_id from route param/header/token; validate against user entitlements; attach to RequestContext; reject requests without valid campaign scope (HTTP 400/403).\n- WS connection handshake: require campaign_id param; bind connection to `realtime:<campaignId>` room; store on connection context.\n- Job queue: include campaignId in job payload and in job metadata; worker bootstraps RequestContext per job.\n- Repository base class: require campaignId argument; generic guard that throws if undefined; ensure every method includes scoped filters.\n- Utilities (file cache, vector store, scheduler): accept RequestContext or explicit campaignId; remove unscoped overloads to prevent misuse.\n- Add lint rule or TypeScript types that disallow calling repository methods without campaignId param.",
            "status": "pending",
            "testStrategy": "Run unit tests for context extraction and propagation. Ensure failing paths for missing campaignId. Re-run TC017 unit subset."
          },
          {
            "id": 3,
            "title": "Middleware guards for DB query scoping by campaign_id",
            "description": "Implement DB-layer scoping: every read/write query must include campaign_id filter and writes must set campaign_id. Block cross-campaign access even if primary keys are known.",
            "dependencies": [
              "18.1",
              "18.2"
            ],
            "details": "Implementation guidance:\n- Query builder wrapper: augment with `withCampaignScope(campaignId)` that injects `WHERE campaign_id = ?` for SELECT/UPDATE/DELETE and sets `campaign_id` on INSERT.\n- Row-level security (optional if supported): add DB RLS policy enforcing `current_setting('app.campaign_id')` match; set via per-connection session variable from middleware.\n- Repository audit: refactor repositories to use the scoped builder; remove unsafe methods.\n- Add guard tests for typical entities: Messages, Assets, Players, Schedules, Memories.\n- Add migration checks: ensure tables have campaign_id column and composite indices `(campaign_id, key)` for performance.",
            "status": "pending",
            "testStrategy": "Execute unit tests for middleware guards and repository scoping; run integration DB tests for campaigns A and B performing cross reads/writes expected to fail."
          },
          {
            "id": 4,
            "title": "Per-campaign file cache directories and access controls",
            "description": "Ensure all cached assets are stored under per-campaign subdirectories and cannot be read across campaigns. Prevent path traversal and enforce read/write isolation.",
            "dependencies": [
              "18.1",
              "18.2"
            ],
            "details": "Implementation guidance:\n- Directory structure: `<CACHE_ROOT>/campaigns/<campaignId>/<assetType>/<hash or uuid>`.\n- Helper API: `getCampaignCachePath(campaignId, ...segments)` validates segments (no `..`, no absolute paths) and ensures directory exists with strict permissions.\n- File read/write wrappers require campaignId and enforce path within the campaign root.\n- Garbage collection: clean only within campaign root.\n- Add OS-level permissions if applicable (uid/gid separation in multi-tenant hosts).",
            "status": "pending",
            "testStrategy": "Run unit tests for path resolver/traversal prevention and cross-campaign access denial. Integration: write assets in A and verify they are absent/inaccessible in B."
          },
          {
            "id": 5,
            "title": "Realtime namespaces per campaign; prevent cross-broadcasts",
            "description": "Create isolated realtime namespaces keyed by campaign_id and ensure events emitted in one namespace are never delivered to another.",
            "dependencies": [
              "18.1",
              "18.2"
            ],
            "details": "Implementation guidance:\n- Namespace schema: `realtime:<campaignId>` rooms/topics.\n- On connect: validate campaignId; join only that room; store mapping connectionId→campaignId.\n- Publish API: requires campaignId; automatically routes to the correct namespace; reject attempts to publish to mismatched campaign.\n- Server-side filters: beforeEmit hook checks message.campaignId matches connection's campaignId.\n- Monitoring: metrics per namespace to detect anomalies.",
            "status": "pending",
            "testStrategy": "Unit: verify publish/subscribe isolation rules. Integration: spawn two WS clients for A and B; publish in A; assert B receives nothing (TC017)."
          },
          {
            "id": 6,
            "title": "Vector memory namespaces with campaign and player isolation",
            "description": "Implement vector memory segregation using explicit namespaces for campaign and player data; enforce retrieval scoped to the caller’s campaign and optional player.",
            "dependencies": [
              "18.1",
              "18.2",
              "18.3"
            ],
            "details": "Implementation guidance:\n- Namespace keys: `campaign:<campaignId>` for shared memory; `player:<playerId>` for per-player; both always tied to campaignId in metadata.\n- Write API requires campaignId; for player memory, also require playerId that is validated within the same campaign.\n- Retrieval API: `retrieve(query, scope)` requires scope ∈ {campaign, player}; when player, include both playerId and campaignId; ensure cross-campaign queries return empty.\n- Storage backends: ensure embeddings index is partitioned or filtered by namespace; if single index, always include namespace token in vector metadata and filter pre/post search.\n- Auditing: log namespace and campaignId for writes/reads.",
            "status": "pending",
            "testStrategy": "Unit: namespace enforcement and cross-campaign retrieval returns empty. Integration: seed A and B with distinct vectors; verify isolation holds; align with TC017."
          },
          {
            "id": 7,
            "title": "Scheduler isolation: per-campaign job tagging and dispatch filtering",
            "description": "Ensure scheduled tasks and background jobs are isolated by campaign_id, including triggers, runners, and time-based schedules.",
            "dependencies": [
              "18.1",
              "18.2"
            ],
            "details": "Implementation guidance:\n- Job schema: include `campaignId` and optional `tenantKey` in job payload and indexing.\n- Enqueue API requires campaignId; worker initializes RequestContext and validates job.campaignId.\n- Dispatch filters: workers subscribe to streams filtered by campaignId; prevent a worker from handling jobs of a different campaign context unless explicitly multi-campaign safe.\n- Cron/schedule store: persist schedules with campaignId; when firing, pass campaignId into job creation.\n- Archive state handling: if campaign archived, skip/disable schedules.",
            "status": "pending",
            "testStrategy": "Unit: verify enqueuing without campaignId fails; worker refuses mismatched jobs. Integration: two campaigns with overlapping schedules fire independently (TC019)."
          },
          {
            "id": 8,
            "title": "Clone flow: deep copy campaign data into new isolated campaign",
            "description": "Implement clone API to deep copy campaign-scoped entities (data, assets, vector memories, schedules) into a new campaign with new identifiers and namespaces, ensuring no shared references or cross-links.",
            "dependencies": [
              "18.1",
              "18.3",
              "18.4",
              "18.5",
              "18.6",
              "18.7"
            ],
            "details": "Implementation guidance:\n- Clone plan: create new campaign record; map old→new IDs; copy DB records with campaign_id set to new; regenerate secrets/tokens.\n- Assets: duplicate files from `<A>` to `<A2>` cache directory; re-hash if necessary; update references.\n- Vector memories: reindex into `campaign:<A2>` namespace; do not share underlying vector IDs.\n- Schedules: duplicate with new identifiers and ensure next-run timestamps preserved or offset per spec.\n- Realtime: create namespace for new campaign; no clients auto-subscribed.\n- Validation: ensure no foreign keys or URLs point to original campaign after clone.",
            "status": "pending",
            "testStrategy": "Integration: TC018 part 1. After clone, assert all artifacts exist under new campaign and none are referenced back to the source. Run WS isolation and cache isolation on cloned campaign."
          },
          {
            "id": 9,
            "title": "Archive flow: enforce read-only state and disable schedules/broadcasts",
            "description": "Implement campaign archive operation that marks campaign as archived and enforces read-only access, disables schedules, and blocks realtime broadcasts for that campaign.",
            "dependencies": [
              "18.1",
              "18.3",
              "18.5",
              "18.7"
            ],
            "details": "Implementation guidance:\n- DB: campaign status field `active|archived`.\n- Middleware: if archived, reject mutating operations (POST/PUT/PATCH/DELETE) with 409/423.\n- Scheduler: on archive, cancel or pause schedules; workers drop jobs with archived campaignId.\n- Realtime: publishing in archived campaign returns error/no-op.\n- File cache: keep assets accessible read-only; block writes.\n- Admin override: explicit maintenance token for unarchive if needed.",
            "status": "pending",
            "testStrategy": "Integration: TC018 part 2. Archive a campaign; verify writes fail, schedules stop, and realtime publish is blocked; reads still scoped and allowed."
          },
          {
            "id": 10,
            "title": "API surface validation: enforce campaign_id requirement on all endpoints",
            "description": "Audit and update all API endpoints to require campaign_id in path or header, validate authorization, and pass context downstream. Add contract tests.",
            "dependencies": [
              "18.2",
              "18.3"
            ],
            "details": "Implementation guidance:\n- OpenAPI: declare campaignId parameter for relevant routes; mark required.\n- Middleware binding: standardize extraction from path `/campaigns/{campaignId}/...` or `X-Campaign-Id` header.\n- Reject endpoints lacking campaignId in definition unless explicitly global/admin.\n- Contract tests: generate client from OpenAPI and assert required parameter presence.",
            "status": "pending",
            "testStrategy": "Run API contract tests and unit tests on middleware extraction; smoke E2E on a few endpoints to ensure context propagation."
          },
          {
            "id": 11,
            "title": "Security hardening: deny and log cross-campaign access attempts",
            "description": "Add centralized denial and security logging for any cross-campaign access attempt across layers (HTTP, WS, jobs, DB), with deterministic messages and redacted sensitive data.",
            "dependencies": [
              "18.2",
              "18.3",
              "18.5"
            ],
            "details": "Implementation guidance:\n- Central Guard: `assertCampaignScope(expected, actual, contextInfo)` throws `ScopeViolationError` with code and correlation ID.\n- Logging: structured logs include campaignId, userId, endpoint, resourceType, action, correlationId; exclude PII.\n- Metrics/alerts: counter for scope violations per endpoint; alert on spikes.\n- Rate limit repeated violations.",
            "status": "pending",
            "testStrategy": "Unit: error type and message content. Integration: simulate cross-campaign requests and verify denial + logs emitted; ensure no data returned (TC017 negative cases)."
          },
          {
            "id": 12,
            "title": "Performance and scalability validation under parallel campaigns",
            "description": "Benchmark isolation mechanisms with multiple concurrent campaigns to ensure acceptable latency/throughput and no contention between namespaces.",
            "dependencies": [
              "18.3",
              "18.4",
              "18.5",
              "18.6",
              "18.7"
            ],
            "details": "Implementation guidance:\n- Load scenarios: N=10 campaigns, M=50 concurrent users each; mixed DB reads/writes, WS messages, vector queries, file cache ops, scheduler triggers.\n- Metrics: p50/p95 latencies per campaign; verify no cross-campaign degradation.\n- Indexing and partitioning: validate composite indices; adjust cache directory structure and vector index sharding if needed.\n- Tune WS rooms and backpressure per namespace.",
            "status": "pending",
            "testStrategy": "Automated load tests; assert latency SLOs and zero cross-campaign events. Keep TC017 as gating checks after load."
          },
          {
            "id": 13,
            "title": "Developer tooling and lint rules to prevent unscoped access",
            "description": "Provide tooling that prevents introducing unscoped repository calls or APIs, including type-level enforcement and linters.",
            "dependencies": [
              "18.2",
              "18.3",
              "18.10"
            ],
            "details": "Implementation guidance:\n- TypeScript: define interfaces where `campaignId` is a required parameter; mark deprecated any unscoped overloads.\n- ESLint custom rule: flag repository calls that lack campaignId argument; forbid `SELECT *` without campaign filter in SQL strings.\n- CI step: run lints and fail on violations.\n- Code templates: generators pre-wire campaignId in new modules.",
            "status": "pending",
            "testStrategy": "Run lint tests with fixtures containing intentional violations; ensure CI fails. Re-run unit tests to ensure no regressions."
          },
          {
            "id": 14,
            "title": "Documentation and runbooks for isolation layer",
            "description": "Produce developer and ops documentation detailing isolation guarantees, required parameters, error codes, and operational procedures for clone/archive.",
            "dependencies": [
              "18.8",
              "18.9",
              "18.10",
              "18.11"
            ],
            "details": "Implementation guidance:\n- Dev docs: context propagation patterns, repository usage, WS namespaces, scheduler tagging, vector namespaces.\n- API docs: OpenAPI examples with campaignId.\n- Ops runbooks: cloning steps, archiving, restoring from backups per campaign, troubleshooting scope violations.\n- Security notes: logging, metrics, alerts, compliance posture.",
            "status": "pending",
            "testStrategy": "Docs linting, link checks; have an internal DRY-RUN using docs to perform clone/archive and verify TC018 steps."
          },
          {
            "id": 15,
            "title": "Final E2E isolation validation suite and CI gating",
            "description": "Integrate TC017–TC019 into CI as required gates, running full E2E suite across two or more campaigns on every PR touching isolation-critical code.",
            "dependencies": [
              "18.5",
              "18.6",
              "18.7",
              "18.8",
              "18.9",
              "18.10",
              "18.11",
              "18.12",
              "18.13",
              "18.14"
            ],
            "details": "Implementation guidance:\n- CI workflow: spin ephemeral environment; seed campaigns A and B; execute E2E tests for DB/cache/WS/vector/scheduler isolation; run clone and archive scenarios.\n- Artifacts: collect logs and metrics; fail build on any leakage or guard bypass.\n- Flake control: retries with idempotent steps; timeouts tuned for stability.",
            "status": "pending",
            "testStrategy": "Ensure CI must pass TC017–TC019. Periodically chaos-test by running load + E2E concurrently."
          }
        ]
      },
      {
        "id": 19,
        "title": "Scheduling with RRULE, Reminders, and Warmups",
        "description": "Implement campaign schedules with CRUD, recurrence (RRULE), reminders, and pre-session warmups (keys validation, memory prefetch, image pregen).",
        "details": "- Use rrule library for recurrence\n- Schedules table and API /schedules CRUD; optional ICS export\n- Reminder service: local notifications/email optional local SMTP off by default\n- Warmups: validate provider keys, prefetch relevant memories, pre-generate key images; structured logs\n- UI schedule editor integrated into campaign",
        "testStrategy": "- TC018: CRUD+recurrence correctness; reminders fired; warmups executed and logged with success/failure stats\n- Time travel tests using fake timers\n- ICS export validated by parser",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for schedules CRUD, RRULE recurrence, reminders, warmups, and ICS export (TC018)",
            "description": "Author unit, integration, and UI tests that define acceptance criteria for campaign scheduling: CRUD on /schedules, RRULE evaluation correctness including time zones and exceptions, reminder dispatch timing with fake timers, warmups execution and structured logging, and ICS export validity. Include at least one unit test and one integration/UI test. Tag all with TC018. Do NOT implement production code yet.",
            "dependencies": [],
            "details": "- Tech: Node/Jest or Vitest with ts-node, Supertest for API, Playwright for UI, Sinon/Jest fake timers, an ICS parser (e.g., ical.js), and rrule test vectors.\n- Unit tests:\n  - Model/validator tests for schedule payload shape (RRULE strings, DTSTART, EXDATE, timezone, reminders array, warmups flags).\n  - RRULE expansion tests (daily/weekly/monthly, BYDAY, COUNT/UNTIL, EXDATE, DTSTART in different TZ) comparing expected occurrences.\n  - Reminder scheduler tests: given upcoming occurrence times, ensure reminders fire at offsets (e.g., -15m, -1h) using fake timers; verify de-duplication and idempotency.\n  - Warmups pipeline tests: simulate providers and verify steps (keys validation, memory prefetch, image pregen) are called and log structured entries with success/failure counts.\n  - ICS export tests: parse generated ICS, assert VEVENT fields (UID, DTSTART/DTEND with TZID, RRULE/EXDATE), and round-trip RRULE.\n- Integration tests (API):\n  - CRUD flows on /schedules: create->get->update->list->delete; validate persisted fields and soft-delete if applicable.\n  - Time-travel: create schedule with next occurrence in near future with reminders; advance timers and assert reminder events enqueued and dispatched.\n- UI tests (Playwright):\n  - Open campaign schedule editor, create a recurring schedule, set reminders and warmups, save; verify rendering of upcoming occurrences list.\n  - Accessibility smoke with axe-core.\n- Fixtures: seed campaign/session records; env with SMTP disabled by default and local notification sink.\n- Test IDs: map to TC018 and sub-ids (e.g., TC018-CRUD, TC018-RRULE, TC018-REMINDERS, TC018-WARMUPS, TC018-ICS, TC018-UI).",
            "status": "pending",
            "testStrategy": "Run `pnpm test` for unit/integration with fake timers and `pnpm test:e2e` for Playwright. Tests should fail until implementation exists."
          },
          {
            "id": 2,
            "title": "Design schedules schema, domain model, and migrations",
            "description": "Define DB schema for schedules with recurrence and reminders, including migrations and typed ORM models. Cover timezone, RRULE, EXDATE, reminders, warmups config, and audit fields.",
            "dependencies": [
              "19.1"
            ],
            "details": "- Table schedules:\n  - id (uuid), campaign_id (fk), title, description\n  - dtstart (datetime with tz), dtend (nullable), timezone (IANA string)\n  - rrule (text), exdates (json array of ISO with tz), rdate (optional json)\n  - reminders (json: [{offsetMs:number, channel:'local'|'email'}])\n  - warmups (json: {validateKeys:boolean, prefetchMemories:boolean, pregenImages:boolean})\n  - enabled (boolean), created_at, updated_at, deleted_at (nullable)\n  - metadata (jsonb) for future\n- Indexes: by campaign_id, enabled, next_run_at (if maintained), and GIN on reminders if needed.\n- Consider a materialized next_occurrence cache table or computed view later; start with on-the-fly expansion.\n- ORM models (Drizzle/Kysely) with zod schemas for API validation.\n- Migration scripts up/down; seed example schedules for tests.\n- Update ERD and data access layer interfaces: ScheduleRepo with CRUD and occurrence query.",
            "status": "pending",
            "testStrategy": "Run TC018-CRUD unit/integration tests; ensure schema validation tests pass."
          },
          {
            "id": 3,
            "title": "Implement RRULE parsing/expansion service with timezone and exceptions",
            "description": "Create a service that expands occurrences from RRULE/RDATE/EXDATE with DTSTART and IANA timezone support using rrule library. Provide APIs to get next N occurrences and next occurrence after a timestamp.",
            "dependencies": [
              "19.1",
              "19.2"
            ],
            "details": "- Use rrule library: construct RRuleSet combining RRULE, RDATEs, and EXDATEs.\n- Timezones: store DTSTART as zoned; convert to UTC for storage but preserve timezone for expansion using luxon or date-fns-tz; ensure DTSTART with TZID is honored.\n- API:\n  - getNextOccurrences(schedule, {after: Date, limit: number}) => Date[]\n  - getNextOccurrence(schedule, after) => Date | null\n- Handle COUNT and UNTIL; validate invalid RRULE strings with descriptive errors.\n- Performance: cap expansions (e.g., 1000) and guard against infinite rules.\n- Deterministic tests using fake timers.\n- Logging: debug-level inputs/outputs for TC018 diagnostics.",
            "status": "pending",
            "testStrategy": "Run TC018-RRULE unit tests to verify daily/weekly/monthly patterns, BYDAY, COUNT/UNTIL, EXDATE."
          },
          {
            "id": 4,
            "title": "Build /schedules REST API with validation and CRUD",
            "description": "Expose schedules CRUD endpoints with payload validation, RBAC/ownership checks, and integration with RRULE service for preview of upcoming occurrences.",
            "dependencies": [
              "19.1",
              "19.2",
              "19.3"
            ],
            "details": "- Endpoints:\n  - POST /schedules: create; validate with zod; verify RRULE parses; default warmups false; normalize timezone.\n  - GET /schedules/:id: fetch by id; includes computed preview upcomingOccurrences (e.g., next 5) via RRULE service.\n  - GET /campaigns/:id/schedules: list for campaign; pagination.\n  - PATCH /schedules/:id: partial update; re-validate rule.\n  - DELETE /schedules/:id: soft delete.\n- Auth: ensure campaign-level access per user/session.\n- Serialization: ISO 8601 with timezone; include reminders and warmups configs.\n- Errors: standardized problem+json.\n- Structured logs for create/update/delete with IDs and campaign context.",
            "status": "pending",
            "testStrategy": "Run TC018-CRUD API tests; verify 2xx/4xx flows, validation errors, and preview correctness."
          },
          {
            "id": 5,
            "title": "Implement ICS export endpoint",
            "description": "Provide ICS generation for a schedule or campaign schedules, including RRULE/EXDATE, DTSTART/DTEND with TZID, and UID. Optionally authenticated tokenized URL.",
            "dependencies": [
              "19.1",
              "19.3",
              "19.4"
            ],
            "details": "- Endpoint: GET /schedules/:id.ics and GET /campaigns/:id/schedules.ics.\n- Use ical-generator or node-ical builder to emit VCALENDAR with VEVENT per schedule.\n- Map fields: SUMMARY=title, DESCRIPTION, DTSTART/DTEND with TZID, RRULE string, EXDATEs, UID=schedule.id@app-domain, SEQUENCE from updated_at.\n- Content-Type: text/calendar; CRLF line endings.\n- Option: signed token query for unauthenticated calendar clients; rotateable.\n- Tests parse ICS with ical.js and verify fields and RRULE round-trip.",
            "status": "pending",
            "testStrategy": "Run TC018-ICS tests; ensure parser reads exported files and matches schedule data."
          },
          {
            "id": 6,
            "title": "Develop reminder scheduler and dispatcher",
            "description": "Create a background scheduler that computes upcoming occurrences and schedules reminder jobs at specified offsets; implement dispatch to local notifications and optional email via SMTP (off by default).",
            "dependencies": [
              "19.1",
              "19.3",
              "19.4"
            ],
            "details": "- Components:\n  - ReminderPlanner: periodically scans enabled schedules and computes reminder fire times using RRULE service; persists jobs in reminders_jobs table (id, schedule_id, occurrence_at, fire_at, channel, status, attempts, payload, dedupe_key).\n  - ReminderWorker: processes due jobs, sends via channel adapters.\n- Channel adapters:\n  - local: writes to a notifications table/stream for UI consumption.\n  - email: nodemailer with local SMTP transport disabled by default; config flag to enable.\n- Idempotency: dedupe_key = schedule_id + occurrence_at + offset + channel; enforce unique index.\n- Time: all comparisons in UTC; supports fake timers in tests.\n- Backoff/retry policy with max attempts and DLQ logging.\n- Structured logs for plan, enqueue, dispatch, success/failure counts.",
            "status": "pending",
            "testStrategy": "Run TC018-REMINDERS with fake timers: create schedule with T+10m occurrence and -5m reminder; advance time and assert a single reminder is dispatched with correct payload."
          },
          {
            "id": 7,
            "title": "Implement warmups pipeline (keys validation, memory prefetch, image pre-generation) with structured logging",
            "description": "Build a pre-session warmups executor that runs before each occurrence: validates provider keys, prefetches relevant memories, and pre-generates key images, emitting structured logs and metrics.",
            "dependencies": [
              "19.1",
              "19.5",
              "19.6"
            ],
            "details": "- Trigger: when ReminderWorker dispatches a special 'warmup' job at a configurable lead time (e.g., -10m) or on-demand; alternatively, chain after reminder planning for occurrence.\n- Steps:\n  - Keys validation: use Provider Adapter Framework (Task 5) to check configured adapters are reachable; do not store raw keys; return capability snapshot.\n  - Memory prefetch: query VectorIndex/DB (Task 2) for top-N memories by campaign/session context; warm cache layer.\n  - Image pregen: call ImageGenAdapter to pre-generate commonly used images; store in images cache and index to campaign assets.\n- Concurrency: run steps in parallel with bounded pool; collect per-step success/failure.\n- Logging: structured event per step with schedule_id, occurrence_at, step, duration_ms, success, error.\n- Config: warmups flags on schedule decide which steps to execute.",
            "status": "pending",
            "testStrategy": "Run TC018-WARMUPS: simulate providers and vector index with fakes; trigger warmups and assert each step executed conditionally with logs and success/failure stats."
          },
          {
            "id": 8,
            "title": "Integrate reminder and warmup events with UI notifications stream",
            "description": "Expose a notifications feed for the UI to consume local reminders and warmup results for campaigns, enabling surface in the schedule editor and lobby.",
            "dependencies": [
              "19.4",
              "19.6",
              "19.7"
            ],
            "details": "- Server: SSE or WebSocket endpoint /notifications subscribing to campaign_id topics.\n- Message schema: {type:'reminder'|'warmup', scheduleId, occurrenceAt, title, severity, details}.\n- Persistence: notifications table for replay; cursor-based pagination.\n- UI: lightweight badge/ toast hooks to display incoming reminders and warmup statuses; integrate into existing UI shell (Task 4) surfaces.\n- Security: authorize by campaign membership.",
            "status": "pending",
            "testStrategy": "Extend TC018-REMINDERS integration/UI to assert a reminder appears in UI via notifications; verify warmup result message received."
          },
          {
            "id": 9,
            "title": "Build Schedule Editor UI integrated into campaign view",
            "description": "Implement a React-based schedule editor to create, update, and delete schedules with RRULE builder, timezone picker, reminders, warmups toggles, and preview of upcoming occurrences.",
            "dependencies": [
              "19.4",
              "19.8"
            ],
            "details": "- Components:\n  - ScheduleList: list schedules per campaign with enable/disable, next occurrence, and actions.\n  - ScheduleForm: fields for title, description, DTSTART/DTEND pickers, timezone, RRULE builder (frequency, interval, BYDAY, COUNT/UNTIL), EXDATE editor, reminders editor, warmups toggles.\n  - Preview panel showing next 5 occurrences using API preview.\n- Accessibility: keyboard navigation, labels, contrast tokens; validation errors inline.\n- State: use existing store (Zustand/RTK); optimistic updates with rollback on error.\n- ICS export buttons linking to .ics endpoints.\n- Structured analytics events on save/delete.",
            "status": "pending",
            "testStrategy": "Playwright UI test (TC018-UI): create a weekly schedule with a -15m reminder and warmups enabled; verify list shows next occurrence, notifications appear on time with fake timers, and form validation works."
          },
          {
            "id": 10,
            "title": "Add admin observability: logs, metrics, and dashboards for schedules/reminders/warmups",
            "description": "Expose structured logs and counters for schedule planning, reminder dispatch, warmup steps, and failures. Provide a simple dashboard view or API for monitoring.",
            "dependencies": [
              "19.6",
              "19.7"
            ],
            "details": "- Metrics: counters (reminders_planned, reminders_sent, warmups_started/succeeded/failed), gauges (pending_jobs), histograms (dispatch_latency_ms, warmup_step_duration_ms).\n- Export to existing logging/metrics sinks (pino + Prometheus if available) and expose /metrics endpoint.\n- Admin UI panel: table of recent events with filters by campaign/schedule and status.\n- Alerts: optional threshold-based warnings surfaced in admin panel.\n- Correlation IDs: propagate schedule_id and occurrence_at across logs.",
            "status": "pending",
            "testStrategy": "Unit tests assert metrics increment; integration test queries /metrics to contain expected counters after simulated runs."
          },
          {
            "id": 11,
            "title": "Hardening: idempotency, race conditions, and backfill handling",
            "description": "Ensure scheduler handles restarts, avoids duplicate reminders, and can backfill missed reminders after downtime with safe deduplication.",
            "dependencies": [
              "19.6"
            ],
            "details": "- Enforce unique index on reminders_jobs.dedupe_key; worker uses SELECT ... FOR UPDATE / transactional update to mark in-progress.\n- On startup, scan for jobs with fire_at <= now and status=pending; process with rate limits.\n- Graceful shutdown: drain worker.\n- Race tests: simulate concurrent workers; ensure only one dispatch occurs.\n- Backfill policy: time window cap (e.g., last 24h) to avoid storm.",
            "status": "pending",
            "testStrategy": "Integration tests create overlapping jobs and run two workers; assert single dispatch. Advance time over downtime window and verify capped backfill."
          },
          {
            "id": 12,
            "title": "Documentation and examples",
            "description": "Write developer and user docs: API contracts, payload examples, RRULE guidance, ICS subscriptions, reminder channels config, warmups behavior, and troubleshooting.",
            "dependencies": [
              "19.4",
              "19.5",
              "19.6",
              "19.7",
              "19.9",
              "19.10",
              "19.11"
            ],
            "details": "- README sections: schedules schema, example POST payloads, RRULE cheat sheet, timezone caveats, ICS examples, enabling email reminders, warmups flags and logs.\n- Include curl and UI walkthrough GIFs.\n- Provide example RRULEs (weekly on Mon 9am TZ) and their preview outputs.\n- Troubleshooting: common RRULE errors, SMTP off-by-default note, how to read structured logs.",
            "status": "pending",
            "testStrategy": "Docs linting; sample commands executed in CI to ensure examples remain valid."
          }
        ]
      },
      {
        "id": 20,
        "title": "CRDT Realtime for Shared Notes/Map/Inventory",
        "description": "Add CRDT-based collaboration for shared notes/map/inventory with convergence over WebSockets.",
        "details": "- Choose Yjs or Automerge; define documents per campaign/session\n- Sync protocol over existing WS; persistence snapshots in DB\n- Permissions: role-based access to docs\n- Conflict resolution tested via CRDT invariants",
        "testStrategy": "- Convergence tests under random edits\n- Disconnect/reconnect merges without data loss\n- Performance with 10+ concurrent editors locally",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and unit/integration tests for CRDT realtime (TC001–TC006)",
            "description": "Before implementation, codify the core acceptance criteria and create failing tests covering convergence, conflict resolution, permission enforcement, persistence, and WS sync for notes/map/inventory documents.",
            "dependencies": [],
            "details": "Create a test plan mapping to verification IDs:\n- TC001 Convergence: Random concurrent edits across 3 replicas converge to identical state for notes, map annotations, and inventory.\n- TC002 Reconnection: Disconnect/reconnect with buffered ops results in convergence without data loss.\n- TC003 Permissions: Role-based access enforced (viewer: read-only, editor: mutate allowed docs, GM: full access). Unauthorized ops are rejected and do not apply.\n- TC004 Persistence: Snapshot and incremental updates persisted and restored produce identical document state hashes.\n- TC005 Performance: Local 10+ simulated editors maintain <150ms average latency for visible updates and complete convergence within 2s after burst.\n- TC006 Protocol Validations: WS crdt-sync schema validation and backpressure handling; duplicate/out-of-order messages handled idempotently.\nImplement tests:\n- Unit tests (Jest/Vitest) for CRDT object composition (notes text, map layers/markers, inventory items), merge semantics, and invariants.\n- Property-based tests for convergence under random operation interleavings (fast-check).\n- Integration tests using ws/superwstest to spin up WS gateway (Task 3 dependency mocked if needed) with 3–5 clients performing edits and network partitions.\n- Persistence roundtrip tests using SQLite (Task 2) with snapshot+incremental log.\n- Permission tests via mocked auth contexts and role matrices.\nDefine helper utilities: Replica harness, op generators for each document type, deterministic seed for reproducibility, state hash function (stable JSON + hash).",
            "status": "pending",
            "testStrategy": "Start with red tests. Use seed-based fuzzing (N=200 sequences). Add metrics assertions for latency using fake timers where applicable."
          },
          {
            "id": 2,
            "title": "Select CRDT library and document model (Yjs vs Automerge) and scaffold types",
            "description": "Evaluate Yjs vs Automerge for text, map structures, and inventory; decide and scaffold TypeScript types and document schemas per campaign/session.",
            "dependencies": [
              "20.1"
            ],
            "details": "Decision criteria: performance with 10+ editors, text CRDT maturity, binary encoding, GC/tombstone handling, conflict semantics, ecosystem.\nRecommendation: Choose Yjs for production-grade text and map/list structures with awareness of optimized sets and composition techniques; model complex docs via CRDT object composition and CRDT-valued maps.[2][3] Adopt techniques to avoid tombstones where possible.[1]\nDefine document types:\n- NotesDoc: Y.Text for rich/plain text per note; metadata registers (title LWW-style), map of notes within session.\n- MapDoc: map layers (Y.Map), list of markers (Y.Array of objects with id, pos, label), per-marker metadata as nested maps; treat as list/set of CRDTs.[3]\n- InventoryDoc: Y.Map of itemId -> object (qty counter, props LWW registers), collection modeled as CRDT map.[4][5]\nNamespaces: campaign:<id>/session:<id>/<doc-kind>/<doc-id>.\nCreate TypeScript interfaces for DocManager, DocHandles, and serialization boundaries.",
            "status": "pending",
            "testStrategy": "Run TC001 unit tests focused on type-level constraints and basic merge semantics using Yjs in-memory providers until tests pass."
          },
          {
            "id": 3,
            "title": "Design CRDT message schema and zod validators for crdt-sync",
            "description": "Specify and implement the wire protocol messages for CRDT sync over existing WebSockets, including schemas and versioning.",
            "dependencies": [
              "20.1",
              "20.2"
            ],
            "details": "Define message types (all include protocolVersion, campaignId, sessionId, docKind, docId):\n- crdt-sync-init: client->server subscribe with auth token and role.\n- crdt-sync-update: server<->client binary update payload (Yjs update Uint8Array base64-encoded), seq, timestamp, replicaId.\n- crdt-sync-snapshot-req/resp: request snapshot and receive compressed snapshot blob + clock/vector info.\n- crdt-sync-ack: acknowledge receipt with seq; supports backpressure.\n- crdt-sync-error: validation or permission errors.\nImplement zod schemas shared between client/server; integrate with existing message routing from Task 3. Include idempotency keys and causal metadata fields informed by CRDT composition guidance.[2][3]\nAdd schema versioning and feature flags per doc kind.",
            "status": "pending",
            "testStrategy": "Execute TC006 protocol validation tests: invalid messages rejected, duplicates ignored, out-of-order updates applied via Yjs merge to same state."
          },
          {
            "id": 4,
            "title": "Implement CRDT DocManager and in-memory replica harness",
            "description": "Create a DocManager that opens/creates Yjs documents per namespace, applies updates, emits deltas, and integrates with the replica test harness.",
            "dependencies": [
              "20.1",
              "20.2",
              "20.3"
            ],
            "details": "Components:\n- DocRegistry keyed by namespace -> Y.Doc, with per-doc awareness of substructures (notes/map/inventory) using composition patterns.[2]\n- ApplyUpdate(doc, update, origin) and EncodeUpdate events for outgoing changes.\n- State hashing function for test equality (deterministic stable stringify + hash).\n- ReplicaHarness: create N replicas, simulate random ops for notes/map/inventory, collect updates, and apply across replicas to verify convergence (inspired by composition and collection patterns).[2][3]\n- GC/awareness: disable heavy GC during tests; expose ability to encode state vector and diff updates.\nEnsure no tombstone leaks by relying on Yjs internal optimizations and documented techniques to avoid unbounded metadata.[1]",
            "status": "pending",
            "testStrategy": "Run TC001 property tests using harness; ensure all replicas converge after randomized operation sequences across structures."
          },
          {
            "id": 5,
            "title": "Integrate with WebSocket Gateway channels and presence",
            "description": "Wire DocManager updates to WS gateway (Task 3) using crdt-sync topics; manage joins/leaves, subscriptions, and presence for editors.",
            "dependencies": [
              "20.1",
              "20.3",
              "20.4"
            ],
            "details": "Server:\n- On crdt-sync-init: validate auth, role, campaign/session membership; subscribe connection to doc topic; send snapshot+state vector; backfill missed updates.\n- On crdt-sync-update: validate schema, permissions, apply to DocManager, broadcast diff to subscribers except origin.\n- Presence: maintain editor list per doc; heartbeat using existing ping; publish presence changes.\nClient SDK:\n- Connect, subscribe, apply incoming updates to local Y.Doc, encode local changes and send updates with backpressure-aware batching.\n- Reconnect tokens to resume missed seq range (Task 3 capability).\nUse schemas from 20.3 and channels defined in Task 3.",
            "status": "pending",
            "testStrategy": "Run integration tests: multiple clients join/leave, perform concurrent edits; verify TC002 reconnect merges and TC006 backpressure/acks via simulated packet loss."
          },
          {
            "id": 6,
            "title": "Persistence: snapshotting and incremental update log in SQLite",
            "description": "Persist Y.Doc snapshots and incremental updates to local SQLite with compaction and restore paths.",
            "dependencies": [
              "20.1",
              "20.4",
              "20.5"
            ],
            "details": "Schema:\n- crdt_documents(docKey, kind, campaignId, sessionId, version, snapshotBlob, stateVector, updatedAt)\n- crdt_updates(id, docKey, seq, updateBlob, createdAt)\nImplement:\n- On interval or size threshold, snapshot current doc (encodeStateAsUpdate from empty) and store state vector; truncate updates older than latest snapshot seq.\n- On startup or client subscribe, load latest snapshot + subsequent updates to hydrate DocManager.\n- Ensure atomic writes using transactions; compress blobs (gzip/brotli).\n- Provide compaction job.\nMap composition of nested CRDTs into single Y.Doc snapshot consistent with object composition guidance.[2]",
            "status": "pending",
            "testStrategy": "Execute TC004 persistence tests: write/read roundtrip yields identical state hash; restart server and verify hydration; simulate crash between update and snapshot and ensure recovery."
          },
          {
            "id": 7,
            "title": "Role-based permissions and access control for CRDT operations",
            "description": "Enforce role-based permissions at message ingress and document mutation boundaries; implement doc-level ACLs.",
            "dependencies": [
              "20.1",
              "20.3",
              "20.5"
            ],
            "details": "Define roles: viewer, editor, GM/admin. Policy matrix:\n- viewer: subscribe read-only; cannot send crdt-sync-update.\n- editor: can update allowed docs within campaign/session.\n- GM: can create/delete docs, manage map layers, force overwrite metadata.\nImplement middleware: validate on crdt-sync-init and crdt-sync-update using campaign/session membership and doc ACLs. For inventory, enforce item-specific constraints (qty >= 0) via pre-apply checks; reject invalid ops.\nEmit crdt-sync-error with codes (PERMISSION_DENIED, INVALID_OP).",
            "status": "pending",
            "testStrategy": "Run TC003 tests: attempt unauthorized updates, ensure no state change and error returned; validate role transitions at runtime."
          },
          {
            "id": 8,
            "title": "Map document structures and operations",
            "description": "Implement high-level operations for collaborative map: layers, markers, shapes with IDs; ensure list/set semantics and stable IDs.",
            "dependencies": [
              "20.2",
              "20.4",
              "20.5"
            ],
            "details": "Within MapDoc (Y.Doc):\n- layers: Y.Map<string, Layer>, where Layer has Y.Map props and Y.Array markerIds.\n- markers: Y.Map<string, Marker>, Marker: { id, position {x,y}, label (Y.Text), props } using object composition of CRDTs.[2][3]\n- shapes: optional Y.Array of shape objects with control points.\nProvide API: addLayer, renameLayer (LWW), addMarker (generate id), moveMarker, editLabel, deleteMarker (tombstone-free by removing entry), reorder layers using Y.Array.\nEnsure independent operations act on independent state to preserve intention.[3]\nWire UI events to these APIs in client SDK.",
            "status": "pending",
            "testStrategy": "Unit tests: concurrent moves and label edits converge; deleting a marker concurrently with label edit results in delete-wins behavior as specified. Integration test: 3 clients rapidly move the same marker and edit labels; verify TC001/TC002 convergence."
          },
          {
            "id": 9,
            "title": "Notes document structures and operations",
            "description": "Implement collaborative notes with Y.Text, titles, and note collections per session.",
            "dependencies": [
              "20.2",
              "20.4",
              "20.5"
            ],
            "details": "Within NotesDoc:\n- notes: Y.Map<noteId, { title: Y.Text or LWW string, body: Y.Text, tags: Y.Array<string> }>. Prefer Y.Text for title if collaborative inline editing; otherwise LWW register semantics for last-writer-wins using logical time.[4]\nAPIs: createNote, editTitle, editBody (apply Y.Text deltas), addTag/removeTag, deleteNote.\nUse CRDT object composition to keep title/body independent.[2]",
            "status": "pending",
            "testStrategy": "Unit tests: concurrent title/body edits; delete concurrent with edit; collection add/remove races yield intended behavior. Integration: 3 clients edit same note; verify convergence and low latency (TC001/TC005)."
          },
          {
            "id": 10,
            "title": "Inventory document structures and operations",
            "description": "Implement collaborative inventory with quantities, item properties, and move operations between containers.",
            "dependencies": [
              "20.2",
              "20.4",
              "20.5",
              "20.7"
            ],
            "details": "Within InventoryDoc:\n- items: Y.Map<itemId, { name (LWW), qty (integer counter via composed register with invariants), props (Y.Map), containerId (LWW) }>. Use object composition; avoid physical timestamps pitfalls by using logical clocks/Lamport semantics via CRDT library rather than wall clocks.[5]\nAPIs: addItem, updateQty(delta), moveItem(containerId), updateProps, deleteItem. Ensure qty never negative; reject at ingress (permission layer) and clamp in client UI.\nOptionally model qty using add-wins counter if needed.",
            "status": "pending",
            "testStrategy": "Unit tests: concurrent qty updates merge associatively; move and rename conflicts resolved per LWW policy; deletion wins vs prop edits. Integration: 3 clients adjust quantities and move items; verify TC001/TC003."
          },
          {
            "id": 11,
            "title": "Client SDK: CRDT binding and offline queue",
            "description": "Create client-side bindings to UI models, manage local Y.Doc, offline queueing, and reconnection with state vector diffs.",
            "dependencies": [
              "20.5",
              "20.8",
              "20.9",
              "20.10"
            ],
            "details": "Implement a ClientDocBinding with:\n- Local Y.Doc per namespace, awareness API for cursors/presence (optional), and event listeners mapping to app state.\n- Outbox queue for updates when offline; on reconnect, compute diff using state vector and send minimal updates.\n- Batch and debounce local changes; apply server acks for backpressure.\n- Expose hooks (useNotesDoc, useMapDoc, useInventoryDoc) for UI.\n- Handle snapshot hydration and late-join using snapshot + incremental updates.",
            "status": "pending",
            "testStrategy": "UI/integration tests: simulate offline edits, then reconnect; verify TC002 convergence and no data loss. Measure latency to satisfy TC005 locally."
          },
          {
            "id": 12,
            "title": "Conflict resolution invariant tests and fuzzing harness",
            "description": "Extend property-based tests to cover edge-case invariants and long sequences with deletes, renames, and counter updates.",
            "dependencies": [
              "20.4",
              "20.8",
              "20.9",
              "20.10"
            ],
            "details": "Add fuzz suites per doc kind:\n- Notes: interleaved title/body edits, deletes, recreates.\n- Map: concurrent move+delete+rename, layer reorder conflicts.\n- Inventory: qty increments/decrements with deletes/moves.\nUse fast-check to generate sequences; verify invariants: convergence, no negative qty, referential integrity (markerId in layer list implies marker exists), and independence of unrelated operations per composition principles.[2][3]",
            "status": "pending",
            "testStrategy": "Run 1k random sequences per suite with deterministic seeds; capture minimal counterexamples on failure. Maps to TC001 and conflict-invariant coverage."
          },
          {
            "id": 13,
            "title": "Performance tuning and load tests with 10+ editors",
            "description": "Profile server/client under simulated load, tune message batching, compression, and apply rate limits.",
            "dependencies": [
              "20.5",
              "20.6",
              "20.11"
            ],
            "details": "Create a load test script spinning 12 clients per doc, performing paced edits. Measure:\n- Update apply latency, CPU, memory, bandwidth.\nTune:\n- Batch updates per 50–100ms, coalesce Yjs updates, enable compression on WS frames, snapshot compaction cadence, and rate limit per connection.\nEnsure backpressure and retries interact correctly with crdt-sync-ack.",
            "status": "pending",
            "testStrategy": "Satisfy TC005 thresholds. Record traces and ensure no dropped updates; convergence after bursts within 2s."
          },
          {
            "id": 14,
            "title": "Admin/GM tools for document ACLs and lifecycle",
            "description": "Implement APIs/UI hooks to create/delete docs, manage ACLs, and inspect state for debugging.",
            "dependencies": [
              "20.7",
              "20.6"
            ],
            "details": "Server endpoints or WS messages: createDoc, deleteDoc, setAcl(role matrix), listDocs. Persist ACLs tied to campaign/session. Provide doc inspection (state vector, snapshot size) for debugging.",
            "status": "pending",
            "testStrategy": "Integration tests: GM can create/delete and set ACLs; viewers cannot. Verify persistence restores ACLs correctly (TC003/TC004)."
          },
          {
            "id": 15,
            "title": "Observability and metrics for CRDT subsystem",
            "description": "Add logging and metrics for sync events, errors, snapshot sizes, and convergence timing.",
            "dependencies": [
              "20.5",
              "20.6",
              "20.13"
            ],
            "details": "Emit metrics: updates/sec, bytes sent, snapshot size, compaction frequency, apply latency, reject counts by reason. Structured logs for crdt-sync-error. Dashboards or console summaries for dev.",
            "status": "pending",
            "testStrategy": "Assert metrics counters change as expected during integration/load tests; budgets not exceeded under TC005."
          },
          {
            "id": 16,
            "title": "Security hardening: validation, quotas, and sandboxing",
            "description": "Ensure binary payload limits, schema version gating, and defensive handling against malformed or abusive clients.",
            "dependencies": [
              "20.3",
              "20.5",
              "20.7"
            ],
            "details": "Implement per-connection quotas (messages/sec, bytes/min), max doc size, max update size, and snapshot rate limiting. Schema version checks; reject unknown docKind/docId formats. Sanitize labels/text limits. Kill-switch feature flag to disable CRDT per campaign.",
            "status": "pending",
            "testStrategy": "Negative integration tests: send oversized payloads, invalid schema versions, rapid-fire updates; verify rejections and no server instability (extends TC006)."
          },
          {
            "id": 17,
            "title": "Documentation and developer guide",
            "description": "Produce developer docs detailing document schemas, sync protocol, ACLs, persistence, and testing procedures.",
            "dependencies": [
              "20.2",
              "20.3",
              "20.5",
              "20.6",
              "20.7",
              "20.11",
              "20.12",
              "20.13"
            ],
            "details": "Write docs: rationale for Yjs selection with references to composition and collection patterns, message schemas, example flows, persistence compaction, ACL configuration, and troubleshooting. Include runbooks for tests and load harness.",
            "status": "pending",
            "testStrategy": "Docs linting and example snippets compiled; follow a walkthrough to run TC001–TC006 tests successfully."
          }
        ]
      },
      {
        "id": 21,
        "title": "GM Orchestration Loop and Narration Beats",
        "description": "Implement GM loop delivering 2–4 sentence beats with high agency, integrating rules, missions, memory, and adapters.",
        "details": "- Prompt templates with tools: rules.check, mission.advance, memory.query, image.request, tts.speak\n- Streaming LLM responses; latency target <3s median via prompt compaction and warmups\n- Tool schema validation with zod; retries on invalid\n- Periodic insert of situation updates",
        "testStrategy": "- Latency benchmarks; synthetic sessions verify median <3s locally\n- Tool invocation unit tests with strict schema validation\n- E2E: players make actions; loop produces beats and advances mission",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write acceptance tests for GM loop, beats, tools, and latency (TC011–TC015)",
            "description": "Create a comprehensive test suite that encodes the core acceptance criteria for the GM orchestration loop: produces 2–4 sentence narration beats with high agency; integrates rules.check, mission.advance, memory.query, image.request, tts.speak; streams responses; validates tool schemas with zod and retries on invalid; periodically inserts situation updates; and meets a local median latency target <3s under synthetic sessions.",
            "dependencies": [],
            "details": "Implement unit tests and integration tests before any implementation. Include:\n- Unit tests:\n  - TC011: Beat length and agency detection. Assert output is 2–4 sentences, imperative/decisive tone tokens present, and no meandering qualifiers.\n  - TC012: Tool invocation schema validation. Mock adapters; validate zod schemas; assert retries on invalid payload; assert backoff policy and max retry cap.\n  - TC013: Prompt compaction logic. Given long memory/missions/rules, assert compactor trims to token budget while preserving priority content.\n  - TC014: Situation updater cadence. Assert periodic inserts occur every N beats or T ms, configurable.\n- Integration/E2E tests:\n  - TC015: Synthetic player actions drive loop; verify mission advances, rules checked, memory queried, optional image.request queued, tts.speak called with produced beat; stream tokens to client; measure local median time-to-first-token and time-to-final <3s across 30 runs.\n- Performance tests:\n  - Harness to simulate LLM with controllable latency distribution and token rate to measure orchestration overhead. Report median and p95.\n- Testing infrastructure:\n  - Jest/Vitest for unit, Playwright for E2E stream verification, a fake WebSocket/feed recorder for streaming assertions, and a mock clock for periodic inserts.\n- Include fixtures: sample rules, missions, memory snapshots, adapter schemas, and long-context samples for compaction tests.",
            "status": "pending",
            "testStrategy": "Run CI job stage `21-tests-acceptance` gating implementation. Fail build if TC011–TC015 do not pass. Collect latency metrics artifacts and assert thresholds."
          },
          {
            "id": 2,
            "title": "Define tool adapter interfaces and zod schemas with strict validation",
            "description": "Create typed interfaces and zod schemas for rules.check, mission.advance, memory.query, image.request, tts.speak, plus a common ToolInvocation envelope and result shape with error codes for retries.",
            "dependencies": [
              "21.1"
            ],
            "details": "Implement a tools module:\n- Common types: ToolName, ToolInvocation {id, name, input, correlationId}, ToolResult {ok, output|error}\n- zod schemas per tool with explicit min/max constraints and enums.\n- Validation helpers: validateOrThrow(name, payload) returning typed input.\n- Map tool -> adapter function signature and schema.\n- Add unit tests extending TC012 to check invalid payloads produce schema errors; ensure error messages include jsonPath.\n- Provide a mock-adapters package for tests with controllable success/failure.",
            "status": "pending",
            "testStrategy": "Run all tests; ensure TC012 passes and coverage includes both success and invalid cases."
          },
          {
            "id": 3,
            "title": "Implement retry policy with bounded backoff for invalid/failed tool calls",
            "description": "Add a generic retry wrapper with exponential backoff and jitter specifically for schema-invalid and adapter failure cases, with limits to avoid latency inflation.",
            "dependencies": [
              "21.1",
              "21.2"
            ],
            "details": "Create retryToolCall(toolFn, options) with:\n- Policies: maxRetries (default 2), baseDelay 60–120ms jitter, stop on non-retriable errors (e.g., rules violation definitive).\n- On schema invalid: attempt one prompt-side repair (LLM self-correction hint) then retry.\n- Instrumentation: counters for attempts, lastError, totalDelay; expose to metrics.\n- Plug into adapters execution layer used by GM loop.\n- Extend TC012: assert retries occur and stop at cap; measure added overhead <300ms median.",
            "status": "pending",
            "testStrategy": "Unit tests for retry logic, backoff sequence, jitter bounds, and non-retriable passthrough."
          },
          {
            "id": 4,
            "title": "Design prompt templates and compaction strategy with tool affordances",
            "description": "Create modular prompt templates guiding high-agency 2–4 sentence beats and enabling tool use affordances; implement prompt compaction and warmup strategies to hit <3s median.",
            "dependencies": [
              "21.1"
            ],
            "details": "Deliver:\n- System and developer templates encoding: role (GM), constraints (2–4 sentences, decisive verbs), safety/rules integration, mission context, memory cues, adapters instruction with function calling/tool use, and situation update slots.\n- Compaction pipeline: priority tiers (rules>current mission>recent memory>player last actions>older memory); token budget function; summarizer for older memory; truncation with ellipsis markers.\n- Warmup: pre-load model with priming conversation or cached compiled prompt skeletons; pre-request embeddings/summaries.\n- Unit tests (extends TC011, TC013): ensure compactor reduces tokens while keeping priority content; beats remain 2–4 sentences under heavy context.",
            "status": "pending",
            "testStrategy": "Snapshot tests for prompts under different contexts; token counts asserted against model max and target latency budgets."
          },
          {
            "id": 5,
            "title": "Implement GM orchestration state machine",
            "description": "Create the core loop as a finite-state machine handling input ingestion, context assembly, LLM call, tool execution, beat streaming, and cooldown/periodic updates.",
            "dependencies": [
              "21.1",
              "21.2",
              "21.3",
              "21.4"
            ],
            "details": "States: Idle -> AssembleContext -> InvokeLLM -> ExecuteTools (may interleave) -> StreamBeat -> PostBeat (update memory/mission logs, schedule situation updates) -> Idle.\n- Context assembly pulls rules, mission status, recent memory, player actions; passes through compactor.\n- Supports tool function-calling mode: parse tool calls, validate via zod, execute via retry wrapper, feed results back to LLM until final beat.\n- Periodic situation update injection: every K beats or T seconds, insert a lightweight scene delta before or within the beat per config.\n- Configurable knobs: sentence range 2–4, cadence, tool timeouts, max tool chain length.\n- Events and metrics emitted at each transition.",
            "status": "pending",
            "testStrategy": "Integration tests driving the FSM with synthetic actions; assert order of states, correct emissions, and that TC014 and TC015 pass."
          },
          {
            "id": 6,
            "title": "Streaming response pipeline with time-to-first-token optimization",
            "description": "Implement streaming from the LLM to clients and to TTS adapter, minimizing orchestration overhead and ensuring backpressure handling.",
            "dependencies": [
              "21.1",
              "21.5"
            ],
            "details": "Add:\n- Stream multiplexer: LLM SSE/WebSocket tokens -> client stream and TTS pre-buffer.\n- Backpressure: bounded queues; drop/collapse slow consumer strategy with notices.\n- Early flush: send header/meta immediately, start tokens as they arrive; compute TTFB.\n- Cancellation: user interrupts cancel current generation and tool chain safely.\n- Metrics: TTFB, tokens/sec, end-to-end time.\n- Ensure beat boundary detection for 2–4 sentences; finalize on sentence end or token cap.",
            "status": "pending",
            "testStrategy": "E2E streaming tests using Playwright: assert tokens arrive incrementally, captions/TTF sync hook invoked; verify median TTFB contributes to <3s total (TC015)."
          },
          {
            "id": 7,
            "title": "Integrate tool adapters into loop with strict schema validation",
            "description": "Wire rules.check, mission.advance, memory.query, image.request, and tts.speak into the ExecuteTools stage with validation and retries.",
            "dependencies": [
              "21.2",
              "21.3",
              "21.5"
            ],
            "details": "Implement execution router:\n- On tool call message, validate input via zod; on success, call adapter through retryToolCall; on result, append to tool context and continue LLM function-calling until final content.\n- Enforce max tool depth/chain length to avoid loops; timeouts per tool.\n- For tts.speak, start after first sentence boundary to minimize perceived latency; ensure payload matches TTS task expectations (voice id, text chunking).\n- For image.request, queue async and return placeholder reference for later rendering.",
            "status": "pending",
            "testStrategy": "Unit/integration tests using mocks: ensure invalid schemas are retried; verify tool outputs are surfaced to the LLM and reflected in the final beat; ensure TC012 and TC015 continue to pass."
          },
          {
            "id": 8,
            "title": "High-agency beat generator with sentence control",
            "description": "Enforce 2–4 sentence outputs with decisive tone and content validation; implement post-processor to trim/merge sentences and reject low-agency phrasing.",
            "dependencies": [
              "21.4",
              "21.5",
              "21.6"
            ],
            "details": "Add a BeatPostprocessor:\n- Sentence segmentation; enforce limits; if >4, truncate at boundary; if <2, request LLM continuation or synthesize concise closer.\n- Agency heuristics: forbid weak hedges list; require imperative verbs or strong assertions; soft-penalize passive voice; fallback correction prompt if needed.\n- Ensure compatibility with streaming: hold a rolling window to validate and decide early tts.speak triggers.\n- Configuration per campaign for tone/dialect.",
            "status": "pending",
            "testStrategy": "Extend TC011 with adversarial prompts; assert beats remain 2–4 sentences and pass agency checks. Add unit tests for sentence segmentation edge cases."
          },
          {
            "id": 9,
            "title": "Situation update scheduler and insertion logic",
            "description": "Implement periodic situation updates injected into the narration flow without breaking pacing.",
            "dependencies": [
              "21.5"
            ],
            "details": "Develop a scheduler tracking beats count and time; when threshold met, prepend or append a concise scene delta (1 sentence) via a lightweight LLM call or templated update using world state deltas. Provide debouncing so updates do not cluster after pauses.",
            "status": "pending",
            "testStrategy": "Validate TC014 with fake clock; ensure updates fire on cadence and are integrated as separate sentences without exceeding 4-sentence cap."
          },
          {
            "id": 10,
            "title": "Latency budgeter, warmups, and prompt token budgeting",
            "description": "Introduce a latency budget manager orchestrating warmup calls, cache hits for prompts, and token budgets to meet <3s median locally.",
            "dependencies": [
              "21.4",
              "21.5",
              "21.6"
            ],
            "details": "Components:\n- Warmup manager: issue tiny priming calls at session start/idle intervals; keep adapter connections warm.\n- Prompt cache: hash of compacted prompt skeleton + context keys; reuse where safe.\n- Token budget calculator: model throughput tokens/sec; aim for output <= 80 tokens for 2–4 sentences; adjust stop sequences.\n- Abort long generations at cap and request concise restatement if needed.",
            "status": "pending",
            "testStrategy": "Performance tests: simulate 30 sessions; assert median end-to-end <3s, track improvements when warmups enabled. Ensures TC015 passes consistently."
          },
          {
            "id": 11,
            "title": "Metrics, tracing, and observability for the GM loop",
            "description": "Add structured logging, traces, and counters to measure tool attempts, retries, latency breakdowns, and success rates.",
            "dependencies": [
              "21.5",
              "21.6"
            ],
            "details": "Emit spans for states and tool calls; counters for retries, invalid schemas, tool chain depth; histograms for TTFB, total time; gauges for queue sizes. Provide a debug dashboard or CLI report summarizing last N sessions.",
            "status": "pending",
            "testStrategy": "Add assertions in tests to check metrics are emitted; run perf suite and export a trace to verify spans and timing breakdowns."
          },
          {
            "id": 12,
            "title": "E2E integration with TTS and image adapters",
            "description": "Ensure beats are chunked to TTS with voice context and captions, and image requests are queued and resolved into UI placeholders.",
            "dependencies": [
              "21.6",
              "21.7",
              "21.8"
            ],
            "details": "For TTS: split beat into sentence chunks; send first sentence as soon as stable; include speaker/NPC voice id and captions timestamps hooks. For image: enqueue generation, return handle; when ready, emit event to append visual to scene.",
            "status": "pending",
            "testStrategy": "E2E test: player action -> beat spoken with correct voice and captions; image placeholder appears and resolves. Complements Task 7 tests."
          },
          {
            "id": 13,
            "title": "Error handling, recovery, and user-facing fallbacks",
            "description": "Implement graceful degradation: if tools or LLM fail, produce a concise beat explaining a brief delay and continue; persist minimal state to resume.",
            "dependencies": [
              "21.5",
              "21.6",
              "21.7"
            ],
            "details": "Add categorized errors and fallbacks: switch to minimal-context template on repeated failures; skip optional tools (image) under pressure; revert to cached summaries if memory.query fails; ensure loop does not deadlock.",
            "status": "pending",
            "testStrategy": "Fault injection in integration tests: drop adapter responses, force schema errors; assert a beat still emits within 3s with a fallback message; metrics record the incident."
          },
          {
            "id": 14,
            "title": "Configuration, feature flags, and admin controls",
            "description": "Expose knobs for sentence limits, cadence, max tool depth, timeouts, warmup intervals, and situation update policies with runtime flags.",
            "dependencies": [
              "21.5",
              "21.9",
              "21.10"
            ],
            "details": "Provide config schema and hot-reload; validate with zod; bind to environment and per-campaign overrides; log effective config per session.",
            "status": "pending",
            "testStrategy": "Unit tests ensure invalid configs are rejected; E2E toggles verify behavior changes (e.g., sentence cap from 4 to 3)."
          },
          {
            "id": 15,
            "title": "Documentation and developer guide with examples",
            "description": "Author developer docs showing state machine diagrams, prompt examples, tool schemas, and troubleshooting playbooks.",
            "dependencies": [
              "21.5",
              "21.11",
              "21.14"
            ],
            "details": "Include: sequence diagrams for a typical turn; code samples for adding a new tool; latency optimization checklist; FAQ for schema errors and retries; guidance for writing high-agency styles.",
            "status": "pending",
            "testStrategy": "Doc lints build; examples compiled in CI; runnable snippets as part of tests where feasible."
          }
        ]
      },
      {
        "id": 22,
        "title": "Accessibility and Captioning Compliance",
        "description": "Ensure captions everywhere, adjustable speech rate/volume, color contrast, and keyboard navigation fallback.",
        "details": "- Global caption track toggle; per-channel captions; ARIA roles and landmarks\n- Contrast tokens meet WCAG AA; focus management\n- Keyboard-only flows for critical actions\n- Settings persist per player locally",
        "testStrategy": "- Automated axe tests; manual keyboard nav checklist\n- Contrast checker CI step\n- Verify captions available for all audio sources",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and write failing tests for accessibility and captioning (TC001–TC006)",
            "description": "Capture concrete acceptance criteria and implement initial failing tests covering captions availability, caption toggles, per-channel captions, adjustable speech rate/volume controls, color contrast tokens (WCAG AA), keyboard-only navigation for critical flows, ARIA roles/landmarks, focus management, and per-player local persistence.",
            "dependencies": [],
            "details": "• Define acceptance criteria mapped to verification IDs:\n  - TC001: Captions available for all audio sources and channels; default off unless globally toggled.\n  - TC002: Global caption track toggle affects all players; per-channel caption toggles override global.\n  - TC003: Adjustable speech rate and volume per channel with defined ranges (rate 0.5–2.0x in 0.1 steps; volume 0–1.0 in 0.05 steps) and persistence per player in local storage/indexedDB.\n  - TC004: Color contrast tokens meet WCAG 2.1 AA (text ≥ 4.5:1; large text ≥ 3:1; UI components ≥ 3:1) and are enforced via design tokens.\n  - TC005: Keyboard-only flows for critical actions (play/pause, toggle captions, adjust rate/volume, open/close settings, save) with visible focus and logical tab order.\n  - TC006: ARIA roles/landmarks present; focus management returns to invoking control; live regions for captions.\n• Unit tests: token contrast calculations, persistence adapter R/W, reducer/state for toggles and controls, ARIA attributes presence, focus trap utilities.\n• Integration/UI tests (e.g., Playwright/Cypress + Axe): keyboard-only paths for critical flows, axe automated checks, captions displayed and synced during playback, global vs per-channel precedence, contrast checker step on theme tokens.\n• Provide test fixtures: mock audio sources, mock TTS timestamps, seeded theme tokens.\n• Ensure tests fail initially to drive implementation.",
            "status": "pending",
            "testStrategy": "Implement Jest/Vitest unit tests and Playwright/Cypress E2E with axe-core. Add CI job: contrast check over tokens and axe run on key pages. Record TC001–TC006 mappings in test names."
          },
          {
            "id": 2,
            "title": "Implement caption data model and rendering with ARIA live region",
            "description": "Introduce data structures and UI components to render captions for all audio sources and channels with a live region for assistive tech.",
            "dependencies": [
              "22.1"
            ],
            "details": "• Add CaptionTrack model: {id, channelId, cues: [{start,end,text}], source: 'tts'|'file'|'manual'}.\n• Implement CaptionService: APIs to register tracks per channel, subscribe to playback time, and emit active cues.\n• UI: <CaptionsOverlay channelId> reads active cues and renders text with high-contrast styling, role='region' aria-live='polite' aria-atomic='true'.\n• Ensure overlay is toggleable and does not trap focus; it should be screen-reader friendly but not interfere with keyboard nav.\n• Provide fallback when timestamps unavailable: time-based approximate sync using chunked text.\n• Run tests from 22.1 and make TC001 pass.",
            "status": "pending",
            "testStrategy": "Unit: cue selection given currentTime boundaries and edge cases; fallback chunking when timestamps missing. UI: captions appear within 100ms tolerance; axe has no violations for overlay; TC001 integration verifies all audio sources render captions."
          },
          {
            "id": 3,
            "title": "Global and per-channel captions toggle with precedence rules",
            "description": "Add global caption toggle and per-channel toggles with clear precedence logic and persisted state.",
            "dependencies": [
              "22.1",
              "22.2"
            ],
            "details": "• State: captions: {globalEnabled: boolean, channels: Record<channelId, {enabled?: boolean}>}.\n• Precedence: effectiveEnabled(channel) = channels[channel]?.enabled ?? globalEnabled.\n• UI: global toggle in settings menu; per-channel toggle in channel controls.\n• Connect to CaptionsOverlay visibility by effectiveEnabled.\n• Integrate with persistence layer (see 22.6) and emit events for analytics if needed.\n• Run tests and ensure TC002 passes.",
            "status": "pending",
            "testStrategy": "Unit: precedence function truth table; reducer actions; persisted hydration. UI: toggling global cascades; per-channel override respected; axe checks on toggle controls."
          },
          {
            "id": 4,
            "title": "Implement speech rate and volume controls per channel with bounds and smoothing",
            "description": "Provide per-channel rate and volume controls with defined ranges, step increments, debounced updates, and immediate audio effect.",
            "dependencies": [
              "22.1",
              "22.2"
            ],
            "details": "• Expose per-channel AudioController APIs: setRate(rate), setVolume(vol), getState(). Ensure clamped ranges: rate 0.5–2.0, volume 0–1.0.\n• UI controls: slider inputs with keyboard operability (Left/Right/Up/Down/Page keys), aria-valuemin/max/now, labeled by.\n• Apply ramping (linRampToValue over 100–200ms) to avoid pops.\n• Wire to captions timing: adjust caption pacing if derived from TTS timestamps; otherwise do not desync.\n• Persist control values per player (22.6).\n• Run tests and ensure TC003 passes.",
            "status": "pending",
            "testStrategy": "Unit: clamping, step rounding, ramp scheduling. UI: keyboard adjustment sequences; live updates reflect immediately; E2E verifies persistence reload."
          },
          {
            "id": 5,
            "title": "WCAG AA color contrast tokens and enforcement",
            "description": "Define design tokens for text, large text, and UI components that meet WCAG 2.1 AA and enforce via lint/CI.",
            "dependencies": [
              "22.1"
            ],
            "details": "• Token set: semantic colors (textPrimary, textSecondary, link, focusRing, background, surface, buttonPrimary, buttonText, disabled, captionBg, captionText).\n• Compute contrast ratios programmatically and fail build if below thresholds (text ≥ 4.5:1; large text and UI components ≥ 3:1).\n• Add contrast CI step that checks tokens and common combinations.\n• Update themes to use tokens in components including CaptionsOverlay.\n• Run tests and ensure TC004 passes.",
            "status": "pending",
            "testStrategy": "Unit: contrastRatio(colorA,colorB) util; snapshot of token ratios. CI: run contrast checker over tokens; fail pipeline on violations. Visual regression optional."
          },
          {
            "id": 6,
            "title": "Per-player local persistence for accessibility settings",
            "description": "Persist caption toggles, rate, and volume per player using local storage/indexedDB with a namespaced key including playerId.",
            "dependencies": [
              "22.1",
              "22.3",
              "22.4"
            ],
            "details": "• Storage key: accessibility:<playerId> with schema {captionsGlobal, captionsByChannel, rateByChannel, volumeByChannel, lastUpdated}.\n• Implement persistence adapter with debounce and versioning/migration.\n• Hydrate settings on player session start and broadcast to relevant components.\n• Run tests and update previous subtasks to use persistence; ensure TC003/TC002 persistence aspects pass.",
            "status": "pending",
            "testStrategy": "Unit: read/write, migrations, corruption handling. Integration: reload page preserves settings; multi-channel values restored."
          },
          {
            "id": 7,
            "title": "Keyboard-only navigation for critical flows with focus management",
            "description": "Ensure all critical actions are operable via keyboard with logical order, visible focus, ARIA semantics, and proper focus trapping/return.",
            "dependencies": [
              "22.1",
              "22.3",
              "22.4",
              "22.5"
            ],
            "details": "• Identify critical flows: play/pause, open settings, toggle captions (global/channel), adjust rate/volume, save/close.\n• Implement focus styles using tokens (focusRing), ensure tab order follows DOM order; add skip links if needed.\n• Dialogs: role='dialog' aria-modal='true', focus trap inside, return focus to opener on close.\n• Controls: ensure role, name, value exposed; sliders support Arrow/Page/Home/End keys.\n• Add keyboard shortcut hints (tooltips with aria-describedby).\n• Run tests to satisfy TC005.",
            "status": "pending",
            "testStrategy": "Playwright with keyboard-only scripts; assert focus movement and action results. Axe automated checks for interactive components. Manual checklist for edge cases."
          },
          {
            "id": 8,
            "title": "ARIA roles, landmarks, and live regions audit and implementation",
            "description": "Add appropriate ARIA roles/landmarks across the player UI and verify announcements for dynamic captions content.",
            "dependencies": [
              "22.1",
              "22.2",
              "22.7"
            ],
            "details": "• Landmarks: role='banner' for header, 'main' for content, 'complementary' if side panel, 'contentinfo' for footer.\n• Controls: ensure native elements or add roles; name via aria-label/aria-labelledby; state via aria-pressed/aria-checked as appropriate.\n• Captions: aria-live='polite' with throttled updates; aria-atomic for entire line announcements.\n• Ensure no redundant or conflicting roles.\n• Run tests to meet TC006.",
            "status": "pending",
            "testStrategy": "Axe audits should pass; screen reader smoke tests (NVDA/VoiceOver) for captions announcements and control labels. Unit snapshot tests for ARIA attributes presence."
          },
          {
            "id": 9,
            "title": "Integration: Caption sync with TTS and audio playback",
            "description": "Wire captions to TTS timestamps when available and fall back gracefully when missing; ensure sync across variable speech rates.",
            "dependencies": [
              "22.2",
              "22.4",
              "22.7"
            ],
            "details": "• Subscribe to TTS adapter events for word/phrase timestamps if Task 7 provides; map to cues.\n• Adjust timing when rate changes by scaling cue windows; if only audio clock available, align via currentTime.\n• Ensure channels independently sync.\n• Run tests to verify TC001/TC003 end-to-end with TTS integration.",
            "status": "pending",
            "testStrategy": "E2E: simulated TTS stream with timestamps; verify cue highlighting matches audio segments within tolerance. Unit: scaling math for rate changes."
          },
          {
            "id": 10,
            "title": "Automated accessibility testing in CI (axe, contrast checker) and reporting",
            "description": "Add CI jobs to run axe against key player routes and a contrast checker against tokens; publish artifacts and gating rules.",
            "dependencies": [
              "22.5",
              "22.7",
              "22.8"
            ],
            "details": "• Configure headless browser to load player pages; run axe-core and collect violations.\n• Contrast step: run token contrast script; fail on AA violations.\n• Output JUnit/HTML reports; annotate PRs with violations; add thresholds to block merges.\n• Run test suite to ensure TC004–TC006 are enforced automatically.",
            "status": "pending",
            "testStrategy": "CI pipeline dry run with seeded violations to ensure failures are caught; then enforce gating."
          },
          {
            "id": 11,
            "title": "UI polish: caption overlay theming, resizing, and readability controls",
            "description": "Enhance captions overlay with adjustable font size, background opacity, and positioning while maintaining accessibility.",
            "dependencies": [
              "22.2",
              "22.5",
              "22.6"
            ],
            "details": "• Add per-player settings: caption font size (e.g., 14–36px), background opacity (0.3–0.85), position (bottom/top).\n• Ensure contrast between caption text and overlay background meets AA at all combinations; restrict ranges to guarantee compliance.\n• Keyboard-accessible controls; persist values.\n• Run tests to ensure no new contrast or keyboard issues.",
            "status": "pending",
            "testStrategy": "Unit: validate setting ranges and contrast checks. UI: keyboard adjustments reflect visually and persist."
          },
          {
            "id": 12,
            "title": "Keyboard-only flows E2E and manual checklist completion",
            "description": "Execute comprehensive keyboard-only E2E tests and finalize manual checklist coverage for edge cases and regressions.",
            "dependencies": [
              "22.7",
              "22.8",
              "22.10"
            ],
            "details": "• Expand E2E to include error states, modal reopen, multiple channels concurrently, and rapid toggling.\n• Validate focus trapping, escape to close, and return focus in all dialogs.\n• Document any exceptions and create follow-up defects if needed.\n• Run tests and ensure they pass before sign-off.",
            "status": "pending",
            "testStrategy": "Playwright scripts for complex sequences; manual pass with standardized keyboard nav checklist logged in CI artifacts."
          }
        ]
      },
      {
        "id": 23,
        "title": "Performance and Reliability Hardening",
        "description": "Implement retries/backoff for provider calls, WebSocket stability, and caching to meet performance targets.",
        "details": "- Exponential backoff with jitter for adapters\n- Connection monitor and auto-reconnect; offline queueing\n- Image cache hit optimization; token usage tracking and prompt compaction\n- Profiling and flamegraphs; GC tuning hints",
        "testStrategy": "- Load tests simulate burst traffic; verify targets: STT<800ms, GM<3s, TTS<1.2s medians locally\n- Fault injection tests for adapter failures\n- Cache hit rate monitoring >60% for repeated requests",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance criteria and write unit/integration tests for performance and reliability hardening",
            "description": "Before implementation, codify acceptance criteria and create tests covering retries/backoff with jitter for provider adapters, WebSocket stability (monitoring, auto-reconnect, offline queue), caching effectiveness, and profiling hooks. Include at least one unit test and one integration test. Tag tests with verification IDs: TC016 (retry/backoff), TC017 (WebSocket stability), TC018 (caching hit rate), TC019 (latency targets).",
            "dependencies": [],
            "details": "• Draft acceptance criteria: \n- Retries: adapter calls use exponential backoff with full jitter; cap max delay; idempotent-safe retries; circuit breaker opens after threshold.\n- WebSocket: connection monitored; auto-reconnect with backoff; offline queue buffers outbound events until connected; no message duplication or reordering beyond at-least-once semantics.\n- Caching: image cache achieves >=60% hit rate on repeated requests; cache keying and eviction strategy defined; token usage tracked; prompt compaction reduces tokens by >=20% on repeated dialog context.\n- Performance targets locally: STT median <800ms, Generation/GM median <3s, TTS median <1.2s under burst traffic.\n• Tests to add:\n- Unit: backoff schedule correctness with jitter bounds; retry stops on non-retryable errors; circuit breaker transitions; cache key/hash determinism; LRU eviction; token accounting; prompt compaction length reduction.\n- Integration: fault injection for adapter failures verifying retries and final behavior; simulated WebSocket server that drops/halts to verify reconnect and offline queue flush; load test harness generating burst traffic and measuring latencies; repeated image requests to measure cache hit rate.\n- Include metrics assertions and export hooks used by tests.\n• Testing scaffolding: add test helpers for fake time (advance timers), flaky provider stubs (error rates), WS test server, and metrics registry. \n• Mark tests with TC016–TC019 and wire into CI job `perf-reliability-suite`.",
            "status": "pending",
            "testStrategy": "Run new test suites to see them fail initially: unit (retry/backoff, caching) and integration (WS stability, load/caching). Establish baseline reports for TC016–TC019."
          },
          {
            "id": 2,
            "title": "Implement exponential backoff with full jitter utility and integrate into provider adapters",
            "description": "Create a reusable backoff module implementing exponential backoff with full jitter, max attempts, max delay, and per-error retry policies. Integrate into all provider adapters (LLM, STT, TTS, Image). Ensure idempotency and timeouts.",
            "dependencies": [
              "23.1"
            ],
            "details": "• Backoff utility: function signature like `retry(fn, {base=100ms, factor=2, jitter='full', maxDelay=5s, maxAttempts=6, timeoutPerAttempt, isRetryable(err), onAttempt, signal})`.\n• Full jitter: nextDelay = random(0, min(maxDelay, base * factor^n)).\n• Respect cancellation and deadlines via AbortSignal.\n• Define retryable categories: 429/5xx, network errors, timeouts. Non-retryable: 4xx (except 408/409/429), validation errors.\n• Add per-adapter policies (e.g., image generation longer timeouts). \n• Instrument attempts, delays, outcomes via metrics (counters and histograms) and logs with structured fields.\n• Update adapters to wrap outbound calls with `retry`. Ensure idempotent request keys for safe retries when provider supports it; otherwise guard side-effecting endpoints (no retry on partial success signals).\n• Add configuration: env/flags for backoff parameters and max attempts; sane defaults.",
            "status": "pending",
            "testStrategy": "Run unit tests for backoff schedule, jitter bounds, and retry policies (TC016). Run integration fault injection tests to ensure retries occur and stop appropriately."
          },
          {
            "id": 3,
            "title": "Add circuit breaker around provider adapters",
            "description": "Introduce a circuit breaker to prevent cascading failures on persistent errors, with states Closed/Half-Open/Open and rolling error rate calculation.",
            "dependencies": [
              "23.1",
              "23.2"
            ],
            "details": "• Implement breaker with configurable failure threshold (e.g., >50% over last N requests or consecutive failures), open duration, half-open probe count.\n• Expose metrics for state transitions and short-circuits. \n• Wrap provider adapter calls: on Open, immediately fail fast with specific error; half-open allows limited trial calls.\n• Ensure interoperability with retry: retries operate within Closed/Half-Open; Open should not schedule retries.\n• Add config toggles and per-adapter overrides.",
            "status": "pending",
            "testStrategy": "Unit: simulate failure bursts to trigger Open; verify Half-Open probes; ensure reset on success (TC016). Integration: inject provider outage; verify fail-fast after threshold and recovery when provider returns."
          },
          {
            "id": 4,
            "title": "WebSocket connection monitor with auto-reconnect and exponential backoff",
            "description": "Implement a connection monitor for client/server WebSockets that detects disconnects, schedules reconnects with backoff+jitter, and surfaces connection state.",
            "dependencies": [
              "23.1"
            ],
            "details": "• Monitor responsibilities: heartbeat/ping-pong, idle timeout, detect close/error codes, and reconnect strategy using the backoff utility with jitter and caps.\n• Preserve authentication/session context on reconnect; refresh tokens if needed.\n• Provide observable state machine: CONNECTING, OPEN, CLOSING, CLOSED, RECONNECTING. Emit events for UI/logic.\n• Metrics: connection uptime %, reconnect attempts, time-to-reconnect.\n• Configurable policies: max attempts, initial delay, ping interval, idle timeout.",
            "status": "pending",
            "testStrategy": "Integration: WS test server that closes connections randomly; assert reconnect within bounded window and state transitions (TC017). Unit: heartbeat timeout detection logic."
          },
          {
            "id": 5,
            "title": "Offline outbound queue with exactly-once de-duplication on reconnect",
            "description": "Add an offline queue buffering outbound messages/events when WS is disconnected, flushing on reconnect with idempotency keys to prevent duplicates.",
            "dependencies": [
              "23.1",
              "23.4"
            ],
            "details": "• Queue design: durable (in-memory with optional persistence), ordering preserved; backpressure via size/time caps and drop policies for non-critical messages.\n• Each message carries idempotency key and monotonic sequence; server acknowledges processed keys, enabling client to skip duplicates on resend.\n• Flush strategy: upon OPEN event, drain queue respecting rate limits; retry with backoff on transient send failures.\n• Ensure at-least-once delivery semantics without duplication on server via dedupe cache.\n• Metrics: queue length, dropped messages, flush duration.",
            "status": "pending",
            "testStrategy": "Integration: simulate offline period; enqueue messages; reconnect and verify no duplicates and preserved order (TC017). Unit: queue eviction and dedupe logic."
          },
          {
            "id": 6,
            "title": "Image cache with key normalization, LRU eviction, and prewarming",
            "description": "Implement an image cache layer with deterministic keying and LRU eviction to improve hit rate for repeated image generation/fetches; include optional prewarm hooks.",
            "dependencies": [
              "23.1"
            ],
            "details": "• Cache key: normalize prompts, parameters, model version, seed, size, and post-processing options; hash into stable key.\n• Storage: in-memory LRU with size limits (count/bytes) plus optional disk-backed store; respect TTLs.\n• Prewarm: allow seeding cache for common assets.\n• Expose metrics: hit/miss, evictions, byte hit rate.\n• Thread-safety and concurrency: lock per key to prevent thundering herd (single-flight).",
            "status": "pending",
            "testStrategy": "Unit: key normalization determinism; LRU eviction correctness; single-flight prevents duplicate work (TC018). Integration: repeated requests under load achieve >=60% hit rate."
          },
          {
            "id": 7,
            "title": "Token usage tracking and prompt compaction middleware",
            "description": "Add middleware to track token usage across requests and implement prompt compaction to reduce context length while preserving fidelity.",
            "dependencies": [
              "23.1"
            ],
            "details": "• Token accounting: intercept adapter requests; compute prompt and completion tokens using tokenizer; record per-request metrics and cumulative usage.\n• Prompt compaction: rules such as deduplicating repeated instructions, trimming stale turns beyond window, summarizing long histories, and compressing system prompts; target >=20% reduction where applicable.\n• Configurable policies per campaign/session. \n• Emit metrics and attach compaction summaries for auditing.",
            "status": "pending",
            "testStrategy": "Unit: verify token counts align with tokenizer; compaction reduces tokens >=20% on synthetic long history; idempotency of compaction for repeated runs. Integration: end-to-end run shows reduced token usage without changing required outputs (spot-check)."
          },
          {
            "id": 8,
            "title": "Profiling hooks, flamegraph capture, and GC tuning hints",
            "description": "Integrate profiling instrumentation to capture CPU profiles/flamegraphs and expose memory/GC metrics. Provide guidance knobs for GC tuning.",
            "dependencies": [
              "23.1"
            ],
            "details": "• Add start/stop profiling endpoints or CLI flags to capture CPU/heap profiles during load tests; export in standard formats (pprof or similar).\n• Emit metrics: GC pauses, heap in use, allocation rate, object churn.\n• Configurable GC parameters via env flags (e.g., heap growth target, concurrent GC toggles) with safe defaults and documentation.",
            "status": "pending",
            "testStrategy": "Manual/integration: run load test and collect profiles; verify artifacts generated and metrics exposed. Unit: basic sanity on metrics exporters."
          },
          {
            "id": 9,
            "title": "Latency load tests for STT, GM, and TTS with burst traffic",
            "description": "Build a load testing harness to generate burst traffic across STT, generation/GM, and TTS paths, recording latency distributions and asserting medians meet targets.",
            "dependencies": [
              "23.1",
              "23.2",
              "23.3",
              "23.4",
              "23.5",
              "23.6",
              "23.7",
              "23.8"
            ],
            "details": "• Implement scenarios: concurrent requests with spikes; representative payloads.\n• Collect p50/p95 latencies and throughput; export JUnit-like assertions for CI.\n• Targets: STT <800ms p50, GM <3s p50, TTS <1.2s p50 on local profile. Gate CI if violated (TC019).\n• Integrate with profiling hooks to capture flamegraphs during runs.",
            "status": "pending",
            "testStrategy": "Execute harness repeatedly to stabilize results; verify CI gating and profile artifacts (TC019)."
          },
          {
            "id": 10,
            "title": "Cache effectiveness tests and tuning",
            "description": "Measure and tune cache hit rates under realistic workloads; adjust keying, TTLs, and prewarming to achieve >=60% hit rate for repeated requests.",
            "dependencies": [
              "23.1",
              "23.6",
              "23.9"
            ],
            "details": "• Design workload with repeated asset requests and variant mixes to avoid overfitting.\n• Iterate on TTLs, LRU capacity, and prewarm sets.\n• Add dashboard or logs summarizing hit/miss and byte hit rate; assert TC018 threshold.",
            "status": "pending",
            "testStrategy": "Run workload and confirm hit rate >=60% and stable under bursts (TC018)."
          },
          {
            "id": 11,
            "title": "Fault injection scenarios for adapter reliability",
            "description": "Expand fault injection to simulate timeouts, 429s, intermittent 5xx, malformed responses, and slow responses; verify retries/backoff and circuit breaker behavior end-to-end.",
            "dependencies": [
              "23.1",
              "23.2",
              "23.3",
              "23.9"
            ],
            "details": "• Implement adapter fakes with configurable error rates and latency distributions.\n• Scenarios check: retry counts, exponential delays with jitter, breaker open on sustained failures, recovery after cooldown.\n• Collect metrics snapshots to confirm behavior matches design (TC016).",
            "status": "pending",
            "testStrategy": "Run each scenario multiple times to cover edge probabilities; assert no request storms and bounded latencies."
          },
          {
            "id": 12,
            "title": "WebSocket soak and chaos tests with offline queue validation",
            "description": "Subject WebSocket layer to long-running and chaotic conditions to validate reconnection, backoff, and offline queue correctness.",
            "dependencies": [
              "23.1",
              "23.4",
              "23.5"
            ],
            "details": "• Chaos patterns: random disconnects, network partitions, high latency, packet loss.\n• Assertions: reconnect within bounded windows, no message loss, no duplicates (idempotency keys), bounded queue growth.\n• Collect uptime %, reconnect counts, and flush times (TC017).",
            "status": "pending",
            "testStrategy": "Run soak for several hours in CI nightly; quick chaos smoke in PRs. Use deterministic seeds where possible."
          },
          {
            "id": 13,
            "title": "Documentation and configuration templates for performance and reliability features",
            "description": "Document configuration parameters, operational runbooks, and provide defaults for backoff, breaker, WS, caching, and profiling/GC settings.",
            "dependencies": [
              "23.2",
              "23.3",
              "23.4",
              "23.5",
              "23.6",
              "23.7",
              "23.8",
              "23.9",
              "23.10",
              "23.11",
              "23.12"
            ],
            "details": "• Write docs covering: settings, recommended defaults, when to tune, and troubleshooting guides.\n• Include configuration examples for local, staging, production.\n• Add dashboards/alerts suggestions for key metrics.",
            "status": "pending",
            "testStrategy": "Docs lint/build passes; operator walkthrough validated against a staging environment."
          }
        ]
      },
      {
        "id": 24,
        "title": "AI-Generated Video Upgrade (Feature Flag)",
        "description": "Add optional video generation for cutscenes and ambient loops with caching and identity consistency from images/storyboards.",
        "details": "- Feature flag r13VideoEnabled\n- VideoGenAdapter interface; providers: local i2v or cloud (disabled by default)\n- API: /videos request lifecycle similar to images; cache reuse by storyboard hash\n- Identity consistency: reuse character embeddings/prompts from images\n- UI: preview player; ambient loop support",
        "testStrategy": "- TC019: lifecycle, identity/continuity tolerance checks; cache reuse SLA\n- Fallbacks when disabled; ensure no external calls when flag off",
        "priority": "low",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define acceptance tests for video lifecycle, caching, identity consistency, and flag off behavior",
            "description": "Create failing unit and integration/UI tests that capture the core acceptance criteria for AI-generated video under feature flag r13VideoEnabled, including lifecycle parity with images, cache reuse by storyboard hash, identity consistency with images/storyboards, ambient loop handling, and no external calls when the flag is off.",
            "dependencies": [],
            "details": "Implement tests before any production code. Cover:\n- TC019: Video request lifecycle mirrors images: POST /videos creates job, status polling, completion with asset URLs, errors, cancellation. Include SLA assertions for cache reuse path (faster completion) vs cold path.\n- Identity consistency: for the same characters/storyboard, generated videos reuse character embeddings/prompts from images; verify deterministic identity features (e.g., facial embedding cosine similarity threshold) between poster frame of video and source image.\n- Cache reuse by storyboard hash: second request with same storyboardHash returns cached video or immediate reference; ensure idempotency and cache hit markers in response metadata.\n- Ambient loop support: generate loopable short ambient clip; verify auditory track optional and loop points encoded or visual loop seamlessness (frame delta threshold at boundary).\n- Feature flag OFF: with r13VideoEnabled=false, POST /videos returns 403 or 501 with clear error; ensure no provider adapter invocation and no outbound network calls.\n- UI: preview player renders when flag ON and hides when OFF; basic play/pause and loop toggle; integration/UI test to confirm.\n- Provider selection: default disabled; local i2v and cloud adapters behind adapter registry.\nCreate unit tests for API controllers, services, adapter selection, cache service; integration tests hitting in-memory server; UI tests via Playwright/Cypress. Seed test fixtures: sample storyboard JSON, character image embeddings.",
            "status": "pending",
            "testStrategy": "Unit tests: Jest/Vitest for controllers/services; mock adapters. Integration: supertest against in-memory server for /videos lifecycle. Caching: use a temp cache store and measure path selection. Identity: compute CLIP/FaceNet embeddings to assert similarity over threshold. UI: Playwright/Cypress to validate preview visibility, playback, loop toggle, and disabled state when flag OFF. Tag with TC019 in relevant tests."
          },
          {
            "id": 2,
            "title": "Introduce r13VideoEnabled feature flag wiring and guard rails",
            "description": "Add runtime-configurable feature flag r13VideoEnabled across API, services, and UI. Default to false. Ensure all video-related paths are gated to prevent adapter invocation and outbound calls when disabled.",
            "dependencies": [
              "24.1"
            ],
            "details": "Backend: extend config provider (env/remote) with r13VideoEnabled (default false). Add middleware/guard in /videos routes and VideoService that short-circuits with 501 Not Implemented and telemetry event video.flag_disabled. Ensure adapters are not resolved when disabled. Add network guard assertion hook to verify no outbound calls when flag off. Frontend: conditionally render preview player and menu items based on flag fetched from /config. Add feature docs and ops toggle. Run tests and make them pass.",
            "status": "pending",
            "testStrategy": "Run TC019 flag-off tests; assert route returns 501 and no adapter calls using spies; UI test confirms hidden components."
          },
          {
            "id": 3,
            "title": "Define VideoGenAdapter interface and provider registry",
            "description": "Create a provider-agnostic VideoGenAdapter interface and a registry to resolve adapters by name with providers: local i2v and cloud (both disabled by default).",
            "dependencies": [
              "24.1",
              "24.2"
            ],
            "details": "Design interface methods: generate(params), getJobStatus(jobId), cancel(jobId), supports(options), and capabilities metadata (maxDuration, resolutions, loopSupport). Define DTOs: VideoRequest (storyboardHash, prompt, characterRefs, duration, resolution, style, loop), VideoJob (id, status, progress, artifactRef, startedAt, completedAt), VideoArtifact. Implement AdapterRegistry with lazy provider binding and feature flag check. Stub LocalI2VAdapter and CloudAdapter (no real calls yet) returning NotConfigured error by default. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests for interface typing and registry resolution. Verify providers disabled by default. Ensure no calls when flag off."
          },
          {
            "id": 4,
            "title": "Implement /videos API lifecycle aligned with images flow",
            "description": "Add REST endpoints and service orchestration mirroring /images: POST /videos to create jobs, GET /videos/:id for status, DELETE /videos/:id to cancel, and GET /videos for listing by filters.",
            "dependencies": [
              "24.1",
              "24.2",
              "24.3"
            ],
            "details": "Model persistence: videos table/collection with fields (id, storyboardHash, requestJson, status, adapter, jobRef, artifactUrl, cacheHit, meta, createdAt, updatedAt). Controller maps requests to VideoService. Service: validates request, checks cache by storyboardHash, if hit returns cached artifact and marks cacheHit=true; otherwise enqueues job via adapter. Implement polling status mapping to unified statuses (queued, running, completed, failed, canceled). Add idempotency via Idempotency-Key header or storyboardHash+params key. Telemetry for lifecycle events. Ensure parity with /images response shape for client reuse. Run tests.",
            "status": "pending",
            "testStrategy": "Integration tests for lifecycle including creation, polling to completion via mocked adapter progress, cancellation, and cache hit behavior. Validate response schema and parity fields."
          },
          {
            "id": 5,
            "title": "Storyboard hash-based cache service",
            "description": "Create a cache layer keyed by storyboardHash and request parameters to reuse existing generated videos and skip recomputation.",
            "dependencies": [
              "24.1",
              "24.4"
            ],
            "details": "Design CacheService with get(hash, paramsKey), set(hash, paramsKey, artifactRef, meta), markHit(jobId). Store artifact URL, checksum, duration, resolution, loop flag, and identity fingerprint. Implement TTL/pinning policy and invalidation hooks when input changes. Ensure concurrency safety: lock per key to avoid thundering herd. Expose metrics: hit rate, latency delta. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests: concurrent requests deduplicate; subsequent requests return cached artifact with cacheHit=true; integrity check on checksum."
          },
          {
            "id": 6,
            "title": "Identity consistency: character embedding reuse from images",
            "description": "Plumb character identity from image generation into video requests by reusing stored embeddings/prompts to ensure visual continuity.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.5"
            ],
            "details": "Define CharacterIdentityStore interface to fetch embeddings/prompts by characterId or imageAssetId. Extend VideoRequest to accept characterRefs [{characterId, imageAssetId, weight}]. In VideoService, resolve and attach identity payload to adapter call. Implement simple fusion strategy: pass embeddings/prompts to provider as control inputs; for providers without native support, seed with reference frames (first frame generation) or conditioning images. Compute identity fingerprint of output (poster frame embedding) and store in cache meta for later validation. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests to ensure identity payload assembly and adapter call includes identity data. Identity similarity assertions per TC019 using fixtures."
          },
          {
            "id": 7,
            "title": "Ambient loop generation support",
            "description": "Add parameters and processing to support ambient loop clips, including loop flag, duration caps, and seamlessness checks.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.3"
            ],
            "details": "Extend request schema with loop=true, loopDurationSec, and loopTechnique (crossfade, latent-loop if provider supports). Adapter capability check for loopSupport; fallback to post-process with crossfade or ping-pong. Implement LoopPostProcessor to make loop points seamless: match first/last N frames using optical flow or audio crossfade if audio present. Validate loopiness with frame diff threshold metric and store in meta. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests for post-processor producing low boundary deltas; integration test creating a short loop and validating metric threshold."
          },
          {
            "id": 8,
            "title": "Local I2V provider adapter (mocked functional)",
            "description": "Provide a functional LocalI2VAdapter that simulates generation with deterministic outputs for tests, with toggles to later wire real model.",
            "dependencies": [
              "24.1",
              "24.3",
              "24.4",
              "24.6",
              "24.7"
            ],
            "details": "Implement LocalI2VAdapter with job queue, deterministic PRNG seeded by storyboardHash to produce reproducible progress and artifacts (e.g., generate placeholder MP4 with colored frames and optional loop enforcement). Accept identity payload and embed into metadata. Respect cancellation. No external calls. Provide configuration flag to enable this adapter in dev/test. Run tests.",
            "status": "pending",
            "testStrategy": "Integration tests exercising full lifecycle end-to-end with LocalI2VAdapter, ensuring determinism and cache reuse speedup."
          },
          {
            "id": 9,
            "title": "Cloud adapter scaffold with safe disabled default",
            "description": "Implement CloudVideoAdapter skeleton with signed-request preparation and strict disabled-by-default posture; no network calls unless explicitly enabled.",
            "dependencies": [
              "24.1",
              "24.3",
              "24.4"
            ],
            "details": "Create CloudVideoAdapter implementing interface but returning NotConfigured unless env var VIDEO_CLOUD_ENABLED=true and credentials present. Include network allowlist integration from security policy. Stub methods to map to provider job model; add exponential backoff polling when enabled. Ensure redaction of sensitive fields in logs. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests confirm disabled behavior, redaction of config in logs, and adherence to network guard. No actual network calls in CI."
          },
          {
            "id": 10,
            "title": "UI preview player and request form",
            "description": "Add a video preview player component and request form mirroring image generation UI, with controls for play/pause, loop, resolution, duration, and storyboard selection.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.5",
              "24.7",
              "24.8"
            ],
            "details": "Frontend: create VideoPreview component using HTML5 video with loop toggle; show cacheHit badge; display identity continuity indicator (green/yellow/red based on similarity metric). Add VideoRequestForm with fields prompt, storyboard, characters, duration, resolution, loop. Integrate with /videos API and polling hook reused from images. Hide components when r13VideoEnabled=false. Add accessible controls and error states. Run tests.",
            "status": "pending",
            "testStrategy": "UI tests with Playwright/Cypress: render when flag ON, hidden when OFF; submit request, poll to completion, preview plays, loop toggle works, cacheHit badge shows on second request. Snapshot test for UI state."
          },
          {
            "id": 11,
            "title": "Parity schema and validators with /images",
            "description": "Align /videos request/response schemas and validation with /images to enable client reuse and consistent telemetry.",
            "dependencies": [
              "24.1",
              "24.4"
            ],
            "details": "Create zod/ajv schemas for VideoRequest/Response paralleling image schemas: fields for id, status, artifactUrl, meta, cacheHit, error. Validate at controller boundary and on client. Add OpenAPI spec updates. Ensure telemetry fields (latencyMs, adapter, cacheHit) are recorded consistently. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests for schema validation and OpenAPI conformance; integration test comparing keys between image and video responses."
          },
          {
            "id": 12,
            "title": "Asset storage and CDN integration for videos",
            "description": "Wire video artifact storage, checksuming, and CDN URLs consistent with image pipeline, including content-type and range requests support.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.5"
            ],
            "details": "Extend AssetService to handle video mime types (mp4, webm), compute checksum, store poster frame, and return signed or CDN URLs. Support HTTP Range for streaming previews. Generate poster frame on completion for identity checks. Add cleanup policies. Run tests.",
            "status": "pending",
            "testStrategy": "Integration tests: upload/store simulated artifacts, verify URL generation and range requests, poster extraction correctness."
          },
          {
            "id": 13,
            "title": "Caching metrics, SLA checks, and observability",
            "description": "Add metrics for cache hit rate, cold vs warm completion times, adapter latencies, and identity similarity distributions; alert on regressions.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.5",
              "24.6"
            ],
            "details": "Instrument VideoService to emit metrics: video.cache.hit, video.latency.cold/warm, adapter.progress, identity.similarity, loop.seamlessness. Add logs with requestId and storyboardHash. Create dashboards and SLOs (e.g., cached reuse p50 < 1s). Integrate with tracing spans. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests for metrics emission using test sink; integration test simulating cache hit/miss and validating metric values and labels."
          },
          {
            "id": 14,
            "title": "Security, redaction, and compliance for video requests",
            "description": "Ensure sensitive data in prompts and character metadata are redacted in logs and stored according to local-first security policies.",
            "dependencies": [
              "24.1",
              "24.3",
              "24.4"
            ],
            "details": "Reuse redaction middleware to scrub PII in video prompts and metadata. Ensure no plaintext keys in configs; integrate with network allowlist. Mask adapter responses. Add consent flags for using character images for identity conditioning. Update structured logging to include redacted fields only. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests for redaction on video request/response logs. Integration tests ensuring denied outbound when not allowlisted and consent gating behavior."
          },
          {
            "id": 15,
            "title": "Concurrency control and job worker",
            "description": "Introduce a video job worker with bounded concurrency and backpressure, mirroring images pipeline.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.8"
            ],
            "details": "Implement queue (BullMQ/SQS/inproc) with per-adapter concurrency limits, retries, and cancellation. Worker pulls from queue to call adapters, updates status, stores artifacts. Ensure idempotency and deduping by storyboardHash+params. Add graceful shutdown and resume. Run tests.",
            "status": "pending",
            "testStrategy": "Integration tests enqueue multiple jobs, verify ordering, concurrency caps, retries, and cancellation behavior."
          },
          {
            "id": 16,
            "title": "Error handling, retries, and fallback paths",
            "description": "Standardize error taxonomy and retry policies for adapters; fallback to cache or alternative adapter when available.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.9",
              "24.15"
            ],
            "details": "Define errors: Transient, Permanent, NotConfigured, QuotaExceeded. Configure retry with jitter and max attempts per class. On failure with existing cache, return last-known-good artifact with warning meta. If primary adapter unavailable and secondary enabled, route to fallback. Run tests.",
            "status": "pending",
            "testStrategy": "Unit tests simulating adapter errors and asserting retry/fallback; integration tests verifying user-facing meta and status codes."
          },
          {
            "id": 17,
            "title": "Documentation and developer ergonomics",
            "description": "Document feature usage, configuration, and extension points for adapters; provide dev scripts for local e2e with LocalI2VAdapter.",
            "dependencies": [
              "24.1",
              "24.3",
              "24.4",
              "24.8",
              "24.10"
            ],
            "details": "Add README with r13VideoEnabled toggle, environment variables, how caching works, identity consistency tips, and UI usage. Provide scripts: yarn dev:video, yarn test:video, and sample requests. Include troubleshooting and FAQ. Run tests to ensure examples align.",
            "status": "pending",
            "testStrategy": "Doc tests: CI step that executes sample curl and validates responses in a mocked environment."
          },
          {
            "id": 18,
            "title": "Performance profiling and memory/disk safeguards",
            "description": "Benchmark video generation path; add limits for duration, resolution, and disk usage to prevent resource exhaustion.",
            "dependencies": [
              "24.1",
              "24.4",
              "24.8",
              "24.12",
              "24.15"
            ],
            "details": "Add guardrails: maxDuration, maxResolution, maxConcurrentJobs; enforce in validators. Implement streaming write to disk and temp file cleanup. Profile CPU/GPU usage with LocalI2VAdapter simulations; record p50/p95 latencies. Run tests.",
            "status": "pending",
            "testStrategy": "Load tests to enqueue multiple jobs; assert limits enforced and no OOM. Metrics assertions for latencies."
          },
          {
            "id": 19,
            "title": "Finalize end-to-end QA and release toggle",
            "description": "Run full suite, verify TC019 across environments, and provide a controlled release plan with feature flag rollout and rollback procedures.",
            "dependencies": [
              "24.1",
              "24.2",
              "24.3",
              "24.4",
              "24.5",
              "24.6",
              "24.7",
              "24.8",
              "24.9",
              "24.10",
              "24.11",
              "24.12",
              "24.13",
              "24.14",
              "24.15",
              "24.16",
              "24.17",
              "24.18"
            ],
            "details": "Execute test matrix: flag OFF/ON, cache MISS/HIT, identity present/missing, loop ON/OFF, adapter local/cloud-disabled, errors and fallbacks. Validate observability dashboards and SLOs. Prepare release notes, migration scripts, and feature flag rollout plan (gradual enable in dev→staging→prod). Ensure safe rollback by disabling flag. Sign off.",
            "status": "pending",
            "testStrategy": "Manual and automated e2e runs; verify TC019 pass criteria; canary in staging; rollback drill."
          }
        ]
      },
      {
        "id": 25,
        "title": "Metrics and Telemetry (Local)",
        "description": "Capture latency and token usage per provider; cache hit rates; campaign retention; fairness metrics.",
        "details": "- Local structured metrics store in SQLite tables metrics_*; no external export by default\n- Dashboards in UI for basic charts\n- Hooks in adapters and GM loop to log timings and counts\n- Opt-in export to CSV",
        "testStrategy": "- Unit tests for metrics aggregation queries\n- E2E: run session and see metrics populate\n- Privacy: verify PII redaction applied before logging",
        "priority": "low",
        "dependencies": [
          24
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Write tests for local metrics capture and dashboards (TC001–TC006)",
            "description": "Author unit and integration/UI tests that define the acceptance criteria for local metrics and telemetry. Cover: (1) latency and token usage per provider recorded to SQLite metrics_* tables; (2) cache hit/miss metrics for image/content cache; (3) campaign retention metrics (DAU/WAU/MAU-style session retention, campaign return rate); (4) fairness metrics across providers (latency distribution, error rate, allocation share); (5) hooks in adapters and GM loop emit structured events; (6) opt-in CSV export respects privacy redaction. Include at least one unit test per metrics domain and one end-to-end test that runs a mock session and verifies metrics populate and render basic charts in the UI. Define verification IDs TC001–TC006 mapped to these domains.",
            "dependencies": [],
            "details": "Create test scaffolding:\n- DB: Spin up an isolated SQLite database file in tmp with schema migrations applied.\n- Seed: Use seeded time provider to simulate timestamps; use deterministic random.\n- Unit tests:\n  - TC001: Insert/emit provider call start/stop; assert metrics_latency records provider, model, duration p50/p95 aggregate, count.\n  - TC002: Emit token usage events; assert metrics_tokens aggregates by provider and by session; verify total and per-message breakdown.\n  - TC003: Emit cache hits/misses; assert metrics_cache has hit_rate and SLA check (cached <6s median).\n  - TC004: Simulate multi-session campaign re-entries across days; assert metrics_retention with D1/D7 and campaign return rate.\n  - TC005: Simulate multi-provider routing; assert fairness metrics: proportion of calls per provider vs policy target, latency parity (gaps), error rate parity.\n  - TC006: CSV export on with privacy flag: assert PII fields are redacted in export rows.\n- Integration/UI:\n  - Spin up minimal UI with charts fed by metrics endpoints; simulate session; assert charts render non-empty series (smoke test) and correct labels.\n- Mocks: Adapter hooks and GM loop event emitters mocked to generate events into the metrics pipeline.\n- Tooling: Jest/Vitest + Playwright/Cypress; tag tests by TC IDs.",
            "status": "pending",
            "testStrategy": "Unit: validate schema writes and aggregation queries via in-memory/temporary SQLite. Integration: run a short session using mocked providers; verify metrics endpoints and UI charts. Privacy: inject PII in events and assert redaction in logs/exports."
          },
          {
            "id": 2,
            "title": "Define SQLite schema for metrics_* tables and indices",
            "description": "Design and migrate SQLite schema for all local structured metrics tables with necessary indices and foreign keys. Tables: metrics_events (raw), metrics_latency, metrics_tokens, metrics_cache, metrics_retention, metrics_fairness, metrics_exports, and a pii_redaction_audit table. Include views for common aggregations.",
            "dependencies": [
              "25.1"
            ],
            "details": "Implement migration files:\n- metrics_events: id, session_id, campaign_id, provider, model, type, payload_json, ts_ms, redaction_applied BOOLEAN.\n- metrics_latency: id, provider, model, session_id, request_id, duration_ms, success BOOLEAN, ts_ms.\n- metrics_tokens: id, provider, model, session_id, request_id, prompt_tokens, completion_tokens, total_tokens, ts_ms.\n- metrics_cache: id, cache_key, domain (image, text), hit BOOLEAN, latency_ms, ts_ms, campaign_id.\n- metrics_retention: daily aggregates: date_utc, active_campaigns, returning_campaigns_d1, d7, active_sessions.\n- metrics_fairness: window_start, window_end, provider, calls, successes, errors, p50_ms, p95_ms, allocation_share, expected_share.\n- metrics_exports: id, filename, rows, started_at, finished_at, pii_redaction_version, status.\n- pii_redaction_audit: id, source, field, original_hash, mask, ts_ms.\nIndices on ts_ms, provider, model, campaign_id, and composite (provider, ts_ms).\nViews:\n- v_provider_latency_agg (p50/p95/p99 per provider, per model, per day).\n- v_cache_hit_rate (hit_rate per domain and campaign per day).\n- v_tokens_by_provider (sum totals per day).\n- v_fairness_window (allocation vs expected).",
            "status": "pending",
            "testStrategy": "Run migration against temp DB; verify tables and indices exist. Execute sample inserts from tests TC001–TC005 to ensure constraints and queries succeed."
          },
          {
            "id": 3,
            "title": "Implement event hooks in adapters and GM loop",
            "description": "Add lightweight, synchronous-safe hooks that emit structured metric events from all providers/adapters and the GM loop. Ensure minimal overhead and no external I/O. Hooks write to metrics_events and specialized tables.",
            "dependencies": [
              "25.1",
              "25.2"
            ],
            "details": "Create MetricsEmitter interface with methods: recordLatency, recordTokens, recordCacheEvent, recordGMEvent, recordError. Implementation writes to SQLite via a buffered queue with batch commits (e.g., every 100ms or max 100 records). Instrument:\n- Provider adapters (LLM, image gen): on request start/finish capture ts, duration, success, tokens.\n- Cache layer: record hit/miss and latency with domain and campaign.\n- GM loop: record turn timings and counts as GM events (optional aggregate only).\n- Ensure PII redaction middleware is invoked before write (use Task 15 redactor when available; inject placeholder deterministic masker until Task 15).\n- Provide noop emitter for tests.\n- Add configuration flag to enable/disable metrics.",
            "status": "pending",
            "testStrategy": "Run TC001–TC005 unit tests; they should pass by recording expected events. Validate that emitter batching flushes within test timeouts."
          },
          {
            "id": 4,
            "title": "Metrics aggregation workers and SQL views",
            "description": "Build periodic aggregation jobs that transform raw events into queryable aggregates for dashboards and reports. Jobs compute percentile latencies, token sums, cache hit rates, retention metrics, and fairness windows.",
            "dependencies": [
              "25.1",
              "25.2",
              "25.3"
            ],
            "details": "Implement a background scheduler (node-cron or internal tick) to run aggregations every minute and daily rollups at UTC midnight:\n- Latency: compute p50/p95 per provider/model/day using window functions or approximate percentile if needed.\n- Tokens: sum prompt/completion/total per provider/model/day and per session.\n- Cache: hit_rate = hits/(hits+misses) per campaign and global per domain; SLA check flag cached_median_lt_6s.\n- Retention: compute D1/D7 returning campaigns from sessions_by_day derived table.\n- Fairness: sliding windows (e.g., 1h/24h) compute allocation_share vs expected_share (config) and error/latency parity metrics.\nStore outputs into metrics_* aggregate tables and refresh views.",
            "status": "pending",
            "testStrategy": "Extend TC001–TC005 to advance fake clock and trigger workers; assert aggregate rows match expectations, including percentile calculations and hit_rate."
          },
          {
            "id": 5,
            "title": "Privacy redaction integration for metrics pipeline",
            "description": "Integrate PII redaction so that any payloads or identifiers stored in metrics are masked per policy. Ensure opt-in export is redacted and add audit trail.",
            "dependencies": [
              "25.1",
              "25.2",
              "25.3"
            ],
            "details": "Wire existing redaction middleware from Task 15 via an interface. For now, implement a redaction adapter that accepts text fields and returns masked strings plus a hash for audit. Apply to metrics_events.payload_json and any free-text fields. Set redaction_applied flag and write to pii_redaction_audit. Ensure performance by skipping redaction for known numeric/ID fields.",
            "status": "pending",
            "testStrategy": "Run TC006; assert that test PII strings are masked in metrics tables and CSV exports, and audit entries are created."
          },
          {
            "id": 6,
            "title": "Implement local metrics API endpoints",
            "description": "Expose read-only endpoints to power dashboards: /metrics/latency, /metrics/tokens, /metrics/cache, /metrics/retention, /metrics/fairness. Support filters (date range, provider, model, campaign).",
            "dependencies": [
              "25.1",
              "25.2",
              "25.4",
              "25.5"
            ],
            "details": "Create HTTP handlers that query aggregate tables/views with parameterized SQL. Validate inputs; default to last 7 days. Return compact JSON series for charting. Add pagination where result sets can grow. Ensure endpoints do not expose raw PII fields.",
            "status": "pending",
            "testStrategy": "Integration test: call endpoints after seeding events (TC001–TC005) and verify JSON schema and values. Security test: ensure PII fields are absent."
          },
          {
            "id": 7,
            "title": "UI dashboards for basic charts",
            "description": "Build simple dashboards to visualize key metrics: latency percentiles per provider/model, token usage trends, cache hit rates/SLA, campaign retention, and fairness indicators.",
            "dependencies": [
              "25.1",
              "25.6"
            ],
            "details": "Implement frontend views:\n- Latency: line/area charts with p50/p95 per provider; model filter.\n- Tokens: stacked area for total tokens by provider.\n- Cache: gauge or line for hit rate; badge for SLA cached <6s median.\n- Retention: cohort/line chart for D1/D7 campaign retention.\n- Fairness: bar charts for allocation share vs expected and error rate by provider.\nUse existing chart library. Add basic empty-state and error handling.",
            "status": "pending",
            "testStrategy": "UI test (Playwright/Cypress): After seeding data, navigate dashboards and assert charts render with expected labels/series (extends initial UI part of TC001–TC006)."
          },
          {
            "id": 8,
            "title": "Opt-in CSV export with privacy safeguards",
            "description": "Implement CSV export for selected metrics with explicit opt-in flag. Respect redaction, include export metadata, and write metrics_exports record.",
            "dependencies": [
              "25.1",
              "25.2",
              "25.5",
              "25.6"
            ],
            "details": "Create endpoint /metrics/export?type=latency|tokens|cache|retention|fairness&filters=... requiring export_enabled=true config. Stream CSV rows from aggregate queries. Ensure field set excludes PII and applies masking if any free-text. Persist export job record in metrics_exports with status progression.",
            "status": "pending",
            "testStrategy": "Extend TC006 to request CSV export and verify content headers, row counts, and redaction. Negative test: export disabled returns 403."
          },
          {
            "id": 9,
            "title": "Fairness metrics computation and config",
            "description": "Finalize fairness definitions and computation logic, including expected allocation shares per provider, parity thresholds, and alerts.",
            "dependencies": [
              "25.1",
              "25.3",
              "25.4",
              "25.6"
            ],
            "details": "Add configuration for expected provider shares (e.g., A:50%, B:30%, C:20%). Compute in sliding windows: allocation_share, error_rate, p95 latency. Calculate parity deltas and a fairness_score. Surface via /metrics/fairness and UI badges. Optionally add soft alerts (in-UI warnings) when thresholds exceeded.",
            "status": "pending",
            "testStrategy": "Unit: feed synthetic multi-provider data and assert allocation_share and parity calculations. Integration: endpoints return correct fairness metrics that match UI."
          },
          {
            "id": 10,
            "title": "Campaign retention metrics pipeline",
            "description": "Implement cohort/retention calculations for campaigns returning on D1/D7 and rolling active campaigns, based on session activity.",
            "dependencies": [
              "25.1",
              "25.2",
              "25.4",
              "25.6"
            ],
            "details": "Derive sessions_by_day from events or session table (dependency on existing session source). Compute per-campaign first_seen date and subsequent activity flags for D1/D7. Populate metrics_retention daily. Expose via endpoints and charts.",
            "status": "pending",
            "testStrategy": "Unit: simulate campaigns active across days with fake clock; assert D1/D7 counts. Integration: endpoint returns expected values; UI renders retention chart."
          },
          {
            "id": 11,
            "title": "Cache metrics and SLA checks",
            "description": "Measure cache hit rates and retrieval latency; verify cached retrieval median under 6s for images as SLA. Integrate with Task 8 cache layer.",
            "dependencies": [
              "25.1",
              "25.3",
              "25.4",
              "25.6"
            ],
            "details": "Emit cache events from image generation service (hits/misses, latency). Aggregate hit_rate by campaign and globally. Compute median latency for cached items; flag SLA violations per day and last 1h. Display SLA badge in UI.",
            "status": "pending",
            "testStrategy": "Integration with Task 8 TC003 data: assert hit_rate and SLA median computations. UI shows correct badge state."
          },
          {
            "id": 12,
            "title": "Token usage accounting per provider",
            "description": "Accurately record prompt/completion/total tokens by provider and model; support session and campaign breakdowns.",
            "dependencies": [
              "25.1",
              "25.3",
              "25.4",
              "25.6"
            ],
            "details": "From adapter responses capture token counts; when unavailable, estimate via tokenizer library mapped per model. Aggregate tokens per day, session, and campaign. Provide filters in API/UI.",
            "status": "pending",
            "testStrategy": "Unit: verify estimation matches tokenizer outputs for known prompts. Integration: seed events and assert totals by provider/model/session."
          },
          {
            "id": 13,
            "title": "Latency metrics per provider/model",
            "description": "Collect and aggregate latency distributions per provider and model with percentiles and error segmentation.",
            "dependencies": [
              "25.1",
              "25.3",
              "25.4",
              "25.6"
            ],
            "details": "Instrument timers around provider calls; record success/error states. Aggregations compute p50/p95/p99 and error-rate-weighted stats. Expose separate series for successes vs errors.",
            "status": "pending",
            "testStrategy": "Unit: feed synthetic durations and assert percentile outputs. Integration: endpoint returns correct series; UI renders multiple series."
          },
          {
            "id": 14,
            "title": "End-to-end session metrics smoke test",
            "description": "Create a full E2E test that runs a short session with mixed providers, cache hits/misses, and campaign interactions, then validates that all metrics and dashboards update accordingly.",
            "dependencies": [
              "25.1",
              "25.3",
              "25.4",
              "25.6",
              "25.7",
              "25.8",
              "25.9",
              "25.10",
              "25.11",
              "25.12",
              "25.13"
            ],
            "details": "Use mock adapters to simulate realistic timings, tokens, errors, and cache outcomes. Run aggregations, query endpoints, and open UI routes. Validate presence and correctness of key figures. Tag as E2E and link verification IDs used earlier.",
            "status": "pending",
            "testStrategy": "E2E runner executes headless UI tests plus API assertions. Pass criteria: no 5xx, charts render, metrics values match seeded expectations."
          },
          {
            "id": 15,
            "title": "Performance and backpressure controls",
            "description": "Ensure the metrics pipeline has negligible overhead and cannot overwhelm the app. Add batching, backpressure, and configurable sampling.",
            "dependencies": [
              "25.3",
              "25.4"
            ],
            "details": "Implement: bounded queues, drop-oldest or sample when above thresholds, configurable sampling rate per event type, async batch commits with WAL mode in SQLite, and periodic vacuum. Add health metrics for the metrics system itself.",
            "status": "pending",
            "testStrategy": "Load test with synthetic high-rate events; assert tail latencies for main app unaffected and metrics loss within configured sampling/drop policies."
          },
          {
            "id": 16,
            "title": "Documentation and developer ergonomics",
            "description": "Add README and inline docs describing metrics schema, hooks, APIs, and dashboards; provide examples for emitting events and querying metrics.",
            "dependencies": [
              "25.3",
              "25.6",
              "25.7",
              "25.8"
            ],
            "details": "Write docs with code snippets, SQL examples, and troubleshooting (e.g., WAL settings, locking). Include a quickstart to run tests and view dashboards locally.",
            "status": "pending",
            "testStrategy": "Docs linting/build checks; manual verification that steps reproduce local dashboard with sample data."
          }
        ]
      },
      {
        "id": 26,
        "title": "Verification Plan Mapping and Test Suites TC001–TC019",
        "description": "Implement automated tests mapped to each requirement’s test cases ensuring acceptance criteria coverage.",
        "details": "- Test harness tagging by R-xxx/TCxxx\n- Playwright scenarios for voice UI, multi-client sync, images, alliances, mission DSL, memory isolation, resume/branch, providers, ticker, packs, multi-campaign, scheduling, video\n- CI matrix runs smoke for prototype and full for MVP\n- Latency sanity tests as per phases",
        "testStrategy": "- Ensure each TC passes with reports; coverage thresholds >80% lines in core modules\n- Flakiness tracker; retries with artifacts (logs, HAR, screenshots)",
        "priority": "high",
        "dependencies": [
          24
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Author unit tests for verification harness core (tagging, RTM, coverage gates)",
            "description": "Before implementation, create unit tests that codify acceptance criteria for the verification harness: requirement/test-case tagging by R-xxx/TCxxx, requirements-to-test traceability matrix (RTM) generation, coverage thresholds (>80% lines for core modules), and flakiness tracking metadata presence. These tests should fail initially and define the expected public APIs and artifacts.",
            "dependencies": [],
            "details": "Implement tests using your repo’s unit framework (e.g., Jest/Mocha). Write tests that: 1) Assert a tag parser maps file-level and test-level annotations like @req:R-123 and @tc:TC007 to an internal model; 2) Verify RTM builder emits JSON/CSV with rows: requirement_id, tc_id, file, status; 3) Enforce coverage gate by mocking a coverage report object and asserting that the gate fails below 80% lines on core modules; 4) Validate that a FlakinessTracker API records retries, artifacts paths, and pass/fail deltas; 5) Check that a LatencySanity schema exists for per-phase latency checks with thresholds injected via config.",
            "status": "pending",
            "testStrategy": "Unit only in this subtask. Snapshot RTM output and validate schema. Use fixtures for annotated test files. Mock coverage data sources. Ensure tests fail prior to implementation."
          },
          {
            "id": 2,
            "title": "Implement verification harness core to satisfy unit tests",
            "description": "Build the tagging, RTM, coverage gate, flakiness tracker, and latency sanity schema to make Subtask 26.1 tests pass. Provide CLI hooks to integrate into CI.",
            "dependencies": [
              "26.1"
            ],
            "details": "Implement modules: TagIndexer (glob test files, parse @req and @tc tags), RTMBuilder (emit RTM.json/RTM.csv), CoverageGate (read lcov/istanbul JSON, enforce per-module thresholds configurable, default 80% lines on core), FlakinessTracker (record retry counts, attach logs/HAR/screenshots paths), LatencySanity (YAML schema with phases and thresholds). Provide CLI: verify:build-rtm, verify:coverage, verify:flakiness, verify:latency:validate. Re-run tests and iterate until green.",
            "status": "pending",
            "testStrategy": "Run unit tests from 26.1 and ensure 100% pass. Add minimal integration test invoking the CLI with sample fixtures to produce RTM."
          },
          {
            "id": 3,
            "title": "Author unit and integration tests for CI matrix and reporting",
            "description": "Define tests verifying CI matrix execution plan: smoke for prototype, full for MVP; artifact collection (logs, HAR, screenshots); and publishing RTM and coverage reports.",
            "dependencies": [
              "26.2"
            ],
            "details": "Write unit tests for a MatrixPlanner that, given env TARGET=prototype, selects smoke test set; when TARGET=mvp, selects full suite. Integration tests simulate CI job config generation (e.g., GitHub Actions YAML or equivalent) and assert steps include: build, verify:build-rtm, run smoke/full Playwright sets, collect artifacts, upload reports. Test that report publisher places RTM and coverage under artifacts/verification/ with run metadata.",
            "status": "pending",
            "testStrategy": "Use snapshot tests for generated CI config. Mock filesystem to assert artifact paths. Ensure tests fail before implementation."
          },
          {
            "id": 4,
            "title": "Implement CI matrix planner, report publishing, and artifact wiring",
            "description": "Implement the CI matrix and reporting integrations to satisfy tests, including smoke vs full selection and artifact publication.",
            "dependencies": [
              "26.3"
            ],
            "details": "Create MatrixPlanner with tag expressions (e.g., @smoke) and test selectors for Playwright/Jest. Generate CI config via templates. Implement ReportPublisher to package RTM.json/RTM.csv, coverage, junit.xml, flakiness.json, and Playwright artifacts into versioned paths. Update npm scripts and CI workflows. Re-run tests until passing.",
            "status": "pending",
            "testStrategy": "Run integration tests from 26.3, then perform a dry-run CI locally (act or local runner) to validate steps."
          },
          {
            "id": 5,
            "title": "Write tests for Playwright test scaffolding and tagging (TC001–TC019)",
            "description": "Create tests asserting Playwright project config defines scenarios and per-TC tag mapping across voice UI, multi-client sync, images, alliances, mission DSL, memory isolation, resume/branch, providers, ticker, packs, multi-campaign, scheduling, video.",
            "dependencies": [
              "26.2"
            ],
            "details": "Add a meta-test (Node script or unit test) that loads playwright.config and asserts: projects exist for web, video, and latency; testDir includes e2e; expect reporters: list + junit + html; per-test annotations include @tc:TCxxx and @req:R-xxx via file headers. Validate that grep for @smoke slices include the intended minimal tests per area. Ensure initial failure to drive implementation.",
            "status": "pending",
            "testStrategy": "Unit tests over config objects plus a Playwright dry-run (—list) parsing to verify presence of TC001–TC019 tags."
          },
          {
            "id": 6,
            "title": "Implement Playwright config, base fixtures, and TC tag mapping",
            "description": "Implement Playwright projects, fixtures (multi-client), and test annotations to satisfy the scaffolding tests.",
            "dependencies": [
              "26.5"
            ],
            "details": "Configure multiple projects: chromium, firefox (optional), webkit (optional), video. Implement base fixtures: multiClientContext (2+ pages with shared session), media permissions for mic/camera, websocket HAR capture. Add test annotation helpers to stamp @tc and @req. Ensure smoke.list covers fast sanity paths for prototype. Re-run tests.",
            "status": "pending",
            "testStrategy": "Run Playwright —list and meta-tests to confirm TC coverage and tags; execute a sample test to validate fixtures."
          },
          {
            "id": 7,
            "title": "TC001 Voice UI: author failing tests (unit: latency calc; e2e: captions/diarization multi-client)",
            "description": "Create tests for TC001 acceptance: visible transcript/captions in multi-client sessions, diarization by speaker, partial hypotheses streaming, end-to-end latency median <800 ms locally, graceful degradation under packet loss.",
            "dependencies": [
              "26.6",
              "26.2"
            ],
            "details": "Unit: test LatencyEstimator computes median and enforces threshold from LatencySanity config. E2E: Playwright test spins two clients, simulates audio via pre-recorded WAV/Opus, verifies transcript events, caption rendering per speaker, and measures E2E latency (start speaking to caption display). Add a network condition (packet loss 5–10%) and assert UI degrades but maintains updates.",
            "status": "pending",
            "testStrategy": "Use synthetic audio fixtures; capture timestamps; assert median <800ms locally; tag @tc:TC001 @smoke for the fastest path."
          },
          {
            "id": 8,
            "title": "Satisfy TC001 tests with minimal adapters and mocks",
            "description": "Implement or mock the STT streaming adapter and client UI hooks in the test app to pass TC001 tests without full production dependencies.",
            "dependencies": [
              "26.7"
            ],
            "details": "Provide a test STT adapter that streams partial/final hypotheses with speaker tags by connection id. Implement caption rendering with timestamps and diarization labels. Add network resilience logic (buffering, backoff). Integrate latency measurement hooks. Rerun TC001 until green.",
            "status": "pending",
            "testStrategy": "Run TC001 unit and E2E repeatedly; collect artifacts (screenshots, HAR) on failure; record flakiness."
          },
          {
            "id": 9,
            "title": "TC002 Multi-client synchronization: tests for shared state coherence",
            "description": "Author tests verifying state sync across multiple clients with consistency under joins/leaves and network jitter.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Two to three clients perform synchronized actions (e.g., room join, event broadcast). Assert delivery order constraints and final state convergence. Unit: test a CRDT/WS sync module for idempotency and dedup.",
            "status": "pending",
            "testStrategy": "Introduce 200–500ms artificial jitter; assert no divergence; tag @tc:TC002."
          },
          {
            "id": 10,
            "title": "Implement sync fixtures and pass TC002",
            "description": "Implement the minimal sync mechanisms or mocks to satisfy TC002 tests.",
            "dependencies": [
              "26.9"
            ],
            "details": "Add a test WS gateway and deterministic ordering buffer in test harness. Ensure merge semantics produce convergence. Rerun tests until passing.",
            "status": "pending",
            "testStrategy": "Playwright E2E with 3 clients; verify event logs; capture HAR."
          },
          {
            "id": 11,
            "title": "TC003 Image handling: tests for upload, rendering, and alt/accessibility",
            "description": "Create tests to validate image upload pipeline, caching, rendering, and alt text/accessibility semantics.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Upload image, verify thumbnail and full-resolution render. Unit: test image metadata extraction and cache keying. Accessibility: assert alt text present and announced.",
            "status": "pending",
            "testStrategy": "Use local image fixtures; tag @tc:TC003."
          },
          {
            "id": 12,
            "title": "Implement minimal image pipeline and pass TC003",
            "description": "Provide basic upload/caching/render paths to satisfy TC003.",
            "dependencies": [
              "26.11"
            ],
            "details": "Implement in-memory or tmp-dir storage, thumbnail generator stub, and accessible UI rendering. Rerun tests until green.",
            "status": "pending",
            "testStrategy": "Rerun E2E/UI tests; verify no console errors; collect screenshots."
          },
          {
            "id": 13,
            "title": "TC004–TC005 Alliances and leaderboard: author tests",
            "description": "Add API/UI tests for alliance lifecycle and leaderboard updates on scoring events; verify per-campaign separation.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Create alliance, invite/join/leave, assign team; assert visibility in UI. Trigger scoring events; verify leaderboard updates and fairness invariants. Unit: validate data model functions and isolation by campaign.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC004 and @tc:TC005; include smoke subset."
          },
          {
            "id": 14,
            "title": "Implement stubs/mocks to pass TC004–TC005",
            "description": "Implement minimal API handlers and UI to satisfy alliance and leaderboard tests within the test app context.",
            "dependencies": [
              "26.13"
            ],
            "details": "Create in-memory tables for alliances, members, and scores; implement endpoints and simple UI views. Ensure per-campaign scoping. Re-run tests until passing.",
            "status": "pending",
            "testStrategy": "Run E2E; verify WS updates for leaderboard where applicable."
          },
          {
            "id": 15,
            "title": "TC006 Mission DSL: tests for parse/execute and rule hooks",
            "description": "Create unit and E2E tests that define a small mission DSL script and verify parsing, rule evaluation, and UI state effects.",
            "dependencies": [
              "26.6"
            ],
            "details": "Unit: parser produces AST; executor evaluates conditions and emits events. E2E: Load mission script, perform actions that trigger state changes; assert UI reflects mission progress.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC006. Include negative test for invalid syntax."
          },
          {
            "id": 16,
            "title": "Implement mission DSL minimal runtime to pass TC006",
            "description": "Provide a small interpreter and hooks into the demo UI to satisfy mission DSL tests.",
            "dependencies": [
              "26.15"
            ],
            "details": "Implement parser (PEG or hand-rolled) for a narrow subset; executor with event bus; bind to UI updates. Rerun tests.",
            "status": "pending",
            "testStrategy": "Unit parser tests + E2E mission progress path."
          },
          {
            "id": 17,
            "title": "TC007 Memory isolation: tests for per-session/campaign boundaries",
            "description": "Author tests that validate no cross-leakage of vector memories or caches between sessions/campaigns.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Run two campaigns in parallel; write memory in A; verify absence in B. Unit: guard middleware blocks cross-campaign queries. Validate file cache uses per-campaign subdirs.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC007; include HAR to verify namespaces."
          },
          {
            "id": 18,
            "title": "Implement isolation guards and cache scoping to pass TC007",
            "description": "Add middleware and storage scoping to satisfy memory isolation tests.",
            "dependencies": [
              "26.17"
            ],
            "details": "Implement context.campaign_id propagation, enforce scoping on DB/Vector/Cache queries, and file cache pathing. Rerun tests.",
            "status": "pending",
            "testStrategy": "Re-run unit/E2E; assert no leakage; check logs for denied access."
          },
          {
            "id": 19,
            "title": "TC008 Resume/branch: tests for session resume and branching history",
            "description": "Write tests that verify a user can resume a session and branch from a prior state with correct history and isolation.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Save checkpoint; resume later; create branch; verify timelines. Unit: serialization/deserialization of state snapshot.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC008; assert deterministic replay."
          },
          {
            "id": 20,
            "title": "Implement resume/branch minimal functionality to pass TC008",
            "description": "Implement checkpoint store and UI controls sufficient for passing resume/branch tests.",
            "dependencies": [
              "26.19"
            ],
            "details": "Add snapshot serializer, storage (in-memory + file fallback), resume loader, and branching identifiers; update UI to list branches.",
            "status": "pending",
            "testStrategy": "Re-run tests; ensure history correctness with assertions."
          },
          {
            "id": 21,
            "title": "TC009 Provider adapters: tests for multiple model providers with fallback",
            "description": "Create tests ensuring provider selection, fallback on error/latency, and consistent interface.",
            "dependencies": [
              "26.6"
            ],
            "details": "Unit: ProviderRegistry chooses best provider by policy. E2E: Force primary failure, verify fallback engages and user flow continues.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC009; include latency thresholds per provider."
          },
          {
            "id": 22,
            "title": "Implement provider registry and fallbacks to pass TC009",
            "description": "Add minimal provider adapters and registry logic to satisfy provider tests.",
            "dependencies": [
              "26.21"
            ],
            "details": "Implement a common interface, policy-based selection, retry/backoff, and circuit breaker flags. Use mock providers for tests.",
            "status": "pending",
            "testStrategy": "Re-run unit and E2E; verify metrics and selection logs."
          },
          {
            "id": 23,
            "title": "TC010 Ticker/notifications: tests for real-time updates",
            "description": "Write tests for ticker stream rendering and reliability (ordering, dedup, persistence).",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Trigger events; assert ticker UI updates in order with no duplicates. Unit: sequence number logic and persistence buffer.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC010; include offline/online toggle test."
          },
          {
            "id": 24,
            "title": "Implement ticker stream to pass TC010",
            "description": "Add sequence-aware ticker stream and UI rendering to satisfy tests.",
            "dependencies": [
              "26.23"
            ],
            "details": "Implement server emitter with seq ids, client dedup buffer, and persistence for last N events; update UI.",
            "status": "pending",
            "testStrategy": "Re-run tests with artificial packet loss."
          },
          {
            "id": 25,
            "title": "TC011 Content packs: tests for pack load/enable and override precedence",
            "description": "Define tests verifying content pack selection, conflict resolution, and hot-reload in dev.",
            "dependencies": [
              "26.6"
            ],
            "details": "Unit: resolver picks highest precedence override. E2E: Enable/disable packs; assert content changes immediately.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC011; negative test for missing pack."
          },
          {
            "id": 26,
            "title": "Implement pack loader/resolver to pass TC011",
            "description": "Implement minimal pack loader and precedence resolver.",
            "dependencies": [
              "26.25"
            ],
            "details": "Add manifest reader, merge strategy, and UI toggle. Support hot-reload in dev using file watchers.",
            "status": "pending",
            "testStrategy": "Re-run tests; validate no UI flicker on toggle."
          },
          {
            "id": 27,
            "title": "TC012 Multi-campaign: author tests for isolation across full stack",
            "description": "Create comprehensive tests that run two concurrent campaigns and verify isolation across DB, caches, WS namespaces, and schedules.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Spin campaigns A and B; perform operations; assert no cross-broadcasts and separate assets. Unit: middleware blocks cross-campaign access.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC012; include stress with parallel actions."
          },
          {
            "id": 28,
            "title": "Implement multi-campaign isolation layer to pass TC012",
            "description": "Wire context propagation and namespacing to pass full-stack isolation tests.",
            "dependencies": [
              "26.27"
            ],
            "details": "Implement per-campaign WS namespaces, DB query scoping, and file cache subdirs. Reuse from Task 18 where available.",
            "status": "pending",
            "testStrategy": "Re-run tests; assert namespace separation via logs/HAR."
          },
          {
            "id": 29,
            "title": "TC013 Scheduling: tests for job creation, execution windows, and per-campaign scoping",
            "description": "Add tests verifying scheduler respects cron/interval windows, dedup, and isolation.",
            "dependencies": [
              "26.6"
            ],
            "details": "Unit: scheduler computes next run accurately. E2E: Create jobs in A and B; ensure no cross-trigger; verify missed-run catch-up rules.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC013; simulate clock with fake timers."
          },
          {
            "id": 30,
            "title": "Implement scheduler minimal features to pass TC013",
            "description": "Provide a lightweight scheduler service with per-campaign queues and dedup keys.",
            "dependencies": [
              "26.29"
            ],
            "details": "Implement cron parsing, next-run calc, queue per campaign, and execution hooks. Ensure isolation by campaign_id.",
            "status": "pending",
            "testStrategy": "Re-run unit/E2E; assert deterministic scheduling with fake timers."
          },
          {
            "id": 31,
            "title": "TC014 Video: tests for playback, streaming join, and caption sync with TTS/STT",
            "description": "Create tests ensuring video sessions initialize, playback controls work, and captions sync with TTS/STT where applicable.",
            "dependencies": [
              "26.6"
            ],
            "details": "E2E: Join a video session, play/pause/seek, verify caption track alignment. Unit: timeline mapper from STT/TTS timestamps to VTT cues.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC014; allow headful CI mode for media."
          },
          {
            "id": 32,
            "title": "Implement video session stubs and caption track to pass TC014",
            "description": "Add minimal video player integration with caption track generation.",
            "dependencies": [
              "26.31"
            ],
            "details": "Use HTML5 video with a mock media source; generate VTT cues from timestamps; expose controls in UI.",
            "status": "pending",
            "testStrategy": "Re-run E2E; verify cues align within tolerance."
          },
          {
            "id": 33,
            "title": "TC015 Providers performance: latency sanity tests per phase",
            "description": "Add latency sanity tests per project phase, asserting configured thresholds for key provider operations.",
            "dependencies": [
              "26.2",
              "26.6"
            ],
            "details": "Unit: read LatencySanity YAML and ensure enforcement logic applies per environment (dev/prototype/mvp). E2E: run representative provider calls and measure median/95th vs thresholds.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC015; skip or relax on CI if env var set."
          },
          {
            "id": 34,
            "title": "Implement latency collectors and metrics to pass TC015",
            "description": "Wire timing hooks and metrics export to satisfy latency sanity tests.",
            "dependencies": [
              "26.33"
            ],
            "details": "Implement timers around provider calls, collect histograms, and expose results to the test harness for assertion. Support JSON export.",
            "status": "pending",
            "testStrategy": "Re-run tests; verify medians below thresholds locally."
          },
          {
            "id": 35,
            "title": "TC016 Images accessibility and performance budgets",
            "description": "Expand image tests to include LCP budget and alt text compliance across views.",
            "dependencies": [
              "26.11"
            ],
            "details": "E2E: Measure LCP for an image-heavy page and assert under budget; ensure alt text present for all images and no empty alts unless decorative.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC016; integrate with Playwright trace for timings."
          },
          {
            "id": 36,
            "title": "Implement image perf budgets and a11y checks to pass TC016",
            "description": "Add lazy-loading, responsive sources, and a11y lint rules to meet budgets and compliance.",
            "dependencies": [
              "26.35"
            ],
            "details": "Implement loading=lazy, srcset/sizes, and an eslint-plugin-jsx-a11y rule gate. Adjust caching headers in dev server.",
            "status": "pending",
            "testStrategy": "Re-run LCP and a11y tests; validate budgets."
          },
          {
            "id": 37,
            "title": "TC017 Full isolation (multi-campaign, DB, cache, WS): tests aligned to Task 18",
            "description": "Mirror Task 18’s TC017 acceptance tests in this suite to ensure end-to-end isolation verification.",
            "dependencies": [
              "26.27",
              "26.17"
            ],
            "details": "E2E: Two concurrent campaigns, verify no leakage across DB queries, caches, and WS channels. Unit: middleware denies cross-access.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC017; coordinate with Task 18 artifacts."
          },
          {
            "id": 38,
            "title": "Ensure TC017 passes using Task 18 layer",
            "description": "Integrate Task 18 isolation implementation into the test app to make TC017 green in this suite.",
            "dependencies": [
              "26.37"
            ],
            "details": "Wire context propagation and isolation middleware from Task 18 into the test harness paths used by Playwright tests.",
            "status": "pending",
            "testStrategy": "Re-run TC017; inspect HAR for namespaces; confirm green."
          },
          {
            "id": 39,
            "title": "TC018 Multi-campaign UI management and schedules visibility",
            "description": "Add tests verifying UI controls for switching campaigns, viewing schedules, and ensuring isolation of views and actions.",
            "dependencies": [
              "26.6",
              "26.29"
            ],
            "details": "E2E: Switch campaigns in UI; validate assets, schedules, and leaderboards update to selected campaign only.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC018; include smoke view-switch test."
          },
          {
            "id": 40,
            "title": "Implement UI scaffolding for multi-campaign management to pass TC018",
            "description": "Provide minimal UI for campaign switching and scoped data views.",
            "dependencies": [
              "26.39"
            ],
            "details": "Add a campaign selector component, scope data fetches by campaign_id, and update views (schedules, leaderboard) accordingly.",
            "status": "pending",
            "testStrategy": "Re-run tests; verify no leakage upon switching."
          },
          {
            "id": 41,
            "title": "TC019 End-to-end regression suite assembly and gating",
            "description": "Create a meta-test ensuring all TC001–TC019 are included, tagged correctly, and reported in RTM with pass status before release gate passes.",
            "dependencies": [
              "26.4",
              "26.6"
            ],
            "details": "Implement a gate script that reads RTM.json and JUnit results; fails if any TC001–TC019 absent or failing. Validate that smoke vs full gates are applied based on TARGET environment.",
            "status": "pending",
            "testStrategy": "Tag @tc:TC019; simulate failing case to ensure gate blocks."
          },
          {
            "id": 42,
            "title": "Docs and traceability: verification plan and RTM publication",
            "description": "Publish the Software Verification and Validation Plan snippets, RTM, and how-to-run docs; ensure CI uploads artifacts for each run.",
            "dependencies": [
              "26.4",
              "26.41"
            ],
            "details": "Add docs/verification/ with SVVP overview, mapping TCs to requirements, run commands, and CI links. Ensure CI step publishes RTM and validation reports to artifacts and, if available, a dashboard.",
            "status": "pending",
            "testStrategy": "Link-check docs; run a full CI dry-run to confirm artifacts present."
          }
        ]
      },
      {
        "id": 27,
        "title": "Implement Subscription/Depth Progression Preset (Default) with Achievements",
        "description": "Add a default campaign preset focused on long-term progression (levels, perks, artifacts, crew achievements, soft-fail credit) with private telemetry points, configurable visibility/leaderboard/fail-forward toggles, full achievements system (definitions, unlocks, rewards, notifications), DB schema, UI (achievements panel + banner, preset settings), tests, and isolation/perf hardening. Feature must be gated behind preset selection and applied to new campaigns.",
        "details": "Scope and architecture\n- Preset definition\n  - Create a CampaignPreset registry keyed by enum: DEFAULT_SUBSCRIPTION_DEPTH.\n  - Preset sets defaults: pointsVisibility=private, leaderboardScope=off, failForward=strict (configurable), progression model=levels+perks+artifacts, crewAchievements=enabled, softFailCredit=enabled.\n  - Hook preset into campaign creation flow so new campaigns default to this preset unless user chooses another.\n\n- Progression mechanics integration\n  - Extend rules/progression module to expose: computeXP(missionOutcome, skillChecks, artifactsFound, allianceFeats), level thresholds, perk point allocation, artifact slots and gating.\n  - Implement fail-forward accounting: on failed missions grant reduced XP and soft credit toward next mission gate. Add tunables in preset for fraction (e.g., 30–50%).\n  - Record per-mission private points (telemetry only) separate from public scores table; do not emit leaderboard updates in this preset.\n\n- Achievements system\n  - Definitions: per-player and per-crew achievements with fields: id, scope (player|crew), name, description, rarity, category, unlockConditions (DSL or JSON: missionCompletions>=N, skillChecks[DC>=X] success count, collectArtifact[set], allianceFeat[raidX], time-bounded), rewards (xp, items, titles), icon, enabled, version.\n  - Unlocks: per subject table to store unlocked achievements with timestamps, campaign_id, subject_id, version, reward_granted flag; include progress tracking for incremental achievements.\n  - Evaluators: event-driven evaluators subscribing to rules and mission events; incremental progress updates and final unlock with idempotent reward grant.\n  - Notifications: lightweight in-session banner/toast with accessibility labels; queue dedupe; batch multiple unlocks.\n\n- Campaign-level toggles\n  - Expose settings on campaign model: pointsVisibility (private|friends|public), leaderboardScope (off|friends), failForwardStrictness (off|lenient|strict). Enforce at API and UI. For this preset: default private/off/strict, but allow owner to adjust within allowed bounds (no public leaderboard in this preset).\n\n- Privacy and isolation\n  - Ensure no writes to leaderboard tables when leaderboardScope=off; guard in service layer. Enforce DB constraints or service checks to prevent cross-campaign leakage. Ensure vector memory namespaces remain campaign:<id> and player:<id> only.\n\n- Telemetry\n  - Event schema: achievement_progress, achievement_unlocked, mission_points_recorded, perk_allocated, artifact_acquired. Only stored locally; redact PII; ensure pointsVisibility=private prevents any external export.\n\n- Database schema (migrations)\n  - achievements_definitions(id PK, scope, key UNIQUE, name, description, rarity, category, conditions JSON, rewards JSON, icon, enabled, version, created_at).\n  - achievements_unlocks(id PK, campaign_id, scope, subject_id, def_id FK, progress JSON, unlocked_at NULLABLE, reward_granted BOOL, UNIQUE(campaign_id, scope, subject_id, def_id)).\n  - telemetry_points(id PK, campaign_id, player_id NULLABLE, mission_id, points INT, reason TEXT, created_at).\n  - progression_state(id PK, campaign_id, player_id, level INT, xp INT, perk_points INT, artifacts JSONB).\n  - campaign_settings add: preset enum, points_visibility, leaderboard_scope, fail_forward_strictness.\n\n- API\n  - POST /campaigns with preset selection (applies defaults). PATCH /campaigns/:id/settings for toggles with validation.\n  - GET /achievements/definitions?scope=player|crew, GET /achievements/unlocks/:subject, POST /achievements/claim/:unlockId (idempotent claim if rewards require claim), POST /progression/perk-allocate.\n  - POST /telemetry/mission-points (internal server call) stores private points when missions resolve.\n\n- UI\n  - Achievements panel: filter by All/Unlocked/Locked, categories; show progress bars; claim button when applicable. Respect scope switch between Player and Crew for current campaign.\n  - Lightweight banner/toast for unlocks with small icon, title, reward summary; queue with max display rate; accessible and non-blocking.\n  - Campaign Settings for this preset: radio/selectors for points visibility (private only with info tooltip), leaderboard scope (off or friends-only disabled state note), fail-forward strictness; preset badge and description.\n  - Indicate that leaderboards are disabled in this preset in any leaderboard UI, and suggest switching modes (without enabling here).\n\n- Security & performance\n  - Validate all preset toggle updates server-side; reject public leaderboard in this preset.\n  - Idempotency keys for unlock/reward claims to prevent duplication on retries.\n  - Ensure vector index namespace resolution uses campaign_id guard; add unit tests around it. No external writes for telemetry or achievements.\n\n- Data seeding\n  - Provide initial achievements set: examples — First Steps (first mission), Skillful (10 DC15+ successes), Relic Hunter (collect 3 artifacts), United We Stand (crew completes alliance feat), Unstoppable (complete mission after prior fail).\n  - Provide XP curve defaults and sample perks.\n\n- Feature flagging\n  - Gate all UI and API behind preset feature and a server flag to allow staged rollout.\n",
        "testStrategy": "Unit tests\n- Progression math: XP calculation across success/fail-forward paths; level thresholds; perk allocation bounds; artifact slot gating.\n- Achievements logic: incremental progress and unlock for each seeded achievement; idempotent reward grant; evaluator filtering by campaign preset.\n- Privacy/isolation: when leaderboardScope=off, any score submit call is a no-op and logs warning; points written only to telemetry_points; vector namespace isolation enforced on all evaluators.\n- Settings validation: API rejects attempts to set leaderboardScope=public for this preset; pointsVisibility cannot be set to public.\n- Telemetry: events serialized without PII; schema conformance.\n\nIntegration/API tests\n- Create campaign with default preset via /campaigns; verify settings default and preset recorded.\n- Mission resolution posts private points and triggers achievement progress; GET unlocks reflects updates.\n- Toggle failForwardStrictness and verify XP outcomes adjust; verify friends-only leaderboard option is disabled/unavailable in this preset.\n- Idempotent reward claim: POST claim twice returns same state and no duplicate rewards.\n\nUI/End-to-end (Playwright)\n- Achievements panel: filtering, progress bars, unlocked state, claim flow; accessibility checks (axe) pass.\n- Unlock banner displays with correct text/icon and queues when multiple unlocks occur; screen reader announcements present.\n- Campaign settings UI shows preset badge and enforces disabled public leaderboard; changes persist and reflect in API.\n\nSecurity/performance\n- Fuzz tests: no negative XP, no level overflow; unlock spam throttled, banner queue bounded.\n- Verify no external writes when pointsVisibility=private (network inspection/mocking).\n- Vector memory isolation tests to ensure no cross-campaign reads/writes.\n\nAcceptance mapping\n- Ensure scenarios cover R-003/004/005/006/008/009/011 by linking to TC004/TC006/TC007/TC009/TC014/TC015/TC017 in the test harness tags and reports.",
        "status": "pending",
        "dependencies": [
          26
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Author test plans and scaffolding mapped to TC004/TC006/TC007/TC009/TC014/TC015/TC017",
            "description": "Create test plans and skeleton test files covering achievements, progression math, preset toggles, privacy/isolation, telemetry, API/UI flows. Tag tests with TC IDs and requirement references. Establish fixtures, factories, and mock event buses required across subsequent tests. This is the foundation for test-first development.",
            "dependencies": [],
            "details": "• Create test directories: server/tests/progression, server/tests/achievements, server/tests/campaign_preset, server/tests/privacy_isolation, server/tests/api, web/tests/achievements, web/tests/settings, web/tests/notifications.\n• Add jest/vitest config with testNamePattern including TC IDs and reporters for CI mapping from Task 26.\n• Introduce factories: CampaignFactory (with preset variations), PlayerFactory, MissionFactory, AchievementDefFactory.\n• Introduce shared test utilities: mockEventBus, freezeTime helpers, idempotencyKey helper, DB test harness with transactional rollback.\n• Define Playwright test project for UI panels and toasts with accessibility assertions.\n• Document mapping: TC004 Progression math; TC006 Soft-fail integration; TC007 Preset toggles enforcement; TC009 Privacy/isolation; TC014 Achievements definitions/unlocks; TC015 Notifications; TC017 Feature flag/preset gating.",
            "status": "pending",
            "testStrategy": "Smoke-run empty tests to ensure CI wiring passes; validate tags TC004/6/7/9/14/15/17 appear in reports."
          },
          {
            "id": 2,
            "title": "Write unit tests for progression math and fail-forward (TC004, TC006)",
            "description": "Specify expected behavior for computeXP, level thresholds, perk allocation bounds, artifact slot gating, and fail-forward XP/soft credit fractions tuned by preset.",
            "dependencies": [
              "27.1"
            ],
            "details": "• Add tests in server/tests/progression/progression_math.test.ts.\n• Cases: success mission grants full XP per weights; failure grants 30–50% per preset tunable; ensure soft credit accrues toward next mission gate and caps correctly; verify level-ups at thresholds and perk points awarded per level; artifact slots unlock at defined levels; negative or overflow inputs rejected.\n• Include boundary tests at threshold edges and multiple missions accumulation; property tests for monotonicity of XP->level.\n• Include tests asserting no leaderboard writes when computing or recording points.",
            "status": "pending",
            "testStrategy": "Run tests expecting current code to fail (red) until implementation; snapshot expected curves for regression."
          },
          {
            "id": 3,
            "title": "Write unit tests for achievements definitions, progress, unlocks, idempotent rewards (TC014)",
            "description": "Define tests covering seeded achievements, incremental progress tracking, unlock gating by preset, idempotent reward grants, and versioning.",
            "dependencies": [
              "27.1"
            ],
            "details": "• Add tests in server/tests/achievements/achievements_engine.test.ts.\n• Seed mock definitions: First Steps, Skillful (10 DC15+), Relic Hunter (3 artifacts), United We Stand (crew feat), Unstoppable (win after fail), each with rewards (xp, items, titles).\n• Simulate event stream: mission_completed, skill_check_result, artifact_acquired, alliance_feat.\n• Assert progress JSON updates, unlock only once; reward_granted toggles idempotently with idempotency key; evaluator respects campaign preset (disabled outside preset).\n• Test version bump migration: older unlock with version X remains unlocked; new version creates separate track as per policy.\n• Verify per-player vs per-crew scoping and UNIQUE constraint behavior.",
            "status": "pending",
            "testStrategy": "Red tests verifying unlock counts, timestamps, and reward grant calls; include race-condition test by parallel grant attempts."
          },
          {
            "id": 4,
            "title": "Write privacy/isolation tests for telemetry and leaderboard off (TC009)",
            "description": "Ensure private points are stored only in telemetry_points, no writes to leaderboard tables, and namespace isolation guards for vector memory by campaign_id/player_id.",
            "dependencies": [
              "27.1"
            ],
            "details": "• Add tests in server/tests/privacy_isolation/privacy_isolation.test.ts.\n• Simulate mission resolution calling internal POST /telemetry/mission-points; assert row in telemetry_points with redact PII fields, and zero writes to leaderboard tables.\n• Validate service layer guards reject any leaderboard write when leaderboardScope=off.\n• Add vector index namespace tests: operations require campaign_id guard; ensure cross-campaign access rejects; include unit tests around namespace computation.\n• Add DB constraint test or mock to enforce policy where feasible.",
            "status": "pending",
            "testStrategy": "Use DB query counters/spies; simulate malicious call attempting leaderboard write; verify errors and no side effects."
          },
          {
            "id": 5,
            "title": "Write API contract tests for campaigns preset and settings toggles (TC007, TC017)",
            "description": "Define tests for POST /campaigns with preset selection applying defaults, PATCH /campaigns/:id/settings validation, and feature flag/preset gating of related endpoints.",
            "dependencies": [
              "27.1"
            ],
            "details": "• Create server/tests/api/campaign_preset.api.test.ts.\n• Cases: creating campaign without specifying preset defaults to DEFAULT_SUBSCRIPTION_DEPTH; explicit selection applies; response includes settings with private/off/strict defaults.\n• PATCH validation: owner can adjust within allowed bounds (no public, leaderboardScope only off or friends); invalid transitions rejected with 4xx.\n• Feature gating: achievements/progression endpoints return 404/403 when feature flag off or campaign not using preset; enabled when on.\n• Include concurrency tests for toggle updates and ETag/If-Match support if available.",
            "status": "pending",
            "testStrategy": "Supertest or equivalent against in-memory server; verify schema using OpenAPI validators if present."
          },
          {
            "id": 6,
            "title": "Write API tests for achievements and telemetry endpoints (TC014, TC009)",
            "description": "Cover GET definitions, GET unlocks, POST claim, POST telemetry mission-points, and POST progression/perk-allocate including idempotency behavior.",
            "dependencies": [
              "27.1"
            ],
            "details": "• Create server/tests/api/achievements.api.test.ts.\n• GET /achievements/definitions?scope=player|crew: pagination, filtering, enabled=true only.\n• GET /achievements/unlocks/:subject: returns progress and unlocked_at; respects campaign.\n• POST /achievements/claim/:unlockId: idempotent with idempotency key; reward granted once; returns reward summary.\n• POST /telemetry/mission-points: internal auth required; stores telemetry_points with reason.\n• POST /progression/perk-allocate: validates available points, bounds, and updates progression_state; emits telemetry event perk_allocated.",
            "status": "pending",
            "testStrategy": "Table-driven tests for success/error codes, auth failures, and boundary conditions."
          },
          {
            "id": 7,
            "title": "Write UI tests for Achievements panel and unlock banner/toast (TC015, TC014)",
            "description": "Add Playwright tests for achievements panel filters, progress bars, claim flow, accessibility, and unlock notification queueing/deduping.",
            "dependencies": [
              "27.1"
            ],
            "details": "• web/tests/achievements/achievements_panel.spec.ts: verify All/Unlocked/Locked filters, category filters, scope switch Player/Crew, progress bar updates with simulated server progress.\n• Claim button flow: after unlock, shows claim CTA if applicable; after claim, CTA disabled and reward shown.\n• web/tests/notifications/unlock_toast.spec.ts: enqueue multiple unlocks, ensure batching and max display rate; aria-live polite/roles; dedupe identical unlocks.\n• Visual regression baseline screenshots for panel and toasts in light/dark.",
            "status": "pending",
            "testStrategy": "Run Playwright against stubbed API with MSW; assert a11y using axe."
          },
          {
            "id": 8,
            "title": "Write UI tests for Campaign Settings preset controls and leaderboard disabled UX (TC007, TC017)",
            "description": "Ensure preset badge/description renders, toggles limited per preset, and leaderboard UIs show disabled state and guidance.",
            "dependencies": [
              "27.1"
            ],
            "details": "• web/tests/settings/campaign_preset_settings.spec.ts: verify points visibility shows Private only with info tooltip; leaderboard scope off with friends-only disabled note; fail-forward strictness radio present; badge shows DEFAULT_SUBSCRIPTION_DEPTH.\n• Leaderboard page: shows disabled messaging and suggestion to switch modes without enabling here; no network calls to leaderboard APIs.",
            "status": "pending",
            "testStrategy": "Playwright with UI state assertions; network inspection to ensure no leaderboard requests."
          },
          {
            "id": 9,
            "title": "Database migrations for achievements, telemetry, progression, and campaign settings",
            "description": "Implement schema changes: achievements_definitions, achievements_unlocks, telemetry_points, progression_state, and campaign_settings additions for preset and toggles.",
            "dependencies": [
              "27.2",
              "27.3",
              "27.4",
              "27.5",
              "27.6",
              "27.7",
              "27.8"
            ],
            "details": "• Create migration files with forward/backward steps.\n• Tables:\n  - achievements_definitions(id PK, scope, key UNIQUE, name, description, rarity, category, conditions JSON/JSONB, rewards JSON/JSONB, icon, enabled, version, created_at TIMESTAMP).\n  - achievements_unlocks(id PK, campaign_id, scope, subject_id, def_id FK, progress JSONB, unlocked_at TIMESTAMP NULL, reward_granted BOOL, created_at, UNIQUE(campaign_id, scope, subject_id, def_id)).\n  - telemetry_points(id PK, campaign_id, player_id NULL, mission_id, points INT, reason TEXT, created_at TIMESTAMP).\n  - progression_state(id PK, campaign_id, player_id, level INT, xp INT, perk_points INT, artifacts JSONB).\n  - campaign_settings add columns: preset ENUM, points_visibility ENUM, leaderboard_scope ENUM, fail_forward_strictness ENUM.\n• Add indices on (campaign_id, subject_id), (campaign_id, mission_id), and partial index for unlocked_at IS NOT NULL.\n• Add FK constraints and check constraints where applicable.\n• Generate types for ORM.",
            "status": "pending",
            "testStrategy": "Run migration tests on ephemeral DB; verify UNIQUE constraints and rollback integrity."
          },
          {
            "id": 10,
            "title": "Implement CampaignPreset registry and default hook in campaign creation",
            "description": "Add registry keyed by enum DEFAULT_SUBSCRIPTION_DEPTH, define defaults, and integrate into POST /campaigns to apply preset unless overridden.",
            "dependencies": [
              "27.5",
              "27.9"
            ],
            "details": "• Define enum CampaignPreset { DEFAULT_SUBSCRIPTION_DEPTH, ... } and registry map with config: pointsVisibility=private, leaderboardScope=off, failForward=strict, progressionModel=levels+perks+artifacts, crewAchievements=enabled, softFailCredit=enabled.\n• Update campaign creation service to apply preset defaults; expose preset metadata for UI.\n• Respect server feature flag; if disabled, reject selection with 403.\n• Persist settings into campaign_settings.",
            "status": "pending",
            "testStrategy": "Run API tests from 27.5; ensure defaults match and feature gating enforced."
          },
          {
            "id": 11,
            "title": "Implement progression engine: computeXP, thresholds, perks, artifacts, fail-forward",
            "description": "Extend rules/progression module with XP computation, level thresholds, perk allocation, artifact slot gating, fail-forward accounting with tunables stored in preset.",
            "dependencies": [
              "27.2",
              "27.9",
              "27.10"
            ],
            "details": "• Add computeXP(missionOutcome, skillChecks, artifactsFound, allianceFeats, presetTunables) returning {xp, softCredit}.\n• Define level thresholds curve (e.g., array or function), and helper to compute level from total XP and allocate perk points.\n• Implement artifact slot unlock schedule and validation.\n• Fail-forward: on failure, grant fraction XP and soft credit toward next mission gate per preset tunable; parametrize 0.3–0.5.\n• Ensure functions pure, deterministic, and covered with property tests.\n• No leaderboard writes; only return values.",
            "status": "pending",
            "testStrategy": "Execute unit tests in 27.2 until green; add fuzz tests for XP monotonicity."
          },
          {
            "id": 12,
            "title": "Implement private telemetry pipeline and service guards for leaderboard=off",
            "description": "Add service to persist mission_points_recorded into telemetry_points and enforce no leaderboard writes when scope is off; redact PII and support internal auth path.",
            "dependencies": [
              "27.4",
              "27.9",
              "27.10"
            ],
            "details": "• Implement TelemetryService.recordMissionPoints({campaignId, playerId?, missionId, points, reason}).\n• Add middleware/guard: when campaign.settings.leaderboardScope===off, block any calls to LeaderboardService and log security event.\n• Ensure pointsVisibility=private prevents any external export; add export function returning empty for this preset.\n• Redact PII fields; store minimal identifiers.\n• Wire POST /telemetry/mission-points to call service behind internal auth.",
            "status": "pending",
            "testStrategy": "Run privacy tests from 27.4 and API tests from 27.6."
          },
          {
            "id": 13,
            "title": "Implement achievements definitions store and seeding",
            "description": "Create repository and seed initial achievements set with categories, conditions JSON/DSL, rewards, icons, enabled flags, and versions.",
            "dependencies": [
              "27.3",
              "27.9"
            ],
            "details": "• Define AchievementsDefinition model and repository with CRUD (admin), read-only for clients.\n• Seed initial set: First Steps, Skillful (10 DC15+), Relic Hunter (3 artifacts), United We Stand (crew feat), Unstoppable (win after fail); include rarity, category, rewards JSON.\n• Add scope field (player|crew) and key uniqueness.\n• Support versioning and enabled toggles; expose GET /achievements/definitions with filtering by scope, enabled.",
            "status": "pending",
            "testStrategy": "Run API tests for definitions from 27.6 and engine tests from 27.3."
          },
          {
            "id": 14,
            "title": "Implement achievements unlocks repository and event-driven evaluators",
            "description": "Create unlocks table access, progress tracking, event subscribers, and idempotent reward application for per-player and per-crew achievements within a campaign.",
            "dependencies": [
              "27.3",
              "27.9",
              "27.11",
              "27.13"
            ],
            "details": "• Implement UnlocksRepo: getOrCreate(campaignId, scope, subjectId, defId), updateProgress(progressJSON), markUnlocked(timestamp), setRewardGranted(idempotentKey).\n• Event evaluators subscribe to mission and rules events: mission_completed, skill_check_result, artifact_acquired, alliance_feat, mission_failed->next_mission_completed for Unstoppable pattern.\n• Evaluators compute incremental progress; emit achievement_progress and achievement_unlocked telemetry events.\n• Enforce idempotency via unique constraint and idempotency keys; concurrent unlock attempts race-safe.\n• Respect preset gating: evaluators active only when campaign preset is DEFAULT_SUBSCRIPTION_DEPTH and feature flag on.",
            "status": "pending",
            "testStrategy": "Run unit tests from 27.3; add concurrency test using parallel promises to unlock same achievement."
          },
          {
            "id": 15,
            "title": "Implement rewards grant and claim API with idempotency",
            "description": "Provide POST /achievements/claim/:unlockId to finalize reward grants for achievements requiring explicit claim, ensuring idempotent behavior and accurate reward summaries.",
            "dependencies": [
              "27.6",
              "27.14"
            ],
            "details": "• Add RewardsService.applyRewards(unlock, def) issuing xp/items/titles; update progression_state for xp; record items/titles where applicable.\n• Require Idempotency-Key header; store key hash on unlock row; on retry return prior result.\n• Validate subject ownership and campaign membership; enforce scope-specific permissions (crew claims by owner/admin).\n• Return payload with granted rewards and updated unlock state.",
            "status": "pending",
            "testStrategy": "Run API tests from 27.6 and unit tests verifying idempotency and side-effect counts."
          },
          {
            "id": 16,
            "title": "Implement progression_state persistence and perk allocation API",
            "description": "Persist per-player progression state and expose POST /progression/perk-allocate with validation and telemetry emission.",
            "dependencies": [
              "27.2",
              "27.6",
              "27.9",
              "27.11"
            ],
            "details": "• Create ProgressionStateRepo with read/update methods; update on XP changes and level-ups including perk_points increments.\n• Implement /progression/perk-allocate validating available points and perk bounds/gating; update artifacts/slots and perks state as needed.\n• Emit telemetry event perk_allocated; ensure atomic updates with transactions.",
            "status": "pending",
            "testStrategy": "Run API tests from 27.6 and unit tests from 27.2 regarding perk bounds and artifact slot gating."
          },
          {
            "id": 17,
            "title": "Implement UI: Achievements panel (list, filters, progress, claim)",
            "description": "Build the achievements UI with scope switch, filters, progress bars, claim button, and accessibility, wired to API.",
            "dependencies": [
              "27.7",
              "27.13",
              "27.14",
              "27.15"
            ],
            "details": "• Create AchievementsPanel component with tabs: All, Unlocked, Locked; category filter; scope toggle Player/Crew.\n• Render cards with icon, name, description, rarity, progress bar (from unlocks.progress), and claim button when applicable.\n• Handle optimistic updates on claim; error states; skeleton loaders.\n• Add keyboard navigation and ARIA roles; ensure screen reader labels.\n• Integrate with feature flag/preset gating: hide or show disabled state accordingly.",
            "status": "pending",
            "testStrategy": "Run Playwright tests from 27.7; add unit tests for component logic with MSW mocks."
          },
          {
            "id": 18,
            "title": "Implement UI: Unlock banner/toast system with queue and batching",
            "description": "Add lightweight notification component for achievement unlocks that dedupes and rate-limits displays.",
            "dependencies": [
              "27.7",
              "27.14"
            ],
            "details": "• Create ToastManager with queue; batch multiple unlocks into a summary when threshold exceeded; apply max display rate.\n• Subscribe to achievements_unlocked events via websocket or polling; fall back to local event bus.\n• Provide accessible aria-live region; ensure non-blocking UX.",
            "status": "pending",
            "testStrategy": "Run Playwright tests from 27.7; unit-test queueing and dedupe logic."
          },
          {
            "id": 19,
            "title": "Implement UI: Campaign Settings for preset toggles and disabled leaderboard UX",
            "description": "Add settings UI for this preset: points visibility (private with tooltip), leaderboard scope (off, friends-only disabled note), fail-forward strictness, preset badge/description.",
            "dependencies": [
              "27.8",
              "27.10"
            ],
            "details": "• Build SettingsPresetSection component reading campaign settings; radio/selectors constrained per preset.\n• Show preset badge DEFAULT_SUBSCRIPTION_DEPTH and description; display info explaining private telemetry and disabled leaderboards.\n• Disable friends-only if restricted; show inline help.\n• Save via PATCH /campaigns/:id/settings with validation feedback.",
            "status": "pending",
            "testStrategy": "Run Playwright tests from 27.8; verify no leaderboard API calls."
          },
          {
            "id": 20,
            "title": "Security and performance hardening for isolation and event pipeline",
            "description": "Add server-side validation for preset toggle updates, guard vector index namespaces, add idempotency, and micro-benchmarks for event evaluators.",
            "dependencies": [
              "27.12",
              "27.14",
              "27.15",
              "27.16"
            ],
            "details": "• Validate all preset updates server-side; block public leaderboard when preset is DEFAULT_SUBSCRIPTION_DEPTH.\n• Enforce namespace conventions: campaign:<id>, player:<id>; add guards and unit tests; include metrics for rejected cross-campaign attempts.\n• Ensure idempotency keys required on claim; retries safe.\n• Add simple benchmarks for evaluator throughput under burst of events; ensure O(n) per event bounded by active defs.",
            "status": "pending",
            "testStrategy": "Run privacy tests (27.4); add perf test suite with synthetic 10k events and assert latency bounds."
          },
          {
            "id": 21,
            "title": "Feature flag integration and gating for API/UI",
            "description": "Wire a server flag to enable staged rollout; gate all API endpoints and UI routes/components behind the flag and preset selection.",
            "dependencies": [
              "27.5",
              "27.6",
              "27.10",
              "27.17",
              "27.19"
            ],
            "details": "• Introduce feature flag SUBSCRIPTION_DEPTH_PRESET enabled per environment.\n• Gate evaluators, definitions exposure, claim endpoint, progression endpoints based on campaign preset and flag.\n• UI: hide panels when disabled; show rollout tooltip; avoid network calls when gated.",
            "status": "pending",
            "testStrategy": "Run TC017 tests in 27.5, 27.7, 27.8 ensuring correct 403/hidden states."
          },
          {
            "id": 22,
            "title": "End-to-end flow tests for new campaign with preset and achievements",
            "description": "Add E2E tests: create campaign with preset, run missions causing progress/unlocks, ensure UI reflects state and privacy rules are enforced.",
            "dependencies": [
              "27.10",
              "27.11",
              "27.12",
              "27.13",
              "27.14",
              "27.15",
              "27.16",
              "27.17",
              "27.18",
              "27.19",
              "27.21"
            ],
            "details": "• Script: create campaign (preset default), simulate mission success/fail-forward events; verify telemetry_points entries; computeXP applied; level/perk updates; achievements unlocked and claimable; toasts shown.\n• Verify no leaderboard writes; verify settings toggles constrained.\n• Validate accessibility and state persistence across refresh.",
            "status": "pending",
            "testStrategy": "Playwright + backend test harness; run in CI with artifacts and HAR captures."
          },
          {
            "id": 23,
            "title": "Documentation and admin tools for achievements and presets",
            "description": "Author developer docs and minimal admin endpoints/tools to manage achievement definitions and preset tunables safely.",
            "dependencies": [
              "27.13",
              "27.14",
              "27.21"
            ],
            "details": "• Write docs: preset behavior, fail-forward tunables, XP curve, achievements DSL/JSON, event schemas.\n• Add admin-safe endpoints behind auth to list/update enabled/version; migration guide for version bumps.\n• Provide seed scripts and sample JSON files.",
            "status": "pending",
            "testStrategy": "Docs linting; manual validation using admin tool against staging."
          },
          {
            "id": 24,
            "title": "Run full test suite and stabilize",
            "description": "Execute all unit, API, UI, and E2E tests; fix flakes; ensure coverage thresholds met; prepare change log.",
            "dependencies": [
              "27.22",
              "27.23"
            ],
            "details": "• Run CI matrix; address flaky tests with retries and deterministic seeds.\n• Ensure coverage >80% in core modules.\n• Review logs for privacy guard hits; verify no external exports.\n• Prepare release notes and changelog entries.",
            "status": "pending",
            "testStrategy": "CI run with reruns for flaky specs; generate coverage and stability report."
          }
        ]
      },
      {
        "id": 28,
        "title": "Implement Viral Scoring Preset (Seasonal Leaderboards & Sharing)",
        "description": "Add a selectable campaign preset that enables public mission scoring, seasonal leaderboards (campaign/global scopes), viral share flows, and weekly featured missions with privacy, anti-griefing, ELO/MMR, and season rewards. Provide full tests (unit/integration/UI/API), rate limiting, and campaign isolation; preset is disabled by default and can be toggled per campaign.",
        "details": "Scope and architecture\n- Preset definition and registry\n  - Extend CampaignPreset registry with enum: VIRAL_SCORING. Preset flags: publicScores=opt-in, leaderboardScope=friends|campaign|global, seasons=enabled, featuredMissions=weekly, allowSharing=opt-in, redactPII=on, storageMode=local-only-compliant, antiGriefing=on, eloEnabled=per-arena, partialCredit=soft-fail enabled. Disabled by default; selectable per campaign in settings UI and during creation wizard.\n  - Add campaign-level toggles: enablePublicScores, leaderboardScope, enableSeasons, shareDefaults (opt-in off), allianceScoreInclusion, seasonSchedule (start, end, grace), and rewardTiers.\n\n- Data model (SQLite)\n  - Tables (new): scores(id, campaign_id, session_id, mission_id, player_id, team_id, scope, metric, value, partial, fail_reason, created_at); seasons(id, campaign_id, name, scope, start_at, end_at, rollover_state, rewards_schema, version); season_entries(id, season_id, player_id, team_id, rank, mmr, division, elo_mu, elo_sigma, last_update); share_artifacts(id, campaign_id, score_id, artifact_type, url_or_blobref, pii_redacted JSON, created_at, consent_at); featured_missions(id, campaign_id, mission_id, week_of, curated_by).\n  - Migrations: create indices on (campaign_id, scope, metric, created_at), (season_id, rank DESC), and composite unique keys to prevent duplicate submissions per mission attempt.\n\n- Scoring formulas and soft-fail\n  - Implement a scoring module keyed by missionType: time-attack, survival, puzzle, social-coop, arena. Each defines base points, bonuses, penalties, and clamps. Support partial credit on soft-fail: grant proportional points based on progress fraction, with anti-exploit caps.\n  - Fair-play checks: validate mission completion evidence, server-side timestamps, min duration thresholds, attempt cooldowns, host consent for social missions, and client signature verification (reuse adapter auth if present). Rate limit score submissions per player and per campaign.\n\n- Anti-griefing and security\n  - Timeouts: enforce max attempt duration; auto-abort stale submissions. Consent gates: for team scores, require majority consent or GM approval. Cross-campaign isolation: all queries filtered by campaign_id and leaderboard scope; add row-level guards in access layer.\n  - Validation: reject out-of-bounds values; detect suspicious streaks; quarantine flagged scores pending review.\n\n- Seasonal leaderboards and rollover\n  - Implement seasonal versioning: active season per campaign/scope; archived seasons are immutable snapshots with view filters. Provide monthly/quarterly schedules and manual admin rollover. Compute standings on event update and via periodic job; freeze during grace period. Support divisions and ranks for large populations; include alliance/crew aggregates.\n\n- ELO/MMR for arenas\n  - Arena matches update MMR per outcome with K-factor scaling by uncertainty; maintain elo_mu/sigma for Bayesian variants. Persist per season. Calibrate initial placement matches; decay on inactivity. Expose API to fetch matchmaking band.\n\n- Rewards and featured missions\n  - Cosmetic season rewards generation based on final rank/percentile and achievement thresholds. Weekly featured missions rotation: auto-select based on engagement signals with manual override.\n\n- Sharing and privacy\n  - Share flows: generate share_artifacts with opt-in consent; render redacted cards (hide PII, show campaign-safe names). Provide copy-link and image export; ensure local-only storage compliance (no external uploads unless configured). Include per-scope badges (friends/global/campaign) in the artifact.\n\n- UI integration\n  - Preset settings pane: toggles, schedule editor, reward tiers editor, privacy controls. Leaderboards views: current season, friends, global (if enabled), past seasons, alliance standings; entry detail with share action. Share dialog with preview and consent checkbox.\n\n- APIs\n  - POST /scores/submit; GET /leaderboards?scope&season; POST /seasons/rollover; GET /seasons/current; POST /share/create; GET /featured-missions; POST /featured-missions/override. Enforce rate limits and schema validation. Contract tests included.\n\n- Performance\n  - Incremental leaderboard updates with upsert + denormalized standings table; background recompute for heavy scopes. Bounded history retention for hot paths; archive to cold tables. Apply submission rate limits (per IP/player) and exponential backoff on abuse.\n\n- Compatibility and toggles\n  - Integrate with alliances/teams so alliance and crew achievements contribute to seasonal standings when enabled. Respect campaign preset defaults; no cross-talk with other presets. Disabled by default for all existing campaigns until explicitly selected.\n\nReferences and rationale\n- Implement seasonal versioning and resets modeled after established practices for seasonal leaderboards to keep competition fresh[3].\n- Apply best practices for leaderboard scopes, reset cycles, and community health to mitigate toxicity and maintain engagement[2][1].\n- Support divisions/ranks concepts akin to league systems to scale competition fairly across skill bands[5].",
        "testStrategy": "Unit tests\n- Scoring math per mission type: deterministic outputs for boundary cases; partial credit proportionality; clamp and cap behaviors. Fuzz against invalid inputs to ensure rejection and quarantine.\n- ELO/MMR updates: verify K-factor scaling, placement matches, win/loss/draw updates, inactivity decay, and season scoping.\n- Season schedule: compute active/archived state, grace period logic, and rollover versioning.\n\nIntegration tests\n- Leaderboard updates: submit scores concurrently; verify standings update correctly, alliance aggregates reflect member contributions, and per-campaign isolation holds. Validate friends vs campaign vs global scopes.\n- Season rollover: run end-of-season; freeze submissions; archive standings; create next season; rewards issuance; verify no mutations to archived season.\n- Rate limiting and anti-griefing: exceed submission thresholds; ensure 429s and quarantine flow; validate consent gates for team submissions; timeouts on stale attempts.\n- Featured missions: weekly rotation triggers; manual override persists; UI surfaces current featured set.\n\nUI tests (Playwright)\n- Preset selection: ensure VIRAL_SCORING appears, is disabled by default, and can be enabled per campaign.\n- Leaderboards views: paginate, filter by scope, switch current/past seasons, view alliance standings, open share dialog, confirm PII redaction and consent requirement.\n- Share flows: create artifact, copy link/image export, verify privacy banner and opt-in remembered per user.\n\nAPI contract tests\n- /scores/submit validation and idempotency; /leaderboards query combinations; /seasons/rollover permissions and effects; /share/create artifact schema; /featured-missions endpoints. Schema versioning and backward compatibility checks.\n\nPerformance and reliability tests\n- Load: burst score submissions maintain SLOs; recompute latency under N concurrent updates; no cross-campaign leakage. Chaos: kill periodic job during rollover; system recovers idempotently.\n\nAcceptance mapping\n- Verify channels and requirements R-001, R-003, R-004, R-010, R-011, R-012 pass via TC004/TC005/TC006/TC016/TC017/TC018 as mapped in Task 26.",
        "status": "pending",
        "dependencies": [
          26,
          27
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 29,
        "title": "Implement Ollama Provider Adapters (LLM + Embeddings) with Streaming, Tools, Safety, and A/B Harness Integration",
        "description": "Add Ollama adapters implementing LLMProvider and EmbeddingProvider with streaming, tool schema/function-calling, safety filters, config, metrics, and full tests; update provider UI and docs.",
        "details": "Scope and architecture\n- Create packages/modules: providers/ollama/llmAdapter.ts and providers/ollama/embeddingAdapter.ts implementing existing LLMProvider and EmbeddingProvider interfaces.\n- Configuration\n  - Env/config keys: OLLAMA_BASE_URL (default http://localhost:11434), OLLAMA_API_KEY (optional for gateway), provider.settings.modelAllowlist = ['llama3','mistral','phi3'] (configurable).\n  - Validate base URL reachability at startup with lightweight /api/tags or /api/version probe and log model availability.\n- LLM adapter\n  - API shape: supports chat completion with messages[], model, temperature, maxTokens, seed (if supported), tools (JSON schema), tool_choice=auto/none, streaming.\n  - Streaming: use server-sent stream from Ollama and emit tokens/chunks in our standard StreamDelta events; handle finish reasons and tool call events.\n  - Tools: convert zod/JSON Schema tool definitions to Ollama’s function/tool schema; on tool call deltas, aggregate into a function_call struct {name, arguments} and surface via our ToolCall event; validate against schema; on invalid schema, retry with corrected schema once.\n  - Params mapping: temperature->temperature, maxTokens->num_predict, top_p if present in request, seed->seed. Respect stop sequences. Provide fallback when parameter not supported by particular model.\n  - Metrics: capture start/end timestamps, latency, prompt/completion token counts when exposed; if not available, estimate tokens via tokenizer fallback. Cost = 0 for local Ollama. Emit to A/B harness metrics sink.\n  - Retries/backoff: integrate with global adapter retry policy (exponential with jitter); classify retryable errors (429 from gateways, ECONNRESET, timeouts) vs non-retryable (400 schema errors after one correction attempt).\n  - Safety: apply content filters/redaction pipeline pre-send and post-receive. Redact PII/secrets in prompts and tool args; check outputs and mask as configured.\n  - Determinism: if seed provided, pass through and document per-model determinism caveats.\n- Embeddings adapter\n  - Use Ollama embeddings endpoint for selected model; require embedding-capable model in allowlist.\n  - Return Float32Array normalized vectors; include dimensionality discovery on first call and cache.\n  - Batch inputs with size limits; streaming not required.\n- A/B harness integration\n  - Register Ollama as an LLM and Embedding provider in the model matrix; expose provider id, model list (from allowlist intersected with server-available models), and metrics mapping.\n  - Ensure zero cost recorded for this provider.\n- UI and docs\n  - Update Settings > Providers UI to include Ollama provider card with fields: Base URL, API Key (optional), Model allowlist help, connectivity test.\n  - Update providers.md with configuration, supported features, limits, and troubleshooting.\n- Security/ops\n  - Timeouts, circuit breaker guard, and connection pooling. Respect per-campaign isolation and safety settings.\n- Examples\n  - Provide sample code to invoke streaming with tools and embeddings with normalization in docs.\n",
        "testStrategy": "Unit tests\n- Adapter shape: construct OllamaLLMAdapter and OllamaEmbeddingAdapter; verify methods, parameter mapping, defaults, and allowlist enforcement.\n- Streaming: mock Ollama stream; assert ordered StreamDelta emissions, final finish event, and backpressure handling.\n- Tools: validate JSON schema conversion; simulate tool call chunks and ensure aggregated function_call matches schema; invalid schema triggers one retry then fails with tagged error.\n- Retries/backoff: inject transient network errors and verify exponential backoff with jitter and max attempts; non-retryable errors do not retry.\n- Safety: ensure pre-send redaction masks PII and post-receive filters apply; verify redaction does not leak originals to transport layer logs.\n- Embeddings: return type is Float32Array; values normalized to unit length within epsilon; batch processing splits correctly.\n\nIntegration tests\n- Minimal prompt roundtrip against local Ollama (skipped in CI if not available; flag to enable): verify successful completion, streaming order, and metrics capture (latency present, tokens if provided or estimated fallback recorded).\n- Deterministic seed: with same prompt+seed verify identical text for models that support seed; if model lacks determinism, assert at least same first N tokens or mark as conditional skip.\n- Tool-call structure: run prompt that elicits a function call; validate name and JSON arguments parse and zod-validate.\n- Embeddings: compute embeddings for stable inputs; assert dimensionality stable and cosine similarity >0.99 for identical input across runs.\n\nVerification/acceptance\n- Tag tests with TC011 and TC013 where applicable and map in verification plan; ensure R-007 updated requirement satisfied for Ollama.\n- Update providers.md and UI provider list; manual checklist includes connectivity test in UI and A/B harness registration.\n",
        "status": "pending",
        "dependencies": [
          26
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 30,
        "title": "Implement Group Chat: Global and Ad‑Hoc Voice+Text Channels with Invites",
        "description": "Build campaign‑scoped group chat supporting a global All‑Hands channel and ad‑hoc invite‑based voice+text channels with roles, moderation, audit logging, API/WS, DB schema, and UI; integrate with voice capture/captions and ensure isolation/security.",
        "details": "Scope and architecture\n- Channel model\n  - Channel types: GLOBAL (one per campaign, All‑Hands) and AD_HOC.\n  - Properties: id, campaign_id, type, name, description, is_invite_only, created_by, created_at, updated_at, archived_at, voice_room_id (nullable), text_retention_days, default_join_muted.\n  - Memberships: id, channel_id, user_id, role (owner|mod|member), mute (self), volume (0–100), joined_at, left_at (nullable), is_present_in_voice (derived from voice engine presence).\n  - Invites: id, channel_id, inviter_id, invitee_id, status (pending|accepted|declined|expired|revoked), expires_at, created_at, rate_limit_bucket.\n  - Channel events (audit): id, channel_id, actor_id, event_type (create|update|delete|join|leave|invite_create|invite_accept|invite_decline|role_change|mute|kick), payload (JSON), created_at.\n  - Text messages: reuse existing messages table if present; otherwise define messages(id, channel_id, author_id, content, kind=text|caption|system, ts, ref (optional)). Transcripts store STT captions as messages with kind=caption and diarization metadata.\n\n- API design\n  - REST\n    - POST /channels (create ad‑hoc; enforce campaign scope; assign owner)\n    - GET /channels (list by campaign with membership and unread counts)\n    - GET /channels/:id (details, last N messages, membership summary)\n    - PATCH /channels/:id (name, invite_only, description) – owner/mod only\n    - DELETE /channels/:id (archive) – owner only for ad‑hoc; GLOBAL cannot be deleted\n    - POST /channels/:id/members/join (join; default muted in voice)\n    - POST /channels/:id/members/leave (leave; owner transfer/constraints)\n    - POST /channels/:id/members/:userId/roles (role transition; auth checks)\n    - POST /channels/:id/moderation/mute (self or mod‑enforced target)\n    - POST /channels/:id/moderation/kick (remove from membership; mod/owner)\n    - POST /channels/:id/invites (create; rate limited; invite_only respected)\n    - POST /channels/:id/invites/:inviteId/accept\n    - POST /channels/:id/invites/:inviteId/decline\n  - WebSocket events (namespaced by campaign)\n    - channel.created/updated/archived\n    - channel.member.joined/left/role_changed\n    - channel.invite.created/accepted/declined\n    - channel.moderation.muted/kicked\n    - channel.voice.presence (join/leave/talking/VAD)\n    - channel.text.message (text and caption kinds)\n    - channel.audit.appended\n\n- Voice integration\n  - On channel join, create/ensure voice room mapping (voice_room_id) and attach presence to membership; default join muted; push‑to‑talk and VAD states reflected in WS presence events.\n  - Per‑channel mute/volume stored in membership; client applies volume locally; server tracks mute for moderation and signaling.\n  - Captions/diarization: consume STT pipeline outputs and emit as channel.text.message with kind=caption, speaker tag (connection/user id), timestamps; store in transcripts/messages.\n\n- Text integration\n  - Message history per channel; pagination by ts+id; captions appear inline with badges; system messages for invites/joins/leaves.\n  - Moderation deletes redact content and append audit event.\n\n- Security and isolation\n  - All endpoints authorize campaign membership; channels cannot cross campaigns; per‑action role checks; enforce invite_only: only invited users can join; global channel membership allowed to all campaign users but can be left/joined.\n  - Rate limit invites per inviter+channel (e.g., 10/min, 100/day) with backoff and 429 responses.\n  - Validate WS subscriptions to campaign and channel membership; no leakage across campaigns.\n\n- Database schema (SQL sketch)\n  - channels(id PK, campaign_id FK, type, name, description, is_invite_only, voice_room_id, default_join_muted, text_retention_days, created_by, created_at, updated_at, archived_at)\n  - channel_memberships(id PK, channel_id FK, user_id FK, role, mute, volume, joined_at, left_at)\n  - channel_invites(id PK, channel_id FK, inviter_id FK, invitee_id FK, status, expires_at, created_at, updated_at)\n  - channel_events(id PK, channel_id FK, actor_id FK, event_type, payload JSONB, created_at)\n  - channel_messages(id PK, channel_id FK, author_id FK NULL for system/captions, kind, content TEXT/JSON, ts, meta JSONB)\n  - Indexes: by campaign_id, (channel_id, ts DESC), unique (channel_id, user_id) active membership, invite dedupe (channel_id, invitee_id, status='pending').\n\n- UI/UX\n  - Channel list/switcher scoped to campaign; global channel pinned/bannered; unread badges; voice presence dots.\n  - Create channel dialog: name, invite_only, initial invites; role shown as owner for creator.\n  - Invite notifications: toast + inbox; accept/decline; deep‑link to channel.\n  - Per‑channel controls: join/leave, push‑to‑talk toggle, VAD toggle, mute/volume slider; captions pane; message composer.\n  - Accessibility: keyboard PTT, ARIA live for captions, color contrast; localized strings; dark/light.\n\n- Event sourcing and audit\n  - Emit channel_events for all state mutations; include actor_id, reason/message; render minimal audit feed for mods.\n\n- Migration and seeding\n  - On campaign creation, auto‑create GLOBAL All‑Hands channel with default_join_muted=true and captions on.\n\n- Performance\n  - Backpressure on WS text/caption streams; coalesce presence updates; message send debouncing; pagination size defaults; apply existing WS reconnection policies.\n\n- Error handling and edge cases\n  - Owner leave requires transfer or archive; prevent removing last owner; invite accept auto‑joins channel; decline keeps audit.\n  - Kicks remove from voice and membership; surface reason to target; prevent rejoin if invite_only and no invite.\n\nImplementation notes\n- Backend: TypeScript (Node) services; reuse existing WS hub; zod validation; transactional writes for membership/invite flows; outbox pattern to emit WS after commit.\n- Client: React; state via existing store; optimistic UI for text; reconcile on WS acks; persistent per‑channel audio settings in local storage.\n- Telemetry: log invite rate‑limit hits, moderation actions, errors; redact PII in events.\n",
        "testStrategy": "Unit tests (server)\n- Authorization and role enforcement: create/update/delete channel; role transitions with constraints; moderation mute/kick auth; prevent cross‑campaign access.\n- Invite lifecycle: create (rate‑limited), accept (auto‑join), decline, revoke/expire; dedupe pending invites per user/channel; audit events emitted.\n- Membership: join/leave; default join muted; owner transfer and last‑owner guard; unique active membership per user/channel.\n- Text routing: messages stored and broadcast to channel members only; captions stored with kind=caption and diarization metadata.\n- Audit logs: verify channel_events appended for all mutations with correct payloads.\n\nIntegration/API tests\n- CRUD: create ad‑hoc channel, update props, archive; global channel existence per campaign and non‑deletable guard.\n- Membership flows: join/leave endpoints; per‑channel mute/volume updates persisted; kick removes voice presence and membership.\n- Invites: create -> invitee receives WS invite; accept -> becomes member; decline -> no membership; rate‑limit returns 429 with reset header.\n- WS sequencing: subscribe to campaign; assert event order and idempotency on reconnect; presence/talking events throttled.\n- Voice/text coupling: join channel -> voice room presence mirrors membership; captions received in text stream; push‑to‑talk/VAD state reflected in presence events.\n\nUI (Playwright)\n- Global channel banner visible; join/leave/mute and volume work and persist; captions visible with ARIA live.\n- Create ad‑hoc channel; invite flow end‑to‑end (create, notify, accept/decline); membership roles displayed; permissions UI enforced.\n- Send/receive text and captions; unread counts and switcher updates; invite notifications actionable.\n\nNon‑functional\n- Rate limits honored under load; invite burst blocked; WS reconnect maintains channel subscriptions and resyncs last cursor.\n- Privacy/isolation: cross‑campaign access attempts denied in API and WS; no events leaked in multi‑campaign test.\n- Persistence: pagination returns stable ordering; retention purger (if configured) removes old messages without breaking pagination.\n",
        "status": "pending",
        "dependencies": [
          26
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 31,
        "title": "Scaffold React UI per UI Visual Design with Storybook, Theming, and Test Gates",
        "description": "Create the React component library structure in src/ui_frontend matching framework_docs/ui_visual_design.md, implement dark-theme tokens with Tailwind/CSS variables, wire to mocked APIs, and add Storybook/Ladle with accessibility and testing gates (Jest/RTL, Playwright+MSW, visual regression).",
        "details": "Scope and deliverables\n- Create src/ui_frontend/ui with component folders matching the visual layout: TopBar, ChannelsList, PartyPanel, SceneMedia, NPCRoster, QuickIntents, ObjectivesPanel, SituationTicker, AchievementsToasts, TranscriptChat, Modals/ChannelManager, Modals/InviteDialog.\n- For each component:\n  - Files: Component.tsx, Component.stories.tsx, Component.test.tsx, Component.accessibility.test.tsx, index.ts, styles.css (or .module.css if not using Tailwind), and fixtures.mock.ts.\n  - Export public components via src/ui_frontend/ui/index.ts and aggregated src/ui_frontend/index.ts for app consumption.\n  - Add data-testid values exactly as defined in framework_docs/ui_visual_design.md; fail builds if mismatched.\n  - Props: accept minimal props per ASCII wireframes (titles, counts, selected states, lists) and callbacks (onSelectChannel, onToggleMute, onOpenInvite, etc.). No real backend calls.\n- Theming and styles\n  - Default dark theme using CSS variables in :root[data-theme='dark'] and an optional Tailwind config using theme tokens. Define core tokens: color.bg, color.panel, color.text, color.text-muted, color.accent, color.error, elevation.s, elevation.m, radius.s|m, spacing scale, typography tokens.\n  - Support prefers-color-scheme: dark by default; provide a simple ThemeProvider that toggles data-theme on <html>.\n- State management and mocking\n  - Components are primarily presentational; create lightweight container/demo mocks in stories using MSW to simulate API data for: channel list, invites, transcript stream, achievements toasts, ticker items.\n  - Provide a shared mock service worker setup for Storybook and Playwright.\n- Storybook (or Ladle) setup\n  - Configure Storybook with @storybook/addon-a11y, @storybook/addon-interactions, and storybook-addon-msw. Provide stories for happy path and edge states (empty lists, long names, overflow, error banners).\n  - Global decorators for ThemeProvider and MSW.\n- Playwright scaffold\n  - E2E smoke for main layout shell rendering all panels, opening InviteDialog from TopBar/ChannelManager, toggling mute, switching ChannelsList selection. Use MSW to intercept API calls. Add data-testid hooks per design.\n- Visual regression\n  - Capture baseline snapshots for TopBar, ChannelsList, PartyPanel, ObjectivesPanel, SituationTicker, TranscriptChat, AchievementsToasts in both default and edge cases.\n- Accessibility\n  - ARIA roles/labels per component: navigation/menubar for TopBar, list/listitem for ChannelsList, dialog role with labelledby/ describedby for modals, log or feed role for TranscriptChat/Ticker, status for AchievementsToasts, buttons and toggle buttons with aria-pressed for mute.\n- Project wiring\n  - Ensure components are isolated from backend; all data via props or MSW mocks. Provide a mockApi.ts with handlers for channels, invites, presence toggles.\n  - Add npm scripts: ui:storybook, ui:test, ui:e2e, ui:validate-testids.\n- Docs\n  - Add framework_docs/COMPONENTS_README.md describing structure, tokens, test IDs, and story usage.\n\nImplementation notes and examples\n- File structure example\n  - src/ui_frontend/ui/TopBar/TopBar.tsx\n  - src/ui_frontend/ui/TopBar/TopBar.stories.tsx\n  - src/ui_frontend/ui/TopBar/TopBar.test.tsx\n  - src/ui_frontend/ui/TopBar/TopBar.accessibility.test.tsx\n  - src/ui_frontend/ui/TopBar/index.ts\n  - Repeat for all components and Modals/ChannelManager, Modals/InviteDialog.\n- Tailwind option\n  - tailwind.config.ts extends with cssVar-based colors: colors: { bg: 'var(--color-bg)', panel: 'var(--color-panel)', text: 'var(--color-text)', accent: 'var(--color-accent)' }.\n- Data contracts for mocks\n  - Channel {id, name, unreadCount, isMuted, isSelected, type}\n  - Invite {id, channelId, inviter, createdAt, status}\n  - TranscriptItem {id, speaker, text, timestamp}\n  - TickerItem {id, type, message, severity}\n\nNon-goals\n- No backend integration, websockets, or persistence.\n- No provider adapters or voice pipeline wiring here.\n",
        "testStrategy": "Unit tests (Jest + React Testing Library)\n- Props/state rendering: verify labels, counts, selected state, and callbacks fire for TopBar, ChannelsList, PartyPanel, etc.\n- Data-testid presence: assert every element defined in ui_visual_design.md exists with exact IDs; add a test that parses the doc and checks IDs where feasible.\n- Accessibility: axe-core checks per component; roles/labels and keyboard nav: focus trap in dialogs, Escape to close, Tab order, Space/Enter activate.\n\nVisual/regression tests\n- For key panels (TopBar, ChannelsList, PartyPanel, ObjectivesPanel, SituationTicker, TranscriptChat, AchievementsToasts), render deterministic stories and capture baseline images; assert diffs < threshold in CI.\n\nPlaywright E2E smoke (with MSW)\n- Load main layout story/preview; verify all primary regions visible.\n- Open InviteDialog via TopBar/ChannelManager; fill and submit; MSW returns success; dialog closes and toast shows.\n- Toggle mute button (aria-pressed toggles, icon changes).\n- Switch channels: click different list items; selection state and panel header update.\n\nAcceptance checks\n- Visual comparison against ASCII wireframes in ui_visual_design.md passes review.\n- Dark theme tokens applied; components respect tokens.\n- All tests green in CI: lint, typecheck, unit, a11y, visual, and Playwright smoke.",
        "status": "pending",
        "dependencies": [
          26,
          30
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 32,
        "title": "Galaxy Map & Planet Setup Initialization",
        "description": "Generate and persist initial galaxy map at campaign create; deterministic seed; systems/planets/deposits persistence and seed API.",
        "details": "- Data model: systems(id, name, sector, coords), planets(id, system_id, name, biome, gravity, hazard, tags), deposits(planet_id, resource, richness).\n- APIs: POST /api/campaigns/:id/map/init (seed & profile) [planned]; interim seed endpoint for tests exists (/api/empire/seed).\n- Determinism: accept seed and generation profile; record seed in campaign state; allow re-gen in dev with diff snapshot logging.\n- Map browse: GET list/browse endpoints for systems and planets (paginated).\n- Tests: deterministic outputs for given seed; persistence verified; dev-only re-gen protected by env flag.",
        "testStrategy": "- Unit: generator determinism for fixed seed (same systems/planets set); schema validation for persistence.\n- API: init endpoint creates systems/planets/deposits and records seed; browse endpoints return expected shapes.\n- E2E (Playwright): after init, HUD map panel shows at least one planet/system; screenshots for baseline.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Schema: systems and link planets→systems",
            "description": "Add systems table and FK from planets; migrations and accessors.",
            "dependencies": [],
            "details": "DDL + repository helpers; backfill existing demo planets to a default system in dev.",
            "status": "pending",
            "testStrategy": "Unit: FK integrity; list systems and planets by system"
          },
          {
            "id": 2,
            "title": "Init endpoint: POST /api/campaigns/:id/map/init",
            "description": "Create systems/planets/deposits from seed and profile; persist seed.",
            "dependencies": [
              32.1
            ],
            "details": "Input: { seed, mapSize, systems, habitablePerRegion, richnessProfile, hazardProfile }.",
            "status": "pending",
            "testStrategy": "API happy path; idempotency guard; dev-only re-init with flag"
          },
          {
            "id": 3,
            "title": "Browse endpoints: systems, planets",
            "description": "Read APIs to navigate galaxy map.",
            "dependencies": [
              32.1
            ],
            "details": "GET /api/map/systems?cursor; GET /api/map/systems/:id/planets",
            "status": "pending",
            "testStrategy": "Pagination and shapes validated"
          },
          {
            "id": 4,
            "title": "HUD: minimal map panel",
            "description": "Add read-only map/planet list to HUD demo after init.",
            "dependencies": [
              32.2,
              32.3
            ],
            "details": "Render top few systems and first planet; link to production panel.",
            "status": "pending",
            "testStrategy": "Playwright: panel renders after init"
          }
        ]
      },
      {
        "id": 33,
        "title": "Empire HUD Tests Stabilization",
        "description": "Stabilize Playwright Empire HUD test by using latest planet helper and periodic refresh; ensure non-flaky stocks/queues assertions.",
        "details": "- Backend: GET /api/empire/planets/latest (added).\n- HUD: periodic refresh (added) and immediate load after seeding.\n- Test: seed via API, pre-tick, then assert stocks and queue progress reliably.",
        "testStrategy": "- Playwright: ensure deterministic flow—seed→pre-tick via API, navigate HUD, wait for stocks textContent > 0; capture screenshot.\n- Retry policy and longer timeout for CI only.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 34,
        "title": "Trade & Economy (Phase 1) — No Equity Investing",
        "description": "Implement interstellar trade MVP with routes/tariffs, contracts, diverse corporations (sector KPIs only), and economy indices. No player equity investing.",
        "details": "- Prices API: GET /api/trade/prices?system=:id computes from stockpiles+demand and tariffs/subsidies.\n- Routes & tariffs: define routes and tariffs; effective prices include fees.\n- Contracts: POST /api/trade/contract (spot/offtake); apply deliveries on tick.\n- Corporations: corps with sectors (Mining, Logistics, Manufacturing, Energy, Agriculture, Biotech, Finance, Trade, Research, Infrastructure); record KPIs, no shares trading.\n- Economy: indices API (resource/logistics/mfg/energy) derived from KPIs and volumes; policies/taxes endpoints to adjust macro levers.\n- UI: Trade panel (prices/contracts), Economy panel (indices, policies/tax sliders), Corp sheet (sector, KPIs, facilities/routes).",
        "testStrategy": "- Unit: price calc from stockpiles + tariffs; contract ledger updates and tick effects; KPIs aggregation into indices.\n- API: contracts flow; corp registry CRUD (no cap table); indices read; policies/taxes set/get.\n- UI (Playwright): create contract; see indices update (bounded); adjust tax slider (authorized) and verify prices/indices shift.",
        "priority": "high",
        "dependencies": [
          32
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Price model and endpoint",
            "description": "Compute live prices per resource by system",
            "dependencies": [],
            "details": "Curve params in config; read stockpiles as supply proxy",
            "status": "done",
            "testStrategy": "Deterministic fixture tests"
          },
          {
            "id": 2,
            "title": "Routes & tariffs tables + effects",
            "description": "Persist routes and tariffs; include in price quotes",
            "dependencies": [
              34.1
            ],
            "details": "routes(from_id,to_id,capacity,risk); tariffs(system_id,resource,rate)",
            "status": "done",
            "testStrategy": "Unit schema + API price changes with tariffs"
          },
          {
            "id": 3,
            "title": "Contracts API (spot, offtake)",
            "description": "Create contract records and schedule delivery",
            "dependencies": [
              34.2
            ],
            "details": "contracts(buyer_system_id,seller_system_id,resource,qty,price,deliver_at)",
            "status": "done",
            "testStrategy": "API e2e: create→tick→stockpiles updated"
          },
          {
            "id": 4,
            "title": "Corps registry + KPIs (sectors)",
            "description": "CRUD corps with sector classification and KPI recording (no equity)",
            "dependencies": [],
            "details": "corps(name, sector, hq_system_id); corp_kpis(corp_id, ts, output, margin, on_time_rate)",
            "status": "done",
            "testStrategy": "CRUD + KPI aggregation tests"
          },
          {
            "id": 5,
            "title": "Economy indices & policies/taxes endpoints",
            "description": "Compute indices and expose policy/tax configuration APIs",
            "dependencies": [
              34.4
            ],
            "details": "indices(region, ts,...); policies(region,type,value); tax_rates(region, corp_tax, tariff_default, vat)",
            "status": "done",
            "testStrategy": "Indices shift with KPIs; policy/tax adjustments bounded"
          },
          {
            "id": 6,
            "title": "UI panels (Trade, Economy, Corp)",
            "description": "Add basic panels to HUD/console",
            "dependencies": [
              34.1,
              34.3,
              34.5
            ],
            "details": "Render prices; submit a contract; show indices and policy/tax sliders; show corp KPIs",
            "status": "done",
            "testStrategy": "Playwright happy path"
          }
        ]
      },
      {
        "id": 39,
        "title": "Empire Analytics & KPIs (Economy, Military, Population, Science)",
        "description": "Implement KPI snapshotting, analytics APIs, and HUD Analytics screen to monitor and manage empire health.",
        "details": "- Data model: kpi_snapshots(scope, region_or_campaign_id, ts, metrics JSONB); corp_kpis aggregation; indices per region.\n- Snapshot service: compute KPIs each tick from in-world state (stockpiles, routes, units, policies, taxes).\n- APIs: GET /api/analytics/empire (latest), GET /api/analytics/trends?window=30 (series).\n- HUD: Analytics screen with panels (Economy, Military, Population, Science, Infrastructure, Alerts) and policy/tax controls (authorized).",
        "testStrategy": "- Unit: KPI math (economy, military, population, science indices).\n- API: latest + trends shapes and bounds.\n- UI (Playwright): renders panels and reacts to policy/tax changes with bounded KPI shifts.",
        "priority": "high",
        "dependencies": [
          32,
          34
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Schema & snapshot repository",
            "description": "Create kpi_snapshots table and repo helpers",
            "dependencies": [],
            "details": "DDL + getLatest/listWindow",
            "status": "pending",
            "testStrategy": "Unit CRUD + shape"
          },
          {
            "id": 2,
            "title": "Snapshot computation service",
            "description": "Compute KPIs from current state on tick",
            "dependencies": [
              35.1
            ],
            "details": "Economy (production, prices, budget), Military (strength/readiness), Population (growth/morale), Science (velocity)",
            "status": "pending",
            "testStrategy": "Fixture inputs → expected KPI outputs"
          },
          {
            "id": 3,
            "title": "Analytics APIs (latest, trends)",
            "description": "Expose latest and timeseries KPIs",
            "dependencies": [
              35.2
            ],
            "details": "GET /api/analytics/empire, GET /api/analytics/trends?window=30",
            "status": "pending",
            "testStrategy": "API contracts stable"
          },
          {
            "id": 4,
            "title": "HUD Analytics screen",
            "description": "Add Analytics UI with charts and controls",
            "dependencies": [
              35.3
            ],
            "details": "Panels for Economy/Military/Population/Science; policy/tax sliders (authorized)",
            "status": "pending",
            "testStrategy": "Playwright charts render and react"
          }
        ]
      },
      {
        "id": 36,
        "title": "Simulation Engine (MVP)",
        "description": "Implement a deterministic in-process engine that advances campaign state per tick with reducers, persists KPI snapshots, and emits Vezies events.",
        "details": "- Engine host: src/server/sim/engine.ts with step({ campaignId, seed, actions[] })\n- Deterministic PRNG; pure-ish reducers; transactional writes\n- Reducer order: production → queues → logistics-cap (stub) → prices → readiness/science proxies → apply policy/tax modifiers → KPIs + Vezies → persist\n- API: POST /api/sim/step (dev-only) to invoke one step\n- Analytics: prefer engine snapshot in GET /api/analytics/empire (fallback if none)",
        "testStrategy": "- Unit: reducers math with fixtures (production, queue completion, price calc)\n- API: POST /api/sim/step writes kpi_snapshots entry\n- Integration: queue completion emits Empire Vezies; new planet emits Discovery Vezies\n- Playwright: HUD shows analytics change after Step Engine button",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Engine host & seed PRNG",
            "description": "Create engine.ts with step() and deterministic PRNG",
            "dependencies": [],
            "details": "No wall-clock; seed = hash(campaignSeed,tickIndex,subsystem)",
            "status": "done",
            "testStrategy": "Deterministic outputs for same seed+state"
          },
          {
            "id": 2,
            "title": "Reducers (MVP)",
            "description": "Implement production, queues, logistics-cap (stub), prices, readiness/science proxies, apply modifiers, KPIs + Vezies",
            "dependencies": [
              36.1
            ],
            "details": "Clamped scalars; conflict resolution by precedence",
            "status": "done",
            "testStrategy": "Fixture expectations for each reducer"
          },
          {
            "id": 3,
            "title": "Persistence & dev API",
            "description": "Transactional writes and POST /api/sim/step",
            "dependencies": [
              36.2
            ],
            "details": "Commit deltas in one unit; return snapshot+logs",
            "status": "done",
            "testStrategy": "API returns 200; snapshot count increases"
          },
          {
            "id": 4,
            "title": "Analytics integration",
            "description": "Use engine latest snapshot in /api/analytics/empire (fallback)",
            "dependencies": [
              36.3
            ],
            "details": "Return engine-derived KPIs when present",
            "status": "done",
            "testStrategy": "Shape and values within bands"
          },
          {
            "id": 5,
            "title": "HUD: Step Engine",
            "description": "Add Step Engine button and last KPIs/logs to /demo/hud",
            "dependencies": [
              36.3,
              36.4
            ],
            "details": "Trigger step then refresh analytics panels",
            "status": "done",
            "testStrategy": "Playwright verifies bar changes"
          }
        ]
      },
      {
        "id": 37,
        "title": "Policies/Laws (Free-form) and AI Advisors (MVP)",
        "description": "Add free-form policies storage and capped, approval-based modifiers; implement advisor query/propose endpoints; engine consumes approved modifiers and pending actions.",
        "details": "- Policies: title/body(scope/tags), suggestions via AI (placeholder), approval to activate modifiers (capped)\n- Modifiers (caps): uptime_mult, throughput_mult, capacity_mult, risk_delta, tariff_delta, subsidy_delta, velocity_mult, readiness_mult\n- Advisors: /api/advisors/:domain/query and /api/advisors/:domain/propose; pending_actions table; engine executes on next step\n- HUD: Policies panel (compose→suggest→approve); Advisors panel (ask→propose→approve)",
        "testStrategy": "- API: create policy → activate → step → KPI delta within band\n- API: advisor propose+approve → step applies action\n- UI: Policies and Advisors flows via Playwright",
        "priority": "high",
        "dependencies": [
          36
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Policies storage & create endpoint",
            "description": "Table policies + POST /api/policies (suggestions placeholder)",
            "dependencies": [],
            "details": "policies(id,title,body,scope,tags,effective_at,expires_at,author,created_at)",
            "status": "done",
            "testStrategy": "CRUD + shape"
          },
          {
            "id": 2,
            "title": "Approval & modifiers",
            "description": "policy_modifiers table + /api/policies/activate; engine reads active modifiers",
            "dependencies": [
              37.1
            ],
            "details": "Clamp to caps; precedence rules; audit trail",
            "status": "done",
            "testStrategy": "KPI changes bounded post-step"
          },
          {
            "id": 3,
            "title": "Advisors endpoints & pending actions",
            "description": "/api/advisors/:domain/query + /api/advisors/:domain/propose; pending_actions table",
            "dependencies": [],
            "details": "Domains: economy, military, science, logistics, governance, diplomacy",
            "status": "done",
            "testStrategy": "Returns recommendations; proposal persisted"
          },
          {
            "id": 4,
            "title": "Engine: consume approved proposals",
            "description": "Execute approved pending actions on next step",
            "dependencies": [
              37.3,
              36.3
            ],
            "details": "Mark executed_at; handle idempotency",
            "status": "done",
            "testStrategy": "Action effect observable in KPIs"
          },
          {
            "id": 5,
            "title": "HUD panels (Policies/Advisors)",
            "description": "Add simple panels to /demo/hud for flows",
            "dependencies": [
              37.2,
              37.4
            ],
            "details": "Policies compose→suggest→approve; Advisors ask→propose→approve",
            "status": "done",
            "testStrategy": "Playwright happy paths"
          }
        ]
      },
      {
        "id": 38,
        "title": "Verification & CI (Engine, Policies, Advisors, Trade)",
        "description": "Add API and Playwright tests; ensure CI starts Postgres/server on 4010 and runs tests with BASE_URL.",
        "details": "- Vitest: engine snapshot write; Vezies on completion; policies/advisors effects; trade pricing and tariffs\n- Playwright: HUD Step Engine, Policies, Advisors, Prices panels\n- CI: docker-compose Postgres; server on 4010; BASE_URL set; artifacts saved",
        "testStrategy": "- All suites green locally and in CI; screenshots/artifacts retained",
        "priority": "medium",
        "dependencies": [
          36,
          37,
          34,
          35
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "API tests: engine & scoring",
            "description": "Step → snapshot; queue completion → Vezies",
            "dependencies": [
              36.3
            ],
            "details": "Fixture-driven deterministic checks",
            "status": "pending",
            "testStrategy": "Stable outputs for seeds"
          },
          {
            "id": 2,
            "title": "API tests: policies & advisors",
            "description": "Activate modifier; propose action; step → effects",
            "dependencies": [
              37.2,
              37.4
            ],
            "details": "Bounds and idempotency",
            "status": "pending",
            "testStrategy": "Delta within expected bands"
          },
          {
            "id": 3,
            "title": "UI tests: HUD flows",
            "description": "Step Engine and panels interactions",
            "dependencies": [
              36.5,
              37.5
            ],
            "details": "Bars and text react post-step",
            "status": "pending",
            "testStrategy": "Playwright non-flaky"
          },
          {
            "id": 4,
            "title": "CI plumbing",
            "description": "Compose Postgres; start server; run tests with BASE_URL",
            "dependencies": [],
            "details": "Screenshots/artifacts stored",
            "status": "pending",
            "testStrategy": "Green pipeline"
          }
        ]
      },
      {
        "id": 40,
        "title": "Vector Memory & AI Context System",
        "description": "Implement vector-based memory system for AI-powered natural language understanding, semantic search, and contextual conversation management across the gaming platform.",
        "details": "Implementation of comprehensive vector memory system with the following core components:\n\n**Phase 1: Foundation Infrastructure**\n- Integrate existing Qdrant vector database service from docker-compose.yml\n- Implement embedding service supporting multiple providers (Ollama local, OpenAI remote)\n- Create conversation storage schema with rich metadata (campaign context, entities, game state)\n- Develop basic vector insert/search functionality with performance optimization\n\n**Phase 2: Core Memory Features**\n- Build conversation capture middleware to automatically store all player-AI interactions\n- Implement semantic search API with filtering by campaign, timeframe, entities, and context\n- Integrate memory injection into existing LLM factory for enhanced AI responses\n- Create memory management interface for admin operations and analytics\n\n**Phase 3: Intelligence Enhancement**\n- Add advanced entity extraction and conversation tagging\n- Implement pattern recognition for player behavior and preferences\n- Develop predictive suggestions based on similar past scenarios\n- Create cross-campaign learning and insights system\n\n**Technical Architecture:**\n- Vector Database: Qdrant (already configured in Docker)\n- Storage: High-dimensional vectors (768-1536 dims) with metadata\n- APIs: Store, search, analytics endpoints with < 200ms retrieval latency\n- Integration: PostgreSQL campaigns + SQLite events + Vector conversations\n- Performance: Support 100K+ conversations with concurrent access\n\n**Key Features:**\n- Semantic search for similar conversations with 85%+ accuracy\n- Real-time conversation context retention across sessions\n- AI response enhancement with relevant memory injection\n- Admin dashboard for memory management and analytics\n- Configurable retention policies and privacy controls",
        "testStrategy": "**Unit Testing:**\n- Embedding service accuracy and consistency validation\n- Vector storage/retrieval operations with performance benchmarks\n- Memory query filtering and ranking algorithms\n- Conversation capture middleware integration\n\n**Integration Testing:**\n- End-to-end conversation storage and retrieval workflows\n- LLM factory integration with memory context injection\n- Performance testing under concurrent load (50+ users)\n- Data consistency across PostgreSQL, SQLite, and Qdrant systems\n\n**User Acceptance Testing:**\n- AI response quality improvement with memory context\n- Conversation continuity verification across game sessions\n- Memory search relevance and accuracy measurements\n- System performance validation during active gameplay\n\n**Performance Benchmarks:**\n- Embedding generation: < 500ms per message\n- Semantic search queries: < 200ms response time\n- Vector storage scaling: 100K+ conversations support\n- Memory retrieval impact on AI response latency\n\n**Security Testing:**\n- Conversation data encryption at rest validation\n- Access control and player privacy protection\n- Memory retention policy compliance verification\n- Audit trail functionality for memory operations",
        "priority": "high",
        "dependencies": [
          1,
          7
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup Qdrant Vector Database Service",
            "description": "Start and configure the existing Qdrant service from docker-compose.yml with proper health checks and connectivity verification.",
            "dependencies": [],
            "details": "**Objective:** Establish reliable Qdrant vector database infrastructure\n\n**Implementation Steps:**\n- Start Qdrant service: `docker-compose up -d qdrant`\n- Verify service health and API accessibility on port 6333\n- Test basic connection and create initial collections for conversation storage\n- Configure Qdrant client library in Node.js with proper error handling\n- Set up vector collection schema with 768-dimensional embeddings\n- Implement connection pooling and retry logic for production readiness\n\n**Technical Requirements:**\n- Collection name: `conversations`\n- Vector size: 768 dimensions (compatible with most embedding models)\n- Distance metric: Cosine similarity for semantic search\n- Metadata fields: campaignId, timestamp, role, entities, gameState\n\n**Integration Points:**\n- Docker health checks for service monitoring\n- Environment variables for Qdrant connection settings\n- Logging integration for monitoring and debugging",
            "status": "done",
            "testStrategy": "Verify Qdrant API responds to health checks, test collection creation and basic vector operations, validate connection pooling under load."
          },
          {
            "id": 2,
            "title": "Implement Embedding Service with Multiple Providers",
            "description": "Create embedding service supporting local Ollama and cloud providers for text-to-vector conversion with fallback mechanisms.",
            "dependencies": [
              1
            ],
            "details": "**Objective:** Build robust text embedding service with provider abstraction\n\n**Core Features:**\n- Primary provider: Ollama local embedding models\n- Fallback provider: OpenAI text-embedding-3-small\n- Batch processing for efficient embedding generation\n- Caching layer for repeated text to avoid recomputation\n- Rate limiting and retry logic for external APIs\n\n**Implementation Architecture:**\n```typescript\ninterface EmbeddingService {\n  generateEmbedding(text: string): Promise<number[]>;\n  generateBatch(texts: string[]): Promise<number[][]>;\n  getProvider(): string;\n}\n```\n\n**Provider Integration:**\n- Ollama: Use existing OLLAMA_BASE_URL from docker-compose\n- OpenAI: Configurable via OPENAI_API_KEY environment variable\n- Automatic provider switching on failure\n- Embedding dimension normalization (768 dims standard)\n\n**Performance Optimizations:**\n- LRU cache for recent embeddings (in-memory)\n- Batch processing with configurable batch sizes\n- Async processing queue for high-volume operations",
            "status": "done",
            "testStrategy": "Unit tests for each provider, integration tests with actual embedding models, performance benchmarks for batch processing, fallback mechanism validation."
          },
          {
            "id": 3,
            "title": "Create Conversation Storage Schema and API",
            "description": "Design and implement conversation storage layer with rich metadata support and efficient querying capabilities.",
            "dependencies": [
              1,
              2
            ],
            "details": "**Objective:** Build comprehensive conversation storage with semantic search capabilities\n\n**Database Schema Design:**\n- Vector storage: Qdrant for embeddings and semantic search\n- Metadata storage: PostgreSQL for structured data and indexing\n- Conversation linking: Foreign keys to campaigns and game states\n\n**PostgreSQL Schema:**\n```sql\nCREATE TABLE conversations (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  campaign_id INTEGER REFERENCES campaigns(id),\n  player_id VARCHAR,\n  role VARCHAR(20) CHECK (role IN ('user', 'assistant', 'system')),\n  content TEXT NOT NULL,\n  timestamp TIMESTAMPTZ DEFAULT NOW(),\n  game_state JSONB,\n  entities TEXT[],\n  action_type VARCHAR(50),\n  vector_id UUID NOT NULL -- Reference to Qdrant vector\n);\n```\n\n**API Endpoints:**\n- `POST /api/memory/store` - Store new conversation with embedding\n- `GET /api/memory/search` - Semantic search with filters\n- `GET /api/memory/conversation/:id` - Retrieve full conversation\n- `DELETE /api/memory/:id` - Remove conversation and vector\n\n**Advanced Features:**\n- Automatic entity extraction from game context\n- Conversation threading and context maintenance\n- Configurable retention policies with automated cleanup",
            "status": "done",
            "testStrategy": "Database migration tests, API endpoint integration tests, vector-metadata consistency validation, performance tests with large datasets."
          },
          {
            "id": 4,
            "title": "Build Conversation Capture Middleware",
            "description": "Implement middleware to automatically capture and process all player-AI interactions with context extraction.",
            "dependencies": [
              3
            ],
            "details": "**Objective:** Seamless conversation capture across all AI interactions\n\n**Middleware Integration:**\n- Express.js middleware for API route interception\n- WebSocket message capture for real-time interactions\n- Integration with existing LLM factory for response capture\n- Context extraction from current game state\n\n**Implementation Strategy:**\n```typescript\n// Middleware integration points\napp.use('/api/trade/*', conversationMiddleware);\napp.use('/api/campaigns/*', conversationMiddleware);\napp.use('/api/advisors/*', conversationMiddleware);\n```\n\n**Automatic Context Extraction:**\n- Campaign ID from request parameters or session\n- Current game state from campaign resume data\n- Resource and entity mentions from trade/campaign context\n- Player action classification (trade, strategy, inquiry)\n\n**Processing Pipeline:**\n1. Request/response capture with metadata\n2. Content filtering (exclude sensitive/system data)\n3. Entity extraction using NLP techniques\n4. Embedding generation via embedding service\n5. Asynchronous storage in vector database\n\n**Performance Considerations:**\n- Non-blocking async processing to avoid latency\n- Queue-based processing for high-volume periods\n- Error handling to prevent middleware from breaking API responses",
            "status": "done",
            "testStrategy": "Middleware integration tests across all API routes, context extraction accuracy validation, performance impact assessment, error handling verification."
          },
          {
            "id": 5,
            "title": "Implement Semantic Search API with Advanced Filtering",
            "description": "Build powerful semantic search capabilities with multi-dimensional filtering and ranked results.",
            "dependencies": [
              3,
              4
            ],
            "details": "**Objective:** Advanced semantic search with contextual filtering\n\n**Search Capabilities:**\n- Text similarity search using vector embeddings\n- Multi-filter support: campaign, timeframe, entities, roles\n- Hybrid search combining vector similarity + metadata filters\n- Relevance scoring and result ranking\n\n**API Design:**\n```typescript\nGET /api/memory/search?q=trade routes&campaign=1&limit=10&minSimilarity=0.7\nPOST /api/memory/search {\n  query: string,\n  filters: {\n    campaignIds?: number[],\n    timeframe?: { start: Date, end: Date },\n    entities?: string[],\n    roles?: string[],\n    actionTypes?: string[]\n  },\n  options: {\n    limit: number,\n    minSimilarity: number,\n    includeContext: boolean\n  }\n}\n```\n\n**Advanced Features:**\n- Query expansion using synonyms and game terminology\n- Result clustering for similar conversations\n- Personalization based on player interaction patterns\n- Real-time search suggestions and autocomplete\n\n**Performance Optimizations:**\n- Query result caching with TTL\n- Index optimization for common filter combinations\n- Pagination for large result sets\n- Search analytics for query optimization",
            "status": "done",
            "testStrategy": "Search accuracy benchmarking, performance tests with large conversation datasets, filter combination validation, relevance scoring verification."
          },
          {
            "id": 6,
            "title": "Integrate Memory Context into AI Responses",
            "description": "Enhance existing LLM providers with conversation memory injection for contextually aware AI responses.",
            "dependencies": [
              5
            ],
            "details": "**Objective:** Memory-enhanced AI responses with contextual awareness\n\n**LLM Integration Strategy:**\n- Modify existing LLM factory to inject memory context\n- Pre-prompt enhancement with relevant conversation history\n- Context window management for optimal memory utilization\n- Graceful degradation when memory is unavailable\n\n**Memory Injection Process:**\n1. Extract context from current request (entities, campaign, action)\n2. Search for relevant past conversations using semantic search\n3. Format memory context for LLM prompt injection\n4. Monitor token usage to stay within context limits\n5. Log memory utilization for analytics and optimization\n\n**Enhanced Provider Implementation:**\n```typescript\n// Enhanced LLM call with memory context\nconst memoryContext = await searchRelevantMemory({\n  campaignId: request.campaignId,\n  entities: extractEntities(request.query),\n  limit: 5,\n  minSimilarity: 0.6\n});\n\nconst enhancedPrompt = formatPromptWithMemory(\n  originalPrompt,\n  memoryContext,\n  conversationHistory\n);\n```\n\n**Context Management:**\n- Smart memory selection based on relevance and recency\n- Token budget allocation between memory and new context\n- Memory confidence scoring for quality control\n- Fallback to non-memory responses when needed",
            "status": "done",
            "testStrategy": "A/B testing for response quality with/without memory, token usage optimization validation, memory relevance scoring accuracy, fallback mechanism testing."
          },
          {
            "id": 7,
            "title": "Create Memory Management Admin Interface",
            "description": "Build comprehensive admin dashboard for memory system monitoring, management, and analytics.",
            "dependencies": [
              6
            ],
            "details": "**Objective:** Complete memory system administration and monitoring\n\n**Dashboard Features:**\n- Real-time memory system status and health monitoring\n- Conversation search and browsing interface\n- Memory analytics: usage patterns, search performance, storage growth\n- Memory curation tools: tagging, categorization, quality scoring\n- Retention policy management and cleanup scheduling\n\n**Administrative Functions:**\n- Bulk memory operations (export, import, cleanup)\n- Memory quality assessment and scoring\n- Player privacy controls and data deletion\n- System performance monitoring and optimization\n- Memory search analytics and improvement insights\n\n**Interface Components:**\n- React-based admin dashboard integrated with existing UI\n- Real-time charts for memory usage and performance metrics\n- Search interface with advanced filtering and result preview\n- Memory timeline visualization for conversation threads\n- Export/import tools for memory backup and migration\n\n**Security & Privacy:**\n- Role-based access control for memory management\n- Audit logging for all administrative actions\n- Player consent management for conversation storage\n- Data anonymization tools for privacy compliance",
            "status": "done",
            "testStrategy": "UI component testing, admin functionality validation, security access control verification, performance monitoring accuracy, data privacy compliance checks."
          },
          {
            "id": 8,
            "title": "Performance Testing and Production Optimization",
            "description": "Comprehensive performance testing, optimization, and production readiness validation for the vector memory system.",
            "dependencies": [
              7
            ],
            "details": "**Objective:** Production-ready performance and scalability validation\n\n**Performance Benchmarking:**\n- Load testing with 50+ concurrent users and memory operations\n- Vector search performance under various query patterns\n- Memory storage and retrieval latency measurement\n- System resource utilization analysis (CPU, memory, disk, network)\n\n**Optimization Targets:**\n- Embedding generation: < 500ms per message\n- Semantic search queries: < 200ms response time\n- Memory injection latency: < 100ms added to AI responses\n- Vector database throughput: 1000+ operations/second\n\n**Scalability Testing:**\n- Memory growth simulation with 100K+ conversations\n- Concurrent user load testing for all memory endpoints\n- Database connection pooling under high load\n- Memory cache effectiveness and hit ratios\n\n**Production Readiness:**\n- Error handling and recovery mechanisms\n- Monitoring and alerting setup for memory system health\n- Backup and disaster recovery procedures\n- Performance tuning based on production workload patterns\n\n**Optimization Deliverables:**\n- Performance benchmarking report with baseline metrics\n- Optimization recommendations and implementation\n- Production deployment checklist and procedures\n- Monitoring dashboard configuration and alerting rules",
            "status": "done",
            "testStrategy": "Load testing with realistic user patterns, performance regression testing, monitoring system validation, disaster recovery testing, production deployment validation."
          }
        ]
      },
      {
        "id": 41,
        "title": "Culture & Social Systems",
        "description": "Implement comprehensive cultural mechanics with dynamic values, social policies, and cultural influence on trade and economy systems.",
        "details": "**Objective:** Build rich cultural and social systems that affect all aspects of civilization\n\n**Core Cultural Mechanics:**\n- Cultural Values System: Liberty, Order, Tradition, Progress, Community, Individualism (0-100 scales)\n- Cultural Evolution: Values shift based on policy decisions, random events, and player choices\n- Cultural Influence: Affects trade relationships, worker productivity, and social stability\n- Traditions & Festivals: Periodic cultural events boosting happiness and providing economic benefits\n\n**Social Policy Framework:**\n- Government Decisions: Policy choices affecting cultural development and economic outcomes\n- Public Opinion System: Dynamic citizen satisfaction tracking with cultural alignment metrics\n- Cultural Buildings: Libraries, theaters, museums providing cultural and educational bonuses\n- Education System: Schools and universities influencing cultural progress and technological advancement\n\n**Integration Features:**\n- Trade Impact: Cultural values affect demand patterns and trade relationship bonuses\n- Campaign Integration: Long-term cultural decisions influencing civilization development\n- Event Sourcing: All cultural changes tracked in SQLite for historical analysis\n- Vector Memory: AI advisors remember cultural preferences and policy outcomes\n\n**Database Schema:**\n```sql\n-- Core cultural values and metrics\nCREATE TABLE cultures (\n  campaign_id INTEGER REFERENCES campaigns(id),\n  liberty/order/tradition/progress/community/individualism (0-100),\n  stability_index, happiness_level, cultural_events tracking\n);\n```\n\n**API Endpoints:**\n- `GET /api/culture/:campaignId` - Current cultural state and metrics\n- `POST /api/culture/policy` - Implement cultural policy decisions\n- `GET /api/culture/events` - Active and upcoming cultural events\n- `POST /api/culture/buildings` - Construct cultural infrastructure\n\n**Performance Requirements:**\n- Cultural calculations: < 100ms for policy impact assessment\n- Real-time cultural metrics updating during gameplay\n- Cultural influence on trade prices: < 50ms additional latency",
        "testStrategy": "**Unit Testing:**\n- Cultural value calculation accuracy and boundary conditions\n- Policy impact verification on different cultural metrics\n- Cultural building bonus calculations and stacking effects\n- Event system triggering and cultural impact measurement\n\n**Integration Testing:**\n- Cultural influence on existing trade system pricing and demand\n- Campaign system integration with long-term cultural development\n- Vector memory integration for AI cultural advice and consistency\n- Database consistency between cultural events and main campaign state\n\n**User Acceptance Testing:**\n- Cultural policy decisions creating meaningful gameplay impacts\n- Visual feedback for cultural changes and their economic effects\n- Cultural building construction providing noticeable civilization benefits\n- Festival and tradition events enhancing player engagement and satisfaction",
        "priority": "high",
        "dependencies": [
          1,
          7,
          40
        ],
        "status": "done"
      },
      {
        "id": 42,
        "title": "World Wonders & Monuments",
        "description": "Create multi-stage world wonder construction system with strategic benefits, resource requirements, and cultural legacy mechanics.",
        "details": "**Objective:** Implement epic wonder construction providing strategic advantages and cultural identity\n\n**Wonder Categories & Benefits:**\n- Ancient Wonders: Pyramids (+culture, +tourism), Temples (+happiness, +stability), Colossus (+trade income)\n- Engineering Marvels: Aqueducts (+population capacity), Great Wall (+defense, +tourism), Roads (+trade efficiency)\n- Cultural Icons: Great Library (+research, +education), National Theater (+culture, +happiness)\n- Modern Achievements: Space Center (+technology, +prestige), Digital Network (+information, +efficiency)\n\n**Construction Mechanics:**\n- Multi-Stage Building: Wonders require 5-20 campaign steps to complete depending on complexity\n- Massive Resource Investment: Thousands of resources over extended time periods\n- Construction Phases: Planning → Foundation → Structure → Details → Completion\n- Strategic Decisions: Rush construction (expensive) vs. steady progress vs. resource optimization\n\n**Wonder Benefits System:**\n- Permanent Bonuses: Ongoing effects on trade, culture, defense, technology, or tourism\n- Scaling Benefits: Some wonders provide larger bonuses as civilization grows\n- Cultural Legacy: Completed wonders become major tourist attractions and cultural symbols\n- Wonder Synergies: Multiple wonders of same type provide additional combined bonuses\n\n**Long-term Project Management:**\n```sql\nCREATE TABLE world_wonders (\n  campaign_id, wonder_type, construction_status,\n  completion_percentage, total_cost (JSONB),\n  invested_resources, construction_time,\n  strategic_benefits (JSONB), tourism_attraction_level\n);\n```\n\n**Integration with Existing Systems:**\n- Trade System: Wonder construction creates massive demand for specific resources\n- Campaign System: Multi-step construction projects spanning multiple campaign phases\n- Tourism System: Completed wonders become major attractions (Task 44 integration)\n- Cultural System: Wonders provide significant cultural influence and happiness bonuses",
        "testStrategy": "**Construction Testing:**\n- Multi-phase construction progression and resource tracking accuracy\n- Wonder completion bonus application and persistence across campaign steps\n- Construction pause/resume functionality and resource cost calculations\n- Wonder cancellation and resource recovery mechanisms\n\n**Strategic Impact Testing:**\n- Wonder benefit calculation and application to relevant game systems\n- Tourism attraction value and visitor impact from completed wonders\n- Cultural significance calculation and influence on civilization metrics\n- Wonder synergy bonuses when multiple wonders of same type are built\n\n**Integration Testing:**\n- Trade system impact during wonder construction (resource demand spikes)\n- Campaign system integration with long-term construction timelines\n- Database consistency for wonder states across campaign saves and loads\n- Vector memory integration for AI advice on wonder construction strategies",
        "priority": "high",
        "dependencies": [
          1,
          7,
          41
        ],
        "status": "pending"
      },
      {
        "id": 43,
        "title": "Household Economic Simulation",
        "description": "Implement realistic household economic stratification with poor/median/rich tiers affecting demand patterns and social mobility mechanics.",
        "details": "**Objective:** Create realistic socioeconomic simulation driving authentic demand patterns and social dynamics\n\n**Economic Stratification Model:**\n- Poor Households (40% of population): Subsistence living, basic goods focus, limited purchasing power\n- Median Households (50% of population): Standard consumption, main drivers of regular goods demand\n- Rich Households (10% of population): High consumption, luxury goods demand, investment capital source\n\n**Household Economic Dynamics:**\n- Income Distribution: Realistic economic distribution based on employment, business ownership, and inheritance\n- Consumption Patterns: Tier-specific preferences (poor: food/shelter, median: comfort goods, rich: luxury items)\n- Price Elasticity: Different sensitivity to price changes by economic tier\n- Seasonal Variations: Income and spending patterns changing with economic cycles\n\n**Social Mobility System:**\n- Education Investment: Households can invest in education to improve economic prospects\n- Business Opportunities: Economic tiers affecting ability to start businesses or invest\n- Life Events: Marriage, inheritance, business success/failure affecting household tier movement\n- Economic Policy Impact: Government decisions affecting income distribution and mobility\n\n**Enhanced Trade Integration:**\n```sql\nCREATE TABLE household_tiers (\n  campaign_id, tier_name ('poor'/'median'/'rich'),\n  household_count, average_income, consumption_power,\n  luxury_demand_multiplier, basic_goods_demand_multiplier,\n  savings_rate, investment_capacity\n);\n\nCREATE TABLE household_consumption (\n  campaign_id, tier_name, resource_id,\n  base_demand, seasonal_multiplier, cultural_influence_multiplier,\n  price_elasticity -- How demand changes with price\n);\n```\n\n**Demand Pattern Revolution:**\n- Luxury Goods: High-end items primarily demanded by rich households\n- Basic Necessities: Food, shelter, clothing with inelastic demand from poor/median\n- Social Goods: Items bridging tiers (median households aspiring to rich consumption)\n- Cultural Influence: Cultural values affecting consumption preferences across all tiers",
        "testStrategy": "**Economic Model Testing:**\n- Household tier distribution accuracy and realistic income ratios\n- Consumption pattern validation against real-world economic data\n- Social mobility mechanism testing with various economic scenarios\n- Price elasticity response accuracy for different household tiers and goods\n\n**Trade System Integration:**\n- Enhanced demand calculation incorporating household tier preferences\n- Price impact testing with tier-specific elasticity responses\n- Resource shortage impact on different economic tiers (poor affected most)\n- Luxury vs. necessity demand patterns during economic growth and recession\n\n**Social Mobility Testing:**\n- Education investment impact on household tier advancement\n- Business opportunity access and success rates by economic tier\n- Life event system affecting household economic status changes\n- Long-term social mobility trends and realistic constraint modeling",
        "priority": "high",
        "dependencies": [
          1,
          7,
          41
        ],
        "status": "done"
      },
      {
        "id": 44,
        "title": "Tourism & Entertainment Systems",
        "description": "Build comprehensive tourism economy with attractions, visitor simulation, hospitality services, and entertainment venues generating significant revenue.",
        "details": "**Objective:** Create new economic layer through tourism generating 15-25% of total civilization income\n\n**Tourism Infrastructure:**\n- Natural Attractions: Scenic locations, natural wonders, unique geographical features\n- Cultural Sites: Museums, historical buildings, cultural districts, traditional markets\n- Entertainment Venues: Theaters, concert halls, sports arenas, amusement parks\n- Hospitality Services: Hotels, restaurants, tour guides, transportation systems\n\n**Visitor Simulation Engine:**\n- Visitor Origins: Different civilizations and regions with varying preferences and spending power\n- Visit Duration: Day trips vs. extended stays affecting total economic impact\n- Visitor Satisfaction: Quality metrics affecting repeat visits and word-of-mouth marketing\n- Seasonal Patterns: Tourism flows changing with weather, cultural events, and economic conditions\n\n**Entertainment & Events System:**\n- Cultural Festivals: Periodic events drawing tourists and providing economic boosts\n- Sporting Events: Competitions attracting visitors and generating media revenue\n- Arts & Culture: Performances, exhibitions, and cultural showcases\n- Adventure Tourism: Outdoor activities, extreme sports, nature expeditions\n\n**Economic Impact Model:**\n```sql\nCREATE TABLE tourism_attractions (\n  campaign_id, attraction_type ('wonder'/'natural'/'cultural'/'entertainment'),\n  name, attraction_level (1-10), visitor_capacity,\n  maintenance_cost, ticket_revenue, economic_multiplier,\n  infrastructure_requirements (JSONB)\n);\n\nCREATE TABLE visitor_flows (\n  campaign_id, campaign_step, total_visitors,\n  visitor_satisfaction, revenue_generated,\n  visitor_origin (JSONB), length_of_stay, spending_per_visitor\n);\n```\n\n**Integration with Wonder System:**\n- Completed wonders become major tourist attractions with high visitor appeal\n- Wonder construction creating temporary tourism (construction site tourism)\n- Cultural wonders providing higher cultural tourism value\n- Modern wonders attracting technology and innovation tourists",
        "testStrategy": "**Tourism Economics Testing:**\n- Visitor flow simulation accuracy and realistic tourism patterns\n- Revenue generation calculation and economic impact measurement\n- Tourism attraction capacity limits and visitor satisfaction correlation\n- Seasonal tourism variation and economic cycle impact validation\n\n**Entertainment System Testing:**\n- Cultural event scheduling and tourism boost calculation\n- Entertainment venue capacity management and revenue optimization\n- Visitor preference matching with available attractions and activities\n- Tourism marketing effectiveness and visitor acquisition cost analysis\n\n**Integration Testing:**\n- Wonder system integration with tourism attraction values\n- Cultural system influence on tourism appeal and visitor satisfaction\n- Household economic impact from tourism employment and local spending\n- Infrastructure requirements and tourism development cost-benefit analysis",
        "priority": "medium",
        "dependencies": [
          1,
          7,
          41,
          42
        ],
        "status": "done"
      },
      {
        "id": 45,
        "title": "Civilization Analytics & Metrics",
        "description": "Implement comprehensive civilization health monitoring with advanced metrics, predictive modeling, and AI-powered advisory dashboard.",
        "details": "**Objective:** Provide deep analytical insights for strategic civilization management and optimization\n\n**Advanced Metrics Suite:**\n- Economic Health: GDP, per capita income, Gini coefficient (inequality), unemployment, inflation rates\n- Social Indicators: Happiness index, education levels, health metrics, social mobility index\n- Cultural Vitality: Cultural diversity, tradition preservation, innovation index, cultural influence\n- Infrastructure Quality: Transportation, utilities, communications, wonder completion rates\n- Sustainability Index: Resource management, environmental impact, long-term viability\n\n**Analytics Dashboard Components:**\n- Real-time Monitoring: Live civilization health metrics with color-coded status indicators\n- Historical Trends: Long-term analysis showing civilization evolution over multiple campaigns\n- Comparative Analysis: Benchmarking against historical periods or other civilizations\n- Predictive Modeling: AI-powered forecasting of social, economic, and cultural trends\n\n**Composite Scoring System:**\n```sql\nCREATE TABLE civilization_metrics (\n  campaign_id, campaign_step, recorded_at,\n  \n  -- Economic: gdp_total, gdp_per_capita, gini_coefficient, unemployment_rate, inflation_rate\n  -- Social: happiness_index, education_level, health_index, social_mobility_index  \n  -- Cultural: cultural_diversity_index, cultural_vitality_score, tradition_preservation, innovation_index\n  -- Infrastructure: infrastructure_quality, tourism_satisfaction, wonder_completion_rate\n  -- Composite: civilization_health_index, sustainability_index, overall_prosperity_score\n);\n```\n\n**AI-Powered Advisory System:**\n- Trend Analysis: Identification of concerning trends before they become critical problems\n- Optimization Recommendations: AI suggestions for improving specific civilization metrics\n- Policy Impact Prediction: Forecasting effects of proposed cultural, economic, or social policies\n- Strategic Planning: Long-term development recommendations based on current trajectory\n\n**Integration & Data Sources:**\n- Trade System: Economic metrics from resource flows, pricing, and market activity\n- Cultural System: Social and cultural indicators from cultural values and policy decisions\n- Household System: Social mobility and inequality metrics from household tier analysis\n- Tourism System: Infrastructure and satisfaction metrics from visitor feedback\n- Wonder System: Cultural significance and tourism attraction metrics",
        "testStrategy": "**Metrics Accuracy Testing:**\n- Composite score calculation verification with known test scenarios\n- Historical trend analysis accuracy with recorded civilization development\n- Predictive model validation against actual civilization development outcomes\n- Dashboard real-time update performance and data visualization accuracy\n\n**AI Advisory Testing:**\n- Advisory recommendation relevance and actionability assessment\n- Policy impact prediction accuracy against actual implemented policy results\n- Trend detection sensitivity and false positive/negative rate analysis\n- Strategic planning recommendation effectiveness measurement\n\n**Integration Testing:**\n- Data pipeline integration from all civilization systems (trade, culture, household, tourism, wonders)\n- Performance testing with large datasets and complex metric calculations\n- Real-time dashboard responsiveness during high-activity gameplay periods\n- Database query optimization for complex analytical queries across multiple systems",
        "priority": "medium",
        "dependencies": [
          1,
          7,
          40,
          41,
          42,
          43,
          44
        ],
        "status": "pending"
      },
      {
        "id": 46,
        "title": "Information Classification & Espionage System",
        "description": "Implement comprehensive information classification, corporate espionage, and intelligence operations system transforming information into strategic resources.",
        "details": "**Objective:** Create sophisticated intelligence system where information becomes as valuable as traditional resources\n\n**Core Features:**\n- **Information Classification**: PUBLIC/PROPRIETARY/CLASSIFIED/TOP_SECRET levels with access control\n- **Corporate Intelligence**: R&D systems, patent protection, technology transfer, industrial espionage\n- **Espionage Operations**: Spy networks, intelligence gathering, counter-intelligence, risk/reward mechanics\n- **Intelligence Market**: Information trading, brokers, dynamic pricing, information decay\n- **Security Framework**: Access control, compartmentalization, security clearances, threat detection\n\n**Strategic Impact:**\n- Transform information into tradable strategic resource\n- Corporate technologies and expertise creating competitive advantages\n- Diplomatic leverage through intelligence gathering and classified information\n- Economic warfare capabilities through information disruption\n- AI-enhanced intelligence analysis using Vector Memory System (Task 40)\n\n**Integration Points:**\n- Vector Memory System: AI-powered intelligence analysis, conversation classification, semantic search for intelligence patterns\n- Trade System: Corporate technologies affecting production, intelligence influencing market strategies\n- Campaign System: Long-term intelligence operations, technological development over time\n- Cultural System: Cultural values affecting surveillance acceptance and espionage effectiveness\n\n**Database Architecture:**\n```sql\n-- Information assets with classification levels\nCREATE TABLE information_assets (\n  id UUID PRIMARY KEY,\n  classification_level VARCHAR(20),\n  owner_type VARCHAR(20),\n  category VARCHAR(50),\n  intelligence_value INTEGER\n);\n\n-- Espionage operations and spy networks\nCREATE TABLE intelligence_operations (\n  id UUID PRIMARY KEY,\n  operation_type VARCHAR(50),\n  success_probability DECIMAL(3,2),\n  resource_cost INTEGER\n);\n\n-- Corporate technologies and research\nCREATE TABLE corporate_technologies (\n  id UUID PRIMARY KEY,\n  corporation_id INTEGER,\n  research_stage VARCHAR(50),\n  patent_status VARCHAR(20)\n);\n```\n\n**Performance Requirements:**\n- Information access control: < 50ms response time\n- Intelligence operation processing: < 200ms\n- Espionage success calculation: < 100ms\n- Corporate technology impact: < 50ms additional trade latency",
        "testStrategy": "**Unit Testing:**\n- Information classification accuracy and access control validation\n- Espionage operation success/failure probability calculations\n- Corporate technology bonus applications and patent system mechanics\n- Intelligence market pricing and information decay algorithms\n\n**Integration Testing:**\n- Vector Memory System integration for AI-enhanced intelligence analysis\n- Trade system integration with corporate technologies and market intelligence\n- Campaign system integration with long-term intelligence operations\n- Security framework effectiveness against various espionage attempts\n\n**System Testing:**\n- Multi-player espionage scenarios with competing intelligence networks\n- Information leakage and security breach simulation\n- Corporate espionage campaigns affecting trade relationships\n- Diplomatic intelligence impact on international relations\n\n**Performance Testing:**\n- Access control system scalability with large user bases\n- Intelligence operation processing under concurrent load\n- Information market transaction throughput and pricing updates\n- Database query optimization for complex intelligence queries",
        "priority": "high",
        "dependencies": [
          1,
          7,
          40,
          41
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Core Information Classification Framework",
            "description": "Implement foundational information classification system with access control, security levels, and basic information management.",
            "dependencies": [],
            "details": "**Phase 1: Core Information Framework**\n\n**Database Schema Implementation:**\n- Create `information_assets` table with classification levels (PUBLIC/PROPRIETARY/CLASSIFIED/TOP_SECRET)\n- Implement `information_access` table for role-based permissions\n- Add `information_categories` for technological/economic/military/diplomatic/cultural classification\n- Create indexes for efficient access control queries\n\n**Classification System:**\n- Implement classification level hierarchy with inheritance rules\n- Create automatic classification suggestions based on content analysis\n- Build declassification timeline system for time-sensitive information\n- Add classification authority system for governments and organizations\n\n**Access Control Framework:**\n- Role-based access control with granular permissions\n- Security clearance levels with personnel screening simulation\n- Need-to-know basis compartmentalization system\n- Access logging and audit trail for security compliance\n\n**API Endpoints:**\n- `GET /api/intel/information` - List accessible information assets\n- `POST /api/intel/classify` - Classify information with security level\n- `PUT /api/intel/access` - Grant/revoke information access permissions\n- `GET /api/intel/information/:id` - Retrieve specific information with access validation\n\n**Integration Preparation:**\n- Vector Memory integration hooks for AI classification assistance\n- Event sourcing for all classification and access changes\n- Cache layer for frequent access control checks\n- Security monitoring and threat detection framework",
            "status": "pending",
            "testStrategy": "Unit tests for classification algorithms, access control validation, security clearance verification. Integration tests with Vector Memory for AI-assisted classification. Performance tests for access control scalability."
          },
          {
            "id": 2,
            "title": "Corporate Technology & R&D Systems",
            "description": "Implement corporate research and development framework with proprietary technologies, patent systems, and technology transfer mechanisms.",
            "dependencies": [
              "46.1"
            ],
            "details": "**Corporate Technology Framework:**\n- Multi-stage R&D projects with resource requirements and timelines\n- Technology tree dependencies and prerequisite research\n- Research specialization areas (manufacturing, efficiency, algorithms, materials)\n- Prototype development and testing phases before commercialization\n\n**Patent System:**\n- Patent application and approval processes with government oversight\n- Patent protection duration and renewal mechanics\n- Prior art search and patent conflict resolution\n- International patent recognition and cross-border enforcement\n\n**Technology Transfer Mechanics:**\n- Licensing agreements with royalty structures and usage restrictions\n- Joint venture research projects with shared intellectual property\n- Technology acquisition through corporate mergers and acquisitions\n- Open source technology releases for competitive advantage\n\n**Proprietary Information Management:**\n```sql\nCREATE TABLE corporate_technologies (\n  id UUID PRIMARY KEY,\n  corporation_id INTEGER,\n  technology_name VARCHAR(200),\n  research_stage VARCHAR(50),\n  completion_percentage DECIMAL(5,2),\n  patent_status VARCHAR(20),\n  classification_level VARCHAR(20),\n  strategic_value INTEGER\n);\n\nCREATE TABLE research_projects (\n  id UUID PRIMARY KEY,\n  corporation_id INTEGER,\n  project_name VARCHAR(200),\n  research_cost INTEGER,\n  timeline_months INTEGER,\n  success_probability DECIMAL(3,2),\n  technology_category VARCHAR(50)\n);\n```\n\n**Technology Impact Systems:**\n- Production efficiency bonuses from manufacturing technologies\n- Trade algorithm improvements affecting market performance\n- Resource extraction efficiency improvements\n- Quality improvements increasing product value and demand\n\n**API Endpoints:**\n- `GET /api/intel/technologies/:corpId` - List corporation's technologies\n- `POST /api/intel/research` - Start new R&D project\n- `GET /api/intel/patents` - List patented technologies and licensing\n- `POST /api/intel/transfer` - Initiate technology transfer negotiation",
            "status": "pending",
            "testStrategy": "Research project progression testing, patent system validation, technology impact measurement on trade system. Technology transfer agreement enforcement testing."
          },
          {
            "id": 3,
            "title": "Espionage Operations & Spy Networks",
            "description": "Develop comprehensive espionage system with agent recruitment, intelligence operations, success/failure mechanics, and counter-intelligence.",
            "dependencies": [
              "46.1",
              "46.2"
            ],
            "details": "**Spy Network Management:**\n- Agent recruitment with specialization (HUMINT/SIGINT/Corporate/Diplomatic)\n- Cover identity creation and maintenance systems\n- Agent skill development and experience progression\n- Network security and operational security (OPSEC) protocols\n\n**Intelligence Operations:**\n- Operation planning with target selection and resource allocation\n- Multi-stage operations requiring coordination between multiple agents\n- Success probability calculation based on agent skills, target security, resources\n- Operation timeline management with milestone checkpoints\n\n**Operation Types:**\n```sql\nCREATE TABLE intelligence_operations (\n  id UUID PRIMARY KEY,\n  operation_type VARCHAR(50),\n  operator_id INTEGER,\n  target_type VARCHAR(20),\n  target_id INTEGER,\n  operation_status VARCHAR(20),\n  success_probability DECIMAL(3,2),\n  resource_cost INTEGER,\n  risk_level INTEGER,\n  started_at TIMESTAMP,\n  result_data JSONB\n);\n\nCREATE TABLE intelligence_agents (\n  id UUID PRIMARY KEY,\n  owner_id INTEGER,\n  agent_name VARCHAR(100),\n  cover_identity VARCHAR(200),\n  specialization VARCHAR(50),\n  skill_level INTEGER,\n  reliability_score DECIMAL(3,2),\n  current_assignment UUID,\n  recruitment_cost INTEGER\n);\n```\n\n**Risk/Reward Systems:**\n- Detection risk increasing with operation complexity and duration\n- Diplomatic consequences for exposed espionage operations\n- Agent capture and interrogation scenarios with information compromise\n- Operation success yielding varying quality and quantity of intelligence\n\n**Counter-Intelligence Framework:**\n- Mole hunting operations to identify enemy agents\n- Disinformation campaigns to mislead enemy intelligence\n- Double agent recruitment and management\n- Security audit systems to identify vulnerabilities\n\n**API Endpoints:**\n- `POST /api/intel/operations` - Launch intelligence gathering operation\n- `GET /api/intel/operations` - List active and completed operations\n- `POST /api/intel/agents/recruit` - Recruit new intelligence agents\n- `PUT /api/intel/operations/:id/abort` - Abort active operation with consequences",
            "status": "pending",
            "testStrategy": "Operation success probability validation, agent skill progression testing, counter-intelligence effectiveness measurement. Risk/reward balance verification through simulation."
          },
          {
            "id": 4,
            "title": "Intelligence Market & Information Trading",
            "description": "Create information marketplace with brokers, dynamic pricing, information decay, and intelligence transaction systems.",
            "dependencies": [
              "46.3"
            ],
            "details": "**Intelligence Market Infrastructure:**\n- Information broker NPCs with different specializations and reliability\n- Market maker system ensuring liquidity for intelligence transactions\n- Auction system for high-value intelligence with bidding mechanics\n- Exclusive information agreements and non-compete contracts\n\n**Information Valuation System:**\n- Dynamic pricing based on relevance, accuracy, exclusivity, and demand\n- Time-decay mechanics reducing intelligence value over time\n- Market demand fluctuations affecting information categories\n- Quality rating system affecting price and buyer confidence\n\n**Transaction Framework:**\n```sql\nCREATE TABLE intelligence_transactions (\n  id UUID PRIMARY KEY,\n  seller_id INTEGER,\n  buyer_id INTEGER,\n  information_id UUID,\n  transaction_price INTEGER,\n  transaction_type VARCHAR(50),\n  broker_id INTEGER,\n  quality_rating INTEGER,\n  executed_at TIMESTAMP\n);\n\nCREATE TABLE information_brokers (\n  id UUID PRIMARY KEY,\n  broker_name VARCHAR(100),\n  specialization VARCHAR(50),\n  reputation_score DECIMAL(3,2),\n  commission_rate DECIMAL(4,3),\n  geographical_focus VARCHAR(100)\n);\n```\n\n**Market Mechanics:**\n- Information authenticity verification services\n- Insurance systems for information quality guarantees\n- Bulk intelligence packages and subscription services\n- Market manipulation detection and prevention systems\n\n**Information Categories for Trading:**\n- Military intelligence (troop movements, capabilities, plans)\n- Economic data (resource reserves, trade routes, market strategies)\n- Technological intelligence (R&D projects, patents, manufacturing processes)\n- Diplomatic information (treaty negotiations, alliance status)\n- Personal intelligence (individual wealth, connections, secrets)\n\n**API Endpoints:**\n- `GET /api/intel/market` - Browse available intelligence for purchase\n- `POST /api/intel/market/sell` - Offer intelligence for sale\n- `POST /api/intel/market/buy` - Purchase intelligence from market\n- `GET /api/intel/brokers` - List available information brokers\n- `POST /api/intel/market/auction` - Create auction for high-value intelligence",
            "status": "pending",
            "testStrategy": "Price calculation algorithm validation, information decay mechanics testing, transaction security verification. Market manipulation prevention testing with adversarial scenarios."
          },
          {
            "id": 5,
            "title": "Security Framework & Counter-Intelligence",
            "description": "Implement comprehensive security measures, threat detection, information leakage systems, and counter-intelligence operations.",
            "dependencies": [
              "46.3"
            ],
            "details": "**Security Measures Implementation:**\n- Multi-factor authentication for classified information access\n- Encryption systems for information storage and transmission\n- Secure communication channels with end-to-end encryption\n- Physical security simulation for facilities and document protection\n\n**Threat Detection Systems:**\n- Anomalous access pattern detection using machine learning\n- Communication interception attempts monitoring\n- Insider threat identification through behavior analysis\n- External penetration attempt detection and response\n\n**Information Leakage Simulation:**\n```sql\nCREATE TABLE security_incidents (\n  id UUID PRIMARY KEY,\n  incident_type VARCHAR(50),\n  affected_information UUID,\n  threat_actor VARCHAR(100),\n  detection_method VARCHAR(50),\n  severity_level INTEGER,\n  discovered_at TIMESTAMP,\n  resolution_status VARCHAR(20)\n);\n\nCREATE TABLE security_clearances (\n  id UUID PRIMARY KEY,\n  person_id INTEGER,\n  clearance_level VARCHAR(20),\n  granted_by INTEGER,\n  valid_until TIMESTAMP,\n  background_check_status VARCHAR(20)\n);\n```\n\n**Counter-Intelligence Operations:**\n- Active monitoring of known enemy agent networks\n- Honeypot operations to trap and identify enemy spies\n- Disinformation dissemination to confuse enemy intelligence\n- Asset protection protocols for high-value information\n\n**Insider Threat Management:**\n- Personnel reliability assessment and continuous monitoring\n- Access privilege escalation detection and prevention\n- Document access logging and suspicious pattern identification\n- Whistleblower protection and secure reporting channels\n\n**Security Audit Framework:**\n- Regular security assessment of information handling procedures\n- Penetration testing simulation to identify vulnerabilities\n- Security clearance review and renewal processes\n- Incident response procedures and damage assessment protocols\n\n**API Endpoints:**\n- `GET /api/intel/security/threats` - List detected security threats\n- `POST /api/intel/security/audit` - Initiate security audit\n- `GET /api/intel/security/clearances` - Manage security clearances\n- `POST /api/intel/security/incident` - Report security incident",
            "status": "pending",
            "testStrategy": "Threat detection accuracy testing, insider threat simulation, counter-intelligence operation effectiveness. Security audit compliance verification and incident response testing."
          },
          {
            "id": 6,
            "title": "Vector Memory Integration & AI Intelligence Analysis",
            "description": "Integrate espionage system with Vector Memory System for AI-enhanced intelligence analysis, semantic search, and automated threat detection.",
            "dependencies": [
              "46.4",
              "46.5"
            ],
            "details": "**AI-Enhanced Intelligence Analysis:**\n- Semantic search for intelligence pattern recognition across vast datasets\n- Automated classification of intercepted communications using Vector Memory\n- Correlation analysis identifying connections between disparate intelligence pieces\n- Predictive intelligence modeling using historical espionage data\n\n**Vector Memory Integration:**\n- Conversation capture for diplomatic communications and classified discussions\n- Memory-aware AI advisors providing intelligence operation recommendations\n- Context-aware responses considering classification levels and access permissions\n- Historical intelligence operation success pattern analysis\n\n**Advanced Analytics Framework:**\n```sql\nCREATE TABLE intelligence_analysis (\n  id UUID PRIMARY KEY,\n  analysis_type VARCHAR(50),\n  source_information_ids UUID[],\n  ai_confidence_score DECIMAL(3,2),\n  analysis_results JSONB,\n  analyst_id INTEGER,\n  analysis_timestamp TIMESTAMP\n);\n\nCREATE TABLE threat_assessments (\n  id UUID PRIMARY KEY,\n  threat_level INTEGER,\n  threat_source VARCHAR(100),\n  assessment_basis JSONB,\n  recommended_actions TEXT[],\n  assessment_confidence DECIMAL(3,2)\n);\n```\n\n**AI-Powered Features:**\n- Automatic intelligence prioritization based on strategic value\n- Cross-reference analysis identifying intelligence gaps\n- Operational security breach prediction using pattern analysis\n- Strategic recommendation generation for intelligence operations\n\n**Conversation Classification:**\n- Automatic classification of diplomatic conversations based on content\n- Real-time threat assessment from intercepted communications\n- Speaker identification and relationship mapping from conversations\n- Sentiment analysis for diplomatic intelligence assessment\n\n**Semantic Intelligence Search:**\n- Natural language queries across classified information databases\n- Similarity matching for intelligence pattern identification\n- Temporal correlation analysis for intelligence timeline reconstruction\n- Entity relationship extraction from intelligence documents\n\n**API Endpoints:**\n- `POST /api/intel/analyze` - Submit intelligence for AI analysis\n- `GET /api/intel/search/semantic` - Semantic search across intelligence\n- `POST /api/intel/classify/auto` - AI-assisted information classification\n- `GET /api/intel/threats/assessment` - AI-generated threat assessments",
            "status": "pending",
            "testStrategy": "AI analysis accuracy validation, semantic search precision testing, threat detection false positive/negative rates. Vector Memory integration performance testing with large intelligence datasets."
          },
          {
            "id": 7,
            "title": "Trade & Campaign System Integration",
            "description": "Integrate espionage system with existing trade and campaign systems, implementing corporate technology impacts and long-term intelligence operations.",
            "dependencies": [
              "46.2",
              "46.6"
            ],
            "details": "**Trade System Integration:**\n- Corporate technology bonuses affecting production efficiency and trade capabilities\n- Market intelligence providing competitive advantages in pricing and demand prediction\n- Industrial espionage disrupting competitor operations and market strategies\n- Resource allocation for espionage operations competing with trade investments\n\n**Campaign System Integration:**\n- Long-term intelligence operations spanning multiple campaign steps\n- Technology development affecting civilization capabilities over extended periods\n- Diplomatic relationship evolution based on espionage activities and information sharing\n- Cultural value changes affecting surveillance acceptance and espionage effectiveness\n\n**Economic Impact Systems:**\n```sql\nCREATE TABLE technology_impacts (\n  id UUID PRIMARY KEY,\n  technology_id UUID,\n  impact_type VARCHAR(50),\n  impact_magnitude DECIMAL(5,2),\n  affected_system VARCHAR(50),\n  effective_from TIMESTAMP\n);\n\nCREATE TABLE intelligence_campaigns (\n  id UUID PRIMARY KEY,\n  campaign_id INTEGER,\n  operation_type VARCHAR(50),\n  target_civilization INTEGER,\n  progress_percentage DECIMAL(5,2),\n  strategic_objectives JSONB\n);\n```\n\n**Corporate Technology Effects:**\n- Manufacturing efficiency improvements reducing production costs\n- Trade algorithm optimization increasing profit margins\n- Quality enhancement technologies improving product competitiveness\n- Resource extraction efficiency affecting supply chain costs\n\n**Long-term Intelligence Operations:**\n- Multi-phase operations requiring sustained resource commitment\n- Intelligence network development and maintenance across campaigns\n- Technology theft operations with multi-step execution plans\n- Diplomatic intelligence gathering for long-term strategic planning\n\n**Cultural Integration:**\n- Cultural values affecting citizen acceptance of surveillance programs\n- Government transparency requirements limiting classification capabilities\n- Social trust levels affecting insider threat vulnerability\n- International reputation impact from exposed espionage activities\n\n**Event Sourcing Integration:**\n- All espionage activities recorded in event sourcing system\n- Historical intelligence operation analysis and pattern recognition\n- Long-term consequences tracking for espionage decisions\n- Reproducible intelligence scenario testing and validation\n\n**API Endpoints:**\n- `GET /api/intel/impact/trade` - Technology impact on trade performance\n- `POST /api/intel/campaigns/create` - Create long-term intelligence campaign\n- `GET /api/intel/cultural/acceptance` - Cultural acceptance of surveillance\n- `PUT /api/intel/diplomatic/relations` - Update diplomatic status from intelligence",
            "status": "pending",
            "testStrategy": "Technology impact validation on trade performance, long-term campaign progression testing, cultural integration effects measurement. Event sourcing completeness verification for intelligence operations."
          },
          {
            "id": 8,
            "title": "UI Integration & Intelligence Dashboard",
            "description": "Create comprehensive intelligence dashboard integrating with Vector Memory admin interface, providing real-time espionage management and intelligence analysis visualization.",
            "dependencies": [
              "46.6",
              "46.7"
            ],
            "details": "**Intelligence Command Center:**\n- Real-time dashboard showing active intelligence operations and their status\n- Threat assessment visualization with security incident timeline\n- Corporate technology development tracking with competitive analysis\n- Intelligence market overview with pricing trends and transaction history\n\n**Enhanced Admin Interface:**\n- Integration with existing Vector Memory admin interface (Task 40.7 completed)\n- Intelligence-specific analytics and reporting capabilities\n- Espionage operation planning and approval workflows\n- Security incident management and response coordination\n\n**Visualization Components:**\n```typescript\n// Intelligence Dashboard Components\ninterface IntelligenceDashboard {\n  activeOperations: OperationStatus[];\n  threatAssessment: ThreatLevel;\n  marketIntelligence: MarketData[];\n  securityIncidents: SecurityIncident[];\n  networkHealth: NetworkStatus;\n}\n\ninterface OperationStatus {\n  id: string;\n  type: 'HUMINT' | 'SIGINT' | 'CORPORATE' | 'DIPLOMATIC';\n  progress: number;\n  riskLevel: number;\n  estimatedCompletion: Date;\n}\n```\n\n**Interactive Features:**\n- Drag-and-drop operation planning with resource allocation\n- Real-time notifications for completed operations and security alerts\n- Filterable and searchable intelligence asset database\n- Interactive network visualization showing spy connections and relationships\n\n**Intelligence Analysis Tools:**\n- Timeline reconstruction for complex intelligence operations\n- Relationship mapping between entities, information, and operations\n- Predictive modeling dashboard for operation success probability\n- Comparative analysis tools for technology and market intelligence\n\n**Security and Access Control:**\n- Role-based UI components showing only authorized information\n- Security clearance level indicators throughout the interface\n- Audit trail visualization for information access and classification changes\n- Emergency response procedures integrated into dashboard workflows\n\n**Mobile Responsiveness:**\n- Responsive design for intelligence monitoring on various devices\n- Critical alert system for immediate security incident notification\n- Simplified mobile interface for field operation management\n- Offline capability for sensitive operations in secure environments\n\n**API Integration:**\n- Real-time WebSocket connections for live operation status updates\n- RESTful API integration for all intelligence system interactions\n- Caching strategies for frequently accessed intelligence data\n- Progressive loading for large intelligence datasets and historical analysis",
            "status": "pending",
            "testStrategy": "UI component testing for intelligence dashboard functionality, accessibility compliance verification, responsive design testing. Real-time update performance testing with high-frequency intelligence operations."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-12T02:21:02.319Z",
      "updated": "2025-08-16T20:41:13.996438",
      "description": "Tasks for master context"
    }
  },
  "feature-live-ops": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Stage Mode Backend Services",
        "description": "Create backend services for Stage Mode including speaker roster management, moderator controls, and approval workflows.",
        "details": "Develop REST API endpoints for /stage with the following functionality:\n- GET /stage - Retrieve current stage status and speaker roster\n- POST /stage/request - Request to join stage (raise hand)\n- PUT /stage/approve/:userId - Approve user to join stage\n- PUT /stage/deny/:userId - Deny user's request to join stage\n- PUT /stage/mute/:userId - Mute/unmute user on stage\n\nImplement WebSocket events for real-time stage updates:\n- stage_update: when speaker roster changes\n- request_approved: when a user's request is approved\n- request_denied: when a user's request is denied\n\nEnsure all endpoints include proper authentication and authorization checks. Implement rate limiting to prevent abuse. Store stage state in a database with appropriate caching for performance.",
        "testStrategy": "Unit tests for each endpoint and WebSocket event. Integration tests for the complete stage workflow. Performance tests simulating 50 concurrent participants with response time measurements. Verify that GM summary median is less than 4.5s at 50 participants as specified in requirements.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and implement database schema for stage management",
            "description": "Create database models and schema for storing stage state, speaker roster, and request queue",
            "dependencies": [],
            "details": "Design database schema to store stage state (active/inactive), speaker roster (users currently on stage with their roles and mute status), and request queue (pending requests to join stage). Implement models with appropriate relationships and indexes for efficient querying. Include fields for timestamps, user metadata, and request status tracking.",
            "status": "pending",
            "testStrategy": "Unit tests for database models and relationships. Performance tests for common query patterns. Verify data integrity constraints and indexing effectiveness."
          },
          {
            "id": 2,
            "title": "Develop REST API endpoints for stage management",
            "description": "Implement the specified REST API endpoints for stage operations with authentication and rate limiting",
            "dependencies": [],
            "details": "Implement all required REST endpoints: GET /stage, POST /stage/request, PUT /stage/approve/:userId, PUT /stage/deny/:userId, and PUT /stage/mute/:userId. Add proper authentication middleware to verify user identity and authorization checks to ensure users have appropriate permissions for each action. Implement rate limiting to prevent abuse, with configurable thresholds for different endpoint types.",
            "status": "pending",
            "testStrategy": "Unit tests for each endpoint with various authentication scenarios. Integration tests for complete workflows. Security tests for authentication bypass attempts. Rate limit verification tests."
          },
          {
            "id": 3,
            "title": "Implement WebSocket events for real-time stage updates",
            "description": "Create WebSocket handlers for stage_update, request_approved, and request_denied events",
            "dependencies": [],
            "details": "Develop WebSocket event handlers that emit stage_update events when the speaker roster changes, request_approved events when a user's request is approved, and request_denied events when a user's request is denied. Implement authentication for WebSocket connections and ensure proper event payload formatting. Create mechanisms to trigger these events from the appropriate API endpoints.",
            "status": "pending",
            "testStrategy": "Unit tests for WebSocket event handlers. Integration tests with simulated clients to verify real-time updates. Latency tests to ensure timely delivery of events."
          },
          {
            "id": 4,
            "title": "Implement caching layer for stage state",
            "description": "Create a caching mechanism for stage state to improve performance under load",
            "dependencies": [],
            "details": "Design and implement a caching strategy for stage state data to reduce database load and improve response times. Use Redis or a similar in-memory cache to store frequently accessed data like current stage status and speaker roster. Implement cache invalidation strategies to ensure data consistency when stage state changes. Add configurable TTL values for different cache types.",
            "status": "pending",
            "testStrategy": "Performance tests comparing cached vs. non-cached responses. Cache hit ratio analysis. Consistency tests to verify cache invalidation works correctly. Load tests simulating concurrent access patterns."
          },
          {
            "id": 5,
            "title": "Create comprehensive testing suite and documentation",
            "description": "Develop unit, integration, and performance tests along with API documentation",
            "dependencies": [],
            "details": "Create a comprehensive test suite covering all endpoints and WebSocket events. Implement unit tests for individual components, integration tests for complete workflows, and performance tests simulating 50 concurrent participants. Document all API endpoints with request/response examples, authentication requirements, and error codes. Include WebSocket event documentation with payload schemas and triggering conditions.",
            "status": "pending",
            "testStrategy": "End-to-end testing of complete stage workflows. Performance testing under load conditions to verify response times meet requirements (GM summary median less than 4.5s at 50 participants). Documentation verification through peer review and automated schema validation."
          }
        ]
      },
      {
        "id": 2,
        "title": "Implement Fireteams Backend Services",
        "description": "Create backend services for Fireteams including CRUD operations for squads and team channel assignment.",
        "details": "Develop REST API endpoints for /fireteams with the following functionality:\n- GET /fireteams - List all fireteams\n- POST /fireteams - Create a new fireteam\n- GET /fireteams/:id - Get details of a specific fireteam\n- PUT /fireteams/:id - Update fireteam details\n- DELETE /fireteams/:id - Delete a fireteam\n- POST /fireteams/:id/members - Add members to a fireteam\n- DELETE /fireteams/:id/members/:userId - Remove a member from a fireteam\n- PUT /fireteams/:id/channel - Assign a voice channel to a fireteam\n\nImplement WebSocket events for real-time fireteam updates:\n- fireteam_created: when a new fireteam is created\n- fireteam_updated: when fireteam details change\n- fireteam_deleted: when a fireteam is deleted\n- member_added: when a member joins a fireteam\n- member_removed: when a member leaves a fireteam\n- channel_assigned: when a voice channel is assigned\n\nImplement action batching for efficient updates across fireteams. Ensure proper database schema design for scalability.",
        "testStrategy": "Unit tests for each endpoint and WebSocket event. Integration tests for complete fireteam workflows. Performance tests with 50 participants divided into multiple fireteams. Verify per-team voice stability under load conditions.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Database Schema for Fireteams",
            "description": "Create a scalable database schema to support fireteams functionality including team details, membership, and channel assignments.",
            "dependencies": [],
            "details": "Design database tables and relationships for fireteams, including: team metadata (name, description, status), member associations with roles, voice channel assignments, and activity timestamps. Implement indexes for efficient querying. Create database migration scripts. Document schema with ERD diagrams.",
            "status": "pending",
            "testStrategy": "Unit tests for database models and relationships. Performance tests with large datasets to verify query efficiency. Validation tests for data integrity constraints."
          },
          {
            "id": 2,
            "title": "Develop Core Fireteams REST API Endpoints",
            "description": "Implement the primary REST API endpoints for fireteam CRUD operations.",
            "dependencies": [
              "2.1"
            ],
            "details": "Implement the following endpoints with proper request validation, error handling, and response formatting: GET /fireteams (with pagination and filtering), POST /fireteams (with validation), GET /fireteams/:id, PUT /fireteams/:id, and DELETE /fireteams/:id. Include authentication middleware and permission checks for each endpoint.",
            "status": "pending",
            "testStrategy": "Unit tests for each endpoint covering success and error cases. Integration tests for complete CRUD workflows. API contract tests to ensure specification compliance."
          },
          {
            "id": 3,
            "title": "Implement Member Management API Endpoints",
            "description": "Create endpoints for adding and removing members from fireteams with proper permission handling.",
            "dependencies": [
              "2.1",
              "2.2"
            ],
            "details": "Implement POST /fireteams/:id/members endpoint with validation for member limits and duplicate prevention. Develop DELETE /fireteams/:id/members/:userId endpoint with proper permission checks. Add logic for handling member roles and permissions within teams. Implement validation for team size limits.",
            "status": "pending",
            "testStrategy": "Unit tests for member addition and removal. Permission tests to verify authorization rules. Edge case tests for team size limits and invalid member operations."
          },
          {
            "id": 4,
            "title": "Implement Voice Channel Assignment System",
            "description": "Create the API endpoint and backend logic for assigning voice channels to fireteams.",
            "dependencies": [
              "2.1",
              "2.2"
            ],
            "details": "Implement PUT /fireteams/:id/channel endpoint for assigning voice channels. Create logic for channel availability checking and conflict resolution. Develop channel release mechanism when fireteams are disbanded. Implement validation to prevent channel double-booking.",
            "status": "pending",
            "testStrategy": "Unit tests for channel assignment and validation. Integration tests with voice service. Conflict resolution tests to verify proper handling of channel assignment disputes."
          },
          {
            "id": 5,
            "title": "Implement WebSocket Events and Action Batching",
            "description": "Create WebSocket event system for real-time fireteam updates with efficient action batching.",
            "dependencies": [
              "2.1",
              "2.2",
              "2.3",
              "2.4"
            ],
            "details": "Implement WebSocket server for real-time events. Create event handlers for fireteam_created, fireteam_updated, fireteam_deleted, member_added, member_removed, and channel_assigned events. Develop action batching system to group similar updates for efficient processing. Implement client connection management and authentication for WebSockets.",
            "status": "pending",
            "testStrategy": "Unit tests for each WebSocket event type. Load tests to verify action batching efficiency. Integration tests with frontend to verify real-time updates. Performance tests with multiple concurrent clients."
          }
        ]
      },
      {
        "id": 3,
        "title": "Develop Stage Mode and Fireteams UI Components",
        "description": "Create UI components for Stage Mode and Fireteams including moderator controls, raise-hand functionality, and per-team voice indicators.",
        "details": "Implement the following UI components:\n\nStage Mode:\n- Moderator control panel with approve/deny/mute actions\n- Participant list with status indicators\n- Raise-hand button and request status for participants\n- Speaker roster display\n- Stage join/leave controls\n\nFireteams:\n- Fireteam creation and management interface\n- Team member list with roles\n- Voice channel assignment controls\n- Per-team voice activity indicators\n- Team switching interface\n\nEnsure all UI components are responsive and accessible. Implement real-time updates using WebSocket connections. Add visual feedback for actions and state changes.",
        "testStrategy": "Unit tests for individual UI components. Integration tests for component interactions. User acceptance testing with different roles (moderator, participant). Accessibility testing. Performance testing with 50 concurrent users to ensure UI remains responsive.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Stage Mode Moderator Controls",
            "description": "Create the moderator control panel with approve/deny/mute actions and participant list with status indicators",
            "dependencies": [],
            "details": "Develop a responsive moderator control panel that includes: 1) Approve/deny buttons for stage access requests, 2) Mute/unmute controls for individual participants, 3) Participant list showing current status (speaking, muted, waiting), 4) Real-time updates via WebSocket connections, 5) Visual feedback for action success/failure states",
            "status": "pending",
            "testStrategy": "Unit tests for individual control components. Integration tests for moderator action flows. Accessibility testing for all controls. Performance testing with 50+ participants in the list to ensure UI responsiveness."
          },
          {
            "id": 2,
            "title": "Develop Stage Mode Participant Interface",
            "description": "Implement raise-hand functionality, speaker roster display, and stage join/leave controls for participants",
            "dependencies": [
              "3.1"
            ],
            "details": "Create participant-facing UI components including: 1) Raise-hand button with visual feedback, 2) Request status indicator showing pending/approved/denied states, 3) Speaker roster showing current active speakers, 4) Stage join/leave controls with appropriate state transitions, 5) Real-time updates for all components",
            "status": "pending",
            "testStrategy": "Unit tests for each participant control. Integration tests for the complete participant workflow (request access, receive approval, join stage, speak, leave). Accessibility testing for all interactive elements."
          },
          {
            "id": 3,
            "title": "Create Fireteam Management Interface",
            "description": "Develop UI for fireteam creation, management, and team member list with roles",
            "dependencies": [],
            "details": "Build the fireteam management interface with: 1) Create new fireteam form with name/description fields, 2) Edit/delete controls for existing fireteams, 3) Team member list showing roles (leader, member), 4) Add/remove member functionality, 5) Role assignment controls, 6) Responsive design for all screen sizes",
            "status": "pending",
            "testStrategy": "Unit tests for fireteam CRUD operations. Integration tests for team creation and member management workflows. Accessibility testing for all form elements and controls."
          },
          {
            "id": 4,
            "title": "Implement Voice Channel Assignment UI",
            "description": "Create interface for voice channel assignment controls and per-team voice activity indicators",
            "dependencies": [
              "3.3"
            ],
            "details": "Develop voice-related UI components including: 1) Channel assignment dropdown/selector for each fireteam, 2) Visual voice activity indicators showing which team members are speaking, 3) Mute/unmute controls for team channels, 4) Volume controls for individual members and teams, 5) Real-time updates via WebSocket for voice activity",
            "status": "pending",
            "testStrategy": "Unit tests for channel assignment controls and voice indicators. Integration tests with mock voice data to verify indicator behavior. Performance testing with multiple simultaneous speakers to ensure UI remains responsive."
          },
          {
            "id": 5,
            "title": "Develop Team Switching Interface",
            "description": "Create UI for users to view available fireteams and switch between them",
            "dependencies": [
              "3.3",
              "3.4"
            ],
            "details": "Implement team switching functionality with: 1) List view of all available fireteams with key information, 2) Join/leave team buttons with appropriate permissions, 3) Current team indicator and status, 4) Team switching confirmation dialog, 5) Visual feedback for successful/failed team switches, 6) Real-time updates when team composition changes",
            "status": "pending",
            "testStrategy": "Unit tests for team listing and switching controls. Integration tests for the complete team switching workflow. User acceptance testing with multiple concurrent users switching teams. Verify proper state updates after team changes."
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement Daily Contracts System",
        "description": "Create a system for daily contracts including rotation, UI surfacing, and rewards distribution for cosmetics, QoL improvements, and alliance resources.",
        "details": "Develop the following components:\n\n1. Contract Definition System:\n- JSON schema for contract definitions\n- Contract types (completion, collection, achievement)\n- Reward types (cosmetics, QoL items, alliance resources)\n\n2. Contract Rotation Service:\n- Daily rotation logic with configurable timing\n- Contract selection algorithm to ensure variety\n- REST API for /live-ops/contracts\n\n3. Contract Progress Tracking:\n- Player progress storage and retrieval\n- Completion validation logic\n- Reward distribution system\n\n4. UI Components:\n- Contract display cards\n- Progress indicators\n- Reward previews\n- Completion celebration\n\nImplement a database schema for storing contract definitions, active contracts, and player progress. Create admin tools for contract management.",
        "testStrategy": "Unit tests for contract rotation logic and progress tracking. Integration tests for the complete contract lifecycle. Verification tests for rotation correctness. Load tests to ensure system handles peak user activity. Test reward distribution accuracy.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Contract Definition System",
            "description": "Create the JSON schema for contract definitions, implement contract types, and define reward types",
            "dependencies": [],
            "details": "Develop a JSON schema for contract definitions that includes fields for contract ID, title, description, type (completion, collection, achievement), requirements, rewards, and duration. Implement the three contract types with appropriate validation rules. Define reward types including cosmetics, QoL items, and alliance resources with proper metadata and distribution parameters.",
            "status": "pending",
            "testStrategy": "Unit tests for schema validation, contract type classification, and reward type definitions. Integration tests to verify contract definitions can be properly created, stored, and retrieved."
          },
          {
            "id": 2,
            "title": "Build Contract Rotation Service",
            "description": "Develop the daily rotation logic, contract selection algorithm, and REST API endpoints",
            "dependencies": [
              "4.1"
            ],
            "details": "Create a service that handles daily contract rotation with configurable timing parameters. Implement a selection algorithm that ensures variety in contract offerings and prevents repetition. Develop REST API endpoints for /live-ops/contracts with GET, POST, PUT, and DELETE operations. Include functionality for admin override of rotation schedule.",
            "status": "pending",
            "testStrategy": "Unit tests for rotation timing logic and selection algorithm. API tests for all endpoints. Integration tests to verify contract rotation occurs correctly at configured times. Load tests to ensure the service handles peak user requests."
          },
          {
            "id": 3,
            "title": "Develop Contract Progress Tracking",
            "description": "Create systems for player progress storage, completion validation, and reward distribution",
            "dependencies": [
              "4.1",
              "4.2"
            ],
            "details": "Implement database schema for storing player progress on active contracts. Create validation logic to verify contract completion based on player actions. Develop a reward distribution system that grants appropriate items upon contract completion. Include transaction handling to ensure rewards are properly delivered even during service interruptions.",
            "status": "pending",
            "testStrategy": "Unit tests for progress tracking and validation logic. Integration tests for the complete contract lifecycle from assignment to completion. Stress tests for concurrent completion events. Data integrity tests to verify progress is never lost."
          },
          {
            "id": 4,
            "title": "Create UI Components for Contracts",
            "description": "Design and implement UI elements for contract display, progress tracking, and rewards",
            "dependencies": [
              "4.1",
              "4.3"
            ],
            "details": "Develop contract display cards showing title, description, requirements, and rewards. Create progress indicators that update in real-time as players complete contract objectives. Implement reward previews with detailed item information. Design and build completion celebration animations and notifications. Ensure UI is responsive and accessible.",
            "status": "pending",
            "testStrategy": "UI component tests for proper rendering and state management. User experience testing for clarity and intuitiveness. Performance tests to ensure UI remains responsive during gameplay. Cross-platform compatibility testing."
          },
          {
            "id": 5,
            "title": "Implement Admin Tools and Database Schema",
            "description": "Create database schema for contracts system and develop admin tools for contract management",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "Design and implement comprehensive database schema for storing contract definitions, active contracts, and player progress. Create admin tools with CRUD operations for contract management, including contract creation, editing, activation/deactivation, and performance analytics. Implement monitoring dashboards for contract engagement metrics and reward distribution statistics.",
            "status": "pending",
            "testStrategy": "Database schema validation tests. Admin tool functionality tests for all CRUD operations. Security tests to ensure proper access controls. Performance tests for database queries under load conditions."
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement Weekly Anomaly System",
        "description": "Create a system for weekly anomalies including activation, teardown, and playlist integration with active mutators.",
        "details": "Develop the following components:\n\n1. Anomaly Definition System:\n- JSON schema for anomaly definitions\n- Mutator types and effects\n- Activation/deactivation rules\n\n2. Anomaly Scheduler Service:\n- Weekly rotation logic with configurable timing\n- Anomaly selection algorithm\n- REST API for /live-ops/anomalies\n\n3. Playlist Integration:\n- Playlist modification based on active anomaly\n- Mutator application to gameplay rules\n- State restoration on anomaly teardown\n\n4. UI Components:\n- Anomaly announcement and description\n- Active anomaly indicators\n- Countdown timers for activation/deactivation\n\nImplement database storage for anomaly definitions and active state. Create admin tools for anomaly management and emergency override.",
        "testStrategy": "Unit tests for anomaly rotation logic and playlist integration. Integration tests for the complete anomaly lifecycle. Verification tests for activation/teardown correctness. Test that anomaly properly applies rules and that teardown restores defaults as specified in requirements.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Anomaly Definition System",
            "description": "Create the JSON schema and core components for defining anomalies, including mutator types, effects, and activation/deactivation rules.",
            "dependencies": [],
            "details": "Develop a comprehensive JSON schema for anomaly definitions that includes fields for name, description, duration, mutator types, and effects. Implement the core logic for different mutator types (gameplay modifiers, visual effects, scoring changes) and their impact on game rules. Create a validation system for anomaly definitions and establish clear activation/deactivation rules including triggers, conditions, and cooldown periods.",
            "status": "pending",
            "testStrategy": "Unit tests for schema validation and mutator effect calculations. Integration tests to verify proper loading of anomaly definitions from database. Test edge cases for activation/deactivation rules under various game states."
          },
          {
            "id": 2,
            "title": "Build Anomaly Scheduler Service",
            "description": "Develop the service responsible for weekly rotation logic, anomaly selection, and exposing the REST API endpoints.",
            "dependencies": [
              "5.1"
            ],
            "details": "Implement a scheduler service that handles weekly rotation with configurable timing parameters. Create an anomaly selection algorithm that ensures variety and prevents repetition. Develop REST API endpoints for /live-ops/anomalies with GET, POST, PUT, and DELETE operations. Include authentication and authorization for admin operations. Implement notification system for upcoming and active anomalies.",
            "status": "pending",
            "testStrategy": "Unit tests for rotation logic and selection algorithms. API endpoint testing with mock requests. Integration tests for the complete scheduling lifecycle including timing accuracy. Test authorization controls for admin operations."
          },
          {
            "id": 3,
            "title": "Develop Playlist Integration System",
            "description": "Create the system that modifies playlists based on active anomalies, applies mutators to gameplay rules, and handles state restoration.",
            "dependencies": [
              "5.1",
              "5.2"
            ],
            "details": "Implement playlist modification logic that dynamically updates available game modes based on active anomalies. Develop the mutator application system that injects rule changes into gameplay sessions. Create state tracking to ensure proper restoration of default settings when anomalies end. Build conflict resolution for cases where multiple anomalies might affect the same gameplay elements.",
            "status": "pending",
            "testStrategy": "Unit tests for playlist modification and mutator application. Integration tests for the complete anomaly lifecycle including activation and teardown. Verification tests to ensure game state properly restores after anomaly conclusion."
          },
          {
            "id": 4,
            "title": "Create UI Components for Anomalies",
            "description": "Develop the user interface elements for anomaly announcements, active indicators, and countdown timers.",
            "dependencies": [
              "5.2",
              "5.3"
            ],
            "details": "Design and implement UI components for anomaly announcements including modal dialogs and notification banners. Create persistent indicators for active anomalies that display in appropriate game screens. Develop countdown timers for activation/deactivation that update in real-time. Implement visual feedback for how anomalies are affecting gameplay. Design UI elements to be responsive across different device types.",
            "status": "pending",
            "testStrategy": "UI component tests for proper rendering and responsiveness. User experience testing for clarity of anomaly information. Integration tests with backend services to verify timers and state indicators accurately reflect server state."
          },
          {
            "id": 5,
            "title": "Implement Database Storage and Admin Tools",
            "description": "Create database schemas for anomaly definitions and active state tracking, plus admin tools for management and emergency override.",
            "dependencies": [
              "5.1",
              "5.2"
            ],
            "details": "Design and implement database schemas for storing anomaly definitions, historical data, and active state information. Develop admin dashboard for creating, editing, and managing anomalies. Implement emergency override functionality for immediate activation or deactivation of anomalies. Create logging and audit trail for all anomaly-related actions. Build analytics tools to track player engagement with different anomaly types.",
            "status": "pending",
            "testStrategy": "Database schema validation tests. Admin tool functionality testing including emergency override procedures. Performance testing for database operations under load. Security testing for admin authentication and authorization controls."
          }
        ]
      },
      {
        "id": 6,
        "title": "Develop Recap Cards Generator",
        "description": "Create a system to automatically generate 3-5 recap beats with hero images, one-click sharing functionality, and seed codes for replay.",
        "details": "Implement the following components:\n\n1. Session Analysis Engine:\n- Identify key moments and significant events\n- Select 3-5 most interesting beats from session\n- Generate descriptive text for each beat\n\n2. Hero Image Generator:\n- Capture or render images for key moments\n- Apply visual styling and formatting\n- Optimize images for sharing\n\n3. Seed Code Generation:\n- Create deterministic seed codes for session replay\n- Compress session state into shareable format\n- Implement seed validation\n\n4. Sharing Integration:\n- One-click share to social platforms\n- Copy to clipboard functionality\n- QR code generation for mobile sharing\n\n5. REST API:\n- POST /recap/generate - Generate recap from session data\n- GET /recap/:id - Retrieve generated recap\n\nStore recap data in database with appropriate TTL. Implement caching for frequently accessed recaps.",
        "testStrategy": "Unit tests for beat selection algorithm and seed generation. Integration tests for the complete recap generation pipeline. Verification tests for recap correctness and seed determinism as specified in requirements. Performance testing for generation speed under various session complexities.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Session Analysis Engine",
            "description": "Develop a system to analyze session data, identify key moments, and select 3-5 most interesting beats with descriptive text.",
            "dependencies": [],
            "details": "Create algorithms to process session data and identify significant events based on player actions, achievements, and game state changes. Implement a scoring system to rank moments by interest level. Develop natural language generation for descriptive text that captures the essence of each moment. Include configuration options for different game modes and event types. Ensure the engine can process sessions of varying lengths efficiently.",
            "status": "pending",
            "testStrategy": "Unit tests for beat selection algorithm and scoring system. Integration tests with sample session data. Performance testing with sessions of varying complexity. Validation tests to ensure selected beats are truly significant and descriptive text is accurate."
          },
          {
            "id": 2,
            "title": "Build Hero Image Generator",
            "description": "Create a system to capture or render images for key moments, apply visual styling, and optimize for sharing.",
            "dependencies": [
              "6.1"
            ],
            "details": "Implement screenshot capture functionality at key moments identified by the Session Analysis Engine. Develop image processing pipeline with filters, overlays, and branding elements. Create templates for different recap card styles. Implement image optimization for web and social media sharing (resolution, file size, format). Support both real-time capture and post-session rendering options.",
            "status": "pending",
            "testStrategy": "Unit tests for image processing functions. Visual regression tests for styling consistency. Performance tests for image generation speed. Compatibility tests across different devices and platforms. File size and quality optimization verification."
          },
          {
            "id": 3,
            "title": "Develop Seed Code Generation System",
            "description": "Create a system to generate deterministic seed codes for session replay, compress session state, and implement validation.",
            "dependencies": [],
            "details": "Design a deterministic algorithm to generate unique seed codes from session data. Implement compression techniques to minimize seed code length while preserving essential replay information. Create encoding/decoding functions for converting between session state and seed codes. Develop validation mechanisms to verify seed code integrity. Implement error handling for invalid or corrupted seeds. Document the seed format specification for potential future extensions.",
            "status": "pending",
            "testStrategy": "Unit tests for encoding/decoding functions. Verification tests for determinism (same input always produces same seed). Compression ratio analysis. Validation tests with valid and invalid seeds. Performance testing for generation and validation speed."
          },
          {
            "id": 4,
            "title": "Implement Sharing Integration",
            "description": "Develop one-click sharing functionality for social platforms, clipboard copying, and QR code generation for mobile sharing.",
            "dependencies": [
              "6.2",
              "6.3"
            ],
            "details": "Integrate with social media APIs (Twitter, Facebook, Discord, etc.) for direct sharing. Implement copy-to-clipboard functionality for seed codes and recap links. Create QR code generation for mobile device sharing. Design sharing templates with preview images and text. Implement tracking for share analytics. Ensure shared content includes appropriate metadata for rich previews on social platforms.",
            "status": "pending",
            "testStrategy": "Integration tests with each social platform API. Cross-browser compatibility tests for clipboard functionality. Mobile device testing for QR code scanning. User acceptance testing for sharing workflow. Analytics verification to ensure tracking is accurate."
          },
          {
            "id": 5,
            "title": "Create REST API and Database Integration",
            "description": "Develop REST API endpoints for recap generation and retrieval, with database storage and caching implementation.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3",
              "6.4"
            ],
            "details": "Implement POST /recap/generate endpoint to accept session data and return generated recap. Create GET /recap/:id endpoint to retrieve previously generated recaps. Design database schema for storing recap data with appropriate TTL. Implement caching layer for frequently accessed recaps to improve performance. Add authentication and rate limiting to protect API endpoints. Create documentation for API usage including request/response formats and error handling.",
            "status": "pending",
            "testStrategy": "Unit tests for individual API endpoints. Load testing to ensure performance under high traffic. Database performance testing for write and read operations. Cache hit ratio analysis. Security testing for authentication and rate limiting. API documentation verification with example requests and responses."
          }
        ]
      },
      {
        "id": 7,
        "title": "Implement Cosmetics and Store System",
        "description": "Create a system for cosmetic entitlements and store UI with local SKUs, ensuring no impact on gameplay balance.",
        "details": "Develop the following components:\n\n1. Cosmetics Catalog:\n- Database schema for cosmetic items\n- Categories, rarity, and visual attributes\n- Preview rendering system\n\n2. Entitlements Service:\n- Player inventory management\n- Entitlement granting/revoking\n- REST API for /entitlements\n\n3. Store Backend:\n- SKU definitions and pricing\n- Rotation and featured items\n- Purchase validation\n- REST API for /store\n\n4. Store UI:\n- Browsable catalog with filtering\n- Item detail views with previews\n- Purchase flow\n- Inventory management\n\nEnsure all cosmetic items are purely visual with no gameplay advantages. Implement proper validation to prevent unauthorized access to entitlements.",
        "testStrategy": "Unit tests for entitlement management and store functionality. Integration tests for the complete purchase flow. Verification tests to ensure entitlement rendering works correctly. Test that cosmetics have no effect on PvP stats as specified in requirements. Security testing for entitlement validation.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop Cosmetics Catalog and Database Schema",
            "description": "Create a comprehensive database schema for cosmetic items with categories, rarity levels, and visual attributes, along with a preview rendering system.",
            "dependencies": [],
            "details": "Implement database tables and relationships for cosmetic items. Define schemas for categories (e.g., outfits, weapons, emotes), rarity levels (common, rare, epic, legendary), and visual attributes. Create a preview rendering system that allows players to see cosmetics before purchase. Ensure proper indexing for efficient queries. Document the schema design and API access patterns.",
            "status": "pending",
            "testStrategy": "Unit tests for database CRUD operations. Integration tests for the preview rendering system. Performance tests for catalog browsing with large numbers of items. Verify that preview rendering works correctly across different cosmetic types."
          },
          {
            "id": 2,
            "title": "Implement Entitlements Service",
            "description": "Build a service to manage player cosmetic inventories with APIs for granting, revoking, and querying entitlements.",
            "dependencies": [
              "7.1"
            ],
            "details": "Develop a RESTful API for /entitlements with endpoints for listing, granting, and revoking cosmetic items. Implement player inventory management with proper validation to prevent unauthorized access. Create database models for tracking ownership history. Ensure proper transaction handling for entitlement operations. Implement caching for frequently accessed inventory data.",
            "status": "pending",
            "testStrategy": "Unit tests for entitlement granting/revoking logic. Security tests to verify authorization controls. Performance tests for inventory queries. Integration tests with the cosmetics catalog to ensure proper item reference integrity."
          },
          {
            "id": 3,
            "title": "Create Store Backend System",
            "description": "Develop the store backend with SKU definitions, pricing, rotation mechanics, and purchase validation.",
            "dependencies": [
              "7.1",
              "7.2"
            ],
            "details": "Implement a store backend with SKU definitions and pricing structure. Create rotation logic for featured items and store sections. Develop purchase validation to prevent fraudulent transactions. Build a RESTful API for /store with endpoints for retrieving available items, featured content, and processing purchases. Implement analytics tracking for store interactions and purchase patterns.",
            "status": "pending",
            "testStrategy": "Unit tests for SKU management and pricing calculations. Integration tests for the complete purchase flow. Security tests for purchase validation. Performance tests for store loading under high traffic. Verify that rotation mechanics work correctly according to configured schedules."
          },
          {
            "id": 4,
            "title": "Design and Implement Store UI",
            "description": "Create a user-friendly store interface with browsable catalog, filtering options, item previews, and purchase flow.",
            "dependencies": [
              "7.3"
            ],
            "details": "Design and implement a browsable store UI with filtering capabilities by category, rarity, and price. Create detailed item view pages with 3D previews of cosmetics. Develop a streamlined purchase flow with confirmation dialogs and feedback. Build inventory management screens for players to view and manage owned items. Ensure responsive design for different screen sizes and platforms.",
            "status": "pending",
            "testStrategy": "UI component tests for store elements. User experience testing for the purchase flow. Cross-browser compatibility tests. A/B testing for different store layouts to optimize conversion. Verify that filtering and sorting options work correctly."
          },
          {
            "id": 5,
            "title": "Implement Validation and Integration Testing",
            "description": "Ensure all cosmetic items have no gameplay impact and integrate the store system with other game components.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.3",
              "7.4"
            ],
            "details": "Implement validation systems to ensure cosmetic items provide no gameplay advantages. Create integration points with other game systems like player profiles and the upcoming Season Pass (Task 8). Develop monitoring tools to track store performance and player engagement. Implement A/B testing framework for store promotions. Create documentation for the entire cosmetics and store system.",
            "status": "pending",
            "testStrategy": "End-to-end tests for the complete store and cosmetics system. Verification tests to confirm cosmetics have no impact on gameplay balance or stats. Integration tests with dependent systems. Load testing to ensure system stability during high-traffic periods like new cosmetic releases."
          }
        ]
      },
      {
        "id": 8,
        "title": "Implement Alliance Season Pass",
        "description": "Create a Season Pass system with cosmetic and QoL tracks, progression tracking, and prestige reset that preserves cosmetics.",
        "details": "Develop the following components:\n\n1. Season Pass Definition:\n- Tiered rewards structure\n- Free and premium tracks\n- Cosmetic and QoL items separation\n\n2. Progression System:\n- XP earning and tracking\n- Level advancement logic\n- Milestone achievements\n\n3. Reward Distribution:\n- Automatic reward granting on level-up\n- Claim UI and notifications\n- Entitlement integration\n\n4. Prestige System:\n- Reset mechanics that preserve cosmetics\n- Prestige benefits and indicators\n- Progress history tracking\n\n5. UI Components:\n- Season pass overview\n- Progress visualization\n- Reward previews\n- Purchase and upgrade options\n\nImplement database schema for season definitions, player progress, and reward status. Create admin tools for season management.",
        "testStrategy": "Unit tests for progression logic and reward distribution. Integration tests for the complete season lifecycle. Verification tests for pass progression as specified in requirements. Test prestige reset to ensure cosmetics are preserved while other elements reset properly.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Season Pass Data Model and Database Schema",
            "description": "Design and implement the database schema for season pass definitions, player progress tracking, and reward status management.",
            "dependencies": [],
            "details": "Create database models for: Season definitions (start/end dates, theme, tiers), Reward tracks (free/premium items at each level), Player progress (XP, current level, purchased status), and Reward status (claimed/unclaimed items). Implement data access layer with CRUD operations. Create admin tools for season configuration and management.",
            "status": "pending",
            "testStrategy": "Unit tests for data model integrity and CRUD operations. Integration tests for database transactions and constraints. Verify proper relationships between season definitions, player progress, and rewards."
          },
          {
            "id": 2,
            "title": "Develop Progression and XP System",
            "description": "Implement the core progression system including XP earning, level advancement logic, and milestone achievements.",
            "dependencies": [
              "8.1"
            ],
            "details": "Create XP calculation algorithms for various player activities. Implement level thresholds and advancement triggers. Design milestone achievement system with event listeners. Build progression tracking service with caching for performance. Develop API endpoints for querying player progress and XP history.",
            "status": "pending",
            "testStrategy": "Unit tests for XP calculations and level advancement logic. Integration tests for the complete progression flow. Performance tests to ensure system handles concurrent XP updates efficiently."
          },
          {
            "id": 3,
            "title": "Build Reward Distribution System",
            "description": "Create the system for automatic reward granting, claim processing, and entitlement integration.",
            "dependencies": [
              "8.1",
              "8.2"
            ],
            "details": "Implement automatic reward triggers on level-up events. Create claim processing service with idempotency guarantees. Develop entitlement integration for adding items to player inventory. Build notification system for new rewards. Implement reward history and status tracking.",
            "status": "pending",
            "testStrategy": "Unit tests for reward distribution logic and entitlement integration. Integration tests for the complete reward flow from earning to claiming. Verification tests to ensure proper reward delivery based on season pass level."
          },
          {
            "id": 4,
            "title": "Implement Prestige System",
            "description": "Develop the prestige reset mechanics that preserve cosmetic rewards while resetting progression.",
            "dependencies": [
              "8.2",
              "8.3"
            ],
            "details": "Create prestige reset logic that preserves cosmetic items but resets progression. Implement prestige benefits (e.g., badges, titles, special rewards). Design progress history tracking across multiple prestige cycles. Build prestige level indicators and UI hooks. Develop migration strategy for existing players entering prestige.",
            "status": "pending",
            "testStrategy": "Unit tests for prestige reset logic and cosmetic preservation. Integration tests for complete prestige cycle. Verification tests to confirm cosmetics are preserved while progression resets properly."
          },
          {
            "id": 5,
            "title": "Develop Season Pass UI Components",
            "description": "Create the user interface components for the season pass including progress visualization, reward previews, and purchase options.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.4"
            ],
            "details": "Design and implement season pass overview screen with tier visualization. Create progress bar and level indicators. Build reward preview cards with item details. Implement purchase and upgrade UI with payment integration. Develop claim buttons and notifications. Create prestige UI elements and indicators.",
            "status": "pending",
            "testStrategy": "UI component tests for rendering and interaction. Integration tests with backend services. Usability tests to ensure clear progression visualization and intuitive reward claiming. Cross-browser and responsive design testing."
          }
        ]
      },
      {
        "id": 9,
        "title": "Implement Cost Telemetry System",
        "description": "Create a telemetry system to track per-turn token counts, STT/TTS seconds, image requests, and generate session-level projections.",
        "details": "Develop the following components:\n\n1. Telemetry Collectors:\n- Token counter for LLM interactions\n- STT/TTS usage timer\n- Image request tracker\n- API call counter\n\n2. Aggregation Service:\n- Real-time metrics collection\n- Session-level aggregation\n- Cost projection algorithms\n\n3. Reporting API:\n- REST endpoints for cost metrics\n- Filtering and time range selection\n- Export functionality\n\n4. Admin Dashboard:\n- Cost visualization by session/user/feature\n- Trend analysis\n- Anomaly detection\n\nImplement efficient storage for high-volume telemetry data. Use time-series database for optimal query performance. Create alerting system for cost anomalies.",
        "testStrategy": "Unit tests for individual collectors and aggregation logic. Integration tests with mock services. Verification tests to ensure counters match provider logs within ±10% as specified in requirements. Performance testing under high load conditions.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Telemetry Collectors",
            "description": "Develop the core telemetry collectors for tracking token counts, STT/TTS usage, image requests, and API calls.",
            "dependencies": [],
            "details": "Create modular collectors that can be integrated at service boundaries to track: 1) Token counter for LLM interactions with input/output token separation, 2) STT/TTS usage timer with millisecond precision, 3) Image request tracker with size and type metadata, 4) API call counter with service categorization. Implement efficient buffering to minimize performance impact. Each collector should have standardized interfaces and configurable sampling rates.",
            "status": "pending",
            "testStrategy": "Unit tests for each collector type with mock services. Integration tests with controlled inputs to verify accuracy. Performance tests to ensure minimal overhead (<1% CPU increase). Comparison tests against provider logs to validate accuracy within ±10%."
          },
          {
            "id": 2,
            "title": "Develop Aggregation Service",
            "description": "Create a service to collect, aggregate, and project cost metrics in real-time and at session level.",
            "dependencies": [
              "9.1"
            ],
            "details": "Implement a scalable aggregation service that: 1) Collects metrics from all telemetry collectors in real-time, 2) Performs session-level aggregation with user and feature attribution, 3) Applies cost projection algorithms based on current pricing models, 4) Supports time-series analysis for trend detection. Use a time-series database (e.g., InfluxDB or TimescaleDB) for efficient storage and querying of high-volume telemetry data.",
            "status": "pending",
            "testStrategy": "Unit tests for aggregation logic and cost projections. Load tests with simulated high-volume telemetry data. Verification tests to ensure aggregated metrics match raw collector data. Performance tests for query response times under various data volumes."
          },
          {
            "id": 3,
            "title": "Build Reporting API",
            "description": "Develop REST endpoints for accessing cost metrics with filtering, time range selection, and export functionality.",
            "dependencies": [
              "9.2"
            ],
            "details": "Create a comprehensive API that provides: 1) REST endpoints for retrieving cost metrics at various granularities (session, user, feature), 2) Filtering capabilities by service type, time range, and user segments, 3) Export functionality in multiple formats (JSON, CSV, Excel), 4) Aggregation endpoints for summary statistics. Implement caching for frequently accessed reports and pagination for large result sets.",
            "status": "pending",
            "testStrategy": "Unit tests for each API endpoint. Integration tests for complex queries and export functionality. Performance tests for response times under load. Security tests to ensure proper access controls for cost data."
          },
          {
            "id": 4,
            "title": "Create Admin Dashboard",
            "description": "Develop a visual dashboard for cost visualization, trend analysis, and anomaly detection.",
            "dependencies": [
              "9.3"
            ],
            "details": "Build an interactive admin dashboard with: 1) Cost visualizations by session/user/feature with drill-down capabilities, 2) Trend analysis tools showing usage patterns over time, 3) Anomaly detection with configurable thresholds and alerts, 4) Projection tools for estimating future costs based on current usage. Use responsive design principles and efficient data visualization libraries to handle large datasets.",
            "status": "pending",
            "testStrategy": "Unit tests for dashboard components. Usability tests with admin personas. Performance tests for dashboard rendering with large datasets. Cross-browser compatibility tests. Verification that anomaly detection correctly identifies unusual patterns."
          },
          {
            "id": 5,
            "title": "Implement Alerting System",
            "description": "Create an alerting system for cost anomalies with configurable thresholds and notification channels.",
            "dependencies": [
              "9.2",
              "9.4"
            ],
            "details": "Develop an alerting system that: 1) Monitors cost metrics in real-time against configurable thresholds, 2) Detects unusual patterns or spikes in usage, 3) Sends notifications through multiple channels (email, Slack, SMS), 4) Provides alert management with acknowledgment and resolution tracking. Implement rate limiting to prevent alert storms and support for escalation policies.",
            "status": "pending",
            "testStrategy": "Unit tests for alert trigger logic. Integration tests with notification services. Simulation tests with artificial anomalies to verify detection. Verification tests for alert delivery timing and content. User acceptance testing for alert management workflow."
          }
        ]
      },
      {
        "id": 10,
        "title": "Implement Single Player Mode",
        "description": "Create solo session scaffolding with pause/resume hooks, companion agent runner, and solo DDA presets.",
        "details": "Develop the following components:\n\n1. Solo Session Manager:\n- Session initialization for single player\n- State persistence and retrieval\n- Pause/resume functionality\n\n2. Companion Agent System:\n- AI agent configuration for solo play\n- Agent behavior customization\n- Performance optimization for solo mode\n\n3. Dynamic Difficulty Adjustment (DDA):\n- Solo-specific DDA presets\n- Difficulty scaling based on player performance\n- Configuration interface\n\n4. UI Components:\n- Solo mode selection\n- Pause menu\n- Session controls\n- Companion settings\n\nImplement efficient state management for paused sessions. Optimize agent performance for single-player scenarios.",
        "testStrategy": "Unit tests for session management and pause/resume functionality. Integration tests for the complete solo experience. Run tests TC034-TC035 as specified in the PRD addenda. Performance testing for agent response times in solo mode.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Solo Session Manager",
            "description": "Create a session manager specifically for single player mode with initialization, state persistence, and pause/resume functionality.",
            "dependencies": [],
            "details": "Develop session initialization logic for single player mode. Implement state persistence and retrieval mechanisms to save and load game progress. Create robust pause/resume functionality that properly suspends and resumes all game systems. Ensure efficient state management for paused sessions with minimal memory overhead. Include session timeout handling and auto-save features.",
            "status": "pending",
            "testStrategy": "Write unit tests for session initialization, state persistence, and pause/resume functionality. Create integration tests to verify proper state management across game systems during pause/resume cycles. Measure memory usage during paused states to ensure efficiency."
          },
          {
            "id": 2,
            "title": "Develop Companion Agent System",
            "description": "Build an AI agent system optimized for solo play with customizable behaviors and performance optimizations.",
            "dependencies": [
              "10.1"
            ],
            "details": "Implement AI agent configuration specifically for solo play scenarios. Create a system for agent behavior customization allowing players to adjust companion behavior. Optimize agent performance for single-player mode by reducing computational overhead. Develop agent response prioritization based on player actions. Include fallback behaviors for edge cases.",
            "status": "pending",
            "testStrategy": "Create unit tests for agent configuration and behavior customization. Perform performance testing to ensure agents respond within acceptable timeframes. Test edge cases to verify fallback behaviors function correctly."
          },
          {
            "id": 3,
            "title": "Implement Solo-Specific DDA System",
            "description": "Create Dynamic Difficulty Adjustment presets and scaling mechanisms specifically for single player mode.",
            "dependencies": [
              "10.1"
            ],
            "details": "Develop solo-specific DDA presets with appropriate challenge levels. Implement difficulty scaling algorithms based on player performance metrics. Create a configuration interface for adjusting DDA parameters. Include real-time difficulty adjustments based on player success/failure rates. Develop persistence for player difficulty profiles across sessions.",
            "status": "pending",
            "testStrategy": "Write unit tests for difficulty scaling algorithms. Create integration tests to verify DDA responds appropriately to player performance. Test persistence of difficulty profiles across multiple game sessions."
          },
          {
            "id": 4,
            "title": "Create Single Player UI Components",
            "description": "Develop UI elements specific to single player mode including mode selection, pause menu, session controls, and companion settings.",
            "dependencies": [
              "10.1",
              "10.2"
            ],
            "details": "Design and implement solo mode selection UI in the main menu. Create a comprehensive pause menu with resume, settings, and exit options. Develop session control UI elements for managing game state. Build companion settings interface for adjusting AI behavior. Ensure all UI elements follow established design patterns and accessibility guidelines.",
            "status": "pending",
            "testStrategy": "Perform UI unit tests to verify component functionality. Conduct usability testing to ensure intuitive navigation. Test accessibility features to ensure compliance with guidelines. Verify UI state consistency during pause/resume cycles."
          },
          {
            "id": 5,
            "title": "Integrate and Optimize Single Player Systems",
            "description": "Connect all single player components and optimize overall performance for the solo experience.",
            "dependencies": [
              "10.1",
              "10.2",
              "10.3",
              "10.4"
            ],
            "details": "Integrate session manager, companion agent system, DDA, and UI components into a cohesive single player experience. Perform end-to-end testing of the complete solo mode workflow. Optimize resource usage for single player scenarios. Implement telemetry to track player engagement with solo features. Create documentation for the single player implementation.",
            "status": "pending",
            "testStrategy": "Run full integration tests for the complete solo experience. Execute tests TC034-TC035 as specified in the PRD addenda. Perform performance testing for agent response times in solo mode. Conduct end-to-end testing of the entire single player experience from launch to exit."
          }
        ]
      },
      {
        "id": 11,
        "title": "Implement Simulation System",
        "description": "Create a simulation system with start/step/stop functionality, snapshot export/import, and reconciliation features.",
        "details": "Develop the following components:\n\n1. Simulation Controller:\n- REST API for /simulation with start/step/stop\n- Simulation state management\n- Execution control flow\n\n2. Snapshot System:\n- State capture at beat boundaries\n- Export/import functionality\n- State hash generation for verification\n\n3. Deterministic Engine:\n- Seed-based randomization\n- Consistent execution ordering\n- Drift detection algorithms\n\n4. Reconciliation Service:\n- State comparison tools\n- Conflict resolution\n- Automatic correction strategies\n\n5. UI Components:\n- Simulation controls\n- State visualization\n- Snapshot management\n- Drift indicators\n\nImplement efficient serialization for state snapshots. Ensure deterministic execution across different environments.",
        "testStrategy": "Unit tests for simulation control and snapshot functionality. Integration tests for the complete simulation lifecycle. Run tests TC036-TC041 as specified in the PRD addenda. Verification tests for deterministic seeds, beat-boundary snapshots with state hash, and drift detection.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Simulation Controller",
            "description": "Develop the REST API for simulation control with start/step/stop functionality and state management",
            "dependencies": [],
            "details": "Create a RESTful API with endpoints for /simulation/start, /simulation/step, and /simulation/stop. Implement simulation state management including current state tracking, execution flow control, and proper error handling. Design the controller to maintain simulation integrity across API calls and implement proper authentication and authorization for simulation control.",
            "status": "pending",
            "testStrategy": "Write unit tests for each API endpoint. Test state transitions between start, step, and stop operations. Verify proper error handling for invalid state transitions. Create integration tests for complete simulation lifecycle."
          },
          {
            "id": 2,
            "title": "Build Snapshot System",
            "description": "Create functionality to capture, export, and import simulation state at beat boundaries",
            "dependencies": [
              "11.1"
            ],
            "details": "Implement state capture mechanism that triggers at beat boundaries. Develop efficient serialization/deserialization for state snapshots. Create export functionality to save snapshots to files or database. Implement import functionality to restore simulation from snapshots. Add state hash generation for verification of snapshot integrity.",
            "status": "pending",
            "testStrategy": "Test snapshot creation at beat boundaries. Verify export/import functionality preserves all state details. Test hash generation and verification. Ensure snapshots can be properly restored across different environments."
          },
          {
            "id": 3,
            "title": "Develop Deterministic Engine",
            "description": "Create a deterministic execution engine with seed-based randomization and consistent ordering",
            "dependencies": [
              "11.1"
            ],
            "details": "Implement seed-based randomization that produces consistent results across environments. Create execution ordering system that ensures operations occur in the same sequence regardless of timing or environment. Develop drift detection algorithms to identify when simulations diverge from expected state. Ensure all random elements use the seeded generator.",
            "status": "pending",
            "testStrategy": "Test that identical seeds produce identical simulation results. Verify execution ordering remains consistent across different environments. Test drift detection by introducing controlled variations and ensuring they're detected."
          },
          {
            "id": 4,
            "title": "Create Reconciliation Service",
            "description": "Implement tools for state comparison, conflict resolution, and automatic correction",
            "dependencies": [
              "11.2",
              "11.3"
            ],
            "details": "Develop state comparison tools that can identify differences between two simulation states. Create conflict resolution strategies for handling divergent states. Implement automatic correction mechanisms that can repair simulation drift when detected. Design logging system to track reconciliation actions for debugging purposes.",
            "status": "pending",
            "testStrategy": "Test state comparison with various types of differences. Verify conflict resolution correctly identifies and resolves issues. Test automatic correction strategies with simulated drift scenarios. Ensure reconciliation actions are properly logged."
          },
          {
            "id": 5,
            "title": "Implement UI Components",
            "description": "Create user interface elements for simulation control, visualization, and snapshot management",
            "dependencies": [
              "11.1",
              "11.2",
              "11.4"
            ],
            "details": "Design and implement UI controls for simulation start/step/stop. Create visualization components for current simulation state. Develop snapshot management interface for saving, loading, and comparing snapshots. Add drift indicators that visually highlight when simulations diverge from expected state. Ensure UI is responsive and provides clear feedback on simulation operations.",
            "status": "pending",
            "testStrategy": "Perform usability testing of simulation controls. Verify state visualization accurately represents simulation data. Test snapshot management UI for saving and loading snapshots. Ensure drift indicators clearly show when and where simulation divergence occurs."
          }
        ]
      },
      {
        "id": 12,
        "title": "Implement Performance Optimization for 50-Player Sessions",
        "description": "Optimize system performance to support 50 concurrent players with acceptable response times and stability.",
        "details": "Implement the following optimizations:\n\n1. Action Batching:\n- Group similar actions for efficient processing\n- Prioritize critical real-time updates\n- Optimize WebSocket message frequency\n\n2. Database Optimization:\n- Index tuning for common queries\n- Connection pooling configuration\n- Query optimization for high-volume operations\n\n3. Caching Strategy:\n- Implement multi-level caching\n- Cache invalidation policies\n- Distributed cache for session data\n\n4. Load Testing Framework:\n- Simulate 50-player sessions\n- Measure response times and resource usage\n- Identify and resolve bottlenecks\n\n5. Monitoring System:\n- Real-time performance metrics\n- Alerting for degraded performance\n- Diagnostic tools for issue resolution\n\nImplement horizontal scaling for key services. Optimize network communication patterns for reduced latency.",
        "testStrategy": "Load tests with simulated 50-player sessions. Performance profiling to identify bottlenecks. Verification that GM summary median is less than 4.5s at 50 participants as specified in requirements. Stability testing for voice communication across teams.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Action Batching System",
            "description": "Develop a system to group similar actions for efficient processing, prioritize critical real-time updates, and optimize WebSocket message frequency.",
            "dependencies": [],
            "details": "Create a batching mechanism that groups similar player actions to reduce processing overhead. Implement priority queues for critical real-time updates. Optimize WebSocket communication by reducing message frequency through intelligent bundling. Include configuration parameters for batch size and timing thresholds. Develop fallback mechanisms for high-priority actions that cannot be delayed.",
            "status": "pending",
            "testStrategy": "Measure message throughput with and without batching. Verify critical actions are processed with appropriate priority. Test with simulated high-frequency actions from 50 concurrent players."
          },
          {
            "id": 2,
            "title": "Optimize Database Performance",
            "description": "Tune database indexes for common queries, configure connection pooling, and optimize queries for high-volume operations.",
            "dependencies": [
              "12.1"
            ],
            "details": "Analyze query patterns and create appropriate indexes for frequently accessed data. Configure connection pooling parameters for optimal resource utilization. Rewrite high-volume queries to minimize execution time and resource consumption. Implement query caching where appropriate. Consider database sharding strategies for horizontal scaling of player data.",
            "status": "pending",
            "testStrategy": "Benchmark query performance before and after optimization. Test connection pool under simulated load of 50 concurrent players. Verify query execution plans are optimal for common operations."
          },
          {
            "id": 3,
            "title": "Implement Multi-level Caching Strategy",
            "description": "Design and implement a multi-level caching system with appropriate invalidation policies and distributed cache for session data.",
            "dependencies": [
              "12.2"
            ],
            "details": "Implement in-memory caching for frequently accessed data. Set up distributed cache using Redis or similar technology for session data. Define cache invalidation policies based on data update patterns. Create cache warming mechanisms for predictable data access. Implement cache hit/miss metrics for performance monitoring.",
            "status": "pending",
            "testStrategy": "Measure system performance with and without caching enabled. Test cache invalidation correctness under various update scenarios. Verify distributed cache consistency across multiple server instances."
          },
          {
            "id": 4,
            "title": "Develop Load Testing Framework",
            "description": "Create a framework to simulate 50-player sessions, measure response times and resource usage, and identify performance bottlenecks.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.3"
            ],
            "details": "Develop automated load testing scripts that simulate realistic player behavior. Implement metrics collection for response times, CPU/memory usage, and network throughput. Create visualization tools for performance data analysis. Design tests for specific scenarios like combat, inventory management, and social interactions. Include gradual scaling tests from 10 to 50 players to identify scaling issues.",
            "status": "pending",
            "testStrategy": "Run load tests with increasing player counts to identify scaling limits. Verify GM summary median is less than 4.5s at 50 participants. Test stability of voice communication across teams under load."
          },
          {
            "id": 5,
            "title": "Implement Performance Monitoring System",
            "description": "Set up real-time performance metrics, alerting for degraded performance, and diagnostic tools for issue resolution.",
            "dependencies": [
              "12.4"
            ],
            "details": "Integrate APM (Application Performance Monitoring) tools to track system performance in real-time. Configure alerting thresholds for key metrics like response time, error rates, and resource utilization. Develop custom dashboards for visualizing performance data. Implement logging enhancements for easier troubleshooting. Create automated reports for performance trends over time.",
            "status": "pending",
            "testStrategy": "Verify alerts trigger appropriately when performance degrades. Test diagnostic tools by introducing controlled performance issues. Confirm monitoring system can handle the additional load without significant performance impact."
          }
        ]
      },
      {
        "id": 13,
        "title": "Implement Voice/NL Interaction UX System",
        "description": "Develop a comprehensive voice and natural language interaction system with multi-speaker diarization, real-time speech-to-text, voice activity detection, and text-to-speech capabilities with multiple personas.",
        "details": "Implement the following components for the Voice/NL Interaction UX system:\n\n1. Multi-Speaker Diarization:\n   - Implement speaker identification and separation algorithms\n   - Create speaker embeddings for unique voice fingerprinting\n   - Develop real-time speaker tracking during conversations\n   - Store speaker profiles for consistent identification across sessions\n\n2. Real-Time Speech-to-Text (STT):\n   - Integrate a high-performance STT engine with low latency\n   - Implement Voice Activity Detection (VAD) for detecting speech segments\n   - Create barge-in functionality to allow interruptions during conversations\n   - Develop turn-taking mechanisms to manage conversation flow\n   - Implement hotword detection for \"Prime Minister\" activation\n\n3. Natural Language Command Processing:\n   - Create a command parser for live NL commands\n   - Implement specific command handlers for:\n     - \"Call emergency cabinet\" functionality\n     - \"Draft two-minute address\" generation\n     - \"Summarize last quarter P&L\" data retrieval and formatting\n   - Design an extensible framework for adding new commands\n\n4. Text-to-Speech (TTS) System:\n   - Implement multiple TTS personas with distinct voice characteristics\n   - Create tone adjustment capabilities (formal, casual, urgent, etc.)\n   - Support multiple languages and accents\n   - Develop a voice selection interface for users\n\n5. Integration Adapters:\n   - Create WebSocket-based real-time audio streaming\n   - Implement REST APIs for voice configuration and management\n   - Develop service connectors for third-party STT/TTS providers\n   - Build caching mechanisms for frequently used voice assets\n\n6. Demo UI and Endpoints:\n   - Create a demonstration interface for voice interaction testing\n   - Implement visualization tools for diarization and turn-taking\n   - Develop sample applications showcasing NL commands\n   - Create documentation and examples for developer integration\n\nTechnical considerations:\n- Optimize for low latency (< 200ms) for real-time interactions\n- Implement fallback mechanisms for network disruptions\n- Consider privacy implications and add user consent workflows\n- Design for accessibility and multilingual support\n- Implement token usage tracking for cost management",
        "testStrategy": "1. Unit Testing:\n   - Test each component (diarization, STT, command processing, TTS) in isolation\n   - Verify hotword detection accuracy with various accents and background noise\n   - Test command parser with different phrasings and variations\n   - Validate TTS output quality across different personas and tones\n\n2. Integration Testing:\n   - Test end-to-end voice interaction flows\n   - Verify correct speaker identification in multi-user scenarios\n   - Test barge-in functionality during ongoing speech\n   - Validate turn-taking mechanisms in group conversations\n   - Verify command execution accuracy and response time\n\n3. Performance Testing:\n   - Measure STT latency under various network conditions\n   - Test system performance with multiple concurrent speakers\n   - Benchmark TTS generation time for different personas\n   - Verify system stability during extended usage sessions\n\n4. User Acceptance Testing:\n   - Conduct tests with diverse speaker demographics\n   - Verify accuracy with different accents and speech patterns\n   - Test in environments with varying noise levels\n   - Validate accessibility features for users with speech impairments\n\n5. Specific Test Cases:\n   - Verify \"Prime Minister\" hotword detection with 95%+ accuracy\n   - Test emergency cabinet call functionality end-to-end\n   - Validate two-minute address generation for coherence and formatting\n   - Test P&L summary accuracy against source data\n   - Verify that voice interaction works correctly with 50 concurrent users\n\n6. Documentation Verification:\n   - Review API documentation for completeness\n   - Verify demo endpoints functionality\n   - Test developer integration examples",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Implement Player-to-People Communications (Speeches) System",
        "description": "Develop a system that parses natural language speeches into deterministic modifiers with caps, decay, and backfire effects, implements a cohort opinions model, and integrates with the tick pipeline.",
        "details": "Implement the following components for the Player-to-People Communications (Speeches) system:\n\n1. Speech Parser:\n   - Create a natural language processing module to analyze player speeches\n   - Implement bounded deterministic modifiers with configurable parameters:\n     - Maximum effect caps to prevent exploitation\n     - Temporal decay functions to model diminishing influence over time\n     - Backfire mechanics for poorly received or contradictory speeches\n   - Design a classification system for speech intent and emotional content\n   - Develop context-aware parsing that considers game state and history\n\n2. Cohort Opinions Model:\n   - Implement a multi-dimensional opinion matrix for different NPC cohorts\n   - Create demographic-based response variations to the same speech\n   - Model opinion spread and influence between related cohort groups\n   - Develop opinion persistence with appropriate state storage\n   - Implement opinion thresholds that trigger gameplay events\n\n3. Audit Logging System:\n   - Create comprehensive logging of all speech inputs and resulting modifiers\n   - Implement searchable history of player communications\n   - Design visualization tools for opinion shifts over time\n   - Store raw inputs alongside parsed interpretations for debugging\n\n4. HTML Demo Interface:\n   - Develop a simple web interface to demonstrate speech effects\n   - Create visual representations of opinion changes\n   - Implement real-time feedback on speech parsing\n   - Design interactive elements to test different speech approaches\n\n5. Tick Pipeline Integration:\n   - Connect speech effects to the main simulation tick system\n   - Ensure proper sequencing of opinion updates within the game loop\n   - Implement efficient state updates that minimize performance impact\n   - Design appropriate hooks for event triggers based on opinion thresholds\n\n6. Performance Considerations:\n   - Optimize NLP processing for minimal latency\n   - Implement batching for multiple speeches when appropriate\n   - Design efficient data structures for opinion storage and retrieval\n   - Create appropriate caching mechanisms for frequently accessed opinion data",
        "testStrategy": "1. Unit Testing:\n   - Test speech parser with various input types, lengths, and emotional content\n   - Verify modifier bounds are properly enforced with extreme inputs\n   - Test decay functions over multiple time periods\n   - Validate backfire mechanics trigger appropriately for contradictory inputs\n   - Verify cohort opinion model updates correctly based on inputs\n\n2. Integration Testing:\n   - Test end-to-end flow from speech input to opinion changes\n   - Verify proper integration with the tick pipeline\n   - Test multi-user scenarios with overlapping speeches\n   - Validate opinion spread mechanics between related cohorts\n   - Ensure audit logging captures all relevant data\n\n3. Performance Testing:\n   - Benchmark speech parsing performance under load\n   - Test system with concurrent speech processing\n   - Verify opinion model updates don't impact tick performance\n   - Measure memory usage during extended gameplay sessions\n\n4. User Acceptance Testing:\n   - Conduct playtests focusing on speech mechanics\n   - Gather feedback on perceived impact of speeches\n   - Test with various speech styles and approaches\n   - Verify HTML demo provides clear visualization of effects\n\n5. Specific Test Cases:\n   - TC-S01: Verify speech with positive sentiment increases relevant opinion metrics\n   - TC-S02: Confirm contradictory speeches trigger backfire mechanics\n   - TC-S03: Test opinion decay over multiple game sessions\n   - TC-S04: Validate opinion thresholds trigger appropriate game events\n   - TC-S05: Verify audit log contains searchable history of all speeches",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Implement Cabinet Voice Meetings System",
        "description": "Develop a cabinet voice meetings pipeline that processes multi-speaker conversations with diarization, transcription, AI natural language summarization, and validated bounded modifiers for coordination, readiness, alignment, and messaging coherence.",
        "details": "Implement the following components for the Cabinet Voice Meetings System:\n\n1. Voice Meeting Pipeline:\n   - Integrate with the existing Voice/NL Interaction UX System for multi-speaker diarization\n   - Implement real-time transcription with speaker identification\n   - Create a deterministic hashing mechanism for canonical transcripts to ensure integrity and non-repudiation\n   - Develop WebSocket indicators for live roster tracking and participant status\n\n2. AI Natural Language Summarization:\n   - Design and implement an AI model to analyze meeting transcripts\n   - Extract key discussion points, decisions, and action items\n   - Generate concise, structured summaries with categorized content\n   - Implement caching mechanisms for efficient retrieval of summaries\n\n3. Validated Bounded Modifiers System:\n   - Create a framework for extracting and quantifying cabinet meeting outcomes:\n     - Coordination: Measure of how well cabinet members are working together\n     - Readiness: Assessment of preparedness for upcoming challenges\n     - Alignment: Degree of agreement on strategic direction\n     - Messaging Coherence: Consistency of communication strategy\n   - Implement validation rules to ensure modifiers remain within realistic bounds\n   - Design decay functions for modifier effects over time\n   - Create feedback mechanisms to adjust modifiers based on subsequent meetings\n\n4. Integration with Simulation System:\n   - Connect meeting outcomes to the simulation state\n   - Apply validated modifiers to relevant game systems\n   - Ensure deterministic application of meeting effects\n   - Implement snapshot compatibility for meeting state\n\n5. User Interface Components:\n   - Design meeting scheduling and management interface\n   - Create visualization for live meeting status and participant roster\n   - Develop dashboard for historical meetings and their outcomes\n   - Implement notification system for scheduled meetings",
        "testStrategy": "1. Unit Testing:\n   - Test diarization accuracy with multiple speakers in various acoustic environments\n   - Verify transcript hashing produces consistent results for identical inputs\n   - Validate summarization quality against human-generated summaries\n   - Test bounded modifier extraction with various meeting scenarios\n   - Verify WebSocket indicators correctly reflect participant status\n\n2. Integration Testing:\n   - Test end-to-end pipeline from voice input to modifier application\n   - Verify integration with the simulation system\n   - Test snapshot export/import with meeting data\n   - Validate that meeting effects properly influence game state\n\n3. Performance Testing:\n   - Measure transcription latency with multiple concurrent speakers\n   - Test system performance with cabinet meetings of various durations\n   - Verify summarization processing time meets requirements\n   - Benchmark WebSocket performance with full participant roster\n\n4. User Acceptance Testing:\n   - Conduct simulated cabinet meetings with test users\n   - Gather feedback on summary quality and accuracy\n   - Verify that modifier effects align with meeting content\n   - Test usability of meeting scheduling and management interface\n\n5. Regression Testing:\n   - Ensure voice meeting functionality doesn't interfere with other voice interactions\n   - Verify that modifier application doesn't disrupt simulation stability\n   - Test compatibility with existing player-to-people communications system",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Implement Government Archetypes and Cabinet HR System",
        "description": "Develop a system that models different government archetypes (democracy, technocracy, corporate, federation, autocracy) as constitutional state machines, with cabinet roles having personality traits that affect governance and a personnel management system for appointments and scandals.",
        "details": "Implement the following components for the Government Archetypes and Cabinet HR System:\n\n1. Constitutional State Machines:\n   - Design and implement state machine models for each government archetype:\n     - Democracy: Electoral cycles, approval ratings, parliamentary procedures\n     - Technocracy: Merit-based advancement, expertise weighting, efficiency metrics\n     - Corporate: Shareholder value, executive authority, profit-driven decision making\n     - Federation: Distributed authority, regional autonomy, consensus mechanisms\n     - Autocracy: Centralized power, loyalty systems, succession planning\n   - Create transition rules between government types based on stability metrics, popular support, and crisis events\n   - Implement constitutional constraints that limit or enable specific actions based on government type\n   - Design event handlers for constitutional crises and reform opportunities\n\n2. Cabinet Role System:\n   - Define a comprehensive set of cabinet positions with:\n     - Core responsibilities and domain influence\n     - Power dynamics and reporting relationships\n     - Archetype-specific variations (e.g., Ministers vs Directors vs Secretaries)\n   - Implement personality trait modeling for cabinet members:\n     - Primary traits: Integrity (resistance to corruption) and Ambition (proactivity/risk-taking)\n     - Secondary traits: Competence, Loyalty, Public Appeal, Factional Alignment\n     - Hidden traits: Corruptibility, Blackmail Vulnerability, Scandal Risk\n   - Create interaction patterns between cabinet members based on personality compatibility\n\n3. Cabinet HR Management:\n   - Appointment system with:\n     - Candidate generation based on government type and player network\n     - Vetting process with incomplete information (hidden traits)\n     - Confirmation/approval mechanics based on government type\n   - Personnel management features:\n     - Performance evaluation metrics tied to domain outcomes\n     - Loyalty and satisfaction modeling\n     - Relationship development between cabinet members\n   - Crisis management:\n     - Scandal generation system with probability tied to hidden traits\n     - Leak mechanics with information propagation models\n     - Media response options and public opinion impact\n   - Cabinet reshuffling tools:\n     - Impact analysis on government stability\n     - Factional balance considerations\n     - Transition costs and institutional memory modeling\n\n4. System Effects and Constraints:\n   - Implement bounded systemic effects for all cabinet actions:\n     - Domain-specific influence caps\n     - Cross-domain interference patterns\n     - Temporal decay of influence\n   - Create feedback loops between:\n     - Cabinet performance and government stability\n     - Personnel decisions and factional support\n     - Scandals and constitutional reform pressure\n   - Design risk assessment tools for player decision support\n\n5. Integration Points:\n   - Connect with Task 15's Cabinet Voice Meetings for policy formation\n   - Interface with Task 14's Communications System for public messaging\n   - Utilize Task 13's Voice/NL system for cabinet member interactions\n   - Ensure compatibility with Task 11's Simulation System for state tracking",
        "testStrategy": "1. Unit Testing:\n   - Test each government archetype state machine for correct transitions and constraints\n   - Verify personality trait generation and interaction models produce realistic outcomes\n   - Test appointment, firing, and reshuffling mechanics for proper systemic effects\n   - Validate scandal and leak generation systems for appropriate probability distributions\n   - Verify bounded effects are properly enforced across all cabinet actions\n\n2. Integration Testing:\n   - Test integration with Cabinet Voice Meetings (Task 15) for proper policy formation\n   - Verify compatibility with Communications System (Task 14) for public messaging\n   - Test voice interactions with cabinet members using Voice/NL system (Task 13)\n   - Validate state persistence and restoration through the Simulation System (Task 11)\n   - Test performance under 50-player load conditions (Task 12)\n\n3. Scenario Testing:\n   - Run complete government lifecycle scenarios from formation to dissolution\n   - Test cabinet crisis scenarios with cascading effects\n   - Verify transition between government types maintains appropriate state\n   - Test extreme scenarios (full cabinet resignation, constitutional crisis)\n   - Validate long-term stability metrics across multiple game sessions\n\n4. Balance Testing:\n   - Verify no single government archetype is inherently superior\n   - Test that personality traits create meaningful trade-offs\n   - Validate that scandal risk scales appropriately with cabinet member power\n   - Ensure reshuffling has appropriate costs and benefits\n   - Test that bounded effects prevent exploitation while allowing meaningful player agency\n\n5. Acceptance Testing:\n   - Verify all requirements from R-063 are implemented correctly\n   - Test usability of cabinet management interfaces\n   - Validate that government archetypes create distinctly different gameplay experiences\n   - Ensure cabinet HR decisions feel consequential but not overwhelming",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "Implement Media & Press Systems",
        "description": "Develop a system that models press freedom and state media influence, parses press briefings to create bounded effects mediated by freedom/reputation, and implements leak/backfire mechanics when claims contradict KPIs.",
        "details": "Implement the following components for the Media & Press Systems:\n\n1. Press Freedom and State Media Model:\n   - Create a numerical model for press_freedom (0-100 scale) that reflects the independence of media\n   - Implement state_media_influence (0-100 scale) to represent government control over media narratives\n   - Design dynamic modifiers that affect these values based on player actions and government type\n   - Develop formulas for how these values interact with message propagation and public opinion\n\n2. Press Briefing Parser:\n   - Create an NLP module to analyze player-generated press briefings\n   - Extract key claims, promises, and policy statements\n   - Implement bounded effect generators with the following characteristics:\n     - Effects scaled by press_freedom and government reputation\n     - Diminishing returns for repeated messaging\n     - Credibility tracking for consistent/inconsistent messaging\n   - Design a classification system for briefing tone and content categories\n\n3. Leak and Backfire Mechanics:\n   - Implement a comparison system between press briefing claims and actual KPIs\n   - Create probability curves for leaks based on discrepancy magnitude and press_freedom\n   - Design backfire effects that damage government credibility when contradictions are exposed\n   - Develop a \"press memory\" system that tracks historical claims for future reference\n\n4. Press Briefing API:\n   - Create a REST endpoint at /press/briefings for submitting and retrieving briefings\n   - Implement authentication and authorization for press secretary role\n   - Design response schemas that include effect predictions and historical context\n   - Add support for scheduling future briefings and embargo periods\n\n5. Press Briefing Demo:\n   - Create a sample UI for press briefing submission and monitoring\n   - Implement visualizations for press freedom, media influence, and briefing effects\n   - Design a dashboard showing historical briefings and their measured impacts\n   - Include a \"press reaction\" simulator for testing briefing effectiveness\n\n6. Integration with Existing Systems:\n   - Connect with the Cabinet Voice Meetings System for coordinated messaging\n   - Integrate with the Player-to-People Communications System to ensure consistent narrative\n   - Link to the Government Archetypes system to reflect constitutional constraints on media\n   - Utilize the Simulation System for deterministic outcomes and state tracking",
        "testStrategy": "1. Unit Testing:\n   - Test press_freedom and state_media_influence models with various inputs and government types\n   - Verify press briefing parser correctly extracts claims and generates appropriate bounded effects\n   - Test leak probability calculations against expected outcomes for different scenarios\n   - Validate backfire mechanics trigger appropriately when claims contradict KPIs\n   - Verify REST API endpoints for correct authentication, authorization, and data handling\n\n2. Integration Testing:\n   - Test integration with Cabinet Voice Meetings System for message consistency\n   - Verify coordination with Player-to-People Communications System\n   - Test how different government archetypes affect press freedom and media influence\n   - Validate that the simulation system correctly captures and restores media state\n\n3. Scenario Testing:\n   - Create test scenarios with varying levels of press freedom and state control\n   - Test the full lifecycle of press briefings from creation to public opinion effects\n   - Simulate contradictory claims and verify appropriate leak and backfire mechanics\n   - Test long-term effects of consistent vs. inconsistent messaging strategies\n\n4. Performance Testing:\n   - Verify press briefing parsing performance under load\n   - Test system stability with multiple concurrent briefings\n   - Measure response times for the press briefing API endpoints\n\n5. Acceptance Testing:\n   - Verify the press briefing demo correctly visualizes all relevant metrics\n   - Test that effects on public opinion align with design specifications\n   - Validate that the system produces realistic outcomes based on real-world media dynamics",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 18,
        "title": "Implement NPC Agent System with Goal-Driven Behavior",
        "description": "Develop a multi-agent system for NPCs representing media outlets, opposition parties, lobbies, think tanks, and foreign leaders with autonomous goal-driven behavior, tool usage capabilities, and interaction through a negotiation/treaty domain-specific language.",
        "details": "Implement the following components for the NPC Agent System:\n\n1. Agent Architecture:\n   - Design a flexible agent architecture with the following components:\n     - Belief system: Internal representation of world state and other agents\n     - Goal framework: Hierarchical goal structure with priorities and satisfaction conditions\n     - Planning module: Ability to formulate plans to achieve goals\n     - Action selection: Decision-making process for choosing optimal actions\n     - Memory system: Short and long-term memory for experiences and knowledge\n   - Implement different agent archetypes with specialized behaviors:\n     - Media outlets: Information dissemination, audience growth, credibility management\n     - Opposition parties: Power acquisition, policy influence, coalition building\n     - Lobbies: Policy influence, resource accumulation, relationship management\n     - Think tanks: Knowledge production, influence on discourse, funding acquisition\n     - Foreign leaders: Diplomatic relations, resource competition, internal stability\n\n2. Tool Usage Framework:\n   - Develop a tool abstraction layer allowing agents to:\n     - Discover available tools through capability inspection\n     - Select appropriate tools based on goals and context\n     - Execute tools with proper parameters\n     - Evaluate tool effectiveness and learn from outcomes\n   - Implement domain-specific tools for each agent type:\n     - Media: Article publication, investigation, interview, fact-checking\n     - Opposition: Rally organization, policy proposal, coalition negotiation\n     - Lobbies: Campaign funding, expert testimony, regulatory comment\n     - Think tanks: Research publication, policy brief, expert panel\n     - Foreign leaders: Diplomatic communiqué, trade negotiation, alliance formation\n\n3. Negotiation/Treaty Domain-Specific Language:\n   - Design a DSL for structured commitments with:\n     - Natural language to formal commitment translation\n     - Commitment types: trade, alliance, non-aggression, information sharing\n     - Temporal conditions: duration, renewal terms, phase-in periods\n     - Enforcement mechanisms: penalties, verification procedures, arbitration\n     - Escape clauses and conditional obligations\n   - Implement a parser to convert natural language proposals to structured commitments\n   - Create a commitment execution engine to monitor and enforce agreements\n   - Develop reputation and trust systems affected by commitment adherence\n\n4. Rumor and Propaganda Network:\n   - Implement an information diffusion model with:\n     - Source credibility ratings that evolve based on accuracy history\n     - Information types: facts, opinions, rumors, propaganda\n     - Propagation mechanics based on network topology and agent relationships\n     - Fact-checking cycles with variable latency and effectiveness\n   - Create information attribution and provenance tracking\n   - Develop audience belief models influenced by:\n     - Prior beliefs and confirmation bias\n     - Source credibility and repetition effects\n     - Emotional resonance and narrative coherence\n     - Social proof and authority signals\n\n5. Agent Interaction System:\n   - Design protocols for inter-agent communication:\n     - Formal diplomatic channels\n     - Public statements and responses\n     - Back-channel negotiations\n     - Information sharing and intelligence gathering\n   - Implement coalition formation mechanics with:\n     - Interest alignment calculation\n     - Power dynamics and hierarchy\n     - Resource sharing agreements\n     - Joint action coordination\n\n6. Integration with Existing Systems:\n   - Connect to the Media & Press Systems (Task 17) for information dissemination\n   - Interface with Government Archetypes (Task 16) for political interactions\n   - Utilize Voice/NL Interaction (Task 13) for agent communication\n   - Integrate with Player-to-People Communications (Task 14) for response generation\n   - Implement hooks into the game's tick system for autonomous agent actions",
        "testStrategy": "1. Unit Testing:\n   - Test agent belief system updates with various information inputs\n   - Verify goal prioritization and satisfaction conditions function correctly\n   - Test planning module generates valid action sequences for different goals\n   - Validate tool selection logic chooses appropriate tools for given contexts\n   - Test DSL parser with various negotiation statements and verify correct structured output\n   - Verify commitment enforcement triggers appropriate penalties when conditions are violated\n   - Test information diffusion model with different network topologies\n   - Validate fact-checking system correctly identifies true and false information\n\n2. Integration Testing:\n   - Test agent interactions with the Media & Press Systems\n   - Verify proper integration with Government Archetypes system\n   - Test coalition formation between multiple agent types\n   - Validate information flow between agents and player systems\n   - Test treaty negotiation and enforcement across multiple game ticks\n   - Verify rumor propagation and fact-checking cycles across the agent network\n\n3. Scenario Testing:\n   - Create test scenarios for each agent type pursuing their primary goals\n   - Test complex multi-agent scenarios with competing and aligned interests\n   - Validate diplomatic crisis scenarios with treaty negotiations\n   - Test media campaign scenarios with rumor and fact-checking cycles\n   - Verify lobby influence campaigns on government policy\n   - Test foreign leader response to player diplomatic initiatives\n\n4. Performance Testing:\n   - Benchmark agent decision-making performance with varying numbers of agents\n   - Test system scalability with up to 100 active NPC agents\n   - Measure memory usage during complex multi-agent negotiations\n   - Profile CPU usage during information propagation across large networks\n   - Test system performance during simultaneous agent actions\n\n5. User Experience Testing:\n   - Evaluate perceived intelligence of agent behaviors through playtesting\n   - Test readability and understandability of treaty DSL outputs\n   - Verify player ability to track information sources and credibility\n   - Validate that agent actions create meaningful gameplay challenges\n   - Test player ability to influence agent behavior through various mechanisms",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 19,
        "title": "Implement Explainability System for Causal Chains",
        "description": "Develop endpoints to explain causal chains for KPI or price changes with natural language narratives and numeric contributions, supporting counterfactual re-simulation capabilities.",
        "details": "Implement the following components for the Explainability System:\n\n1. Causal Chain Analyzer:\n   - Create a graph-based representation of cause-effect relationships between system variables\n   - Implement traversal algorithms to identify paths between input changes and output effects\n   - Develop attribution models to quantify the contribution of each factor in the chain\n   - Support both forward analysis (what effects will this change have) and backward analysis (what caused this outcome)\n\n2. Natural Language Generation:\n   - Design templates for converting causal chains into coherent narratives\n   - Implement context-aware explanation generation with appropriate technical depth\n   - Support different explanation styles based on user role and expertise level\n   - Include confidence levels and uncertainty indicators in explanations\n\n3. Counterfactual Re-simulation Engine:\n   - Create an API for \"what-if\" scenario generation by removing or modifying causal factors\n   - Implement efficient delta-based re-computation that only recalculates affected portions of the simulation\n   - Develop comparison visualizations between original and counterfactual scenarios\n   - Support multiple simultaneous counterfactual scenarios for comparison\n\n4. REST API Endpoints:\n   - `/api/v1/explain/kpi/{kpi_id}` - Generate explanations for changes in specific KPIs\n   - `/api/v1/explain/price/{item_id}` - Generate explanations for price fluctuations\n   - `/api/v1/explain/counterfactual` - Run and retrieve results from counterfactual simulations\n   - Include query parameters for time ranges, detail levels, and format options\n\n5. UI Demonstration Components:\n   - Implement interactive causal chain visualization with node-link diagrams\n   - Create tabular views showing factor contributions with sortable columns\n   - Design narrative panels for textual explanations with expandable details\n   - Develop controls for creating and comparing counterfactual scenarios\n\n6. Integration with Existing Systems:\n   - Connect to the Simulation System (Task 11) for state access and counterfactual execution\n   - Leverage Government Archetypes (Task 16) for context-aware explanations\n   - Utilize NPC Agent System (Task 18) data for agent-based explanations when relevant",
        "testStrategy": "1. Unit Testing:\n   - Test causal chain identification with known input-output relationships\n   - Verify attribution calculations produce correct contribution percentages\n   - Test natural language generation for grammatical correctness and factual accuracy\n   - Validate counterfactual engine produces consistent results for identical inputs\n\n2. Integration Testing:\n   - Verify correct integration with the Simulation System for state access\n   - Test end-to-end flow from user query to explanation generation\n   - Validate counterfactual scenarios correctly modify simulation state\n   - Test performance under load with multiple simultaneous explanation requests\n\n3. Acceptance Testing:\n   - Verify explanations are understandable and accurate for domain experts\n   - Test with real-world scenarios from historical simulation data\n   - Validate that removing factors in counterfactual scenarios produces expected changes\n   - Ensure UI components render explanations correctly across different devices\n\n4. Specific Test Cases:\n   - TC-E01: Verify explanation of inflation rate changes identifies monetary policy factors\n   - TC-E02: Test counterfactual removal of a major policy decision shows correct alternative outcomes\n   - TC-E03: Validate that narrative explanations correctly describe complex multi-step causal chains\n   - TC-E04: Ensure attribution percentages sum to 100% for all explanation requests\n   - TC-E05: Test performance - explanation generation should complete in under 3 seconds for standard queries",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 20,
        "title": "Implement NL Input Canonicalization and Safety Pipeline",
        "description": "Implement a deterministic pipeline for canonicalizing all natural language inputs, including normalization, stripping, segmentation, hashing, and content safety checks with comprehensive audit logging.",
        "details": "Implement the following components for the NL Input Canonicalization and Safety Pipeline:\n\n1. Input Canonicalization Module:\n   - Develop text normalization functions to standardize character encodings, whitespace, and punctuation\n   - Implement stripping functions to remove irrelevant or potentially harmful content (HTML, scripts, etc.)\n   - Create text segmentation algorithms to break inputs into logical units for processing\n   - Design a deterministic hashing system that generates consistent fingerprints for identical inputs\n   - Implement seeded substreams for reproducible randomization when needed\n\n2. Input Validation Framework:\n   - Integrate Zod schema validation for all NL inputs with strict type checking\n   - Define comprehensive validation schemas with appropriate constraints for different input types\n   - Implement custom validators for domain-specific requirements\n   - Create helpful error messages for validation failures\n   - Design a validation pipeline that can be configured per input type\n\n3. Content Safety System:\n   - Implement content moderation checks for inappropriate language, harmful content, etc.\n   - Create configurable safety thresholds and policies\n   - Design fallback mechanisms for potentially problematic inputs\n   - Implement rate limiting and abuse prevention measures\n   - Develop a quarantine system for flagged inputs requiring human review\n\n4. Audit Logging Infrastructure:\n   - Create a comprehensive logging system that captures:\n     - Original input text\n     - Canonicalization steps applied\n     - Hash values generated\n     - Validation schemas used\n     - Safety checks performed and results\n     - Final processed output\n   - Implement provenance tracking to maintain the complete history of input transformations\n   - Design secure storage for audit logs with appropriate retention policies\n   - Create query interfaces for log analysis and investigation\n\n5. Integration with Existing Systems:\n   - Modify the Voice/NL Interaction UX System to use the canonicalization pipeline\n   - Update the Player-to-People Communications System to incorporate safety checks\n   - Integrate with the Simulation System to ensure deterministic processing\n   - Connect to the Explainability System to provide transparency into input processing\n\n6. Configuration Management:\n   - Create a centralized configuration system for all pipeline components\n   - Implement environment-specific settings (development, testing, production)\n   - Design a mechanism for updating safety rules without code changes\n   - Develop documentation for configuration options and best practices",
        "testStrategy": "1. Unit Testing:\n   - Test each canonicalization function with diverse inputs including edge cases\n   - Verify hashing produces consistent results for identical inputs after normalization\n   - Test Zod schema validation with valid and invalid inputs\n   - Verify safety checks correctly identify problematic content\n   - Test audit logging captures all required information accurately\n\n2. Integration Testing:\n   - Test the complete pipeline with various input types and sources\n   - Verify integration with Voice/NL Interaction UX System\n   - Test integration with Player-to-People Communications System\n   - Verify deterministic behavior when integrated with Simulation System\n   - Test audit log querying and analysis functionality\n\n3. Determinism Testing:\n   - Run identical inputs through the pipeline multiple times to verify consistent outputs\n   - Test with different system states to ensure context doesn't affect processing\n   - Verify seeded substreams produce reproducible results\n   - Test across different environments to ensure consistent behavior\n\n4. Security Testing:\n   - Perform penetration testing on the input processing pipeline\n   - Test with malicious inputs designed to bypass safety checks\n   - Verify audit logs cannot be tampered with\n   - Test rate limiting and abuse prevention mechanisms\n\n5. Performance Testing:\n   - Measure throughput and latency of the pipeline under various loads\n   - Test with large volumes of concurrent inputs\n   - Identify and optimize bottlenecks in the processing pipeline\n   - Verify performance meets requirements for real-time interactions\n\n6. Acceptance Testing:\n   - Verify all requirements from R-067 are satisfied\n   - Test end-to-end scenarios with real user inputs\n   - Validate audit logs provide sufficient information for compliance and debugging\n   - Confirm safety checks meet content moderation requirements",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 21,
        "title": "Implement Research Proposal Validation and Knowledge Management System",
        "description": "Develop a system for validating natural language research proposals into programs, tracking knowledge diffusion, managing patent races, monitoring espionage risks, and implementing expertise ladders with spillover effects and brain drain mechanics.",
        "details": "Implement the following components for the Research Proposal Validation and Knowledge Management System:\n\n1. Research Proposal Parser and Validator:\n   - Develop NL processing pipeline to extract key elements from research proposals (objectives, methodology, resources, timeline, expected outcomes)\n   - Implement validation rules to assess proposal feasibility, resource requirements, and alignment with technological capabilities\n   - Create a scoring system that evaluates proposals based on innovation potential, resource efficiency, and strategic alignment\n   - Design a conversion process that transforms validated proposals into executable research programs with defined milestones\n\n2. Knowledge Diffusion Engine:\n   - Implement a graph-based knowledge representation system that models technological domains and their interconnections\n   - Create diffusion algorithms that simulate how knowledge spreads between entities (corporations, nations, research institutions)\n   - Model knowledge transfer rates based on communication channels, collaborative relationships, and information security measures\n   - Implement visualization tools to track knowledge flow and identify critical knowledge hubs\n\n3. Patent Race Simulator:\n   - Design a competitive race system where multiple entities can pursue similar technological breakthroughs\n   - Implement progress tracking with probabilistic advancement based on expertise levels and resource allocation\n   - Create patent protection mechanics that provide competitive advantages to race winners\n   - Model strategic decisions including resource allocation, collaboration opportunities, and espionage attempts\n\n4. Espionage Risk Management:\n   - Develop risk assessment algorithms that evaluate the vulnerability of research programs to espionage\n   - Implement counterintelligence measures with associated costs and effectiveness ratings\n   - Create detection systems for identifying potential espionage activities with false positive/negative rates\n   - Design consequence models for successful/failed espionage attempts including diplomatic, economic, and technological impacts\n\n5. Expertise Ladder System:\n   - Implement hierarchical expertise levels across different technological domains\n   - Create progression mechanics for expertise advancement based on research activities and knowledge acquisition\n   - Model spillover effects where expertise in one domain influences capabilities in related domains\n   - Implement brain drain mechanics where experts can be recruited by competing entities based on incentives and conditions\n\n6. Deterministic Caps and Audit System:\n   - Implement hard caps on technological advancement rates to ensure predictable progression\n   - Create comprehensive audit logging for all research activities, knowledge transfers, and expertise changes\n   - Design verification systems to ensure deterministic outcomes for identical inputs\n   - Implement reporting tools to track technological progress against historical benchmarks\n\n7. Integration with Existing Systems:\n   - Connect with the NL Input Canonicalization pipeline for processing research proposals\n   - Integrate with Government Archetypes to model different research governance approaches\n   - Link to the Explainability System to provide causal narratives for research outcomes\n   - Interface with NPC Agent System to model research institutions and their behaviors",
        "testStrategy": "1. Unit Testing:\n   - Test research proposal parser with diverse proposal formats and content\n   - Verify validation rules correctly identify feasible and infeasible proposals\n   - Test knowledge diffusion algorithms with controlled network configurations\n   - Validate patent race mechanics produce expected outcomes based on inputs\n   - Test espionage risk calculations against known vulnerability patterns\n   - Verify expertise progression follows expected advancement curves\n   - Test deterministic caps maintain consistent technological boundaries\n   - Validate audit logging captures all relevant system events\n\n2. Integration Testing:\n   - Test end-to-end flow from proposal submission to research program execution\n   - Verify knowledge diffusion properly interacts with expertise systems\n   - Test patent race outcomes influence knowledge distribution correctly\n   - Validate espionage attempts properly affect knowledge states\n   - Test expertise spillovers create expected cross-domain effects\n   - Verify brain drain mechanics correctly transfer expertise between entities\n   - Test integration with NL canonicalization pipeline for proposal processing\n   - Validate connections with government archetype systems\n\n3. Simulation Testing:\n   - Run multi-entity simulations with competing research agendas\n   - Test long-term knowledge diffusion patterns against historical models\n   - Verify technological advancement rates remain within deterministic caps\n   - Validate complex interactions between all system components\n   - Test system response to extreme scenarios (massive investment, complete isolation, etc.)\n   - Verify audit system can reconstruct causal chains for all outcomes\n\n4. Performance Testing:\n   - Benchmark system performance with large numbers of concurrent research programs\n   - Test knowledge graph operations with complex technological landscapes\n   - Verify response times for proposal validation remain within acceptable limits\n   - Validate system stability under high transaction volumes\n\n5. Security Testing:\n   - Verify access controls protect sensitive research information\n   - Test audit system's ability to detect unauthorized access attempts\n   - Validate data integrity mechanisms prevent tampering with research records",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 22,
        "title": "Implement Accessibility & Internationalization Support",
        "description": "Develop multilingual speech-to-text, text-to-speech, translation capabilities, captions, and accent-robust ASR across supported locales with appropriate adapters, tests, and demo toggles.",
        "details": "Implement the following components for the Accessibility & Internationalization system:\n\n1. Multilingual Speech Processing Core:\n   - Integrate speech-to-text (STT) engines supporting multiple languages and accents\n   - Implement text-to-speech (TTS) capabilities with natural-sounding voices for all supported locales\n   - Develop accent-robust Automatic Speech Recognition (ASR) that maintains high accuracy across regional accents\n   - Create a unified API layer that abstracts the underlying speech processing engines\n\n2. Translation Services:\n   - Implement real-time translation between supported language pairs\n   - Develop context-aware translation that preserves meaning across cultural contexts\n   - Create fallback mechanisms for handling untranslatable idioms or culturally-specific references\n   - Implement quality metrics to evaluate translation accuracy\n\n3. Caption Generation System:\n   - Develop automatic caption generation for audio content\n   - Implement timing synchronization between audio and captions\n   - Support multiple caption formats (SRT, WebVTT, etc.)\n   - Create styling options for captions to enhance readability\n\n4. Internationalization Framework:\n   - Implement i18n adapters for all user-facing text elements\n   - Create a locale management system that handles language switching without application restart\n   - Develop right-to-left (RTL) layout support for appropriate languages\n   - Implement locale-specific formatting for dates, numbers, and currencies\n\n5. Accessibility Features:\n   - Implement screen reader compatibility throughout the application\n   - Create high-contrast modes and adjustable text sizing\n   - Develop keyboard navigation alternatives for all interactive elements\n   - Implement ARIA attributes and semantic HTML for assistive technology support\n\n6. Demo and Testing Infrastructure:\n   - Create toggleable demo modes to showcase internationalization features\n   - Implement A/B testing framework for accessibility improvements\n   - Develop automated testing for language switching and locale changes\n   - Create performance benchmarks for speech processing across different languages\n\n7. Documentation and Guidelines:\n   - Develop comprehensive documentation for adding new languages\n   - Create accessibility compliance checklists based on WCAG standards\n   - Implement style guides for internationalized content\n   - Provide developer guidelines for maintaining accessibility during feature development",
        "testStrategy": "1. Unit Testing:\n   - Test STT/TTS engines with samples from each supported language and accent\n   - Verify translation accuracy using standardized language proficiency tests\n   - Test caption generation timing and accuracy across different audio samples\n   - Validate locale switching functionality in isolated components\n   - Verify RTL layout rendering in appropriate language contexts\n\n2. Integration Testing:\n   - Test end-to-end workflows involving speech input, processing, and output\n   - Verify seamless transitions between languages throughout the application\n   - Test accessibility features with actual assistive technologies\n   - Validate internationalization adapters work correctly with the UI components\n   - Test performance under load for simultaneous translation and speech processing\n\n3. Accessibility Compliance Testing:\n   - Conduct automated accessibility audits using tools like Axe or Lighthouse\n   - Perform manual testing with screen readers (NVDA, JAWS, VoiceOver)\n   - Verify keyboard navigation works for all interactive elements\n   - Test color contrast ratios meet WCAG AA/AAA standards\n   - Validate that all form elements have appropriate labels and instructions\n\n4. Localization Testing:\n   - Verify all user-facing text is properly translated in each supported locale\n   - Test date, time, number, and currency formatting across locales\n   - Verify that UI layouts adapt appropriately to text expansion/contraction\n   - Test with native speakers to validate natural language quality\n   - Verify cultural appropriateness of icons, colors, and imagery\n\n5. Performance Testing:\n   - Benchmark STT/TTS processing times across different languages\n   - Measure translation latency for real-time conversations\n   - Test memory usage when switching between multiple languages\n   - Verify application responsiveness during intensive language processing tasks\n   - Measure load times for different localized content\n\n6. User Acceptance Testing:\n   - Conduct testing with users who have different accessibility needs\n   - Test with native speakers of each supported language\n   - Gather feedback on accent recognition accuracy from speakers with regional accents\n   - Validate caption readability and usefulness with deaf or hard-of-hearing users",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 23,
        "title": "Implement On-Device ASR and Model Cascading System",
        "description": "Develop an on-device/edge Automatic Speech Recognition (ASR) system with cascading model strategies and summarization layers to optimize performance while maintaining cost controls.",
        "details": "Implement the following components for the On-Device ASR and Model Cascading System:\n\n1. On-Device ASR Engine:\n   - Integrate lightweight ASR models optimized for edge deployment\n   - Implement voice activity detection to minimize processing of non-speech audio\n   - Create adaptive noise cancellation for varying environmental conditions\n   - Develop fallback mechanisms when recognition confidence is low\n   - Support offline operation with periodic model updates\n\n2. Cascading Model Strategy Framework:\n   - Design a tiered approach that starts with small, efficient models and escalates to larger, more accurate models only when necessary\n   - Implement confidence scoring to determine when to escalate to larger models\n   - Create decision logic for model selection based on:\n     - Speech complexity/ambiguity\n     - Available device resources\n     - Network conditions\n     - Cost budgets\n   - Support dynamic thresholds that adapt to user patterns and application context\n\n3. Summarization Layer:\n   - Develop token-capping mechanisms that preserve semantic meaning\n   - Implement deterministic summarization algorithms to ensure consistent outputs\n   - Create content prioritization rules based on domain-specific importance\n   - Support configurable token budgets at the session and request level\n\n4. Cost Control System:\n   - Implement budget enforcement mechanisms with configurable thresholds\n   - Create detailed telemetry integration with the existing cost telemetry system\n   - Develop real-time budget monitoring and automatic fallback triggers\n   - Support graceful degradation of service when approaching budget limits\n\n5. Performance Optimization:\n   - Implement model quantization for reduced memory footprint\n   - Create model caching strategies for frequently used speech patterns\n   - Develop batching mechanisms for efficient processing\n   - Support hardware acceleration where available (CPU/GPU/NPU)\n\n6. Configuration and Management:\n   - Create APIs for dynamic configuration of cascading thresholds\n   - Implement A/B testing framework for model selection strategies\n   - Develop monitoring dashboards for performance and cost metrics\n   - Support remote configuration updates without requiring app updates",
        "testStrategy": "1. Unit Testing:\n   - Test each ASR model individually with standardized speech samples\n   - Verify cascading logic correctly escalates based on confidence thresholds\n   - Test summarization algorithms preserve critical information while reducing tokens\n   - Validate budget enforcement mechanisms correctly limit resource usage\n   - Verify fallback mechanisms activate appropriately under various conditions\n\n2. Integration Testing:\n   - Test end-to-end speech recognition pipeline with the complete cascading strategy\n   - Verify integration with the cost telemetry system (Task 9)\n   - Test performance under varying network conditions and device capabilities\n   - Validate internationalization support works with on-device ASR (integration with Task 22)\n\n3. Performance Testing:\n   - Benchmark speech recognition accuracy across device types\n   - Measure latency for different model tiers and cascading scenarios\n   - Test memory usage under sustained operation\n   - Verify battery impact on mobile devices\n\n4. Cost Efficiency Testing:\n   - Compare token usage with and without summarization layers\n   - Measure cost savings from on-device processing vs. cloud-only approach\n   - Verify budget controls prevent cost overruns in high-usage scenarios\n   - Test accuracy vs. cost tradeoffs across different cascading configurations\n\n5. Acceptance Testing:\n   - Conduct user studies to assess perceived latency and accuracy\n   - Verify accessibility requirements are met across supported languages\n   - Test with realistic user scenarios and speech patterns\n   - Validate deterministic behavior across multiple runs with identical inputs",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-08-14T06:39:07.520Z",
      "updated": "2025-08-14T07:51:25.856Z",
      "description": "Tasks for feature-live-ops context"
    }
  },
  "sprint-a-sim-engine": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Core Simulation Engine",
        "description": "Create the core simulation engine that advances campaign state on a fixed tick with deterministic behavior.",
        "details": "Create src/server/sim/engine.ts with step({campaignId, seed, actions[]}) function that processes game state in a deterministic manner.\n\nImplementation details:\n1. Use a seeded PRNG (like seedrandom library) to ensure deterministic outcomes\n2. Implement the reducer pipeline in the specified order: production -> queues -> logistics cap -> prices -> readiness/science proxies -> apply policy/tax modifiers -> KPIs + Vezies\n3. Ensure all operations are idempotent and wrapped in a database transaction\n4. Create helper functions for each reducer step\n5. Persist KPI snapshots to kpi_snapshots table\n6. Emit Vezies events for queue completion and new planet discoveries\n\nExample code structure:\n```typescript\nimport { seedrandom } from 'seedrandom';\n\nexport async function step({ campaignId, seed, actions = [] }) {\n  // Initialize PRNG with seed\n  const rng = seedrandom(seed);\n  \n  // Start transaction\n  return db.transaction(async (tx) => {\n    // Load campaign state\n    const state = await loadCampaignState(campaignId, tx);\n    \n    // Apply pending actions\n    const stateWithActions = applyPendingActions(state, actions);\n    \n    // Run reducers in sequence\n    const afterProduction = productionReducer(stateWithActions, rng);\n    const afterQueues = queueReducer(afterProduction, rng);\n    const afterLogistics = logisticsReducer(afterQueues, rng);\n    const afterPrices = priceReducer(afterLogistics, rng);\n    const afterProxies = readinessAndScienceReducer(afterPrices, rng);\n    const afterPolicies = policyModifierReducer(afterProxies, rng);\n    const finalState = kpiAndVeziesReducer(afterPolicies, rng);\n    \n    // Persist state changes and KPI snapshots\n    await persistStateChanges(finalState, tx);\n    await persistKpiSnapshot(campaignId, finalState.kpis, tx);\n    \n    // Emit Vezies events\n    await emitVeziesEvents(finalState.veziesEvents, tx);\n    \n    return finalState;\n  });\n}\n```",
        "testStrategy": "1. Unit tests for each reducer function to verify correct behavior with controlled inputs\n2. Integration test for the step function to ensure all reducers are called in the correct order\n3. API test for POST /api/sim/step endpoint to verify 200 response and KPI snapshot creation\n4. Determinism test: verify that the same seed and inputs always produce identical outputs\n5. Transaction test: verify that failed steps don't persist partial state changes",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up the simulation engine structure",
            "description": "Create the basic structure for the simulation engine including the main step function and PRNG initialization",
            "dependencies": [],
            "details": "Create src/server/sim/engine.ts with the step function that accepts campaignId, seed, and actions parameters. Set up the seeded PRNG using the seedrandom library. Implement the transaction wrapper and state loading functions. Create skeleton functions for each reducer step that will be implemented in subsequent tasks.",
            "status": "pending",
            "testStrategy": "Write unit tests to verify the PRNG initialization with different seeds produces consistent results. Test the transaction wrapper to ensure proper error handling and rollback functionality."
          },
          {
            "id": 2,
            "title": "Implement production and queue reducers",
            "description": "Create the first two reducers in the pipeline: production and queue processing",
            "dependencies": [],
            "details": "Implement the productionReducer function that calculates resource production based on current state. Create the queueReducer function that processes building and research queues, advancing progress and completing items when finished. Both reducers should use the seeded RNG for any random operations to ensure deterministic behavior.",
            "status": "pending",
            "testStrategy": "Create unit tests with mock campaign states to verify production calculations are correct. Test queue processing with various queue states to ensure items complete at the expected time and trigger appropriate state changes."
          },
          {
            "id": 3,
            "title": "Implement logistics, price, and proxy reducers",
            "description": "Create the middle reducers in the pipeline: logistics capacity, price adjustments, and readiness/science proxies",
            "dependencies": [],
            "details": "Implement the logisticsReducer to calculate and enforce logistics capacity limits. Create the priceReducer to adjust resource prices based on supply and demand. Develop the readinessAndScienceReducer to calculate military readiness and science progress proxies based on current state.",
            "status": "pending",
            "testStrategy": "Test logistics capacity enforcement with states that exceed capacity. Verify price adjustments respond correctly to different supply/demand scenarios. Ensure readiness and science calculations properly reflect the current game state."
          },
          {
            "id": 4,
            "title": "Implement policy modifiers and KPI/Vezies reducers",
            "description": "Create the final reducers in the pipeline: policy/tax modifiers and KPI/Vezies calculations",
            "dependencies": [],
            "details": "Implement the policyModifierReducer to apply active policy and tax effects to the game state. Create the kpiAndVeziesReducer to calculate key performance indicators and generate Vezies events. Ensure all KPI data is properly formatted for storage in the kpi_snapshots table.",
            "status": "pending",
            "testStrategy": "Test policy modifier application with various policy configurations. Verify KPI calculations match expected values for given states. Test Vezies event generation for queue completions and planet discoveries."
          },
          {
            "id": 5,
            "title": "Implement state persistence and event emission",
            "description": "Create functions to persist state changes, KPI snapshots, and emit Vezies events",
            "dependencies": [],
            "details": "Implement the persistStateChanges function to save the updated game state to the database. Create the persistKpiSnapshot function to store KPI data in the kpi_snapshots table. Develop the emitVeziesEvents function to process and emit events generated during simulation. Ensure all operations are idempotent and properly handled within the database transaction.",
            "status": "pending",
            "testStrategy": "Test state persistence with various state changes to verify correct database updates. Verify KPI snapshots are properly stored with correct timestamps and values. Test event emission to ensure events are properly formatted and delivered."
          }
        ]
      },
      {
        "id": 2,
        "title": "Create Simulation API Endpoint",
        "description": "Implement the API endpoint for triggering simulation steps and retrieving simulation results.",
        "details": "Create a new API endpoint at POST /api/sim/step that triggers the simulation engine to advance the game state by one tick.\n\nImplementation details:\n1. Create a new route handler in the API routes directory\n2. Accept campaignId and optional seed parameter (generate one if not provided)\n3. Call the engine.step() function with the provided parameters\n4. Return the updated KPI snapshot and any Vezies events\n5. Include appropriate error handling and validation\n6. Mark as dev-only in production environments\n\nExample implementation:\n```typescript\n// src/pages/api/sim/step.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { step } from '@/server/sim/engine';\nimport { generateSeed } from '@/utils/random';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (process.env.NODE_ENV === 'production' && !process.env.ENABLE_DEV_ENDPOINTS) {\n    return res.status(403).json({ error: 'Endpoint disabled in production' });\n  }\n\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  try {\n    const { campaignId, seed = generateSeed(), actions = [] } = req.body;\n    \n    if (!campaignId) {\n      return res.status(400).json({ error: 'campaignId is required' });\n    }\n    \n    const result = await step({ campaignId, seed, actions });\n    \n    return res.status(200).json({\n      success: true,\n      seed,\n      kpiSnapshot: result.kpiSnapshot,\n      veziesEvents: result.veziesEvents\n    });\n  } catch (error) {\n    console.error('Simulation step error:', error);\n    return res.status(500).json({ error: 'Failed to process simulation step' });\n  }\n}\n```",
        "testStrategy": "1. API test to verify the endpoint returns 200 with valid inputs\n2. Test that the endpoint rejects non-POST methods with 405\n3. Test that the endpoint requires campaignId parameter\n4. Test that the endpoint is disabled in production unless explicitly enabled\n5. Verify that the response contains the expected KPI snapshot and Vezies events",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create API route handler file structure",
            "description": "Set up the basic file structure for the simulation API endpoint in the API routes directory",
            "dependencies": [],
            "details": "Create the file src/pages/api/sim/step.ts with the basic Next.js API route handler structure. Import necessary types and dependencies including NextApiRequest, NextApiResponse, and the simulation engine. Set up the handler function with proper method checking for POST requests.",
            "status": "pending",
            "testStrategy": "Verify the file structure is correctly set up and imports are working. Test that the endpoint returns 405 for non-POST methods."
          },
          {
            "id": 2,
            "title": "Implement request validation and parameter handling",
            "description": "Add validation for required parameters and handle optional parameters with defaults",
            "dependencies": [
              "2.1"
            ],
            "details": "Extract and validate the campaignId parameter from the request body, ensuring it's required. Implement optional seed parameter handling with fallback to generateSeed() function if not provided. Set up the actions array parameter with a default empty array. Add appropriate error responses for missing required parameters.",
            "status": "pending",
            "testStrategy": "Test that the endpoint requires campaignId parameter and returns 400 if missing. Verify that seed is generated when not provided. Test with various combinations of parameters to ensure proper validation."
          },
          {
            "id": 3,
            "title": "Integrate with simulation engine",
            "description": "Connect the API endpoint to the core simulation engine to process simulation steps",
            "dependencies": [
              "2.2"
            ],
            "details": "Call the engine.step() function with the validated parameters (campaignId, seed, actions). Ensure the function call is properly awaited and wrapped in a try-catch block. Structure the response to include the updated KPI snapshot and Vezies events returned from the engine.",
            "status": "pending",
            "testStrategy": "Test that the endpoint correctly calls the simulation engine with the right parameters. Verify that the response contains the expected data structure with KPI snapshot and Vezies events."
          },
          {
            "id": 4,
            "title": "Implement error handling and logging",
            "description": "Add comprehensive error handling and logging for the API endpoint",
            "dependencies": [
              "2.3"
            ],
            "details": "Implement try-catch block to handle any errors that occur during the simulation step. Log errors with appropriate context information using console.error or a dedicated logging service. Return standardized error responses with appropriate HTTP status codes (400 for client errors, 500 for server errors).",
            "status": "pending",
            "testStrategy": "Test error scenarios by mocking the simulation engine to throw errors. Verify that errors are properly caught, logged, and returned with appropriate status codes. Test with various error types to ensure comprehensive handling."
          },
          {
            "id": 5,
            "title": "Add production environment safeguards",
            "description": "Implement safeguards to disable the endpoint in production unless explicitly enabled",
            "dependencies": [
              "2.1"
            ],
            "details": "Add environment checking logic to disable the endpoint in production environments unless explicitly enabled via ENABLE_DEV_ENDPOINTS environment variable. Return a 403 Forbidden response with an appropriate error message when the endpoint is accessed in production without the flag enabled.",
            "status": "pending",
            "testStrategy": "Test the endpoint behavior in different environments by mocking process.env.NODE_ENV and process.env.ENABLE_DEV_ENDPOINTS. Verify that the endpoint returns 403 in production without the flag and works correctly when the flag is enabled."
          }
        ]
      },
      {
        "id": 3,
        "title": "Implement Policy Storage and Management",
        "description": "Create database schema and API endpoints for storing and managing free-form policies with their associated modifiers.",
        "details": "Implement the storage and management of free-form policies that can be parsed into game modifiers.\n\nImplementation details:\n1. Create database migrations for the policies and policy_modifiers tables:\n```sql\nCREATE TABLE IF NOT EXISTS policies (\n  id SERIAL PRIMARY KEY,\n  title VARCHAR(255) NOT NULL,\n  body TEXT NOT NULL,\n  scope VARCHAR(50) NOT NULL CHECK (scope IN ('campaign', 'region', 'system')),\n  tags JSONB DEFAULT '[]',\n  effective_at TIMESTAMP WITH TIME ZONE,\n  expires_at TIMESTAMP WITH TIME ZONE,\n  author VARCHAR(255),\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS policy_modifiers (\n  id SERIAL PRIMARY KEY,\n  policy_id INTEGER REFERENCES policies(id) ON DELETE CASCADE,\n  key VARCHAR(255) NOT NULL,\n  value NUMERIC NOT NULL,\n  cap_min NUMERIC NOT NULL,\n  cap_max NUMERIC NOT NULL,\n  approved_at TIMESTAMP WITH TIME ZONE,\n  approved_by VARCHAR(255),\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n```\n\n2. Create API endpoints:\n- GET /api/policies - List all policies\n- GET /api/policies/:id - Get a specific policy\n- POST /api/policies - Create a new policy\n- PUT /api/policies/:id - Update a policy\n- DELETE /api/policies/:id - Delete a policy\n- GET /api/policies/active - Get all active policies with approved modifiers\n\n3. Implement database access functions in a repository pattern:\n```typescript\n// src/server/repositories/policyRepository.ts\nexport async function createPolicy(policy) {\n  return db.query(\n    'INSERT INTO policies (title, body, scope, tags, effective_at, expires_at, author) VALUES ($1, $2, $3, $4, $5, $6, $7) RETURNING *',\n    [policy.title, policy.body, policy.scope, JSON.stringify(policy.tags), policy.effective_at, policy.expires_at, policy.author]\n  );\n}\n\nexport async function getActiveModifiers() {\n  const now = new Date();\n  return db.query(\n    `SELECT pm.* FROM policy_modifiers pm\n     JOIN policies p ON pm.policy_id = p.id\n     WHERE pm.approved_at IS NOT NULL\n     AND p.effective_at <= $1\n     AND (p.expires_at IS NULL OR p.expires_at > $1)`,\n    [now]\n  );\n}\n```",
        "testStrategy": "1. Unit tests for database repository functions\n2. API tests for each endpoint to verify CRUD operations\n3. Integration test to verify that active policies are correctly filtered by effective/expiry dates\n4. Test that policy modifiers are correctly associated with policies\n5. Verify that the cap_min and cap_max constraints are enforced",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Database Migrations",
            "description": "Implement database schema for policies and policy_modifiers tables",
            "dependencies": [],
            "details": "Create migration files for the policies table with fields for id, title, body, scope, tags, effective_at, expires_at, author, and created_at. Create migration files for the policy_modifiers table with fields for id, policy_id (foreign key to policies), key, value, cap_min, cap_max, approved_at, approved_by, and created_at. Ensure proper constraints are set including the scope CHECK constraint.",
            "status": "pending",
            "testStrategy": "Verify migrations run successfully and create tables with correct schema. Test constraints by attempting to insert invalid data. Verify foreign key relationships work correctly."
          },
          {
            "id": 2,
            "title": "Implement Policy Repository Functions",
            "description": "Create database access functions using repository pattern for policy operations",
            "dependencies": [
              "3.1"
            ],
            "details": "Implement repository functions for CRUD operations on policies and policy_modifiers: createPolicy, getPolicy, updatePolicy, deletePolicy, listPolicies, createPolicyModifier, getActivePolicies, and getActiveModifiers. Ensure proper error handling and transaction management for operations that affect multiple tables.",
            "status": "pending",
            "testStrategy": "Unit test each repository function with mock database responses. Test edge cases like non-existent records, duplicate entries, and constraint violations. Verify active policies are correctly filtered by dates."
          },
          {
            "id": 3,
            "title": "Create API Endpoints for Policy Management",
            "description": "Implement REST API endpoints for policy CRUD operations",
            "dependencies": [
              "3.2"
            ],
            "details": "Create API handlers for GET /api/policies, GET /api/policies/:id, POST /api/policies, PUT /api/policies/:id, and DELETE /api/policies/:id. Implement request validation, error handling, and appropriate HTTP status codes. Ensure endpoints use the repository functions for database access.",
            "status": "pending",
            "testStrategy": "Test each endpoint with valid and invalid requests. Verify correct HTTP status codes and response formats. Test authentication/authorization if applicable. Verify database operations are performed correctly."
          },
          {
            "id": 4,
            "title": "Implement Active Policies Endpoint",
            "description": "Create endpoint to retrieve active policies with approved modifiers",
            "dependencies": [
              "3.3"
            ],
            "details": "Implement GET /api/policies/active endpoint that returns all currently active policies (based on effective_at and expires_at dates) along with their approved modifiers. Filter out policies without approved modifiers and ensure only active policies are returned.",
            "status": "pending",
            "testStrategy": "Test with policies having various effective/expiry dates. Verify only active policies with approved modifiers are returned. Test with empty database and with policies having no approved modifiers."
          },
          {
            "id": 5,
            "title": "Create Policy Validation and Error Handling",
            "description": "Implement validation logic and error handling for policy operations",
            "dependencies": [
              "3.3",
              "3.4"
            ],
            "details": "Create validation functions for policy and policy_modifier objects. Implement proper error handling for all API endpoints. Ensure modifiers are validated against their cap_min and cap_max values. Create custom error types and consistent error response format across all endpoints.",
            "status": "pending",
            "testStrategy": "Test validation with valid and invalid policy data. Verify error responses have consistent format and appropriate HTTP status codes. Test boundary conditions for modifier caps. Verify validation catches all required fields and format issues."
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement AI Policy Parser",
        "description": "Create an AI-powered endpoint that parses free-form policy text and suggests appropriate game modifiers within capped ranges.",
        "details": "Implement an AI service that analyzes policy text and suggests appropriate modifiers within the specified caps.\n\nImplementation details:\n1. Create a new endpoint POST /api/policies/parse that accepts policy text and returns suggested modifiers\n2. Integrate with an AI service (OpenAI API or similar) to analyze the policy text\n3. Ensure suggested modifiers are within the capped ranges specified in the PRD:\n   - Production: uptime_mult (0.8–1.1), throughput_mult (0.8–1.1)\n   - Logistics: capacity_mult (0.8–1.2), risk_delta (−0.1–0.1)\n   - Prices: tariff_delta (−0.1–0.2), subsidy_delta (−0.15–0.15)\n   - Science: velocity_mult (0.8–1.2)\n   - Military: readiness_mult (0.9–1.1)\n4. Implement a fallback mechanism for when AI is disabled\n\nExample implementation:\n```typescript\n// src/pages/api/policies/parse.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { Configuration, OpenAIApi } from 'openai';\n\nconst MODIFIER_CAPS = {\n  uptime_mult: { min: 0.8, max: 1.1 },\n  throughput_mult: { min: 0.8, max: 1.1 },\n  capacity_mult: { min: 0.8, max: 1.2 },\n  risk_delta: { min: -0.1, max: 0.1 },\n  tariff_delta: { min: -0.1, max: 0.2 },\n  subsidy_delta: { min: -0.15, max: 0.15 },\n  velocity_mult: { min: 0.8, max: 1.2 },\n  readiness_mult: { min: 0.9, max: 1.1 }\n};\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  const { title, body, scope } = req.body;\n  \n  if (!title || !body) {\n    return res.status(400).json({ error: 'Title and body are required' });\n  }\n\n  try {\n    // If AI is disabled, return template suggestions\n    if (!process.env.OPENAI_API_KEY) {\n      return res.status(200).json({\n        suggestedModifiers: [\n          { key: 'uptime_mult', value: 1.05, cap_min: 0.8, cap_max: 1.1 },\n          { key: 'tariff_delta', value: 0.05, cap_min: -0.1, cap_max: 0.2 }\n        ]\n      });\n    }\n\n    // Initialize OpenAI\n    const configuration = new Configuration({\n      apiKey: process.env.OPENAI_API_KEY,\n    });\n    const openai = new OpenAIApi(configuration);\n\n    // Prepare prompt for the AI\n    const prompt = `Analyze this policy and suggest appropriate modifiers within the specified ranges:\\n\\nTitle: ${title}\\nBody: ${body}\\nScope: ${scope}\\n\\nAvailable modifiers and their ranges:\\n${JSON.stringify(MODIFIER_CAPS, null, 2)}\\n\\nReturn only the modifiers that are relevant to this policy, with values within the specified ranges.`;\n\n    // Call OpenAI API\n    const completion = await openai.createCompletion({\n      model: \"text-davinci-003\",\n      prompt,\n      max_tokens: 500,\n    });\n\n    // Parse the AI response and validate modifiers\n    const aiSuggestions = JSON.parse(completion.data.choices[0].text);\n    const validatedModifiers = aiSuggestions.map(mod => ({\n      key: mod.key,\n      value: Math.max(MODIFIER_CAPS[mod.key].min, Math.min(mod.value, MODIFIER_CAPS[mod.key].max)),\n      cap_min: MODIFIER_CAPS[mod.key].min,\n      cap_max: MODIFIER_CAPS[mod.key].max\n    }));\n\n    return res.status(200).json({ suggestedModifiers: validatedModifiers });\n  } catch (error) {\n    console.error('Policy parsing error:', error);\n    return res.status(500).json({ error: 'Failed to parse policy' });\n  }\n}\n```",
        "testStrategy": "1. Unit test the modifier validation logic to ensure values are capped correctly\n2. Mock the AI service response for testing\n3. Test the endpoint with various policy texts and verify the suggested modifiers\n4. Test the fallback mechanism when AI is disabled\n5. Verify that the endpoint rejects requests with missing title or body",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create API Endpoint Structure",
            "description": "Set up the basic structure for the POST /api/policies/parse endpoint that will accept policy text and return suggested modifiers.",
            "dependencies": [],
            "details": "Create the API endpoint file structure in src/pages/api/policies/parse.ts. Implement request validation for required fields (title, body). Set up error handling for invalid requests and server errors. Define the response structure for suggested modifiers that includes key, value, cap_min, and cap_max properties.",
            "status": "pending",
            "testStrategy": "Test endpoint with valid and invalid requests. Verify proper HTTP status codes are returned. Ensure the endpoint rejects non-POST methods with 405 status code. Test validation logic for required fields."
          },
          {
            "id": 2,
            "title": "Define Modifier Caps and Validation Logic",
            "description": "Implement the validation logic to ensure all suggested modifiers are within the specified capped ranges.",
            "dependencies": [
              "4.1"
            ],
            "details": "Create a MODIFIER_CAPS constant that defines the min/max values for each modifier type according to the PRD. Implement a validation function that ensures suggested modifier values are capped within their allowed ranges. The validation should handle all modifier types: production (uptime_mult, throughput_mult), logistics (capacity_mult, risk_delta), prices (tariff_delta, subsidy_delta), science (velocity_mult), and military (readiness_mult).",
            "status": "pending",
            "testStrategy": "Unit test the validation logic with values above, below, and at the cap limits. Verify that values outside the range are properly capped. Test with all modifier types to ensure complete coverage."
          },
          {
            "id": 3,
            "title": "Integrate OpenAI API",
            "description": "Set up the integration with OpenAI API to analyze policy text and suggest appropriate modifiers.",
            "dependencies": [
              "4.1",
              "4.2"
            ],
            "details": "Install and configure the OpenAI SDK. Create a prompt template that effectively communicates the policy analysis task to the AI. Implement the API call to OpenAI with appropriate model selection and parameters. Parse the AI response and convert it to the expected modifier format. Implement error handling for API failures and response parsing issues.",
            "status": "pending",
            "testStrategy": "Mock the OpenAI API responses for testing. Test with various policy texts to verify prompt effectiveness. Verify error handling when the API returns unexpected responses or fails."
          },
          {
            "id": 4,
            "title": "Implement Fallback Mechanism",
            "description": "Create a fallback mechanism that provides default modifier suggestions when AI integration is disabled or unavailable.",
            "dependencies": [
              "4.2"
            ],
            "details": "Implement logic to detect when the OpenAI API key is not available or when the AI service fails. Create a function that generates reasonable default modifier suggestions based on the policy scope. Ensure the fallback suggestions are also within the capped ranges. The fallback should provide at least 2-3 relevant modifiers to give users a starting point.",
            "status": "pending",
            "testStrategy": "Test the fallback mechanism by intentionally disabling the AI integration. Verify that default suggestions are provided and are within the capped ranges. Test with different policy scopes to ensure appropriate defaults are generated."
          },
          {
            "id": 5,
            "title": "Add Environment Configuration and Documentation",
            "description": "Set up environment variables for API keys and add comprehensive documentation for the endpoint.",
            "dependencies": [
              "4.1",
              "4.3",
              "4.4"
            ],
            "details": "Configure environment variables for the OpenAI API key. Add detailed comments explaining the endpoint functionality, expected request/response formats, and the AI integration. Create a README section for the policy parser API with usage examples. Implement logging for debugging and monitoring purposes. Add type definitions for all request and response objects.",
            "status": "pending",
            "testStrategy": "Verify that the endpoint works correctly with and without environment variables set. Review documentation for completeness and accuracy. Test logging functionality to ensure important events are properly recorded."
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement Policy Activation Endpoint",
        "description": "Create an endpoint for approving and activating policy modifiers that will be applied by the simulation engine.",
        "details": "Implement an endpoint to approve and activate policy modifiers that will affect the simulation.\n\nImplementation details:\n1. Create a new endpoint POST /api/policies/activate that accepts policy ID and approved modifiers\n2. Update the policy_modifiers table to mark modifiers as approved\n3. Ensure modifiers are within the capped ranges before approval\n4. Add authentication/authorization checks\n\nExample implementation:\n```typescript\n// src/pages/api/policies/activate.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { getSession } from 'next-auth/react';\nimport { updatePolicyModifiers } from '@/server/repositories/policyRepository';\n\nconst MODIFIER_CAPS = {\n  uptime_mult: { min: 0.8, max: 1.1 },\n  throughput_mult: { min: 0.8, max: 1.1 },\n  capacity_mult: { min: 0.8, max: 1.2 },\n  risk_delta: { min: -0.1, max: 0.1 },\n  tariff_delta: { min: -0.1, max: 0.2 },\n  subsidy_delta: { min: -0.15, max: 0.15 },\n  velocity_mult: { min: 0.8, max: 1.2 },\n  readiness_mult: { min: 0.9, max: 1.1 }\n};\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  // Get user session for authorization\n  const session = await getSession({ req });\n  if (!session) {\n    return res.status(401).json({ error: 'Unauthorized' });\n  }\n\n  const { policyId, modifiers } = req.body;\n  \n  if (!policyId || !modifiers || !Array.isArray(modifiers)) {\n    return res.status(400).json({ error: 'Policy ID and modifiers array are required' });\n  }\n\n  try {\n    // Validate modifiers are within caps\n    const validatedModifiers = modifiers.map(mod => {\n      const caps = MODIFIER_CAPS[mod.key];\n      if (!caps) {\n        throw new Error(`Invalid modifier key: ${mod.key}`);\n      }\n      \n      const value = Math.max(caps.min, Math.min(mod.value, caps.max));\n      \n      return {\n        policy_id: policyId,\n        key: mod.key,\n        value,\n        cap_min: caps.min,\n        cap_max: caps.max,\n        approved_at: new Date(),\n        approved_by: session.user.email\n      };\n    });\n\n    // Update or insert approved modifiers\n    await updatePolicyModifiers(policyId, validatedModifiers);\n\n    return res.status(200).json({\n      success: true,\n      message: 'Policy modifiers activated successfully',\n      modifiers: validatedModifiers\n    });\n  } catch (error) {\n    console.error('Policy activation error:', error);\n    return res.status(500).json({ error: 'Failed to activate policy modifiers' });\n  }\n}\n```",
        "testStrategy": "1. Test that the endpoint correctly validates and caps modifier values\n2. Verify that unauthorized users cannot activate modifiers\n3. Test that modifiers are correctly stored in the database with approval timestamp\n4. Verify that the endpoint rejects invalid modifier keys\n5. Integration test to ensure activated modifiers are applied in the next simulation step",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create API endpoint structure",
            "description": "Set up the basic structure for the POST /api/policies/activate endpoint that will handle policy activation requests.",
            "dependencies": [],
            "details": "Create the endpoint file at src/pages/api/policies/activate.ts. Implement the basic request handler with method validation (POST only). Set up the request body type definition for policyId and modifiers array. Add error handling structure and response formatting.",
            "status": "pending",
            "testStrategy": "Test that the endpoint rejects non-POST methods with 405 status code. Verify the endpoint structure handles basic error cases correctly."
          },
          {
            "id": 2,
            "title": "Implement authentication and authorization",
            "description": "Add user authentication checks to ensure only authorized users can activate policy modifiers.",
            "dependencies": [
              "5.1"
            ],
            "details": "Integrate NextAuth session validation to verify user is logged in. Add authorization logic to check if the user has permission to activate policies. Return appropriate 401 Unauthorized responses for unauthenticated requests.",
            "status": "pending",
            "testStrategy": "Test that unauthenticated requests are rejected with 401 status code. Verify that users with different permission levels are handled correctly."
          },
          {
            "id": 3,
            "title": "Implement modifier validation and capping",
            "description": "Create logic to validate incoming modifiers and ensure they are within the specified capped ranges.",
            "dependencies": [
              "5.1"
            ],
            "details": "Define the MODIFIER_CAPS constant with min/max values for each modifier type. Implement validation logic to check that all submitted modifiers have valid keys. Create capping logic to ensure modifier values are within allowed ranges. Handle validation errors with appropriate error messages.",
            "status": "pending",
            "testStrategy": "Test validation with various modifier values both within and outside allowed ranges. Verify that invalid modifier keys are rejected. Confirm that values outside caps are properly adjusted to the min/max bounds."
          },
          {
            "id": 4,
            "title": "Implement database update functionality",
            "description": "Create the functionality to update the policy_modifiers table with approved modifiers.",
            "dependencies": [
              "5.2",
              "5.3"
            ],
            "details": "Import or implement the updatePolicyModifiers repository function. Add logic to format validated modifiers with approval metadata (timestamp, approver). Ensure proper error handling for database operations. Return appropriate success/error responses based on database operation results.",
            "status": "pending",
            "testStrategy": "Test that modifiers are correctly stored in the database with approval timestamp and approver information. Verify error handling for database failures. Test with various valid modifier combinations."
          },
          {
            "id": 5,
            "title": "Integration testing and documentation",
            "description": "Perform integration testing of the complete endpoint and add documentation for API consumers.",
            "dependencies": [
              "5.4"
            ],
            "details": "Create comprehensive integration tests covering the full endpoint functionality. Add JSDoc comments to document the endpoint's purpose, parameters, and responses. Create example requests and responses for documentation. Ensure the endpoint works correctly with the simulation engine by testing end-to-end flows.",
            "status": "pending",
            "testStrategy": "Perform end-to-end testing with the simulation engine to verify that activated modifiers are correctly applied. Test edge cases like concurrent modifications to the same policy. Document all test scenarios and expected behaviors."
          }
        ]
      },
      {
        "id": 6,
        "title": "Implement AI Advisors System",
        "description": "Create AI advisors for different domains that can provide recommendations and propose actions based on the current game state.",
        "details": "Implement a system of AI advisors that can provide domain-specific recommendations and propose actions.\n\nImplementation details:\n1. Create database migration for the pending_actions table:\n```sql\nCREATE TABLE IF NOT EXISTS pending_actions (\n  id SERIAL PRIMARY KEY,\n  domain VARCHAR(50) NOT NULL CHECK (domain IN ('economy', 'military', 'science', 'logistics', 'governance', 'diplomacy')),\n  payload JSONB NOT NULL,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  approved_at TIMESTAMP WITH TIME ZONE,\n  executed_at TIMESTAMP WITH TIME ZONE\n);\n```\n\n2. Implement advisor endpoints:\n- POST /api/advisors/:domain/query - Ask a question to an advisor\n- POST /api/advisors/:domain/propose - Propose an action for approval\n\n3. Create advisor service with domain-specific logic:\n```typescript\n// src/server/services/advisorService.ts\nimport { Configuration, OpenAIApi } from 'openai';\nimport { getCampaignState } from '@/server/repositories/campaignRepository';\nimport { createPendingAction } from '@/server/repositories/actionRepository';\n\nconst DOMAINS = ['economy', 'military', 'science', 'logistics', 'governance', 'diplomacy'];\n\nexport async function queryAdvisor(domain, campaignId, question) {\n  if (!DOMAINS.includes(domain)) {\n    throw new Error(`Invalid advisor domain: ${domain}`);\n  }\n  \n  // Get current campaign state for context\n  const state = await getCampaignState(campaignId);\n  \n  // If AI is disabled, return template recommendations\n  if (!process.env.OPENAI_API_KEY) {\n    return getTemplateRecommendations(domain, state);\n  }\n  \n  // Initialize OpenAI\n  const configuration = new Configuration({\n    apiKey: process.env.OPENAI_API_KEY,\n  });\n  const openai = new OpenAIApi(configuration);\n  \n  // Prepare domain-specific context\n  const context = getDomainContext(domain, state);\n  \n  // Call OpenAI API\n  const completion = await openai.createCompletion({\n    model: \"text-davinci-003\",\n    prompt: `You are a ${domain} advisor in a space strategy game. The current state is:\\n${JSON.stringify(context, null, 2)}\\n\\nQuestion: ${question}\\n\\nProvide 3 specific recommendations with projected impact on KPIs.`,\n    max_tokens: 500,\n  });\n  \n  // Parse and structure the response\n  const aiResponse = completion.data.choices[0].text;\n  const recommendations = parseRecommendations(aiResponse);\n  \n  return {\n    recommendations,\n    projectedImpact: calculateProjectedImpact(recommendations, state)\n  };\n}\n\nexport async function proposeAction(domain, campaignId, action) {\n  if (!DOMAINS.includes(domain)) {\n    throw new Error(`Invalid advisor domain: ${domain}`);\n  }\n  \n  // Validate the action is appropriate for the domain\n  validateDomainAction(domain, action);\n  \n  // Create a pending action\n  const pendingAction = await createPendingAction({\n    domain,\n    payload: action\n  });\n  \n  return {\n    success: true,\n    pendingActionId: pendingAction.id,\n    message: `Action proposed and pending approval`\n  };\n}\n\n// Helper functions for template responses, context preparation, etc.\n```",
        "testStrategy": "1. Unit tests for each advisor domain to verify recommendation logic\n2. Test the query endpoint with various questions and verify the response format\n3. Test the propose endpoint and verify that pending actions are correctly stored\n4. Integration test to ensure proposed actions are executed in the next simulation step when approved\n5. Verify that the endpoints handle invalid domains appropriately",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Database Migration for Pending Actions",
            "description": "Implement the database migration script for the pending_actions table that will store proposed actions from AI advisors.",
            "dependencies": [],
            "details": "Create a migration file that implements the pending_actions table with the specified schema including id, domain (with domain validation), payload, created_at, approved_at, and executed_at fields. Ensure proper indexing for efficient querying by domain and status.",
            "status": "pending",
            "testStrategy": "Verify the migration runs successfully and creates the table with correct constraints. Test inserting valid and invalid domain values to confirm the CHECK constraint works properly. Verify timestamp fields default correctly."
          },
          {
            "id": 2,
            "title": "Implement Domain-Specific Advisor Logic",
            "description": "Create the core advisor service with specialized logic for each domain (economy, military, science, logistics, governance, diplomacy).",
            "dependencies": [
              "6.1"
            ],
            "details": "Implement the advisor service with domain-specific context preparation, recommendation generation, and impact calculation functions. Create helper functions for each domain that understand the relevant game state metrics and can provide appropriate recommendations. Include fallback template recommendations when AI is disabled.",
            "status": "pending",
            "testStrategy": "Unit test each domain's recommendation logic with various game states. Verify that recommendations are relevant to the domain. Test the fallback mechanism when OpenAI integration is disabled."
          },
          {
            "id": 3,
            "title": "Implement Advisor API Endpoints",
            "description": "Create the API endpoints for querying advisors and proposing actions based on their recommendations.",
            "dependencies": [
              "6.2"
            ],
            "details": "Implement the POST /api/advisors/:domain/query endpoint for asking questions to domain-specific advisors and POST /api/advisors/:domain/propose for submitting actions for approval. Include proper validation for domain parameters and request payloads. Ensure authentication and rate limiting are implemented.",
            "status": "pending",
            "testStrategy": "Test both endpoints with valid and invalid domains. Verify query responses contain structured recommendations. Test action proposals are correctly stored in the pending_actions table. Verify error handling for invalid requests."
          },
          {
            "id": 4,
            "title": "Implement Action Approval and Execution System",
            "description": "Create the system for reviewing, approving, and executing pending actions proposed by advisors.",
            "dependencies": [
              "6.1",
              "6.3"
            ],
            "details": "Implement endpoints for listing pending actions (GET /api/pending-actions), approving actions (POST /api/pending-actions/:id/approve), and rejecting actions (POST /api/pending-actions/:id/reject). Create a service that executes approved actions by updating the appropriate game state based on the action domain and payload.",
            "status": "pending",
            "testStrategy": "Test the approval workflow from proposal to execution. Verify that approved_at and executed_at timestamps are correctly updated. Test that rejected actions are properly handled. Verify that executed actions correctly modify the game state."
          },
          {
            "id": 5,
            "title": "Implement AI Integration with OpenAI",
            "description": "Integrate the advisor system with OpenAI's API to generate intelligent, context-aware recommendations.",
            "dependencies": [
              "6.2",
              "6.3"
            ],
            "details": "Implement the OpenAI API integration for generating advisor recommendations. Create prompt templates for each domain that include relevant game state context. Implement response parsing to extract structured recommendations from AI completions. Add error handling and retry logic for API failures.",
            "status": "pending",
            "testStrategy": "Test the OpenAI integration with mock responses. Verify that prompts include appropriate context for each domain. Test the parsing logic with various AI responses. Verify graceful degradation when the API is unavailable."
          }
        ]
      },
      {
        "id": 7,
        "title": "Integrate Policy Modifiers with Simulation Engine",
        "description": "Extend the simulation engine to apply active policy modifiers during each step of the simulation.",
        "details": "Modify the simulation engine to read and apply active policy modifiers during each simulation step.\n\nImplementation details:\n1. Update the engine.ts file to load active policy modifiers at the beginning of each step\n2. Implement a policyModifierReducer function that applies the modifiers to the appropriate game state values\n3. Ensure modifiers are applied within their capped ranges\n4. Log all applied modifiers with provenance for reproducibility\n\nExample implementation:\n```typescript\n// src/server/sim/engine.ts - Add to existing file\nimport { getActiveModifiers } from '@/server/repositories/policyRepository';\n\n// Add to step function\nasync function step({ campaignId, seed, actions = [] }) {\n  // ... existing code ...\n  \n  // Load active policy modifiers\n  const activeModifiers = await getActiveModifiers();\n  \n  // ... run reducers ...\n  const afterProxies = readinessAndScienceReducer(afterPrices, rng);\n  const afterPolicies = policyModifierReducer(afterProxies, activeModifiers, rng);\n  const finalState = kpiAndVeziesReducer(afterPolicies, rng);\n  \n  // ... existing code ...\n}\n\n// Policy modifier reducer\nfunction policyModifierReducer(state, modifiers, rng) {\n  const newState = { ...state };\n  const appliedModifiers = [];\n  \n  // Group modifiers by key for easier processing\n  const modifiersByKey = modifiers.reduce((acc, mod) => {\n    if (!acc[mod.key]) acc[mod.key] = [];\n    acc[mod.key].push(mod);\n    return acc;\n  }, {});\n  \n  // Apply production modifiers\n  if (modifiersByKey.uptime_mult) {\n    const uptimeModifier = calculateCombinedModifier(modifiersByKey.uptime_mult);\n    newState.production.uptime *= uptimeModifier;\n    appliedModifiers.push({ key: 'uptime_mult', value: uptimeModifier, source: 'policy' });\n  }\n  \n  if (modifiersByKey.throughput_mult) {\n    const throughputModifier = calculateCombinedModifier(modifiersByKey.throughput_mult);\n    newState.production.throughput *= throughputModifier;\n    appliedModifiers.push({ key: 'throughput_mult', value: throughputModifier, source: 'policy' });\n  }\n  \n  // Apply logistics modifiers\n  if (modifiersByKey.capacity_mult) {\n    const capacityModifier = calculateCombinedModifier(modifiersByKey.capacity_mult);\n    newState.logistics.capacity *= capacityModifier;\n    appliedModifiers.push({ key: 'capacity_mult', value: capacityModifier, source: 'policy' });\n  }\n  \n  if (modifiersByKey.risk_delta) {\n    const riskDelta = calculateCombinedDelta(modifiersByKey.risk_delta);\n    newState.logistics.risk += riskDelta;\n    newState.logistics.risk = Math.max(0, Math.min(1, newState.logistics.risk)); // Clamp between 0 and 1\n    appliedModifiers.push({ key: 'risk_delta', value: riskDelta, source: 'policy' });\n  }\n  \n  // Apply price modifiers\n  // ... similar implementation for other modifier types ...\n  \n  // Log all applied modifiers\n  newState.logs.push({\n    type: 'policy_modifiers',\n    timestamp: new Date(),\n    data: { appliedModifiers }\n  });\n  \n  return newState;\n}\n\n// Helper function to calculate combined multiplicative modifiers\nfunction calculateCombinedModifier(modifiers) {\n  return modifiers.reduce((acc, mod) => acc * mod.value, 1);\n}\n\n// Helper function to calculate combined additive deltas\nfunction calculateCombinedDelta(modifiers) {\n  return modifiers.reduce((acc, mod) => acc + mod.value, 0);\n}\n```",
        "testStrategy": "1. Unit test the policyModifierReducer function with various modifier combinations\n2. Test that modifiers are correctly applied within their capped ranges\n3. Verify that the combined effect of multiple modifiers of the same type is calculated correctly\n4. Test that all applied modifiers are properly logged\n5. Integration test to verify that policies created and activated through the API affect the simulation as expected",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Update engine.ts to load active policy modifiers",
            "description": "Modify the simulation engine to fetch active policy modifiers at the beginning of each simulation step.",
            "dependencies": [],
            "details": "Update the step function in engine.ts to import and call getActiveModifiers from the policy repository. Ensure the modifiers are loaded before any reducers are applied. Add appropriate error handling for cases where modifiers cannot be loaded.",
            "status": "pending",
            "testStrategy": "Test that the engine correctly loads active modifiers at the beginning of each step. Verify error handling when the policy repository is unavailable."
          },
          {
            "id": 2,
            "title": "Implement policyModifierReducer function",
            "description": "Create a reducer function that applies policy modifiers to the appropriate game state values.",
            "dependencies": [
              "7.1"
            ],
            "details": "Implement the policyModifierReducer function that takes the current state, active modifiers, and RNG as inputs. Group modifiers by key for easier processing. Apply modifiers to production, logistics, and other relevant game state properties. Return the modified state.",
            "status": "pending",
            "testStrategy": "Unit test the policyModifierReducer with various modifier combinations. Verify that different types of modifiers (multiplicative, additive) are correctly applied to the appropriate state properties."
          },
          {
            "id": 3,
            "title": "Implement modifier capping and validation",
            "description": "Ensure all applied modifiers are within their defined capped ranges.",
            "dependencies": [
              "7.2"
            ],
            "details": "Add validation to ensure that after modifiers are applied, the affected values remain within their allowed ranges. Implement helper functions like calculateCombinedModifier and calculateCombinedDelta to properly combine multiple modifiers of the same type. Add clamping functions to restrict values to their min/max bounds.",
            "status": "pending",
            "testStrategy": "Test that values are properly clamped when modifiers would push them beyond their allowed ranges. Verify that combined modifiers are calculated correctly when multiple modifiers affect the same property."
          },
          {
            "id": 4,
            "title": "Add logging for applied modifiers",
            "description": "Log all applied policy modifiers with provenance information for reproducibility.",
            "dependencies": [
              "7.2",
              "7.3"
            ],
            "details": "Extend the policyModifierReducer to track all applied modifiers in an appliedModifiers array. For each modifier, record its key, calculated value, and source. Add a new log entry to the state.logs array with type 'policy_modifiers' that includes the timestamp and applied modifiers data.",
            "status": "pending",
            "testStrategy": "Verify that all applied modifiers are correctly logged with their provenance information. Test that the logs contain accurate timestamps and modifier details."
          },
          {
            "id": 5,
            "title": "Integrate policyModifierReducer into the simulation pipeline",
            "description": "Update the simulation pipeline to include the policy modifier reducer between existing reducers.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.3",
              "7.4"
            ],
            "details": "Modify the step function to call the policyModifierReducer at the appropriate point in the simulation pipeline. Position it after the readinessAndScienceReducer and before the kpiAndVeziesReducer. Ensure the modified state is passed correctly to subsequent reducers.",
            "status": "pending",
            "testStrategy": "Integration test the full simulation pipeline to verify that policy modifiers are correctly applied during each step. Test that the effects of policy modifiers are properly reflected in the final state and subsequent calculations."
          }
        ]
      },
      {
        "id": 8,
        "title": "Integrate Advisor Actions with Simulation Engine",
        "description": "Extend the simulation engine to process and apply pending advisor actions during each simulation step.",
        "details": "Modify the simulation engine to process pending advisor actions during each simulation step.\n\nImplementation details:\n1. Update the engine.ts file to load approved pending actions at the beginning of each step\n2. Implement domain-specific action handlers for each advisor domain\n3. Mark actions as executed after they are processed\n4. Log all executed actions with their effects\n\nExample implementation:\n```typescript\n// src/server/sim/engine.ts - Add to existing file\nimport { getApprovedPendingActions, markActionsExecuted } from '@/server/repositories/actionRepository';\n\n// Add to step function\nasync function step({ campaignId, seed, actions = [] }) {\n  // ... existing code ...\n  \n  // Load approved pending actions\n  const pendingActions = await getApprovedPendingActions();\n  \n  // Apply pending actions to initial state\n  const stateWithActions = applyPendingActions(state, [...actions, ...pendingActions]);\n  \n  // ... run reducers ...\n  \n  // Mark pending actions as executed\n  await markActionsExecuted(pendingActions.map(a => a.id));\n  \n  // ... existing code ...\n}\n\n// Function to apply pending actions\nfunction applyPendingActions(state, actions) {\n  const newState = { ...state };\n  const executedActions = [];\n  \n  for (const action of actions) {\n    try {\n      switch (action.domain) {\n        case 'economy':\n          applyEconomyAction(newState, action.payload);\n          break;\n        case 'military':\n          applyMilitaryAction(newState, action.payload);\n          break;\n        case 'science':\n          applyScienceAction(newState, action.payload);\n          break;\n        case 'logistics':\n          applyLogisticsAction(newState, action.payload);\n          break;\n        case 'governance':\n          applyGovernanceAction(newState, action.payload);\n          break;\n        case 'diplomacy':\n          applyDiplomacyAction(newState, action.payload);\n          break;\n        default:\n          throw new Error(`Unknown action domain: ${action.domain}`);\n      }\n      \n      executedActions.push({\n        id: action.id,\n        domain: action.domain,\n        payload: action.payload,\n        status: 'executed'\n      });\n    } catch (error) {\n      console.error(`Failed to apply ${action.domain} action:`, error);\n      executedActions.push({\n        id: action.id,\n        domain: action.domain,\n        payload: action.payload,\n        status: 'failed',\n        error: error.message\n      });\n    }\n  }\n  \n  // Log all executed actions\n  newState.logs.push({\n    type: 'executed_actions',\n    timestamp: new Date(),\n    data: { executedActions }\n  });\n  \n  return newState;\n}\n\n// Domain-specific action handlers\nfunction applyEconomyAction(state, payload) {\n  switch (payload.type) {\n    case 'adjust_tariff':\n      state.economy.tariffRate += payload.delta;\n      state.economy.tariffRate = Math.max(0, Math.min(1, state.economy.tariffRate)); // Clamp between 0 and 1\n      break;\n    case 'adjust_subsidy':\n      state.economy.subsidyRate += payload.delta;\n      state.economy.subsidyRate = Math.max(0, Math.min(1, state.economy.subsidyRate)); // Clamp between 0 and 1\n      break;\n    // ... other economy action types ...\n    default:\n      throw new Error(`Unknown economy action type: ${payload.type}`);\n  }\n}\n\n// ... similar implementations for other domains ...\n```",
        "testStrategy": "1. Unit test each domain-specific action handler\n2. Test the applyPendingActions function with various action combinations\n3. Verify that actions are correctly marked as executed after processing\n4. Test error handling for invalid actions\n5. Integration test to verify that advisor actions proposed and approved through the API affect the simulation as expected",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Update engine.ts to load pending actions",
            "description": "Modify the simulation engine to fetch approved pending actions at the beginning of each step and prepare them for processing.",
            "dependencies": [],
            "details": "Update the engine.ts file to import necessary functions from actionRepository. Add code to the step function to fetch approved pending actions using getApprovedPendingActions(). Combine these pending actions with any explicitly passed actions for processing in the simulation step.",
            "status": "pending",
            "testStrategy": "Unit test the modified step function to verify it correctly fetches and combines pending actions. Mock the repository functions to return predefined test actions."
          },
          {
            "id": 2,
            "title": "Implement applyPendingActions function",
            "description": "Create a function that applies a list of actions to the simulation state and tracks their execution status.",
            "dependencies": [
              "8.1"
            ],
            "details": "Implement the applyPendingActions function that takes the current state and a list of actions. The function should create a copy of the state, process each action based on its domain, and track which actions were executed successfully or failed. Return the updated state with all actions applied.",
            "status": "pending",
            "testStrategy": "Test the function with various combinations of actions across different domains. Verify it properly handles errors for invalid actions without affecting other actions' execution."
          },
          {
            "id": 3,
            "title": "Implement domain-specific action handlers",
            "description": "Create handler functions for each advisor domain that apply domain-specific actions to the simulation state.",
            "dependencies": [
              "8.2"
            ],
            "details": "Implement separate handler functions for each domain (economy, military, science, logistics, governance, diplomacy). Each handler should process different action types within its domain and apply the appropriate changes to the simulation state. Include proper validation and error handling for each action type.",
            "status": "pending",
            "testStrategy": "Unit test each domain handler with various action types and payloads. Verify that state changes are applied correctly and that invalid actions throw appropriate errors."
          },
          {
            "id": 4,
            "title": "Add action execution logging",
            "description": "Extend the simulation state to log all executed actions with their effects and status.",
            "dependencies": [
              "8.2",
              "8.3"
            ],
            "details": "Modify the applyPendingActions function to add entries to the state's logs array for all executed actions. Each log entry should include the action ID, domain, payload, execution status (executed/failed), timestamp, and any error messages for failed actions.",
            "status": "pending",
            "testStrategy": "Test that actions are properly logged in the state with correct timestamps and details. Verify both successful and failed actions are logged appropriately."
          },
          {
            "id": 5,
            "title": "Implement action execution marking",
            "description": "Update the repository to mark actions as executed after they are processed by the simulation engine.",
            "dependencies": [
              "8.2",
              "8.4"
            ],
            "details": "After all actions are applied and logged, call the markActionsExecuted function with the IDs of all processed actions. Update the actionRepository implementation to properly mark these actions as executed in the database with an execution timestamp.",
            "status": "pending",
            "testStrategy": "Test that actions are correctly marked as executed in the database after processing. Verify that subsequent simulation steps don't reprocess already executed actions."
          }
        ]
      },
      {
        "id": 9,
        "title": "Implement KPI and Vezies Integration",
        "description": "Integrate KPI tracking and Vezies scoring into the simulation engine and create endpoints for retrieving analytics data.",
        "details": "Implement KPI tracking and Vezies scoring in the simulation engine and update analytics endpoints to use the engine data.\n\nImplementation details:\n1. Create a kpiAndVeziesReducer function in the engine that calculates KPIs and generates Vezies events\n2. Persist KPI snapshots to the kpi_snapshots table\n3. Generate Vezies events for queue completion, planet creation, and production milestones\n4. Update the GET /api/analytics/empire endpoint to use the latest KPI snapshot from the engine\n\nExample implementation:\n```typescript\n// src/server/sim/engine.ts - Add to existing file\nimport { createKpiSnapshot } from '@/server/repositories/kpiRepository';\nimport { createVezyEvent } from '@/server/repositories/vezyRepository';\n\n// KPI and Vezies reducer\nfunction kpiAndVeziesReducer(state, rng) {\n  const newState = { ...state };\n  const vezyEvents = [];\n  \n  // Calculate KPIs\n  const kpis = calculateKpis(newState);\n  newState.kpis = kpis;\n  \n  // Check for queue completions\n  const completedQueues = findCompletedQueues(state, newState);\n  for (const queue of completedQueues) {\n    vezyEvents.push({\n      type: 'queue_completion',\n      source: 'empire',\n      data: { queueId: queue.id, itemType: queue.itemType }\n    });\n  }\n  \n  // Check for new planets\n  const newPlanets = findNewPlanets(state, newState);\n  for (const planet of newPlanets) {\n    vezyEvents.push({\n      type: 'planet_creation',\n      source: 'discovery',\n      data: { planetId: planet.id, systemId: planet.systemId }\n    });\n  }\n  \n  // Check for production milestones\n  const productionMilestones = findProductionMilestones(state, newState);\n  for (const milestone of productionMilestones) {\n    vezyEvents.push({\n      type: 'production_milestone',\n      source: 'empire',\n      data: { resourceType: milestone.resourceType, amount: milestone.amount }\n    });\n  }\n  \n  newState.vezyEvents = vezyEvents;\n  \n  return newState;\n}\n\n// Helper function to calculate KPIs\nfunction calculateKpis(state) {\n  return {\n    economy: {\n      gdp: calculateGdp(state),\n      resourceBalance: calculateResourceBalance(state),\n      tradeVolume: calculateTradeVolume(state)\n    },\n    military: {\n      fleetStrength: calculateFleetStrength(state),\n      readiness: state.military.readiness\n    },\n    science: {\n      researchOutput: calculateResearchOutput(state),\n      techLevel: state.science.techLevel\n    },\n    logistics: {\n      capacity: state.logistics.capacity,\n      efficiency: calculateLogisticsEfficiency(state)\n    },\n    governance: {\n      stability: calculateStability(state),\n      approval: calculateApproval(state)\n    }\n  };\n}\n\n// Helper functions for finding events and calculating KPIs\n// ...\n\n// Update persistKpiSnapshot function\nasync function persistKpiSnapshot(campaignId, kpis, tx) {\n  return createKpiSnapshot({\n    campaignId,\n    timestamp: new Date(),\n    data: kpis\n  }, tx);\n}\n\n// Function to emit Vezies events\nasync function emitVeziesEvents(events, tx) {\n  for (const event of events) {\n    await createVezyEvent({\n      type: event.type,\n      source: event.source,\n      sourceId: event.data.id || null,\n      data: event.data\n    }, tx);\n  }\n}\n```\n\n// Update analytics endpoint\n```typescript\n// src/pages/api/analytics/empire.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { getLatestKpiSnapshot } from '@/server/repositories/kpiRepository';\nimport { getLegacyAnalytics } from '@/server/services/analyticsService';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'GET') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  const { campaignId } = req.query;\n  \n  if (!campaignId) {\n    return res.status(400).json({ error: 'campaignId is required' });\n  }\n\n  try {\n    // Try to get the latest KPI snapshot from the engine\n    const latestSnapshot = await getLatestKpiSnapshot(campaignId);\n    \n    if (latestSnapshot) {\n      return res.status(200).json({\n        success: true,\n        kpis: latestSnapshot.data,\n        timestamp: latestSnapshot.timestamp,\n        source: 'engine'\n      });\n    }\n    \n    // Fall back to legacy analytics if no snapshot exists\n    const legacyAnalytics = await getLegacyAnalytics(campaignId);\n    \n    return res.status(200).json({\n      success: true,\n      kpis: legacyAnalytics,\n      timestamp: new Date(),\n      source: 'legacy'\n    });\n  } catch (error) {\n    console.error('Analytics error:', error);\n    return res.status(500).json({ error: 'Failed to retrieve analytics' });\n  }\n}\n```",
        "testStrategy": "1. Unit test the kpiAndVeziesReducer function to verify KPI calculations\n2. Test the event generation logic for queue completions, new planets, and production milestones\n3. Verify that KPI snapshots are correctly persisted to the database\n4. Test the GET /api/analytics/empire endpoint to ensure it returns the latest KPI snapshot\n5. Verify that the endpoint falls back to legacy analytics when no snapshot exists",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement kpiAndVeziesReducer function",
            "description": "Create a reducer function in the simulation engine that calculates KPIs and generates Vezies events based on state changes.",
            "dependencies": [],
            "details": "Develop the kpiAndVeziesReducer function that takes the current state and returns a new state with updated KPIs and Vezies events. Implement helper functions for calculating various KPIs (economy, military, science, logistics, governance) and detecting events like queue completions, planet creations, and production milestones.",
            "status": "pending",
            "testStrategy": "Write unit tests to verify KPI calculations for different game states. Test event detection logic for queue completions, new planets, and production milestones. Ensure the reducer properly maintains state immutability."
          },
          {
            "id": 2,
            "title": "Implement KPI snapshot persistence",
            "description": "Create functionality to persist KPI snapshots to the database at regular intervals during simulation.",
            "dependencies": [
              "9.1"
            ],
            "details": "Implement the persistKpiSnapshot function that saves KPI data to the kpi_snapshots table. Ensure this function is called at appropriate intervals during the simulation cycle. Include timestamp and campaign ID with each snapshot. Create necessary database repository functions.",
            "status": "pending",
            "testStrategy": "Test that KPI snapshots are correctly persisted to the database with proper timestamps. Verify that snapshots contain all required KPI metrics. Test error handling for database operations."
          },
          {
            "id": 3,
            "title": "Implement Vezies event generation",
            "description": "Create functionality to generate and persist Vezies events for key game milestones.",
            "dependencies": [
              "9.1"
            ],
            "details": "Implement the emitVeziesEvents function that creates Vezies events in the database. Generate events for queue completions, planet creations, and production milestones. Ensure each event has the correct type, source, and data payload. Create necessary database repository functions for the vezy_events table.",
            "status": "pending",
            "testStrategy": "Test that Vezies events are correctly generated for different game state changes. Verify that events contain the proper metadata and payloads. Test error handling for event persistence."
          },
          {
            "id": 4,
            "title": "Update analytics endpoint",
            "description": "Modify the GET /api/analytics/empire endpoint to use the latest KPI snapshot from the engine.",
            "dependencies": [
              "9.2"
            ],
            "details": "Update the analytics endpoint to retrieve the latest KPI snapshot from the database. Implement fallback to legacy analytics if no snapshot exists. Return the KPI data with timestamp and source information. Add proper error handling and validation for the campaignId parameter.",
            "status": "pending",
            "testStrategy": "Test the endpoint with various scenarios including existing snapshots and fallback to legacy analytics. Verify the response format and error handling. Test with invalid campaign IDs and other edge cases."
          },
          {
            "id": 5,
            "title": "Integrate KPI and Vezies with simulation cycle",
            "description": "Integrate the KPI and Vezies functionality into the main simulation cycle.",
            "dependencies": [
              "9.1",
              "9.2",
              "9.3"
            ],
            "details": "Update the main simulation cycle to include the kpiAndVeziesReducer in the processing pipeline. Ensure KPI snapshots are persisted and Vezies events are emitted at appropriate points in the cycle. Add transaction support to ensure data consistency between the simulation state and persisted data.",
            "status": "pending",
            "testStrategy": "Perform integration testing of the full simulation cycle with KPI and Vezies functionality. Verify that KPIs are calculated and persisted correctly during simulation. Test that Vezies events are generated at the right moments. Check for performance impacts on the simulation cycle."
          }
        ]
      },
      {
        "id": 10,
        "title": "Implement HUD Updates and UI Integration",
        "description": "Update the HUD to display simulation results, policy management, and advisor recommendations.",
        "details": "Update the HUD to integrate with the simulation engine, policy management, and advisor systems.\n\nImplementation details:\n1. Add a Step Engine button to /demo/hud that triggers a simulation step\n2. Create a Policies panel for submitting and managing policies\n3. Create an Advisors panel for querying advisors and proposing actions\n4. Update the analytics display to show the latest KPI data\n\nExample implementation:\n```typescript\n// src/components/demo/SimulationControls.tsx\nimport { useState } from 'react';\nimport { Button, Alert } from '@/components/ui';\n\nexport function SimulationControls({ campaignId }) {\n  const [loading, setLoading] = useState(false);\n  const [result, setResult] = useState(null);\n  const [error, setError] = useState(null);\n\n  const handleStepEngine = async () => {\n    setLoading(true);\n    setError(null);\n    \n    try {\n      const response = await fetch('/api/sim/step', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ campaignId })\n      });\n      \n      const data = await response.json();\n      \n      if (!response.ok) {\n        throw new Error(data.error || 'Failed to step engine');\n      }\n      \n      setResult(data);\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"p-4 border rounded-lg\">\n      <h2 className=\"text-xl font-bold mb-4\">Simulation Controls</h2>\n      \n      <Button \n        onClick={handleStepEngine} \n        disabled={loading}\n        className=\"mb-4\"\n      >\n        {loading ? 'Processing...' : 'Step Engine'}\n      </Button>\n      \n      {error && (\n        <Alert variant=\"error\" className=\"mb-4\">\n          {error}\n        </Alert>\n      )}\n      \n      {result && (\n        <div className=\"mt-4\">\n          <h3 className=\"font-semibold\">Last Step Results:</h3>\n          <pre className=\"bg-gray-100 p-2 rounded mt-2 text-xs overflow-auto\">\n            {JSON.stringify(result, null, 2)}\n          </pre>\n        </div>\n      )}\n    </div>\n  );\n}\n\n// src/components/demo/PolicyPanel.tsx\nimport { useState } from 'react';\nimport { Button, TextArea, Input, Select } from '@/components/ui';\n\nexport function PolicyPanel({ campaignId }) {\n  const [title, setTitle] = useState('');\n  const [body, setBody] = useState('');\n  const [scope, setScope] = useState('campaign');\n  const [suggestions, setSuggestions] = useState(null);\n  const [loading, setLoading] = useState(false);\n  const [error, setError] = useState(null);\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    setLoading(true);\n    setError(null);\n    \n    try {\n      const response = await fetch('/api/policies/parse', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ title, body, scope })\n      });\n      \n      const data = await response.json();\n      \n      if (!response.ok) {\n        throw new Error(data.error || 'Failed to parse policy');\n      }\n      \n      setSuggestions(data.suggestedModifiers);\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const handleActivate = async () => {\n    setLoading(true);\n    setError(null);\n    \n    try {\n      // First create the policy\n      const createResponse = await fetch('/api/policies', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ title, body, scope })\n      });\n      \n      const policyData = await createResponse.json();\n      \n      if (!createResponse.ok) {\n        throw new Error(policyData.error || 'Failed to create policy');\n      }\n      \n      // Then activate the modifiers\n      const activateResponse = await fetch('/api/policies/activate', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          policyId: policyData.policy.id,\n          modifiers: suggestions\n        })\n      });\n      \n      const activateData = await activateResponse.json();\n      \n      if (!activateResponse.ok) {\n        throw new Error(activateData.error || 'Failed to activate policy');\n      }\n      \n      // Reset form\n      setTitle('');\n      setBody('');\n      setSuggestions(null);\n      \n      alert('Policy created and activated successfully!');\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"p-4 border rounded-lg\">\n      <h2 className=\"text-xl font-bold mb-4\">Policy Console</h2>\n      \n      <form onSubmit={handleSubmit}>\n        <Input\n          label=\"Title\"\n          value={title}\n          onChange={(e) => setTitle(e.target.value)}\n          required\n          className=\"mb-4\"\n        />\n        \n        <Select\n          label=\"Scope\"\n          value={scope}\n          onChange={(e) => setScope(e.target.value)}\n          options={[\n            { value: 'campaign', label: 'Campaign' },\n            { value: 'region', label: 'Region' },\n            { value: 'system', label: 'System' }\n          ]}\n          className=\"mb-4\"\n        />\n        \n        <TextArea\n          label=\"Policy Text\"\n          value={body}\n          onChange={(e) => setBody(e.target.value)}\n          rows={6}\n          required\n          className=\"mb-4\"\n        />\n        \n        <Button type=\"submit\" disabled={loading}>\n          {loading ? 'Analyzing...' : 'Analyze Policy'}\n        </Button>\n      </form>\n      \n      {error && (\n        <Alert variant=\"error\" className=\"my-4\">\n          {error}\n        </Alert>\n      )}\n      \n      {suggestions && (\n        <div className=\"mt-6\">\n          <h3 className=\"font-semibold mb-2\">Suggested Modifiers:</h3>\n          \n          <ul className=\"mb-4\">\n            {suggestions.map((mod, index) => (\n              <li key={index} className=\"mb-2\">\n                <strong>{mod.key}:</strong> {mod.value} (Range: {mod.cap_min} to {mod.cap_max})\n              </li>\n            ))}\n          </ul>\n          \n          <Button onClick={handleActivate} disabled={loading}>\n            {loading ? 'Activating...' : 'Approve & Activate'}\n          </Button>\n        </div>\n      )}\n    </div>\n  );\n}\n\n// Similar implementation for AdvisorPanel component\n// ...\n\n// Update main HUD component to include these new panels\n```",
        "testStrategy": "1. Playwright UI tests for the Step Engine button functionality\n2. Test the Policies panel flow: submit text → see suggestions → approve → step → KPI change\n3. Test the Advisors panel flow: ask → get recommendation → propose → step → change visible\n4. Verify that the analytics display updates after a simulation step\n5. Test error handling and loading states in all UI components",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement SimulationControls Component",
            "description": "Create a component that allows users to trigger simulation steps and view results",
            "dependencies": [],
            "details": "Develop the SimulationControls.tsx component that includes a 'Step Engine' button to trigger simulation steps. The component should handle API calls to /api/sim/step, display loading states, show errors if they occur, and present the results of the simulation step in a readable format. Include proper error handling and loading indicators.",
            "status": "pending",
            "testStrategy": "Test the API integration with mock responses, verify loading states are correctly displayed, ensure error messages appear when API calls fail, and confirm simulation results are properly rendered."
          },
          {
            "id": 2,
            "title": "Implement PolicyPanel Component",
            "description": "Create a component for submitting and managing policies with modifier suggestions",
            "dependencies": [
              "10.1"
            ],
            "details": "Develop the PolicyPanel.tsx component that allows users to create policies with title, body, and scope. Implement form validation, API integration with /api/policies/parse for analysis, and /api/policies and /api/policies/activate for creation and activation. Display suggested modifiers and provide approval functionality.",
            "status": "pending",
            "testStrategy": "Test form validation, API integration for policy parsing, verify modifier suggestions display correctly, test policy creation and activation flows, and ensure proper error handling throughout the process."
          },
          {
            "id": 3,
            "title": "Implement AdvisorPanel Component",
            "description": "Create a component for querying advisors and proposing actions based on recommendations",
            "dependencies": [
              "10.1"
            ],
            "details": "Develop the AdvisorPanel.tsx component that allows users to query domain-specific advisors and receive recommendations. Implement functionality to ask questions, display advisor responses, and propose actions based on recommendations. Include domain selection, question input, and action proposal confirmation.",
            "status": "pending",
            "testStrategy": "Test advisor query functionality with different domains, verify recommendation display, test action proposal flow, ensure proper error handling, and check that proposed actions are correctly submitted to the API."
          },
          {
            "id": 4,
            "title": "Update Analytics Display Component",
            "description": "Enhance the analytics display to show the latest KPI data from the simulation engine",
            "dependencies": [
              "10.1"
            ],
            "details": "Update the existing analytics display component to fetch and visualize the latest KPI data from the simulation engine. Implement data fetching from the /api/analytics/empire endpoint, create visualizations for key metrics, and ensure the display updates after simulation steps are executed.",
            "status": "pending",
            "testStrategy": "Test data fetching from the analytics API, verify visualizations correctly represent the data, ensure the display updates after simulation steps, and test fallback behavior when data is unavailable."
          },
          {
            "id": 5,
            "title": "Integrate Components into Main HUD",
            "description": "Combine all components into the main HUD interface with proper layout and styling",
            "dependencies": [
              "10.1",
              "10.2",
              "10.3",
              "10.4"
            ],
            "details": "Integrate the SimulationControls, PolicyPanel, AdvisorPanel, and updated Analytics Display components into the main HUD interface. Implement responsive layout, consistent styling, and ensure all components work together seamlessly. Add navigation between different panels if needed and ensure the UI is intuitive.",
            "status": "pending",
            "testStrategy": "Test the integrated HUD with all components, verify responsive behavior across different screen sizes, ensure consistent styling and theme application, test navigation between panels, and conduct end-to-end testing of complete workflows."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-14T06:47:15.594Z",
      "updated": "2025-08-14T06:47:15.594Z",
      "description": "Tasks for sprint-a-sim-engine context"
    }
  },
  "sprint-c-trade-markets": {
    "tasks": [
      {
        "id": 1,
        "title": "Setup Database Schema for Trade and Corporations",
        "description": "Create the initial database schema for the interstellar trade system including markets, tickers, order books, trades, corporations, shares, dividends, contracts, tariffs, and routes tables.",
        "details": "Implement the following tables as specified in the PRD:\n\n1. markets(id, region)\n2. tickers(id, ex_id, symbol, type)\n3. order_books(id, ticker_id, side, price, qty)\n4. trades(id, ticker_id, qty, price, buyer_id, seller_id, at)\n5. corps(id, name, hq_system_id)\n6. corp_shares(corp_id, owner_id, shares)\n7. corp_dividends(id, corp_id, amount, declared_at)\n8. contracts(id, buyer_id, seller_id, commodity, qty, price, deliver_at)\n9. tariffs(system_id, resource, rate)\n10. routes(id, from_id, to_id, capacity, risk)\n\nEnsure proper foreign key constraints, indexes for performance, and appropriate data types for each field. Add timestamps for created_at and updated_at where appropriate.",
        "testStrategy": "Write unit tests to verify schema creation, foreign key constraints, and basic CRUD operations for each table. Test data integrity constraints and verify that the schema matches the requirements specified in the PRD.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Market and Ticker Tables",
            "description": "Create the database schema for markets and tickers tables with appropriate relationships and constraints.",
            "dependencies": [],
            "details": "Implement the markets table with id and region fields. Implement the tickers table with id, ex_id, symbol, and type fields. Ensure proper foreign key relationship between tickers and markets. Add appropriate indexes for performance optimization. Include created_at and updated_at timestamp fields for both tables.",
            "status": "pending",
            "testStrategy": "Write unit tests to verify schema creation, foreign key constraints between markets and tickers, and basic CRUD operations. Test data integrity by attempting to insert invalid data."
          },
          {
            "id": 2,
            "title": "Implement Order Books and Trades Tables",
            "description": "Create the database schema for order books and trades tables with proper relationships to tickers.",
            "dependencies": [],
            "details": "Implement the order_books table with id, ticker_id, side, price, and qty fields. Implement the trades table with id, ticker_id, qty, price, buyer_id, seller_id, and at fields. Ensure proper foreign key relationships to the tickers table. Add appropriate indexes for performance, especially for frequent queries on price and time. Include created_at and updated_at timestamp fields.",
            "status": "pending",
            "testStrategy": "Test foreign key constraints to tickers table. Verify that trades can be properly recorded and retrieved. Test performance of common queries like retrieving recent trades for a specific ticker."
          },
          {
            "id": 3,
            "title": "Create Corporation and Shares Tables",
            "description": "Implement the database schema for corporations, shares, and dividends with appropriate relationships.",
            "dependencies": [],
            "details": "Implement the corps table with id, name, and hq_system_id fields. Create the corp_shares table with corp_id, owner_id, and shares fields. Implement the corp_dividends table with id, corp_id, amount, and declared_at fields. Ensure proper foreign key relationships between these tables. Add appropriate indexes for performance optimization. Include created_at and updated_at timestamp fields where appropriate.",
            "status": "pending",
            "testStrategy": "Test the integrity of corporation ownership data by verifying share allocations. Test dividend declaration and retrieval. Verify that constraints prevent invalid data like negative share counts."
          },
          {
            "id": 4,
            "title": "Develop Contracts and Tariffs Tables",
            "description": "Create the database schema for contracts and tariffs with appropriate constraints and indexes.",
            "dependencies": [],
            "details": "Implement the contracts table with id, buyer_id, seller_id, commodity, qty, price, and deliver_at fields. Create the tariffs table with system_id, resource, and rate fields. Ensure proper constraints to maintain data integrity, such as positive quantities and rates. Add appropriate indexes for performance optimization, especially for queries filtering by buyer, seller, or delivery date. Include created_at and updated_at timestamp fields for contracts.",
            "status": "pending",
            "testStrategy": "Test contract creation with various parameters. Verify that tariff rates can be properly set and retrieved. Test queries that would be common in the application, such as finding all contracts for a specific buyer or commodity."
          },
          {
            "id": 5,
            "title": "Implement Routes Table and Final Integration",
            "description": "Create the routes table and ensure all tables are properly integrated with consistent naming and relationship patterns.",
            "dependencies": [],
            "details": "Implement the routes table with id, from_id, to_id, capacity, and risk fields. Ensure proper foreign key relationships to relevant tables. Review all tables for consistency in naming conventions, data types, and relationship patterns. Verify that all required fields from the PRD are implemented. Create a database migration script that can be used to set up the entire schema. Document the schema with an ER diagram.",
            "status": "pending",
            "testStrategy": "Perform integration testing across all tables to verify that the entire schema works together. Test complex queries that join multiple tables. Verify that the migration script works correctly in a clean environment. Test performance of expected query patterns across the schema."
          }
        ]
      },
      {
        "id": 2,
        "title": "Implement Supply/Demand Price Calculation Engine",
        "description": "Develop the core pricing engine that calculates resource prices based on planet/system-level supply and demand curves.",
        "details": "Create a pricing module that:\n1. Maintains supply and demand curves for each resource per planet/system\n2. Calculates live prices based on current stockpiles and demand\n3. Implements a configurable pricing formula that responds to changes in supply/demand\n4. Provides an interface to query current prices\n5. Updates prices when stockpile quantities change\n\nThe price calculation should follow a formula like:\nPrice = BasePrice * (1 + DemandFactor * (1 - CurrentSupply/TargetSupply))\n\nWhere DemandFactor is tunable per resource and system.",
        "testStrategy": "Unit test the price calculation with various supply/demand scenarios. Verify that prices increase when supply decreases and vice versa. Test edge cases like zero supply or extremely high demand. Integration test with mock stockpile changes to ensure prices update correctly.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Supply/Demand Data Model",
            "description": "Create the data structures to represent supply and demand curves for resources at planet and system levels",
            "dependencies": [],
            "details": "Design and implement classes/interfaces for: Resource definitions with base prices and demand factors; Supply curve representation with current and target supply levels; Demand curve representation with elasticity parameters; Planet and system level aggregation of resource data; Data persistence layer for storing supply/demand state.",
            "status": "pending",
            "testStrategy": "Unit test the data model with mock resource data. Verify that supply/demand curves can be properly represented and manipulated. Test serialization/deserialization of the model for persistence."
          },
          {
            "id": 2,
            "title": "Implement Price Calculation Algorithm",
            "description": "Develop the core algorithm that calculates resource prices based on supply/demand curves",
            "dependencies": [
              "2.1"
            ],
            "details": "Implement the price calculation formula: Price = BasePrice * (1 + DemandFactor * (1 - CurrentSupply/TargetSupply)). Create configurable parameters for DemandFactor per resource and system. Handle edge cases like zero supply or extremely high demand. Implement caching for frequently accessed prices. Create unit tests for various supply/demand scenarios.",
            "status": "pending",
            "testStrategy": "Unit test the price calculation with various supply/demand ratios. Test edge cases like zero supply, zero demand, and extremely high demand. Verify that prices respond correctly to changes in supply and demand parameters."
          },
          {
            "id": 3,
            "title": "Develop Price Update Mechanism",
            "description": "Create the system that updates prices when stockpile quantities change",
            "dependencies": [
              "2.1",
              "2.2"
            ],
            "details": "Implement event listeners for stockpile changes. Create efficient batch update mechanism for multiple price changes. Design price update propagation to dependent systems. Implement transaction support to ensure price consistency. Add logging for price change events for auditing and debugging.",
            "status": "pending",
            "testStrategy": "Test price updates with simulated stockpile changes. Verify that prices update correctly when supply increases or decreases. Test concurrent updates to ensure thread safety. Measure performance with large batches of price updates."
          },
          {
            "id": 4,
            "title": "Create Price Query API",
            "description": "Develop the interface for external systems to query current resource prices",
            "dependencies": [
              "2.2",
              "2.3"
            ],
            "details": "Design RESTful API endpoints for price queries. Implement filtering by resource type, planet, and system. Create bulk query capability for multiple resources. Add caching layer for frequently queried prices. Implement versioning for the API. Document the API with OpenAPI/Swagger.",
            "status": "pending",
            "testStrategy": "Integration test the API endpoints with various query parameters. Test response formats and error handling. Benchmark API performance under load. Verify that price changes are reflected in API responses after updates."
          },
          {
            "id": 5,
            "title": "Implement Market Analysis Tools",
            "description": "Create utilities for analyzing and visualizing supply/demand trends and price histories",
            "dependencies": [
              "2.2",
              "2.4"
            ],
            "details": "Implement price history tracking and storage. Create time-series analysis tools for price trends. Develop supply/demand visualization components. Add market volatility metrics and indicators. Create price prediction models based on historical data. Implement export functionality for market data.",
            "status": "pending",
            "testStrategy": "Test history tracking with simulated market activity. Verify that analysis tools produce correct results with known test data. Test visualization components with extreme market conditions. Validate prediction models against historical outcomes."
          }
        ]
      },
      {
        "id": 3,
        "title": "Implement Trade Routes and Tariffs System",
        "description": "Create the system for defining trade routes between systems, including capacity, risk factors, and tariff calculations.",
        "details": "Build a trade routes module that:\n1. Stores route definitions between star systems\n2. Tracks capacity limits for each route\n3. Assigns risk factors (piracy placeholder) to routes\n4. Calculates tariffs based on system-specific rates\n5. Provides an API to query available routes and their properties\n\nImplement methods to:\n- Create/update/delete routes\n- Apply tariffs to trade contracts based on origin/destination\n- Calculate total shipping costs including tariffs\n- Track route utilization against capacity\n\nFor the piracy risk placeholder, simply store a risk factor (0.0-1.0) that can later be used for more complex calculations.",
        "testStrategy": "Unit test route creation, tariff calculation, and capacity tracking. Test edge cases like routes at full capacity or with extreme risk values. Integration test with the contract system to verify tariffs are correctly applied to trades.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Trade Route Data Model and CRUD Operations",
            "description": "Create the data structures and database schema for trade routes between star systems, along with API endpoints for creating, reading, updating, and deleting routes.",
            "dependencies": [],
            "details": "Design and implement a data model that includes: route ID, origin system, destination system, capacity limit, risk factor (0.0-1.0), and base tariff rate. Create database migrations and entity classes. Implement repository layer for data access. Develop service methods and REST endpoints for CRUD operations on routes. Include validation to ensure routes connect valid star systems and have appropriate capacity values.",
            "status": "pending",
            "testStrategy": "Unit test the repository and service layers with mock data. Test route creation with valid and invalid parameters. Verify that routes can be retrieved, updated, and deleted correctly. Test edge cases like duplicate routes between the same systems."
          },
          {
            "id": 2,
            "title": "Implement Capacity Tracking System",
            "description": "Build functionality to track and manage the utilization of trade routes against their defined capacity limits.",
            "dependencies": [
              "3.1"
            ],
            "details": "Develop a system to track current utilization of each trade route. Create methods to reserve capacity when a trade contract is created and release capacity when contracts are fulfilled or canceled. Implement validation to prevent exceeding route capacity. Add API endpoints to query current utilization and available capacity for routes. Include functionality to handle capacity overrides for special circumstances.",
            "status": "pending",
            "testStrategy": "Unit test capacity reservation and release functions. Test concurrent capacity requests to ensure thread safety. Verify that attempts to exceed capacity are properly rejected. Integration test with mock trade contracts to ensure capacity is correctly managed throughout the contract lifecycle."
          },
          {
            "id": 3,
            "title": "Develop Tariff Calculation Engine",
            "description": "Create the system for calculating tariffs based on route-specific rates, goods being transported, and other relevant factors.",
            "dependencies": [
              "3.1"
            ],
            "details": "Implement a tariff calculation engine that determines fees based on: base tariff rate of the route, type and value of goods being transported, special tariff rules between specific systems, and any applicable exemptions. Create a configurable formula for tariff calculation that can be adjusted per route or system. Develop methods to calculate total shipping costs including tariffs for trade contracts. Include functionality to handle tariff changes over time with effective dates.",
            "status": "pending",
            "testStrategy": "Unit test tariff calculations with various goods types and route configurations. Test edge cases like extremely high-value goods or zero-tariff routes. Verify that special tariff rules are correctly applied. Integration test with the trade contract system to ensure tariffs are properly included in total costs."
          },
          {
            "id": 4,
            "title": "Implement Risk Factor System",
            "description": "Develop the placeholder system for assigning and managing risk factors for trade routes, which will later be used for piracy and other risk calculations.",
            "dependencies": [
              "3.1"
            ],
            "details": "Create a system to assign and store risk factors (0.0-1.0) for each trade route. Implement methods to update risk factors based on events or administrative actions. Develop an API to query risk factors for routes. Include functionality to calculate risk-adjusted costs or insurance premiums based on the risk factor. Design the system to be extensible for future implementation of more complex risk models.",
            "status": "pending",
            "testStrategy": "Unit test risk factor assignment and retrieval. Test calculation of risk-adjusted costs with various risk levels. Verify that risk factors remain within the valid range (0.0-1.0). Integration test the risk factor API endpoints."
          },
          {
            "id": 5,
            "title": "Create Trade Route Query API and Integration",
            "description": "Develop a comprehensive API for querying available routes and their properties, and integrate the trade routes system with the existing contract system.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.3",
              "3.4"
            ],
            "details": "Implement API endpoints to: query available routes between systems, filter routes by capacity, risk, or tariff rates, get detailed information about specific routes, and find optimal routes based on cost or risk. Integrate the trade routes system with the contract system to automatically apply appropriate tariffs and capacity management when contracts are created. Create documentation for the API including example requests and responses. Implement caching for frequently queried route information to improve performance.",
            "status": "pending",
            "testStrategy": "Unit test all API endpoints with various query parameters. Test route optimization with different criteria (lowest cost, lowest risk, etc.). Integration test with the contract system to verify that routes are correctly applied to trade contracts. Performance test the API with large numbers of routes to ensure acceptable response times."
          }
        ]
      },
      {
        "id": 4,
        "title": "Develop Contract System for Spot and Offtake Deals",
        "description": "Implement the contracts endpoint that allows creating and managing spot (immediate) and offtake (long-term) resource deals between parties.",
        "details": "Create a contract system that:\n1. Allows creation of spot contracts (immediate delivery)\n2. Supports offtake contracts (scheduled future delivery)\n3. Validates contract terms (buyer/seller existence, resource availability)\n4. Processes immediate transfers for spot contracts\n5. Schedules future transfers for offtake contracts\n6. Tracks contract status and completion\n\nThe contract API should:\n- Accept POST requests with contract details (buyerId, sellerId, resource, qty, price, deliverAt)\n- Validate resource availability in seller's stockpile\n- Reduce seller stockpiles immediately for spot contracts\n- Schedule delivery for offtake contracts to occur on the specified tick\n- Return contract details including unique ID\n\nImplement a tick-based processor that executes scheduled deliveries when their time arrives.",
        "testStrategy": "Unit test contract creation, validation, and execution. Test both spot and offtake contracts. Verify that seller stockpiles are reduced appropriately and buyer receives resources at the correct time. Test error cases like insufficient resources or invalid parties.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Contract Data Model and Database Schema",
            "description": "Create the data model and database schema for both spot and offtake contracts, including all necessary fields and relationships.",
            "dependencies": [],
            "details": "Design a comprehensive contract data model that includes: contract ID, type (spot/offtake), parties involved (buyerId, sellerId), resource details (type, quantity), pricing information, delivery schedule, status tracking fields, and timestamps. Create database migrations and entity models. Ensure the schema supports efficient querying for contract status and scheduled deliveries.",
            "status": "pending",
            "testStrategy": "Validate the data model with unit tests ensuring all required fields are present. Test database operations (CRUD) on the contract model. Verify relationships between contracts and related entities (buyers, sellers, resources)."
          },
          {
            "id": 2,
            "title": "Implement Contract Creation and Validation API",
            "description": "Develop the API endpoint for creating contracts with comprehensive validation of all contract terms.",
            "dependencies": [
              "4.1"
            ],
            "details": "Create a POST /api/contracts endpoint that accepts contract details including buyerId, sellerId, resource type, quantity, price, and deliverAt timestamp. Implement validation logic to verify: both parties exist, seller has sufficient resources, contract terms are valid (non-negative quantities, valid resource types, etc.). Return appropriate error responses for validation failures. Generate and return a unique contract ID upon successful creation.",
            "status": "pending",
            "testStrategy": "Unit test validation logic with various valid and invalid inputs. Test API responses for different scenarios including success cases and all possible validation failures. Integration test with mock buyer/seller data to verify end-to-end contract creation."
          },
          {
            "id": 3,
            "title": "Develop Spot Contract Execution System",
            "description": "Implement the system for immediate execution of spot contracts, including resource transfer and status updates.",
            "dependencies": [
              "4.2"
            ],
            "details": "Create a service that processes spot contracts by: immediately transferring resources from seller to buyer stockpiles, recording the transaction, updating contract status to completed, and handling any failures gracefully. Implement proper error handling and transaction management to ensure atomicity of transfers. Include logging of all contract executions for audit purposes.",
            "status": "pending",
            "testStrategy": "Unit test the spot contract execution process with various scenarios. Test transaction rollback on failures. Verify stockpile updates occur correctly. Integration test with the full contract creation flow to ensure end-to-end functionality."
          },
          {
            "id": 4,
            "title": "Implement Offtake Contract Scheduling System",
            "description": "Create the system for scheduling and executing future deliveries for offtake contracts based on the game's tick system.",
            "dependencies": [
              "4.2"
            ],
            "details": "Develop a tick-based processor that: maintains a queue of scheduled contract deliveries, executes deliveries when their scheduled tick arrives, updates contract status appropriately (partial or complete fulfillment), and handles any execution failures. Implement methods to query upcoming scheduled deliveries. Create a background process or hook into the game's tick system to trigger delivery execution at the appropriate times.",
            "status": "pending",
            "testStrategy": "Test the scheduling system with contracts at various future ticks. Verify deliveries occur at the correct tick. Test partial and complete fulfillment scenarios. Test failure handling and recovery. Integration test with the tick system to ensure proper timing of deliveries."
          },
          {
            "id": 5,
            "title": "Create Contract Management and Reporting API",
            "description": "Develop API endpoints for querying, filtering, and reporting on contracts and their statuses.",
            "dependencies": [
              "4.3",
              "4.4"
            ],
            "details": "Implement GET /api/contracts endpoints with filtering options for contract type, status, parties involved, and date ranges. Create specialized endpoints for reporting on contract fulfillment, pending deliveries, and historical performance. Include pagination and sorting options for large result sets. Develop endpoints for contract cancellation or modification where appropriate. Implement proper authorization to ensure parties can only view contracts they're involved in.",
            "status": "pending",
            "testStrategy": "Unit test each API endpoint with various query parameters. Test pagination and sorting functionality. Verify filtering works correctly for all supported criteria. Test authorization rules to ensure proper access control. Integration test the complete contract lifecycle from creation through execution and reporting."
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement Corporation Registry and Share Ledger",
        "description": "Create the corporation registry system and share ledger to track corporation ownership and enable share transfers.",
        "details": "Develop a corporation system that:\n1. Allows creation of new corporations with name and HQ location\n2. Maintains a share ledger tracking ownership (owner_id, shares)\n3. Supports share issuance to new or existing shareholders\n4. Enables share transfers between parties\n5. Provides APIs to query corporation details and cap tables\n\nImplement the following endpoints:\n- GET /api/corps - List all corporations\n- POST /api/corps { name, hqSystemId } - Create new corporation\n- GET /api/corps/:id/cap-table - Get corporation shareholders and shares\n- POST /api/corps/:id/shares/issue { ownerId, shares } - Issue new shares\n- POST /api/corps/:id/shares/transfer { fromId, toId, shares } - Transfer shares\n\nEnsure proper validation of share operations (e.g., can't transfer more shares than owned).",
        "testStrategy": "Unit test corporation creation, share issuance, and transfers. Verify cap table calculations are correct after various operations. Test edge cases like transferring all shares or issuing to multiple owners. Integration test the API endpoints with various request scenarios.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and implement corporation data model",
            "description": "Create the database schema and models for corporations and share ledgers",
            "dependencies": [],
            "details": "Design and implement the data models for corporations and share ledgers including:\n- Corporation model with fields for id, name, hqSystemId, creation date\n- ShareLedger model with fields for corporation_id, owner_id, shares\n- Implement validation rules for corporation creation\n- Create database migrations for these models\n- Implement basic CRUD operations for corporations",
            "status": "pending",
            "testStrategy": "Unit test the data models with various inputs. Verify validation rules work correctly. Test edge cases like corporations with the same name or invalid HQ locations."
          },
          {
            "id": 2,
            "title": "Implement corporation registry API endpoints",
            "description": "Create API endpoints for listing and creating corporations",
            "dependencies": [
              "5.1"
            ],
            "details": "Implement the following API endpoints:\n- GET /api/corps - List all corporations with pagination support\n- POST /api/corps { name, hqSystemId } - Create new corporation\n- Include proper request validation\n- Implement error handling for invalid requests\n- Add authentication/authorization checks\n- Document the API endpoints",
            "status": "pending",
            "testStrategy": "Unit test the API endpoints with valid and invalid inputs. Test pagination functionality. Integration test the endpoints with the database. Verify proper error responses for invalid requests."
          },
          {
            "id": 3,
            "title": "Implement share ledger and cap table functionality",
            "description": "Create the core functionality for tracking share ownership and generating cap tables",
            "dependencies": [
              "5.1"
            ],
            "details": "Implement the share ledger functionality including:\n- Methods to query current shareholders and their ownership percentages\n- Cap table generation with total shares outstanding calculation\n- Share issuance logic with validation\n- Share transfer logic with validation (ensuring sender has sufficient shares)\n- Transaction history tracking for share operations",
            "status": "pending",
            "testStrategy": "Unit test share issuance and transfers with various scenarios. Verify cap table calculations are correct after multiple operations. Test edge cases like transferring all shares or issuing to multiple owners."
          },
          {
            "id": 4,
            "title": "Implement share operations API endpoints",
            "description": "Create API endpoints for share issuance, transfers, and cap table queries",
            "dependencies": [
              "5.2",
              "5.3"
            ],
            "details": "Implement the following API endpoints:\n- GET /api/corps/:id/cap-table - Get corporation shareholders and shares\n- POST /api/corps/:id/shares/issue { ownerId, shares } - Issue new shares\n- POST /api/corps/:id/shares/transfer { fromId, toId, shares } - Transfer shares\n- Include proper validation for all operations\n- Implement transaction support to ensure data integrity\n- Add appropriate error handling",
            "status": "pending",
            "testStrategy": "Unit test each endpoint with valid and invalid inputs. Test share operations with edge cases like transferring more shares than owned. Integration test the endpoints with the database to verify data consistency after operations."
          },
          {
            "id": 5,
            "title": "Implement comprehensive testing and documentation",
            "description": "Create thorough tests and documentation for the corporation registry and share ledger system",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "Complete the implementation with:\n- Comprehensive unit tests for all components\n- Integration tests for the entire system\n- Performance tests for cap table generation with large shareholder bases\n- API documentation with examples\n- Internal code documentation\n- User guide for corporation and share operations",
            "status": "pending",
            "testStrategy": "Create a test suite covering all functionality. Include edge cases and error scenarios. Verify system behavior under load with performance tests. Conduct end-to-end testing of the entire corporation lifecycle from creation through multiple share operations."
          }
        ]
      },
      {
        "id": 6,
        "title": "Implement Corporation Facilities and P&L Tracking",
        "description": "Develop the system for corporations to own facilities and routes, with profit and loss tracking per tick.",
        "details": "Create a corporation facilities and financial tracking system that:\n1. Allows corporations to own production facilities and trade routes\n2. Tracks revenue and expenses per facility/route\n3. Calculates profit and loss (P&L) per tick\n4. Provides summary financial data for corporations\n\nImplement the following features:\n- Facility ownership transfer to/from corporations\n- Route ownership and revenue attribution\n- Per-tick calculation of revenues, expenses, and profits\n- Financial summary endpoints for corporation performance\n\nFor the MVP, use placeholder fields for detailed P&L components, focusing on the core tracking mechanism that can be expanded later.",
        "testStrategy": "Unit test facility ownership, revenue tracking, and P&L calculations. Verify that profits are correctly calculated based on facility production and route usage. Test the financial summary generation with various corporation configurations.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Facility Ownership Transfer System",
            "description": "Create the database schema and API endpoints for transferring facility ownership to and from corporations",
            "dependencies": [],
            "details": "Develop a system that allows facilities to be owned by corporations, including: 1) Database schema updates to add corporation_id to facilities table, 2) API endpoints for transferring ownership (POST /api/facilities/:id/transfer), 3) Validation logic to ensure proper ownership transfers, 4) Transaction history tracking for ownership changes, 5) Permission checks to validate transfer requests",
            "status": "pending",
            "testStrategy": "Unit test the ownership transfer logic with various scenarios (valid transfers, invalid transfers, edge cases). Test database constraints and transaction rollbacks. Integration test the API endpoints with authentication and authorization checks."
          },
          {
            "id": 2,
            "title": "Implement Trade Route Ownership and Revenue Attribution",
            "description": "Develop the system for corporations to own trade routes and attribute revenue from route usage",
            "dependencies": [
              "6.1"
            ],
            "details": "Create functionality for: 1) Assigning trade routes to corporation ownership, 2) Tracking usage of routes by various entities, 3) Calculating revenue generated from route tariffs and fees, 4) Attributing revenue to the owning corporation, 5) API endpoints to manage route ownership and view revenue data",
            "status": "pending",
            "testStrategy": "Unit test route ownership assignment and revenue calculation logic. Test with various traffic volumes and tariff rates. Verify correct revenue attribution to corporations. Integration test the API endpoints for route management."
          },
          {
            "id": 3,
            "title": "Implement Per-Tick Financial Calculation Engine",
            "description": "Create the core engine that calculates revenues, expenses, and profits for corporation-owned assets on each game tick",
            "dependencies": [
              "6.1",
              "6.2"
            ],
            "details": "Develop a financial calculation system that: 1) Runs on each game tick, 2) Calculates revenue from all corporation-owned facilities and routes, 3) Determines expenses including maintenance costs and operational expenses, 4) Computes net profit/loss for the tick period, 5) Updates corporation financial records with the results",
            "status": "pending",
            "testStrategy": "Unit test the calculation engine with various revenue and expense scenarios. Verify correct P&L calculation with edge cases (zero revenue, high expenses). Test performance with large numbers of facilities and routes. Integration test with the game tick system."
          },
          {
            "id": 4,
            "title": "Implement Corporation Financial Data Storage",
            "description": "Create the database schema and data access layer for storing and retrieving corporation financial information",
            "dependencies": [
              "6.3"
            ],
            "details": "Design and implement: 1) Database tables for corporation financial data (revenue, expenses, profits), 2) Historical tracking of financial performance over time, 3) Data access methods for retrieving financial information, 4) Aggregation functions for summarizing data across different time periods, 5) Data retention policies for financial records",
            "status": "pending",
            "testStrategy": "Unit test data storage and retrieval functions. Test data integrity with concurrent updates. Verify historical data is correctly maintained. Test aggregation functions with various time periods and corporation configurations."
          },
          {
            "id": 5,
            "title": "Implement Financial Summary API Endpoints",
            "description": "Create API endpoints for retrieving corporation financial performance data",
            "dependencies": [
              "6.4"
            ],
            "details": "Develop API endpoints including: 1) GET /api/corps/:id/financials for overall financial summary, 2) GET /api/corps/:id/financials/facilities for facility-specific data, 3) GET /api/corps/:id/financials/routes for route-specific data, 4) Filtering options by time period and asset type, 5) Summary statistics including total revenue, expenses, profit margins, and growth rates",
            "status": "pending",
            "testStrategy": "Unit test API response formatting and calculation logic. Test with various filter parameters and time ranges. Integration test the endpoints with authentication and authorization. Performance test with large data sets to ensure reasonable response times."
          }
        ]
      },
      {
        "id": 7,
        "title": "Implement Dividend Distribution System",
        "description": "Create the dividend declaration and distribution system for corporations to pay shareholders.",
        "details": "Develop a dividend system that:\n1. Allows corporations to declare dividends of a specific amount\n2. Calculates per-share dividend based on total outstanding shares\n3. Distributes dividends to shareholders proportional to their ownership\n4. Records dividend history for corporations\n5. Provides API to query dividend history\n\nImplement the following endpoints:\n- POST /api/corps/:id/dividend { amount } - Declare a dividend\n- GET /api/corps/:id/dividends - Get dividend history\n\nThe dividend distribution should:\n- Validate that the corporation has sufficient funds\n- Calculate each shareholder's portion based on ownership percentage\n- Transfer funds from corporation to shareholders\n- Record the transaction in the dividend history",
        "testStrategy": "Unit test dividend declaration, calculation, and distribution. Verify that shareholders receive the correct amount based on their ownership percentage. Test edge cases like dividends with fractional amounts or corporations with a single owner. Integration test the API endpoints.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Dividend Declaration API Endpoint",
            "description": "Create the API endpoint that allows corporations to declare dividends of a specific amount",
            "dependencies": [],
            "details": "Develop the POST /api/corps/:id/dividend endpoint that accepts an amount parameter. Implement validation to ensure the corporation has sufficient funds for the dividend. Create database models and services to store the dividend declaration. Include authentication and authorization to ensure only authorized users can declare dividends.",
            "status": "pending",
            "testStrategy": "Unit test the validation logic for sufficient funds. Test authorization rules to ensure only authorized users can declare dividends. Test error handling for invalid inputs and insufficient funds scenarios."
          },
          {
            "id": 2,
            "title": "Implement Dividend Calculation Logic",
            "description": "Create the logic to calculate per-share dividend based on total outstanding shares",
            "dependencies": [
              "7.1"
            ],
            "details": "Develop a service that retrieves the total outstanding shares for a corporation. Implement the algorithm to calculate the per-share dividend amount by dividing the total dividend amount by the number of outstanding shares. Handle edge cases such as fractional shares and rounding issues. Ensure calculations are accurate to prevent discrepancies in distribution.",
            "status": "pending",
            "testStrategy": "Unit test the dividend calculation with various share distributions. Test edge cases like corporations with a single shareholder or fractional shares. Verify calculations match expected results for different dividend amounts."
          },
          {
            "id": 3,
            "title": "Implement Dividend Distribution System",
            "description": "Create the system to distribute dividends to shareholders proportional to their ownership",
            "dependencies": [
              "7.2"
            ],
            "details": "Develop a distribution service that identifies all shareholders of a corporation. Calculate each shareholder's portion based on their ownership percentage. Implement the fund transfer mechanism from corporation to shareholders. Handle transaction atomicity to ensure all transfers succeed or fail together. Include logging of all distribution activities.",
            "status": "pending",
            "testStrategy": "Unit test the distribution logic with various shareholder configurations. Test the transaction atomicity to ensure partial distributions don't occur. Integration test the full distribution process from declaration to shareholder receipt."
          },
          {
            "id": 4,
            "title": "Implement Dividend History Storage",
            "description": "Create the system to record dividend history for corporations",
            "dependencies": [
              "7.3"
            ],
            "details": "Design and implement the database schema to store dividend history records. Include fields for dividend amount, declaration date, distribution date, per-share amount, and distribution status. Create services to record new dividend distributions and query historical records. Implement data retention policies for dividend history.",
            "status": "pending",
            "testStrategy": "Unit test the storage and retrieval of dividend records. Verify that all required fields are properly stored. Test querying capabilities with various filters and sorting options."
          },
          {
            "id": 5,
            "title": "Implement Dividend History API Endpoint",
            "description": "Create the API endpoint to query dividend history for corporations",
            "dependencies": [
              "7.4"
            ],
            "details": "Develop the GET /api/corps/:id/dividends endpoint that returns the dividend history for a corporation. Implement filtering options by date range, status, and amount. Include pagination for large result sets. Add sorting capabilities by various fields. Ensure proper authorization to control who can view dividend history.",
            "status": "pending",
            "testStrategy": "Unit test the API response format and content. Test pagination with large datasets. Test filtering and sorting options. Integration test with the frontend to verify the API meets UI requirements."
          }
        ]
      },
      {
        "id": 8,
        "title": "Develop Trade Panel UI",
        "description": "Create the user interface for the trade panel showing prices list per system and a simple demand heatmap.",
        "details": "Implement a trade panel UI that includes:\n1. A filterable list of resource prices per star system\n2. A simple heatmap visualization showing demand levels across systems\n3. Sorting and filtering options for resources and systems\n4. Price trend indicators (up/down from previous tick)\n5. Integration with the price calculation API\n\nThe UI should:\n- Call GET /api/trade/prices?system=:id to fetch current prices\n- Display prices in a clear tabular format\n- Use color coding for the demand heatmap (red = high demand, blue = low demand)\n- Provide a refresh mechanism to update prices\n- Include responsive design for different screen sizes",
        "testStrategy": "Unit test UI components rendering with mock data. Test sorting and filtering functionality. Integration test with the price API to verify data display. User acceptance testing to verify the heatmap is intuitive and prices are clearly displayed.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and implement price list table component",
            "description": "Create a responsive table component that displays resource prices per star system with sorting and filtering capabilities",
            "dependencies": [],
            "details": "Develop a React component that renders a table showing resource prices across systems. Include columns for resource name, system, current price, and price trend indicators. Implement client-side sorting by any column and filtering by resource type or system. The component should handle the API response from GET /api/trade/prices?system=:id and format the data appropriately. Include up/down arrows to indicate price trends from previous tick.",
            "status": "pending",
            "testStrategy": "Unit test the table component rendering with mock data. Test sorting functionality by different columns. Test filtering capabilities. Verify price trend indicators display correctly based on mock data changes."
          },
          {
            "id": 2,
            "title": "Implement demand heatmap visualization",
            "description": "Create a visual heatmap component that displays resource demand levels across star systems using color coding",
            "dependencies": [],
            "details": "Develop a heatmap visualization that represents demand levels across systems. Use a color gradient from blue (low demand) to red (high demand). The component should be able to display data for all resources or filter to show demand for a specific resource. Include a legend explaining the color coding. The heatmap should be responsive and maintain readability on different screen sizes.",
            "status": "pending",
            "testStrategy": "Unit test the heatmap component with various mock demand datasets. Verify color gradient correctly represents demand values. Test responsiveness on different viewport sizes. Verify filtering functionality works correctly when selecting specific resources."
          },
          {
            "id": 3,
            "title": "Implement API integration and data fetching",
            "description": "Create services to fetch trade data from the API and implement refresh mechanisms",
            "dependencies": [],
            "details": "Develop service functions to fetch price data from GET /api/trade/prices?system=:id. Implement error handling for API failures and loading states. Create a data refresh mechanism that can be triggered manually or automatically at configurable intervals. The service should transform the API response into the format required by the UI components. Include caching to prevent unnecessary API calls.",
            "status": "pending",
            "testStrategy": "Unit test API service functions with mocked responses. Test error handling for various failure scenarios. Test the refresh mechanism triggers correctly. Integration test with a mocked API to verify data transformation and component updates."
          },
          {
            "id": 4,
            "title": "Develop advanced filtering and sorting controls",
            "description": "Create UI controls for filtering and sorting the price data and heatmap visualization",
            "dependencies": [
              "8.1",
              "8.2"
            ],
            "details": "Implement a control panel with dropdown menus, search fields, and toggle buttons to filter and sort the trade data. Include filters for resource types, star systems, price ranges, and demand levels. Add sorting options for prices (high to low, low to high) and alphabetical sorting for resources and systems. The controls should update both the price table and heatmap visualization in real-time as filters are applied.",
            "status": "pending",
            "testStrategy": "Unit test each filter and sort control individually. Test combinations of filters to ensure they work together correctly. Verify the UI updates appropriately when filters are applied or removed. Test edge cases like applying all filters simultaneously."
          },
          {
            "id": 5,
            "title": "Create responsive layout and integrate components",
            "description": "Design and implement the overall trade panel layout and integrate all components into a cohesive UI",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.4"
            ],
            "details": "Design a responsive layout for the trade panel that works well on desktop and mobile devices. Integrate the price table, heatmap visualization, and filter controls into a cohesive interface. Implement tabs or accordions if needed to organize information on smaller screens. Add a header with the refresh button and timestamp of last update. Ensure consistent styling across all components and implement loading states and error messages.",
            "status": "pending",
            "testStrategy": "Test the complete UI on various screen sizes to verify responsive behavior. Verify all components interact correctly when integrated. Test navigation between different sections of the trade panel. Conduct user acceptance testing to ensure the interface is intuitive and information is clearly presented."
          }
        ]
      },
      {
        "id": 9,
        "title": "Implement Contract Builder UI",
        "description": "Create a user interface for building and submitting trade contracts between parties.",
        "details": "Develop a contract builder UI that:\n1. Allows selection of buyer and seller\n2. Provides resource selection with current price information\n3. Includes quantity input with validation\n4. Supports setting delivery date for offtake contracts\n5. Calculates total contract value based on price and quantity\n6. Shows applicable tariffs based on route\n7. Submits contract to the contract API\n\nThe UI should:\n- Integrate with the prices API to show current resource prices\n- Validate inputs (positive quantities, valid parties, etc.)\n- Calculate and display the total contract value\n- Submit to POST /api/trade/contract endpoint\n- Show confirmation on successful contract creation\n- Display appropriate error messages for validation failures",
        "testStrategy": "Unit test form validation and calculation logic. Integration test with the contract API to verify successful submission and error handling. User acceptance testing to verify the contract creation flow is intuitive and error messages are helpful.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design Contract Builder Form Layout",
            "description": "Create the UI layout and component structure for the contract builder form with all required fields and sections.",
            "dependencies": [],
            "details": "Design and implement the form layout with sections for: buyer/seller selection, resource selection, quantity input, delivery date picker, price display, tariff information, and submission controls. Include responsive design considerations and ensure proper spacing and alignment of form elements. Create reusable form components as needed.",
            "status": "pending",
            "testStrategy": "Verify layout renders correctly across different screen sizes. Ensure all form sections are present and properly labeled. Check accessibility compliance with screen readers and keyboard navigation."
          },
          {
            "id": 2,
            "title": "Implement Price API Integration",
            "description": "Connect to the prices API to fetch and display current resource prices in the contract builder.",
            "dependencies": [
              "9.1"
            ],
            "details": "Create service to fetch current resource prices from the prices API. Implement caching mechanism for price data to reduce API calls. Display price information next to resource selection. Update price information when resource selection changes. Handle loading states and error scenarios for API calls.",
            "status": "pending",
            "testStrategy": "Unit test API integration with mock responses. Test price updates when resources are changed. Verify error handling when API is unavailable."
          },
          {
            "id": 3,
            "title": "Implement Form Validation and Calculation Logic",
            "description": "Add validation for all form inputs and implement calculation logic for contract values and tariffs.",
            "dependencies": [
              "9.1",
              "9.2"
            ],
            "details": "Implement validation for: positive quantities, valid parties selection, future delivery dates. Calculate total contract value based on resource price and quantity. Fetch and display applicable tariffs based on buyer/seller locations. Update calculations in real-time as user inputs change. Display validation errors inline with appropriate error messages.",
            "status": "pending",
            "testStrategy": "Unit test validation rules with valid and invalid inputs. Test calculation logic with various price/quantity combinations. Verify tariff calculations match expected values based on routes."
          },
          {
            "id": 4,
            "title": "Implement Contract Submission",
            "description": "Create the functionality to submit completed contracts to the contract API endpoint.",
            "dependencies": [
              "9.3"
            ],
            "details": "Implement form submission handler to POST contract data to /api/trade/contract endpoint. Format request payload according to API requirements. Handle submission states (loading, success, error). Display confirmation message on successful contract creation. Show appropriate error messages for API failures. Implement retry mechanism for failed submissions.",
            "status": "pending",
            "testStrategy": "Integration test with the contract API to verify successful submissions. Test error handling with various API error responses. Verify the UI correctly displays loading, success, and error states."
          },
          {
            "id": 5,
            "title": "Create User Documentation and Final Testing",
            "description": "Create user documentation for the contract builder and perform comprehensive testing of the entire feature.",
            "dependencies": [
              "9.1",
              "9.2",
              "9.3",
              "9.4"
            ],
            "details": "Create user documentation explaining how to use the contract builder. Include tooltips and help text within the UI for key fields. Perform end-to-end testing of the complete contract creation flow. Verify all edge cases and error scenarios. Optimize performance for large datasets. Ensure the UI is intuitive and user-friendly.",
            "status": "pending",
            "testStrategy": "Conduct user acceptance testing with stakeholders. Perform end-to-end testing of the complete contract creation flow. Test performance with large datasets of resources and parties. Verify all error scenarios display appropriate messages."
          }
        ]
      },
      {
        "id": 10,
        "title": "Develop Corporation Sheet UI",
        "description": "Create the user interface for displaying corporation information, including cap table, facilities summary, and dividend history.",
        "details": "Implement a corporation sheet UI that includes:\n1. Corporation overview (name, HQ location, founding date)\n2. Capital table showing all shareholders and ownership percentages\n3. Facilities summary showing owned production facilities and routes\n4. Dividend history with amounts and dates\n5. Basic financial summary showing recent P&L\n\nThe UI should:\n- Call GET /api/corps/:id for basic corporation info\n- Call GET /api/corps/:id/cap-table for ownership information\n- Display facilities and routes owned by the corporation\n- Show the last dividend amount and date\n- Include a dividend declaration form for corporation administrators\n- Provide share transfer functionality for shareholders",
        "testStrategy": "Unit test UI components rendering with mock data. Test the dividend declaration form and share transfer functionality. Integration test with the corporation APIs to verify data display and form submissions. User acceptance testing to verify information is clearly presented and actions are intuitive.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Corporation Overview Component",
            "description": "Create a UI component that displays basic corporation information including name, HQ location, and founding date.",
            "dependencies": [],
            "details": "Develop a React component that fetches data from GET /api/corps/:id endpoint. The component should display the corporation name, headquarters location, founding date, and other basic information in a clean, organized layout. Include proper loading states and error handling for API failures.",
            "status": "pending",
            "testStrategy": "Unit test the component rendering with mock data. Verify all corporation fields display correctly. Test loading states and error handling. Integration test with the API endpoint to ensure data is fetched and displayed properly."
          },
          {
            "id": 2,
            "title": "Build Capital Table and Shareholders Display",
            "description": "Create a component that shows all shareholders and their ownership percentages in a tabular format.",
            "dependencies": [
              "10.1"
            ],
            "details": "Implement a table component that fetches and displays data from GET /api/corps/:id/cap-table endpoint. The table should show shareholder names, ownership percentages, share counts, and allow sorting. Include share transfer functionality for shareholders with appropriate permission checks. The component should update when ownership changes occur.",
            "status": "pending",
            "testStrategy": "Unit test the table rendering with various mock data scenarios. Test sorting functionality. Verify share transfer UI works correctly with different permission levels. Integration test with the cap table API to confirm data display accuracy."
          },
          {
            "id": 3,
            "title": "Develop Facilities and Routes Summary",
            "description": "Create a component that displays all production facilities and trade routes owned by the corporation.",
            "dependencies": [
              "10.1"
            ],
            "details": "Build a component that shows production facilities with their location, type, and capacity. Include a visualization of trade routes between systems with capacity and utilization metrics. The component should fetch facility data from the corporation API and present it in both list and map views where appropriate. Include filtering options by facility type and system location.",
            "status": "pending",
            "testStrategy": "Unit test the facilities display with mock data. Test filtering functionality. Verify the route visualization renders correctly with different data sets. Integration test with the corporation API to ensure facilities data is correctly fetched and displayed."
          },
          {
            "id": 4,
            "title": "Implement Dividend History and Declaration Form",
            "description": "Create a dividend history display and a form for corporation administrators to declare new dividends.",
            "dependencies": [
              "10.1",
              "10.2"
            ],
            "details": "Develop a component that shows historical dividends with amounts and dates in both tabular and chart formats. Implement a dividend declaration form for administrators that includes amount per share, declaration date, and payment date fields. The form should validate inputs and submit to the appropriate API endpoint. Include confirmation dialogs for dividend declarations.",
            "status": "pending",
            "testStrategy": "Unit test the dividend history display with various data sets. Test the declaration form validation logic and submission handling. Test administrator-only access controls. Integration test with the dividend API endpoints to verify data display and form submissions work correctly."
          },
          {
            "id": 5,
            "title": "Create Financial Summary Component",
            "description": "Build a component that displays recent profit and loss information and other key financial metrics.",
            "dependencies": [
              "10.1"
            ],
            "details": "Implement a financial summary component that shows recent P&L data, revenue trends, expense breakdowns, and key financial ratios. Include visualizations like bar/line charts for financial trends. The component should fetch data from the corporation financial endpoints and present it in an easily digestible format with appropriate time period selectors.",
            "status": "pending",
            "testStrategy": "Unit test the financial component rendering with mock data. Test period selection functionality. Verify charts render correctly with different data sets. Integration test with the financial API endpoints to ensure data is correctly fetched and displayed."
          }
        ]
      },
      {
        "id": 11,
        "title": "Implement Regional Exchanges and Order Books",
        "description": "Develop the foundation for regional exchanges with order books supporting limit and market orders (Phase 2).",
        "details": "Create a market exchange system that:\n1. Defines regional exchanges tied to star systems or regions\n2. Implements order books for each tradable instrument\n3. Supports limit orders (specific price) and market orders (best available)\n4. Processes order matching based on price-time priority\n5. Records completed trades in the trades table\n\nImplement the following features:\n- Order submission API for limit and market orders\n- Order matching engine to pair compatible buy/sell orders\n- Order book maintenance (adding, removing, updating orders)\n- Trade execution and recording\n- Basic maker/taker fee structure\n\nThe system should support common shares and resource futures as initial instruments.",
        "testStrategy": "Unit test order submission, matching algorithm, and trade execution. Test various scenarios like partial fills, multiple matches, and order cancellation. Verify that the order book maintains correct state after operations. Integration test the order API with various order types.",
        "priority": "low",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Regional Exchange Structure",
            "description": "Create the data models and database schema for regional exchanges tied to star systems or regions",
            "dependencies": [],
            "details": "Implement database tables and models for regional exchanges including: exchange_regions table with region_id, name, and status fields; exchange_instruments table with instrument_id, symbol, name, type (common shares/resource futures), and region_id; Create API endpoints to query available exchanges and instruments per region; Implement service layer for exchange operations; Document the exchange structure and relationships",
            "status": "pending",
            "testStrategy": "Unit test the data models and relationships. Verify that instruments are correctly associated with regions. Test API endpoints for retrieving exchange and instrument information. Ensure proper validation of exchange region data."
          },
          {
            "id": 2,
            "title": "Implement Order Book Data Structure",
            "description": "Create the core order book data structure that maintains buy and sell orders for each tradable instrument",
            "dependencies": [
              "11.1"
            ],
            "details": "Design and implement order book class that maintains separate buy (bid) and sell (ask) order queues; Implement price-time priority sorting for orders; Create order data structure with fields for order_id, instrument_id, side (buy/sell), quantity, price, timestamp, user_id, and status; Develop methods for adding, removing, and querying orders; Implement database persistence for orders; Create order book snapshot functionality for market data queries",
            "status": "pending",
            "testStrategy": "Unit test order insertion and removal operations. Verify price-time priority is maintained. Test order book state after various operations. Benchmark performance with large numbers of orders."
          },
          {
            "id": 3,
            "title": "Develop Order Matching Engine",
            "description": "Create the matching engine that pairs compatible buy and sell orders based on price-time priority",
            "dependencies": [
              "11.2"
            ],
            "details": "Implement matching algorithm that finds compatible orders based on price (limit orders) or best available price (market orders); Handle partial fills when order quantities don't match exactly; Process limit orders by matching against opposite side of the book when price conditions are met; Process market orders by matching against best available price on opposite side; Implement order lifecycle management (open, partially filled, filled, cancelled); Create transaction log for audit purposes",
            "status": "pending",
            "testStrategy": "Unit test matching algorithm with various scenarios including exact matches, partial fills, and no matches. Test market orders against different book states. Verify that price-time priority is respected. Test edge cases like empty order books or very large orders."
          },
          {
            "id": 4,
            "title": "Create Order Submission API",
            "description": "Develop the API endpoints for submitting, canceling, and querying limit and market orders",
            "dependencies": [
              "11.2",
              "11.3"
            ],
            "details": "Implement POST /api/orders endpoint for submitting new orders with validation for required fields (instrument_id, side, quantity, price for limit orders); Create DELETE /api/orders/:id endpoint for canceling orders; Implement GET /api/orders and GET /api/orders/:id endpoints for querying orders; Add authentication and authorization checks to ensure users can only access their own orders; Implement order validation logic (positive quantities, valid instrument IDs, etc.); Create response formats for successful and failed operations",
            "status": "pending",
            "testStrategy": "Unit test API endpoints with valid and invalid inputs. Test authentication and authorization rules. Integration test the order submission flow from API to order book. Verify proper error handling and response formats."
          },
          {
            "id": 5,
            "title": "Implement Trade Execution and Fee Structure",
            "description": "Develop the system for executing matched trades, recording them in the database, and applying maker/taker fees",
            "dependencies": [
              "11.3",
              "11.4"
            ],
            "details": "Create trades table with fields for trade_id, buy_order_id, sell_order_id, instrument_id, quantity, price, timestamp, and fees; Implement trade execution logic that updates order status and remaining quantities; Develop maker/taker fee calculation (maker: places limit order that doesn't execute immediately, taker: places order that executes immediately); Record fees in the trade record; Update user balances based on trade execution and fees; Implement transaction handling to ensure atomicity of trade operations; Create API endpoint to query trade history",
            "status": "pending",
            "testStrategy": "Unit test trade execution with various scenarios. Verify that fees are correctly calculated and applied. Test database consistency after trades. Integration test the full order-to-trade flow. Verify that balances are correctly updated after trades."
          }
        ]
      },
      {
        "id": 12,
        "title": "Implement Portfolio API and Market Data Endpoints",
        "description": "Create the API endpoints for retrieving market data and portfolio information (Phase 2).",
        "details": "Develop market data and portfolio APIs that:\n1. Provide ticker information for all tradable instruments\n2. Return current order book state for any ticker\n3. List recent trades for instruments\n4. Calculate and return portfolio holdings for any owner\n5. Track portfolio performance over time\n\nImplement the following endpoints:\n- GET /api/markets/tickers - List all available tickers\n- GET /api/markets/orderbook?ticker=:id - Get current order book\n- GET /api/markets/trades?ticker=:id - Get recent trades\n- GET /api/markets/portfolio?owner=:id - Get portfolio holdings\n\nThe portfolio endpoint should aggregate all shares and futures contracts owned by the specified entity and calculate current market value based on last trade prices.",
        "testStrategy": "Unit test data aggregation and calculation logic. Test with various portfolio compositions and market conditions. Integration test the API endpoints with different query parameters. Verify that portfolio values are correctly calculated based on current market prices.",
        "priority": "low",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement GET /api/markets/tickers endpoint",
            "description": "Create the API endpoint that provides ticker information for all tradable instruments in the system.",
            "dependencies": [],
            "details": "Develop the endpoint that retrieves all available tickers from the database. The response should include ticker ID, name, type (share/future), current price, daily change percentage, and trading volume. Implement proper error handling and pagination for large result sets. The endpoint should support filtering by instrument type.",
            "status": "pending",
            "testStrategy": "Unit test the data retrieval logic with mock database responses. Test pagination functionality with large datasets. Integration test the endpoint with various filter parameters. Verify response format matches API documentation."
          },
          {
            "id": 2,
            "title": "Implement GET /api/markets/orderbook endpoint",
            "description": "Create the API endpoint that returns the current order book state for any specified ticker.",
            "dependencies": [
              "12.1"
            ],
            "details": "Develop the endpoint that retrieves the current order book for a specified ticker. The response should include bid and ask orders with price, quantity, and timestamp. Implement query parameter validation for ticker ID. The order book should be sorted with best prices first (highest bids, lowest asks). Include depth parameter to limit the number of orders returned on each side.",
            "status": "pending",
            "testStrategy": "Unit test the order book aggregation logic. Test with various market depths and ticker parameters. Verify sorting order is correct. Test error handling for invalid ticker IDs. Integration test with the database to ensure real-time order book data is returned."
          },
          {
            "id": 3,
            "title": "Implement GET /api/markets/trades endpoint",
            "description": "Create the API endpoint that lists recent trades for a specified instrument.",
            "dependencies": [
              "12.1"
            ],
            "details": "Develop the endpoint that retrieves recent trades for a specified ticker. The response should include price, quantity, timestamp, and trade direction (buy/sell). Implement pagination and limit parameters to control the number of trades returned. Add support for time range filtering to view historical trades. Sort trades by timestamp in descending order (newest first).",
            "status": "pending",
            "testStrategy": "Unit test the trade retrieval logic with mock data. Test pagination and limit functionality. Verify time range filtering works correctly. Integration test with the database to ensure accurate trade history is returned. Test performance with large trade histories."
          },
          {
            "id": 4,
            "title": "Implement GET /api/markets/portfolio endpoint",
            "description": "Create the API endpoint that calculates and returns portfolio holdings for any specified owner.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.3"
            ],
            "details": "Develop the endpoint that aggregates all shares and futures contracts owned by the specified entity. Calculate current market value based on last trade prices. The response should include total portfolio value, individual holdings with quantity and current value, and unrealized profit/loss. Implement proper error handling for invalid owner IDs and securities without recent trades.",
            "status": "pending",
            "testStrategy": "Unit test the portfolio aggregation and valuation logic with various portfolio compositions. Test edge cases like empty portfolios or portfolios with illiquid assets. Verify that market values are correctly calculated based on last trade prices. Integration test with the database to ensure all holdings are properly retrieved and valued."
          },
          {
            "id": 5,
            "title": "Implement portfolio performance tracking",
            "description": "Extend the portfolio endpoint to track and return performance metrics over time.",
            "dependencies": [
              "12.4"
            ],
            "details": "Enhance the portfolio endpoint to include historical performance data. Implement daily snapshots of portfolio value to track changes over time. Add time period parameters to retrieve performance for different intervals (day, week, month, year). Calculate and return key metrics including total return, annualized return, volatility, and comparison to market benchmarks. Store historical portfolio values efficiently to support fast retrieval.",
            "status": "pending",
            "testStrategy": "Unit test the performance calculation logic with mock historical data. Test different time periods and verify calculations are accurate. Test edge cases like portfolios with recent acquisitions or disposals. Integration test the enhanced endpoint with real historical data. Verify performance under load with large portfolios and extended time periods."
          }
        ]
      },
      {
        "id": 13,
        "title": "Implement Input-Output Economic Model",
        "description": "Develop a Leontief input-output model to simulate realistic industry interdependencies and resource flows between economic sectors.",
        "details": "Implement an economic input-output model with the following components:\n\n1. **Leontief Matrix Structure**:\n   - Create a matrix representation of industry interdependencies\n   - Define input coefficients representing how much of each industry's output is required as input for other industries\n   - Implement matrix operations for calculating production requirements\n\n2. **Resource Elasticity System**:\n   - Develop elasticity coefficients for resources that determine how price changes affect supply and demand\n   - Implement price elasticity calculations that modify the base supply/demand curves\n   - Create configurable elasticity parameters per resource and industry\n\n3. **Economic Shock Modeling**:\n   - Implement a system to simulate supply or demand shocks to specific industries\n   - Create recovery tail models that show how industries return to equilibrium after shocks\n   - Include configurable parameters for shock magnitude, recovery rate, and spillover effects\n\n4. **Policy Counterfactual Analysis**:\n   - Develop a framework to simulate alternative economic policies\n   - Implement before/after comparison metrics for policy changes\n   - Create visualization endpoints for policy impact analysis\n\n5. **Exchange Microstructure Improvements**:\n   - Add transaction fees to exchange operations\n   - Implement latency simulation for order processing\n   - Support partial order fills based on available liquidity\n   - Calculate and apply market impact for large orders\n\n6. **API Endpoints**:\n   - GET /api/economy/io-matrix - Retrieve the current input-output matrix\n   - POST /api/economy/simulate/shock - Run shock simulation with parameters\n   - GET /api/economy/elasticities - Get current resource elasticity values\n   - POST /api/economy/simulate/policy - Run policy counterfactual analysis\n\nThe implementation should integrate with the existing price calculation engine and corporation systems to provide a more realistic economic simulation.",
        "testStrategy": "1. **Unit Testing**:\n   - Test matrix operations with known input-output examples from economic literature\n   - Verify elasticity calculations with different coefficient values\n   - Test shock models with various parameters and verify recovery patterns\n   - Validate market impact calculations for different order sizes\n\n2. **Integration Testing**:\n   - Verify that the input-output model correctly affects resource prices\n   - Test that economic shocks propagate through connected industries\n   - Confirm that policy changes produce expected effects across the economy\n   - Validate that exchange microstructure changes affect order execution\n\n3. **Simulation Testing**:\n   - Run historical simulations with known economic patterns to verify model accuracy\n   - Perform stress tests with extreme shock values to ensure system stability\n   - Compare model predictions with expected economic outcomes\n   - Test performance under high transaction volumes\n\n4. **Regression Testing**:\n   - Ensure that the new economic model doesn't break existing price calculations\n   - Verify that corporation P&L is still calculated correctly with the new model\n   - Confirm that trade contracts still execute properly with the new exchange features\n\n5. **API Testing**:\n   - Validate all new API endpoints with various input parameters\n   - Test error handling for invalid simulation requests\n   - Verify response formats and data accuracy",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-08-14T06:48:15.904Z",
      "updated": "2025-08-14T07:49:49.754Z",
      "description": "Tasks for sprint-c-trade-markets context"
    }
  },
  "sprint-2-persistence": {
    "tasks": [],
    "metadata": {
      "created": "2025-08-14T08:09:13.118Z",
      "updated": "2025-08-14T08:09:13.118Z",
      "description": "Tag created on 8/14/2025"
    }
  },
  "sprint-5-analytics": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Monetary/FX Analytics Panels with Inflation and FX Basket Indices",
        "description": "Develop and implement analytics panels for monetary and foreign exchange data, including inflation indices and FX basket indices, with corresponding API endpoints and HUD integration.",
        "details": "This task involves implementing comprehensive monetary and foreign exchange analytics functionality:\n\n1. Backend Implementation:\n   - Create two new API endpoints:\n     - `GET /analytics/inflation`: Returns inflation index data with historical trends\n     - `GET /analytics/fx`: Returns FX basket indices with currency weightings and performance metrics\n   - Implement data processing logic for both endpoints:\n     - Inflation calculation should account for various inflation metrics (CPI, PPI, etc.)\n     - FX basket indices should support multiple currency combinations with configurable weights\n   - Ensure data is properly formatted for frontend consumption (JSON structure)\n   - Add appropriate error handling and validation\n   - Implement caching mechanisms for performance optimization\n\n2. Frontend Implementation:\n   - Create HUD (Heads-Up Display) analytics panels to visualize the data\n   - Design responsive UI components that show:\n     - Inflation trends with historical comparisons\n     - FX basket performance with individual currency contributions\n   - Implement interactive charts showing trends over time steps\n   - Add tooltips and explanatory elements for data interpretation\n   - Ensure panels maintain consistent styling with existing UI\n\n3. Data Integration:\n   - Connect to appropriate data sources for inflation and FX rates\n   - Implement data transformation logic to convert raw data into usable indices\n   - Create scheduled jobs to refresh data at appropriate intervals\n   - Handle missing or incomplete data gracefully\n\n4. Configuration:\n   - Allow customization of time periods for trend analysis\n   - Support configuration of basket compositions for FX indices\n   - Implement user preferences for default views",
        "testStrategy": "Testing should be comprehensive across all components:\n\n1. Backend Testing:\n   - Unit tests for index calculation logic:\n     - Verify inflation index calculations match expected values for known inputs\n     - Confirm FX basket calculations produce correct results with various currency weights\n     - Test edge cases (negative rates, extreme values, missing data points)\n   - API endpoint tests:\n     - Verify correct response format and status codes\n     - Test query parameter handling and validation\n     - Confirm error responses for invalid requests\n   - Performance tests:\n     - Measure response times under various load conditions\n     - Verify caching mechanisms work as expected\n\n2. Frontend Testing:\n   - Unit tests for UI components:\n     - Verify panels render correctly with sample data\n     - Test interactive elements function as expected\n   - Integration tests:\n     - Confirm data flows correctly from API to UI components\n     - Verify trend visualization matches expected patterns\n   - Visual regression tests:\n     - Ensure UI appearance remains consistent across browsers\n     - Check responsive behavior on different screen sizes\n\n3. Determinism Testing:\n   - Run repeated calculations with identical inputs to verify consistent results\n   - Test with different data loads to ensure stability\n\n4. End-to-End Testing:\n   - Create test scenarios that validate the complete flow from data input to visualization\n   - Verify trend analysis correctly reflects changes in underlying data\n   - Test user interactions with the analytics panels\n\n5. User Acceptance Testing:\n   - Prepare demo data sets that showcase the functionality\n   - Create test scripts for manual verification of key features",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Backend API Endpoints for Inflation and FX Analytics",
            "description": "Create the necessary API endpoints to serve inflation index data and FX basket indices data to the frontend.",
            "dependencies": [],
            "details": "Develop two RESTful API endpoints: `GET /analytics/inflation` and `GET /analytics/fx`. The inflation endpoint should return historical inflation data with trends for various metrics (CPI, PPI). The FX endpoint should return basket indices with currency weightings and performance metrics. Implement proper request validation, error handling, and response formatting. Structure the JSON response to include metadata about the indices and the actual data points with timestamps.",
            "status": "pending",
            "testStrategy": "Write unit tests for API controllers to verify correct response structure. Create integration tests that mock the data sources and verify endpoint behavior with different query parameters. Test error handling by simulating various error conditions."
          },
          {
            "id": 2,
            "title": "Develop Data Processing Logic for Inflation and FX Calculations",
            "description": "Implement the core calculation logic for processing raw inflation data and FX rates into meaningful indices and metrics.",
            "dependencies": [],
            "details": "Create services that transform raw inflation and FX data into usable indices. For inflation, implement algorithms to calculate various inflation metrics (CPI, PPI) and their trends over time. For FX baskets, develop logic to calculate weighted indices based on configurable currency combinations. Include functionality to compare current values against historical averages and calculate percentage changes. Implement data normalization to handle different time periods and data frequencies.",
            "status": "pending",
            "testStrategy": "Create comprehensive unit tests with known input/output pairs to verify calculation accuracy. Test edge cases like missing data points, extreme values, and different time periods. Benchmark performance for large datasets."
          },
          {
            "id": 3,
            "title": "Implement Data Integration and Scheduled Updates",
            "description": "Connect to external data sources for inflation and FX rates, and implement scheduled jobs to keep the data current.",
            "dependencies": [],
            "details": "Develop data connectors to fetch raw inflation metrics and FX rates from appropriate sources. Implement data transformation pipelines to convert raw data into the format required by the calculation services. Create scheduled jobs using a task scheduler to refresh data at configurable intervals (daily for FX rates, monthly for inflation metrics). Implement caching mechanisms to optimize performance and reduce external API calls. Add logging and monitoring to track data freshness and update status.",
            "status": "pending",
            "testStrategy": "Test data connectors with mock external services. Verify scheduled jobs execute correctly and handle failures gracefully. Test cache invalidation and refresh logic. Create integration tests that verify the entire data pipeline from source to processed indices."
          },
          {
            "id": 4,
            "title": "Create Frontend HUD Analytics Panels for Data Visualization",
            "description": "Design and implement responsive UI components to visualize inflation and FX basket data in the HUD interface.",
            "dependencies": [],
            "details": "Develop two HUD panel components: one for inflation analytics and one for FX basket analytics. Implement interactive charts showing trends over configurable time periods. For inflation panels, include historical comparisons and forecasting elements. For FX panels, visualize basket performance with individual currency contributions and weights. Add tooltips and explanatory elements to aid data interpretation. Ensure the panels maintain consistent styling with the existing UI and are responsive across different screen sizes.",
            "status": "pending",
            "testStrategy": "Create component tests to verify rendering with different data inputs. Test interactive features like tooltips, time period selection, and responsive behavior. Conduct usability testing to ensure data is presented clearly and intuitively."
          },
          {
            "id": 5,
            "title": "Implement User Configuration and Preferences",
            "description": "Add functionality for users to customize the analytics panels, including time periods, basket compositions, and default views.",
            "dependencies": [],
            "details": "Create a configuration interface that allows users to customize their analytics experience. Implement settings for time period selection (1D, 1W, 1M, 3M, 6M, 1Y, YTD) for trend analysis. Add functionality to create and modify custom FX baskets with user-defined currency weights. Develop a system to save user preferences for default views and restore them on subsequent sessions. Ensure all configuration changes dynamically update the visualizations without requiring page reloads.",
            "status": "pending",
            "testStrategy": "Test the persistence of user preferences across sessions. Verify that configuration changes correctly update the visualizations. Test edge cases in custom basket creation, including validation of weights and currency selections. Conduct end-to-end tests simulating user configuration workflows."
          }
        ]
      },
      {
        "id": 2,
        "title": "UI Specification for Monetary/FX Analytics Panels",
        "description": "Create detailed wireframes and UI specifications for inflation and FX basket analytics panels, including charts, filters, and trend windows, with component API definitions and test-ids according to design/ui_visual_design.md.",
        "details": "This task involves creating comprehensive UI specifications for the Monetary/FX Analytics Panels:\n\n1. Wireframe Development:\n   - Create detailed wireframes for inflation analytics panel showing:\n     - Main inflation indices chart with historical trends\n     - Filtering controls for timeframe and metrics selection\n     - Comparison view for multiple inflation indicators\n   - Design FX basket analytics panel wireframes including:\n     - Currency weightings visualization\n     - Performance metrics charts\n     - Trend analysis windows with customizable timeframes\n\n2. Component API Definitions:\n   - Define props and interfaces for each UI component:\n     ```typescript\n     interface AnalyticsPanelProps {\n       title: string;\n       dataSource: string;\n       filters: FilterConfig[];\n       defaultTimeframe: TimeframeOption;\n     }\n     \n     interface ChartComponentProps {\n       data: DataPoint[];\n       chartType: 'line' | 'bar' | 'area';\n       annotations?: Annotation[];\n       interactionHandlers: InteractionHandlers;\n     }\n     ```\n   - Document event handlers and state management approach\n   - Define data models required for each visualization\n\n3. Test-ID Implementation Plan:\n   - Create a systematic naming convention for test-ids\n   - Map test-ids to each UI component following pattern:\n     ```\n     data-testid=\"analytics-{panel-type}-{component-type}-{specific-identifier}\"\n     ```\n   - Document all test-ids in a reference table for QA team\n\n4. Interaction Specifications:\n   - Define user interactions (clicks, hovers, drags)\n   - Document responsive behavior across device sizes\n   - Specify animation and transition requirements\n\n5. Playwright Test Plan Outline:\n   - Create test scenarios for each component\n   - Define data fixtures needed for testing\n   - Document expected visual states for snapshot testing",
        "testStrategy": "The UI specification will be verified through the following steps:\n\n1. Design Review:\n   - Conduct a formal review with design team to ensure wireframes match visual design guidelines\n   - Verify all components adhere to the design system in design/ui_visual_design.md\n   - Confirm accessibility requirements are met in the specifications\n\n2. Developer Feedback:\n   - Present specifications to frontend developers for implementation feasibility review\n   - Collect feedback on component API definitions and make necessary adjustments\n   - Verify test-id naming conventions are consistent and follow project standards\n\n3. Prototype Validation:\n   - Create a simple clickable prototype of key interactions\n   - Validate that the prototype demonstrates all required functionality\n   - Ensure the prototype works with sample data fixtures\n\n4. Test Plan Verification:\n   - Review Playwright test plan with QA team\n   - Verify that all UI components have corresponding test coverage\n   - Confirm data fixtures are sufficient for comprehensive testing\n\n5. Documentation Completeness Check:\n   - Ensure all wireframes are properly annotated\n   - Verify component API documentation is complete\n   - Confirm all test-ids are documented and follow the established pattern",
        "status": "pending",
        "dependencies": [
          1
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Implement Education Budget System with Expertise/Research Modifiers",
        "description": "Develop a system for managing education budgets and institutions that affect expertise/research with deterministic modifiers, including KPIs, analytics panels, and required API endpoints.",
        "details": "This task involves implementing the education budget system with the following components:\n\n1. Data Models:\n   - Create `EducationBudget` model with fields for budget allocation, institution types, and funding distribution\n   - Implement `EducationModifier` model to represent how budget allocations affect expertise/research metrics\n   - Design modifier caps system to ensure balanced gameplay mechanics\n   - Ensure all modifiers are deterministic with clearly defined formulas\n\n2. Backend Implementation:\n   - Develop API endpoints:\n     - `POST /education/budget`: Accepts budget allocation requests with validation for total budget constraints\n     - `GET /analytics/education`: Returns education KPIs, modifier effects, and historical performance\n   - Implement business logic for calculating expertise/research modifiers based on budget allocations\n   - Create validation middleware to ensure budget allocations stay within defined bounds\n   - Implement deterministic calculation engine that guarantees consistent results for identical inputs\n\n3. Analytics Panel:\n   - Develop education KPI dashboard showing:\n     - Current budget allocation visualization\n     - Expertise/research modifier effects\n     - Historical trends in education outcomes\n     - Comparative analysis against benchmarks\n   - Implement real-time updates when budget allocations change\n\n4. Integration:\n   - Connect education system with existing analytics framework\n   - Ensure proper data flow between education budget system and other game mechanics\n   - Document all modifier formulas and caps in the technical documentation\n\n5. Performance Considerations:\n   - Optimize modifier calculations for performance\n   - Implement caching for frequently accessed education analytics\n   - Ensure system can handle rapid budget reallocation scenarios",
        "testStrategy": "Testing will focus on verifying the education budget system functions correctly:\n\n1. Unit Tests:\n   - Test budget allocation validation logic\n   - Verify modifier calculations produce expected results for various budget scenarios\n   - Confirm modifier caps are properly enforced\n   - Test deterministic behavior by ensuring identical inputs produce identical outputs\n   - Validate API endpoint request/response formats\n\n2. Integration Tests:\n   - Test interaction between education budget system and analytics framework\n   - Verify KPI calculations correctly reflect budget changes\n   - Test budget allocation limits and validation across multiple API calls\n\n3. Performance Tests:\n   - Benchmark modifier calculation performance\n   - Test system under high load with multiple concurrent budget changes\n   - Verify analytics panel updates efficiently with budget changes\n\n4. Specific Test Cases:\n   - Edge case: Test maximum budget allocation to a single institution\n   - Edge case: Test minimum budget allocation across all institutions\n   - Test budget reallocation scenarios and verify modifier changes\n   - Verify deterministic behavior across multiple test runs\n   - Test API error handling for invalid budget allocations\n\n5. UI Testing:\n   - Verify analytics panels correctly display education KPIs\n   - Test filtering and time-range selection in education analytics\n   - Confirm all UI elements update correctly when budget allocations change",
        "status": "pending",
        "dependencies": [
          1
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Education Budget Data Models",
            "description": "Implement the core data models for the education budget system including EducationBudget and EducationModifier models with appropriate relationships and validation rules.",
            "dependencies": [],
            "details": "Create the following models:\n1. EducationBudget model with fields for total allocation, fiscal period, and distribution percentages across different institution types (primary, secondary, higher education, research institutions)\n2. EducationModifier model with fields for modifier type (expertise/research), affected metric, formula parameters, and cap values\n3. Implement validation rules to ensure budget allocations sum to 100% and stay within defined bounds\n4. Add necessary database migrations and seed data for initial education institution types",
            "status": "pending",
            "testStrategy": "Unit test the models with various valid and invalid inputs to verify validation rules work correctly. Test edge cases for budget allocation percentages and modifier calculations."
          },
          {
            "id": 2,
            "title": "Implement Budget Allocation Backend Logic",
            "description": "Develop the core business logic for calculating expertise and research modifiers based on education budget allocations with deterministic formulas.",
            "dependencies": [
              "3.1"
            ],
            "details": "Implement the following components:\n1. Create a ModifierCalculationService that computes expertise/research modifiers based on budget allocations\n2. Implement deterministic formulas for each institution type's impact on expertise/research metrics\n3. Add a capping mechanism to ensure modifiers stay within balanced gameplay ranges\n4. Create utility functions for validating budget allocations against available resources\n5. Implement historical tracking of budget allocations and their effects",
            "status": "pending",
            "testStrategy": "Write comprehensive unit tests for the modifier calculation logic with various budget allocation scenarios. Verify that identical inputs always produce identical outputs. Test edge cases and boundary conditions."
          },
          {
            "id": 3,
            "title": "Develop Education Budget API Endpoints",
            "description": "Create the required API endpoints for managing education budgets and retrieving analytics data.",
            "dependencies": [
              "3.1",
              "3.2"
            ],
            "details": "Implement the following API endpoints:\n1. POST /education/budget - For submitting new budget allocations with validation\n2. GET /education/budget - For retrieving current budget allocation\n3. GET /analytics/education - For retrieving education KPIs, modifier effects, and historical data\n4. Implement request validation middleware to ensure budget allocations are valid\n5. Add error handling for invalid requests with appropriate HTTP status codes\n6. Document all endpoints using API documentation standards",
            "status": "pending",
            "testStrategy": "Create integration tests for each endpoint verifying correct responses for valid inputs and appropriate error handling for invalid inputs. Test authorization rules and rate limiting if applicable."
          },
          {
            "id": 4,
            "title": "Create Education Analytics Dashboard Components",
            "description": "Develop the frontend components for visualizing education budget allocations, modifier effects, and historical trends.",
            "dependencies": [
              "3.3"
            ],
            "details": "Implement the following dashboard components:\n1. Budget allocation visualization (pie/bar charts showing distribution across institution types)\n2. Modifier effect panels showing current expertise/research bonuses from education\n3. Historical trend charts for education outcomes over time\n4. Comparative analysis view showing performance against benchmarks\n5. Interactive controls for adjusting budget allocations with real-time feedback on modifier changes\n6. Implement responsive design for all components",
            "status": "pending",
            "testStrategy": "Create component tests verifying proper rendering and interaction. Test responsive behavior across different screen sizes. Verify that visualizations correctly represent the underlying data."
          },
          {
            "id": 5,
            "title": "Implement Caching and Performance Optimizations",
            "description": "Optimize the education budget system for performance, implementing caching strategies and efficient calculation methods.",
            "dependencies": [
              "3.2",
              "3.3"
            ],
            "details": "Implement the following optimizations:\n1. Add Redis caching for frequently accessed education analytics data\n2. Optimize modifier calculations to minimize computational overhead\n3. Implement batch processing for historical data analysis\n4. Add database indexes to improve query performance\n5. Implement efficient data structures for storing and retrieving education metrics\n6. Add performance monitoring to identify bottlenecks",
            "status": "pending",
            "testStrategy": "Conduct performance testing under various load conditions. Measure response times before and after optimizations. Verify cache hit rates and identify any remaining performance bottlenecks."
          },
          {
            "id": 6,
            "title": "Integrate Education System with Existing Game Mechanics",
            "description": "Connect the education budget system with other game systems, ensuring proper data flow and interaction between components.",
            "dependencies": [
              "3.2",
              "3.3",
              "3.4",
              "3.5"
            ],
            "details": "Complete the following integration tasks:\n1. Connect education modifiers to the expertise/research calculation pipeline\n2. Ensure budget allocations are properly constrained by the overall game economy\n3. Add event listeners to update education metrics when relevant game state changes\n4. Implement hooks for other systems to query education modifiers\n5. Update technical documentation with all modifier formulas and integration points\n6. Create integration tests verifying proper system interaction",
            "status": "pending",
            "testStrategy": "Develop end-to-end tests that verify the complete flow from budget allocation to expertise/research effects. Test interaction with other game systems to ensure proper data flow and state management."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-14T08:09:14.538Z",
      "updated": "2025-08-14T09:29:26.310Z",
      "description": "Tag created on 8/14/2025"
    }
  },
  "sprint-1-core": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Core Simulation Engine",
        "description": "Create the core simulation engine that advances campaign state on a fixed tick with deterministic behavior.",
        "details": "Create src/server/sim/engine.ts with step({campaignId, seed, actions[]}) function that processes game state in a deterministic manner.\n\nImplementation details:\n1. Use a seeded PRNG (like seedrandom library) to ensure deterministic outcomes\n2. Implement the reducer pipeline in the specified order: production -> queues -> logistics cap -> prices -> readiness/science proxies -> apply policy/tax modifiers -> KPIs + Vezies\n3. Ensure all operations are idempotent and wrapped in a database transaction\n4. Create helper functions for each reducer step\n5. Persist KPI snapshots to kpi_snapshots table\n6. Emit Vezies events for queue completion and new planet discoveries\n\nExample code structure:\n```typescript\nimport { seedrandom } from 'seedrandom';\n\nexport async function step({ campaignId, seed, actions = [] }) {\n  // Initialize PRNG with seed\n  const rng = seedrandom(seed);\n  \n  // Start transaction\n  return db.transaction(async (tx) => {\n    // Load campaign state\n    const state = await loadCampaignState(campaignId, tx);\n    \n    // Apply pending actions\n    const stateWithActions = applyPendingActions(state, actions);\n    \n    // Run reducers in sequence\n    const afterProduction = productionReducer(stateWithActions, rng);\n    const afterQueues = queueReducer(afterProduction, rng);\n    const afterLogistics = logisticsReducer(afterQueues, rng);\n    const afterPrices = priceReducer(afterLogistics, rng);\n    const afterProxies = readinessAndScienceReducer(afterPrices, rng);\n    const afterPolicies = policyModifierReducer(afterProxies, rng);\n    const finalState = kpiAndVeziesReducer(afterPolicies, rng);\n    \n    // Persist state changes and KPI snapshots\n    await persistStateChanges(finalState, tx);\n    await persistKpiSnapshot(campaignId, finalState.kpis, tx);\n    \n    // Emit Vezies events\n    await emitVeziesEvents(finalState.veziesEvents, tx);\n    \n    return finalState;\n  });\n}\n```",
        "testStrategy": "1. Unit tests for each reducer function to verify correct behavior with controlled inputs\n2. Integration test for the step function to ensure all reducers are called in the correct order\n3. API test for POST /api/sim/step endpoint to verify 200 response and KPI snapshot creation\n4. Determinism test: verify that the same seed and inputs always produce identical outputs\n5. Transaction test: verify that failed steps don't persist partial state changes",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up the simulation engine structure",
            "description": "Create the basic structure for the simulation engine including the main step function and PRNG initialization",
            "dependencies": [],
            "details": "Create src/server/sim/engine.ts with the step function that accepts campaignId, seed, and actions parameters. Set up the seeded PRNG using the seedrandom library. Implement the transaction wrapper and state loading functions. Create skeleton functions for each reducer step that will be implemented in subsequent tasks.",
            "status": "pending",
            "testStrategy": "Write unit tests to verify the PRNG initialization with different seeds produces consistent results. Test the transaction wrapper to ensure proper error handling and rollback functionality."
          },
          {
            "id": 2,
            "title": "Implement production and queue reducers",
            "description": "Create the first two reducers in the pipeline: production and queue processing",
            "dependencies": [],
            "details": "Implement the productionReducer function that calculates resource production based on current state. Create the queueReducer function that processes building and research queues, advancing progress and completing items when finished. Both reducers should use the seeded RNG for any random operations to ensure deterministic behavior.",
            "status": "pending",
            "testStrategy": "Create unit tests with mock campaign states to verify production calculations are correct. Test queue processing with various queue states to ensure items complete at the expected time and trigger appropriate state changes."
          },
          {
            "id": 3,
            "title": "Implement logistics, price, and proxy reducers",
            "description": "Create the middle reducers in the pipeline: logistics capacity, price adjustments, and readiness/science proxies",
            "dependencies": [],
            "details": "Implement the logisticsReducer to calculate and enforce logistics capacity limits. Create the priceReducer to adjust resource prices based on supply and demand. Develop the readinessAndScienceReducer to calculate military readiness and science progress proxies based on current state.",
            "status": "pending",
            "testStrategy": "Test logistics capacity enforcement with states that exceed capacity. Verify price adjustments respond correctly to different supply/demand scenarios. Ensure readiness and science calculations properly reflect the current game state."
          },
          {
            "id": 4,
            "title": "Implement policy modifiers and KPI/Vezies reducers",
            "description": "Create the final reducers in the pipeline: policy/tax modifiers and KPI/Vezies calculations",
            "dependencies": [],
            "details": "Implement the policyModifierReducer to apply active policy and tax effects to the game state. Create the kpiAndVeziesReducer to calculate key performance indicators and generate Vezies events. Ensure all KPI data is properly formatted for storage in the kpi_snapshots table.",
            "status": "pending",
            "testStrategy": "Test policy modifier application with various policy configurations. Verify KPI calculations match expected values for given states. Test Vezies event generation for queue completions and planet discoveries."
          },
          {
            "id": 5,
            "title": "Implement state persistence and event emission",
            "description": "Create functions to persist state changes, KPI snapshots, and emit Vezies events",
            "dependencies": [],
            "details": "Implement the persistStateChanges function to save the updated game state to the database. Create the persistKpiSnapshot function to store KPI data in the kpi_snapshots table. Develop the emitVeziesEvents function to process and emit events generated during simulation. Ensure all operations are idempotent and properly handled within the database transaction.",
            "status": "pending",
            "testStrategy": "Test state persistence with various state changes to verify correct database updates. Verify KPI snapshots are properly stored with correct timestamps and values. Test event emission to ensure events are properly formatted and delivered."
          }
        ]
      },
      {
        "id": 2,
        "title": "Create Simulation API Endpoint",
        "description": "Implement the API endpoint for triggering simulation steps and retrieving simulation results.",
        "details": "Create a new API endpoint at POST /api/sim/step that triggers the simulation engine to advance the game state by one tick.\n\nImplementation details:\n1. Create a new route handler in the API routes directory\n2. Accept campaignId and optional seed parameter (generate one if not provided)\n3. Call the engine.step() function with the provided parameters\n4. Return the updated KPI snapshot and any Vezies events\n5. Include appropriate error handling and validation\n6. Mark as dev-only in production environments\n\nExample implementation:\n```typescript\n// src/pages/api/sim/step.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { step } from '@/server/sim/engine';\nimport { generateSeed } from '@/utils/random';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (process.env.NODE_ENV === 'production' && !process.env.ENABLE_DEV_ENDPOINTS) {\n    return res.status(403).json({ error: 'Endpoint disabled in production' });\n  }\n\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  try {\n    const { campaignId, seed = generateSeed(), actions = [] } = req.body;\n    \n    if (!campaignId) {\n      return res.status(400).json({ error: 'campaignId is required' });\n    }\n    \n    const result = await step({ campaignId, seed, actions });\n    \n    return res.status(200).json({\n      success: true,\n      seed,\n      kpiSnapshot: result.kpiSnapshot,\n      veziesEvents: result.veziesEvents\n    });\n  } catch (error) {\n    console.error('Simulation step error:', error);\n    return res.status(500).json({ error: 'Failed to process simulation step' });\n  }\n}\n```",
        "testStrategy": "1. API test to verify the endpoint returns 200 with valid inputs\n2. Test that the endpoint rejects non-POST methods with 405\n3. Test that the endpoint requires campaignId parameter\n4. Test that the endpoint is disabled in production unless explicitly enabled\n5. Verify that the response contains the expected KPI snapshot and Vezies events",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create API route handler file structure",
            "description": "Set up the basic file structure for the simulation API endpoint in the API routes directory",
            "dependencies": [],
            "details": "Create the file src/pages/api/sim/step.ts with the basic Next.js API route handler structure. Import necessary types and dependencies including NextApiRequest, NextApiResponse, and the simulation engine. Set up the handler function with proper method checking for POST requests.",
            "status": "pending",
            "testStrategy": "Verify the file structure is correctly set up and imports are working. Test that the endpoint returns 405 for non-POST methods."
          },
          {
            "id": 2,
            "title": "Implement request validation and parameter handling",
            "description": "Add validation for required parameters and handle optional parameters with defaults",
            "dependencies": [
              "2.1"
            ],
            "details": "Extract and validate the campaignId parameter from the request body, ensuring it's required. Implement optional seed parameter handling with fallback to generateSeed() function if not provided. Set up the actions array parameter with a default empty array. Add appropriate error responses for missing required parameters.",
            "status": "pending",
            "testStrategy": "Test that the endpoint requires campaignId parameter and returns 400 if missing. Verify that seed is generated when not provided. Test with various combinations of parameters to ensure proper validation."
          },
          {
            "id": 3,
            "title": "Integrate with simulation engine",
            "description": "Connect the API endpoint to the core simulation engine to process simulation steps",
            "dependencies": [
              "2.2"
            ],
            "details": "Call the engine.step() function with the validated parameters (campaignId, seed, actions). Ensure the function call is properly awaited and wrapped in a try-catch block. Structure the response to include the updated KPI snapshot and Vezies events returned from the engine.",
            "status": "pending",
            "testStrategy": "Test that the endpoint correctly calls the simulation engine with the right parameters. Verify that the response contains the expected data structure with KPI snapshot and Vezies events."
          },
          {
            "id": 4,
            "title": "Implement error handling and logging",
            "description": "Add comprehensive error handling and logging for the API endpoint",
            "dependencies": [
              "2.3"
            ],
            "details": "Implement try-catch block to handle any errors that occur during the simulation step. Log errors with appropriate context information using console.error or a dedicated logging service. Return standardized error responses with appropriate HTTP status codes (400 for client errors, 500 for server errors).",
            "status": "pending",
            "testStrategy": "Test error scenarios by mocking the simulation engine to throw errors. Verify that errors are properly caught, logged, and returned with appropriate status codes. Test with various error types to ensure comprehensive handling."
          },
          {
            "id": 5,
            "title": "Add production environment safeguards",
            "description": "Implement safeguards to disable the endpoint in production unless explicitly enabled",
            "dependencies": [
              "2.1"
            ],
            "details": "Add environment checking logic to disable the endpoint in production environments unless explicitly enabled via ENABLE_DEV_ENDPOINTS environment variable. Return a 403 Forbidden response with an appropriate error message when the endpoint is accessed in production without the flag enabled.",
            "status": "pending",
            "testStrategy": "Test the endpoint behavior in different environments by mocking process.env.NODE_ENV and process.env.ENABLE_DEV_ENDPOINTS. Verify that the endpoint returns 403 in production without the flag and works correctly when the flag is enabled."
          }
        ]
      },
      {
        "id": 3,
        "title": "Implement Policy Storage and Management",
        "description": "Create database schema and API endpoints for storing and managing free-form policies with their associated modifiers.",
        "details": "Implement the storage and management of free-form policies that can be parsed into game modifiers.\n\nImplementation details:\n1. Create database migrations for the policies and policy_modifiers tables:\n```sql\nCREATE TABLE IF NOT EXISTS policies (\n  id SERIAL PRIMARY KEY,\n  title VARCHAR(255) NOT NULL,\n  body TEXT NOT NULL,\n  scope VARCHAR(50) NOT NULL CHECK (scope IN ('campaign', 'region', 'system')),\n  tags JSONB DEFAULT '[]',\n  effective_at TIMESTAMP WITH TIME ZONE,\n  expires_at TIMESTAMP WITH TIME ZONE,\n  author VARCHAR(255),\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS policy_modifiers (\n  id SERIAL PRIMARY KEY,\n  policy_id INTEGER REFERENCES policies(id) ON DELETE CASCADE,\n  key VARCHAR(255) NOT NULL,\n  value NUMERIC NOT NULL,\n  cap_min NUMERIC NOT NULL,\n  cap_max NUMERIC NOT NULL,\n  approved_at TIMESTAMP WITH TIME ZONE,\n  approved_by VARCHAR(255),\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n```\n\n2. Create API endpoints:\n- GET /api/policies - List all policies\n- GET /api/policies/:id - Get a specific policy\n- POST /api/policies - Create a new policy\n- PUT /api/policies/:id - Update a policy\n- DELETE /api/policies/:id - Delete a policy\n- GET /api/policies/active - Get all active policies with approved modifiers\n\n3. Implement database access functions in a repository pattern:\n```typescript\n// src/server/repositories/policyRepository.ts\nexport async function createPolicy(policy) {\n  return db.query(\n    'INSERT INTO policies (title, body, scope, tags, effective_at, expires_at, author) VALUES ($1, $2, $3, $4, $5, $6, $7) RETURNING *',\n    [policy.title, policy.body, policy.scope, JSON.stringify(policy.tags), policy.effective_at, policy.expires_at, policy.author]\n  );\n}\n\nexport async function getActiveModifiers() {\n  const now = new Date();\n  return db.query(\n    `SELECT pm.* FROM policy_modifiers pm\n     JOIN policies p ON pm.policy_id = p.id\n     WHERE pm.approved_at IS NOT NULL\n     AND p.effective_at <= $1\n     AND (p.expires_at IS NULL OR p.expires_at > $1)`,\n    [now]\n  );\n}\n```",
        "testStrategy": "1. Unit tests for database repository functions\n2. API tests for each endpoint to verify CRUD operations\n3. Integration test to verify that active policies are correctly filtered by effective/expiry dates\n4. Test that policy modifiers are correctly associated with policies\n5. Verify that the cap_min and cap_max constraints are enforced",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Database Migrations",
            "description": "Implement database schema for policies and policy_modifiers tables",
            "dependencies": [],
            "details": "Create migration files for the policies table with fields for id, title, body, scope, tags, effective_at, expires_at, author, and created_at. Create migration files for the policy_modifiers table with fields for id, policy_id (foreign key to policies), key, value, cap_min, cap_max, approved_at, approved_by, and created_at. Ensure proper constraints are set including the scope CHECK constraint.",
            "status": "pending",
            "testStrategy": "Verify migrations run successfully and create tables with correct schema. Test constraints by attempting to insert invalid data. Verify foreign key relationships work correctly."
          },
          {
            "id": 2,
            "title": "Implement Policy Repository Functions",
            "description": "Create database access functions using repository pattern for policy operations",
            "dependencies": [
              "3.1"
            ],
            "details": "Implement repository functions for CRUD operations on policies and policy_modifiers: createPolicy, getPolicy, updatePolicy, deletePolicy, listPolicies, createPolicyModifier, getActivePolicies, and getActiveModifiers. Ensure proper error handling and transaction management for operations that affect multiple tables.",
            "status": "pending",
            "testStrategy": "Unit test each repository function with mock database responses. Test edge cases like non-existent records, duplicate entries, and constraint violations. Verify active policies are correctly filtered by dates."
          },
          {
            "id": 3,
            "title": "Create API Endpoints for Policy Management",
            "description": "Implement REST API endpoints for policy CRUD operations",
            "dependencies": [
              "3.2"
            ],
            "details": "Create API handlers for GET /api/policies, GET /api/policies/:id, POST /api/policies, PUT /api/policies/:id, and DELETE /api/policies/:id. Implement request validation, error handling, and appropriate HTTP status codes. Ensure endpoints use the repository functions for database access.",
            "status": "pending",
            "testStrategy": "Test each endpoint with valid and invalid requests. Verify correct HTTP status codes and response formats. Test authentication/authorization if applicable. Verify database operations are performed correctly."
          },
          {
            "id": 4,
            "title": "Implement Active Policies Endpoint",
            "description": "Create endpoint to retrieve active policies with approved modifiers",
            "dependencies": [
              "3.3"
            ],
            "details": "Implement GET /api/policies/active endpoint that returns all currently active policies (based on effective_at and expires_at dates) along with their approved modifiers. Filter out policies without approved modifiers and ensure only active policies are returned.",
            "status": "pending",
            "testStrategy": "Test with policies having various effective/expiry dates. Verify only active policies with approved modifiers are returned. Test with empty database and with policies having no approved modifiers."
          },
          {
            "id": 5,
            "title": "Create Policy Validation and Error Handling",
            "description": "Implement validation logic and error handling for policy operations",
            "dependencies": [
              "3.3",
              "3.4"
            ],
            "details": "Create validation functions for policy and policy_modifier objects. Implement proper error handling for all API endpoints. Ensure modifiers are validated against their cap_min and cap_max values. Create custom error types and consistent error response format across all endpoints.",
            "status": "pending",
            "testStrategy": "Test validation with valid and invalid policy data. Verify error responses have consistent format and appropriate HTTP status codes. Test boundary conditions for modifier caps. Verify validation catches all required fields and format issues."
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement AI Policy Parser",
        "description": "Create an AI-powered endpoint that parses free-form policy text and suggests appropriate game modifiers within capped ranges.",
        "details": "Implement an AI service that analyzes policy text and suggests appropriate modifiers within the specified caps.\n\nImplementation details:\n1. Create a new endpoint POST /api/policies/parse that accepts policy text and returns suggested modifiers\n2. Integrate with an AI service (OpenAI API or similar) to analyze the policy text\n3. Ensure suggested modifiers are within the capped ranges specified in the PRD:\n   - Production: uptime_mult (0.8–1.1), throughput_mult (0.8–1.1)\n   - Logistics: capacity_mult (0.8–1.2), risk_delta (−0.1–0.1)\n   - Prices: tariff_delta (−0.1–0.2), subsidy_delta (−0.15–0.15)\n   - Science: velocity_mult (0.8–1.2)\n   - Military: readiness_mult (0.9–1.1)\n4. Implement a fallback mechanism for when AI is disabled\n\nExample implementation:\n```typescript\n// src/pages/api/policies/parse.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { Configuration, OpenAIApi } from 'openai';\n\nconst MODIFIER_CAPS = {\n  uptime_mult: { min: 0.8, max: 1.1 },\n  throughput_mult: { min: 0.8, max: 1.1 },\n  capacity_mult: { min: 0.8, max: 1.2 },\n  risk_delta: { min: -0.1, max: 0.1 },\n  tariff_delta: { min: -0.1, max: 0.2 },\n  subsidy_delta: { min: -0.15, max: 0.15 },\n  velocity_mult: { min: 0.8, max: 1.2 },\n  readiness_mult: { min: 0.9, max: 1.1 }\n};\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  const { title, body, scope } = req.body;\n  \n  if (!title || !body) {\n    return res.status(400).json({ error: 'Title and body are required' });\n  }\n\n  try {\n    // If AI is disabled, return template suggestions\n    if (!process.env.OPENAI_API_KEY) {\n      return res.status(200).json({\n        suggestedModifiers: [\n          { key: 'uptime_mult', value: 1.05, cap_min: 0.8, cap_max: 1.1 },\n          { key: 'tariff_delta', value: 0.05, cap_min: -0.1, cap_max: 0.2 }\n        ]\n      });\n    }\n\n    // Initialize OpenAI\n    const configuration = new Configuration({\n      apiKey: process.env.OPENAI_API_KEY,\n    });\n    const openai = new OpenAIApi(configuration);\n\n    // Prepare prompt for the AI\n    const prompt = `Analyze this policy and suggest appropriate modifiers within the specified ranges:\\n\\nTitle: ${title}\\nBody: ${body}\\nScope: ${scope}\\n\\nAvailable modifiers and their ranges:\\n${JSON.stringify(MODIFIER_CAPS, null, 2)}\\n\\nReturn only the modifiers that are relevant to this policy, with values within the specified ranges.`;\n\n    // Call OpenAI API\n    const completion = await openai.createCompletion({\n      model: \"text-davinci-003\",\n      prompt,\n      max_tokens: 500,\n    });\n\n    // Parse the AI response and validate modifiers\n    const aiSuggestions = JSON.parse(completion.data.choices[0].text);\n    const validatedModifiers = aiSuggestions.map(mod => ({\n      key: mod.key,\n      value: Math.max(MODIFIER_CAPS[mod.key].min, Math.min(mod.value, MODIFIER_CAPS[mod.key].max)),\n      cap_min: MODIFIER_CAPS[mod.key].min,\n      cap_max: MODIFIER_CAPS[mod.key].max\n    }));\n\n    return res.status(200).json({ suggestedModifiers: validatedModifiers });\n  } catch (error) {\n    console.error('Policy parsing error:', error);\n    return res.status(500).json({ error: 'Failed to parse policy' });\n  }\n}\n```",
        "testStrategy": "1. Unit test the modifier validation logic to ensure values are capped correctly\n2. Mock the AI service response for testing\n3. Test the endpoint with various policy texts and verify the suggested modifiers\n4. Test the fallback mechanism when AI is disabled\n5. Verify that the endpoint rejects requests with missing title or body",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create API Endpoint Structure",
            "description": "Set up the basic structure for the POST /api/policies/parse endpoint that will accept policy text and return suggested modifiers.",
            "dependencies": [],
            "details": "Create the API endpoint file structure in src/pages/api/policies/parse.ts. Implement request validation for required fields (title, body). Set up error handling for invalid requests and server errors. Define the response structure for suggested modifiers that includes key, value, cap_min, and cap_max properties.",
            "status": "pending",
            "testStrategy": "Test endpoint with valid and invalid requests. Verify proper HTTP status codes are returned. Ensure the endpoint rejects non-POST methods with 405 status code. Test validation logic for required fields."
          },
          {
            "id": 2,
            "title": "Define Modifier Caps and Validation Logic",
            "description": "Implement the validation logic to ensure all suggested modifiers are within the specified capped ranges.",
            "dependencies": [
              "4.1"
            ],
            "details": "Create a MODIFIER_CAPS constant that defines the min/max values for each modifier type according to the PRD. Implement a validation function that ensures suggested modifier values are capped within their allowed ranges. The validation should handle all modifier types: production (uptime_mult, throughput_mult), logistics (capacity_mult, risk_delta), prices (tariff_delta, subsidy_delta), science (velocity_mult), and military (readiness_mult).",
            "status": "pending",
            "testStrategy": "Unit test the validation logic with values above, below, and at the cap limits. Verify that values outside the range are properly capped. Test with all modifier types to ensure complete coverage."
          },
          {
            "id": 3,
            "title": "Integrate OpenAI API",
            "description": "Set up the integration with OpenAI API to analyze policy text and suggest appropriate modifiers.",
            "dependencies": [
              "4.1",
              "4.2"
            ],
            "details": "Install and configure the OpenAI SDK. Create a prompt template that effectively communicates the policy analysis task to the AI. Implement the API call to OpenAI with appropriate model selection and parameters. Parse the AI response and convert it to the expected modifier format. Implement error handling for API failures and response parsing issues.",
            "status": "pending",
            "testStrategy": "Mock the OpenAI API responses for testing. Test with various policy texts to verify prompt effectiveness. Verify error handling when the API returns unexpected responses or fails."
          },
          {
            "id": 4,
            "title": "Implement Fallback Mechanism",
            "description": "Create a fallback mechanism that provides default modifier suggestions when AI integration is disabled or unavailable.",
            "dependencies": [
              "4.2"
            ],
            "details": "Implement logic to detect when the OpenAI API key is not available or when the AI service fails. Create a function that generates reasonable default modifier suggestions based on the policy scope. Ensure the fallback suggestions are also within the capped ranges. The fallback should provide at least 2-3 relevant modifiers to give users a starting point.",
            "status": "pending",
            "testStrategy": "Test the fallback mechanism by intentionally disabling the AI integration. Verify that default suggestions are provided and are within the capped ranges. Test with different policy scopes to ensure appropriate defaults are generated."
          },
          {
            "id": 5,
            "title": "Add Environment Configuration and Documentation",
            "description": "Set up environment variables for API keys and add comprehensive documentation for the endpoint.",
            "dependencies": [
              "4.1",
              "4.3",
              "4.4"
            ],
            "details": "Configure environment variables for the OpenAI API key. Add detailed comments explaining the endpoint functionality, expected request/response formats, and the AI integration. Create a README section for the policy parser API with usage examples. Implement logging for debugging and monitoring purposes. Add type definitions for all request and response objects.",
            "status": "pending",
            "testStrategy": "Verify that the endpoint works correctly with and without environment variables set. Review documentation for completeness and accuracy. Test logging functionality to ensure important events are properly recorded."
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement Policy Activation Endpoint",
        "description": "Create an endpoint for approving and activating policy modifiers that will be applied by the simulation engine.",
        "details": "Implement an endpoint to approve and activate policy modifiers that will affect the simulation.\n\nImplementation details:\n1. Create a new endpoint POST /api/policies/activate that accepts policy ID and approved modifiers\n2. Update the policy_modifiers table to mark modifiers as approved\n3. Ensure modifiers are within the capped ranges before approval\n4. Add authentication/authorization checks\n\nExample implementation:\n```typescript\n// src/pages/api/policies/activate.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { getSession } from 'next-auth/react';\nimport { updatePolicyModifiers } from '@/server/repositories/policyRepository';\n\nconst MODIFIER_CAPS = {\n  uptime_mult: { min: 0.8, max: 1.1 },\n  throughput_mult: { min: 0.8, max: 1.1 },\n  capacity_mult: { min: 0.8, max: 1.2 },\n  risk_delta: { min: -0.1, max: 0.1 },\n  tariff_delta: { min: -0.1, max: 0.2 },\n  subsidy_delta: { min: -0.15, max: 0.15 },\n  velocity_mult: { min: 0.8, max: 1.2 },\n  readiness_mult: { min: 0.9, max: 1.1 }\n};\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  // Get user session for authorization\n  const session = await getSession({ req });\n  if (!session) {\n    return res.status(401).json({ error: 'Unauthorized' });\n  }\n\n  const { policyId, modifiers } = req.body;\n  \n  if (!policyId || !modifiers || !Array.isArray(modifiers)) {\n    return res.status(400).json({ error: 'Policy ID and modifiers array are required' });\n  }\n\n  try {\n    // Validate modifiers are within caps\n    const validatedModifiers = modifiers.map(mod => {\n      const caps = MODIFIER_CAPS[mod.key];\n      if (!caps) {\n        throw new Error(`Invalid modifier key: ${mod.key}`);\n      }\n      \n      const value = Math.max(caps.min, Math.min(mod.value, caps.max));\n      \n      return {\n        policy_id: policyId,\n        key: mod.key,\n        value,\n        cap_min: caps.min,\n        cap_max: caps.max,\n        approved_at: new Date(),\n        approved_by: session.user.email\n      };\n    });\n\n    // Update or insert approved modifiers\n    await updatePolicyModifiers(policyId, validatedModifiers);\n\n    return res.status(200).json({\n      success: true,\n      message: 'Policy modifiers activated successfully',\n      modifiers: validatedModifiers\n    });\n  } catch (error) {\n    console.error('Policy activation error:', error);\n    return res.status(500).json({ error: 'Failed to activate policy modifiers' });\n  }\n}\n```",
        "testStrategy": "1. Test that the endpoint correctly validates and caps modifier values\n2. Verify that unauthorized users cannot activate modifiers\n3. Test that modifiers are correctly stored in the database with approval timestamp\n4. Verify that the endpoint rejects invalid modifier keys\n5. Integration test to ensure activated modifiers are applied in the next simulation step",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create API endpoint structure",
            "description": "Set up the basic structure for the POST /api/policies/activate endpoint that will handle policy activation requests.",
            "dependencies": [],
            "details": "Create the endpoint file at src/pages/api/policies/activate.ts. Implement the basic request handler with method validation (POST only). Set up the request body type definition for policyId and modifiers array. Add error handling structure and response formatting.",
            "status": "pending",
            "testStrategy": "Test that the endpoint rejects non-POST methods with 405 status code. Verify the endpoint structure handles basic error cases correctly."
          },
          {
            "id": 2,
            "title": "Implement authentication and authorization",
            "description": "Add user authentication checks to ensure only authorized users can activate policy modifiers.",
            "dependencies": [
              "5.1"
            ],
            "details": "Integrate NextAuth session validation to verify user is logged in. Add authorization logic to check if the user has permission to activate policies. Return appropriate 401 Unauthorized responses for unauthenticated requests.",
            "status": "pending",
            "testStrategy": "Test that unauthenticated requests are rejected with 401 status code. Verify that users with different permission levels are handled correctly."
          },
          {
            "id": 3,
            "title": "Implement modifier validation and capping",
            "description": "Create logic to validate incoming modifiers and ensure they are within the specified capped ranges.",
            "dependencies": [
              "5.1"
            ],
            "details": "Define the MODIFIER_CAPS constant with min/max values for each modifier type. Implement validation logic to check that all submitted modifiers have valid keys. Create capping logic to ensure modifier values are within allowed ranges. Handle validation errors with appropriate error messages.",
            "status": "pending",
            "testStrategy": "Test validation with various modifier values both within and outside allowed ranges. Verify that invalid modifier keys are rejected. Confirm that values outside caps are properly adjusted to the min/max bounds."
          },
          {
            "id": 4,
            "title": "Implement database update functionality",
            "description": "Create the functionality to update the policy_modifiers table with approved modifiers.",
            "dependencies": [
              "5.2",
              "5.3"
            ],
            "details": "Import or implement the updatePolicyModifiers repository function. Add logic to format validated modifiers with approval metadata (timestamp, approver). Ensure proper error handling for database operations. Return appropriate success/error responses based on database operation results.",
            "status": "pending",
            "testStrategy": "Test that modifiers are correctly stored in the database with approval timestamp and approver information. Verify error handling for database failures. Test with various valid modifier combinations."
          },
          {
            "id": 5,
            "title": "Integration testing and documentation",
            "description": "Perform integration testing of the complete endpoint and add documentation for API consumers.",
            "dependencies": [
              "5.4"
            ],
            "details": "Create comprehensive integration tests covering the full endpoint functionality. Add JSDoc comments to document the endpoint's purpose, parameters, and responses. Create example requests and responses for documentation. Ensure the endpoint works correctly with the simulation engine by testing end-to-end flows.",
            "status": "pending",
            "testStrategy": "Perform end-to-end testing with the simulation engine to verify that activated modifiers are correctly applied. Test edge cases like concurrent modifications to the same policy. Document all test scenarios and expected behaviors."
          }
        ]
      },
      {
        "id": 6,
        "title": "Implement AI Advisors System",
        "description": "Create AI advisors for different domains that can provide recommendations and propose actions based on the current game state.",
        "details": "Implement a system of AI advisors that can provide domain-specific recommendations and propose actions.\n\nImplementation details:\n1. Create database migration for the pending_actions table:\n```sql\nCREATE TABLE IF NOT EXISTS pending_actions (\n  id SERIAL PRIMARY KEY,\n  domain VARCHAR(50) NOT NULL CHECK (domain IN ('economy', 'military', 'science', 'logistics', 'governance', 'diplomacy')),\n  payload JSONB NOT NULL,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  approved_at TIMESTAMP WITH TIME ZONE,\n  executed_at TIMESTAMP WITH TIME ZONE\n);\n```\n\n2. Implement advisor endpoints:\n- POST /api/advisors/:domain/query - Ask a question to an advisor\n- POST /api/advisors/:domain/propose - Propose an action for approval\n\n3. Create advisor service with domain-specific logic:\n```typescript\n// src/server/services/advisorService.ts\nimport { Configuration, OpenAIApi } from 'openai';\nimport { getCampaignState } from '@/server/repositories/campaignRepository';\nimport { createPendingAction } from '@/server/repositories/actionRepository';\n\nconst DOMAINS = ['economy', 'military', 'science', 'logistics', 'governance', 'diplomacy'];\n\nexport async function queryAdvisor(domain, campaignId, question) {\n  if (!DOMAINS.includes(domain)) {\n    throw new Error(`Invalid advisor domain: ${domain}`);\n  }\n  \n  // Get current campaign state for context\n  const state = await getCampaignState(campaignId);\n  \n  // If AI is disabled, return template recommendations\n  if (!process.env.OPENAI_API_KEY) {\n    return getTemplateRecommendations(domain, state);\n  }\n  \n  // Initialize OpenAI\n  const configuration = new Configuration({\n    apiKey: process.env.OPENAI_API_KEY,\n  });\n  const openai = new OpenAIApi(configuration);\n  \n  // Prepare domain-specific context\n  const context = getDomainContext(domain, state);\n  \n  // Call OpenAI API\n  const completion = await openai.createCompletion({\n    model: \"text-davinci-003\",\n    prompt: `You are a ${domain} advisor in a space strategy game. The current state is:\\n${JSON.stringify(context, null, 2)}\\n\\nQuestion: ${question}\\n\\nProvide 3 specific recommendations with projected impact on KPIs.`,\n    max_tokens: 500,\n  });\n  \n  // Parse and structure the response\n  const aiResponse = completion.data.choices[0].text;\n  const recommendations = parseRecommendations(aiResponse);\n  \n  return {\n    recommendations,\n    projectedImpact: calculateProjectedImpact(recommendations, state)\n  };\n}\n\nexport async function proposeAction(domain, campaignId, action) {\n  if (!DOMAINS.includes(domain)) {\n    throw new Error(`Invalid advisor domain: ${domain}`);\n  }\n  \n  // Validate the action is appropriate for the domain\n  validateDomainAction(domain, action);\n  \n  // Create a pending action\n  const pendingAction = await createPendingAction({\n    domain,\n    payload: action\n  });\n  \n  return {\n    success: true,\n    pendingActionId: pendingAction.id,\n    message: `Action proposed and pending approval`\n  };\n}\n\n// Helper functions for template responses, context preparation, etc.\n```",
        "testStrategy": "1. Unit tests for each advisor domain to verify recommendation logic\n2. Test the query endpoint with various questions and verify the response format\n3. Test the propose endpoint and verify that pending actions are correctly stored\n4. Integration test to ensure proposed actions are executed in the next simulation step when approved\n5. Verify that the endpoints handle invalid domains appropriately",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Database Migration for Pending Actions",
            "description": "Implement the database migration script for the pending_actions table that will store proposed actions from AI advisors.",
            "dependencies": [],
            "details": "Create a migration file that implements the pending_actions table with the specified schema including id, domain (with domain validation), payload, created_at, approved_at, and executed_at fields. Ensure proper indexing for efficient querying by domain and status.",
            "status": "pending",
            "testStrategy": "Verify the migration runs successfully and creates the table with correct constraints. Test inserting valid and invalid domain values to confirm the CHECK constraint works properly. Verify timestamp fields default correctly."
          },
          {
            "id": 2,
            "title": "Implement Domain-Specific Advisor Logic",
            "description": "Create the core advisor service with specialized logic for each domain (economy, military, science, logistics, governance, diplomacy).",
            "dependencies": [
              "6.1"
            ],
            "details": "Implement the advisor service with domain-specific context preparation, recommendation generation, and impact calculation functions. Create helper functions for each domain that understand the relevant game state metrics and can provide appropriate recommendations. Include fallback template recommendations when AI is disabled.",
            "status": "pending",
            "testStrategy": "Unit test each domain's recommendation logic with various game states. Verify that recommendations are relevant to the domain. Test the fallback mechanism when OpenAI integration is disabled."
          },
          {
            "id": 3,
            "title": "Implement Advisor API Endpoints",
            "description": "Create the API endpoints for querying advisors and proposing actions based on their recommendations.",
            "dependencies": [
              "6.2"
            ],
            "details": "Implement the POST /api/advisors/:domain/query endpoint for asking questions to domain-specific advisors and POST /api/advisors/:domain/propose for submitting actions for approval. Include proper validation for domain parameters and request payloads. Ensure authentication and rate limiting are implemented.",
            "status": "pending",
            "testStrategy": "Test both endpoints with valid and invalid domains. Verify query responses contain structured recommendations. Test action proposals are correctly stored in the pending_actions table. Verify error handling for invalid requests."
          },
          {
            "id": 4,
            "title": "Implement Action Approval and Execution System",
            "description": "Create the system for reviewing, approving, and executing pending actions proposed by advisors.",
            "dependencies": [
              "6.1",
              "6.3"
            ],
            "details": "Implement endpoints for listing pending actions (GET /api/pending-actions), approving actions (POST /api/pending-actions/:id/approve), and rejecting actions (POST /api/pending-actions/:id/reject). Create a service that executes approved actions by updating the appropriate game state based on the action domain and payload.",
            "status": "pending",
            "testStrategy": "Test the approval workflow from proposal to execution. Verify that approved_at and executed_at timestamps are correctly updated. Test that rejected actions are properly handled. Verify that executed actions correctly modify the game state."
          },
          {
            "id": 5,
            "title": "Implement AI Integration with OpenAI",
            "description": "Integrate the advisor system with OpenAI's API to generate intelligent, context-aware recommendations.",
            "dependencies": [
              "6.2",
              "6.3"
            ],
            "details": "Implement the OpenAI API integration for generating advisor recommendations. Create prompt templates for each domain that include relevant game state context. Implement response parsing to extract structured recommendations from AI completions. Add error handling and retry logic for API failures.",
            "status": "pending",
            "testStrategy": "Test the OpenAI integration with mock responses. Verify that prompts include appropriate context for each domain. Test the parsing logic with various AI responses. Verify graceful degradation when the API is unavailable."
          }
        ]
      },
      {
        "id": 7,
        "title": "Integrate Policy Modifiers with Simulation Engine",
        "description": "Extend the simulation engine to apply active policy modifiers during each step of the simulation.",
        "details": "Modify the simulation engine to read and apply active policy modifiers during each simulation step.\n\nImplementation details:\n1. Update the engine.ts file to load active policy modifiers at the beginning of each step\n2. Implement a policyModifierReducer function that applies the modifiers to the appropriate game state values\n3. Ensure modifiers are applied within their capped ranges\n4. Log all applied modifiers with provenance for reproducibility\n\nExample implementation:\n```typescript\n// src/server/sim/engine.ts - Add to existing file\nimport { getActiveModifiers } from '@/server/repositories/policyRepository';\n\n// Add to step function\nasync function step({ campaignId, seed, actions = [] }) {\n  // ... existing code ...\n  \n  // Load active policy modifiers\n  const activeModifiers = await getActiveModifiers();\n  \n  // ... run reducers ...\n  const afterProxies = readinessAndScienceReducer(afterPrices, rng);\n  const afterPolicies = policyModifierReducer(afterProxies, activeModifiers, rng);\n  const finalState = kpiAndVeziesReducer(afterPolicies, rng);\n  \n  // ... existing code ...\n}\n\n// Policy modifier reducer\nfunction policyModifierReducer(state, modifiers, rng) {\n  const newState = { ...state };\n  const appliedModifiers = [];\n  \n  // Group modifiers by key for easier processing\n  const modifiersByKey = modifiers.reduce((acc, mod) => {\n    if (!acc[mod.key]) acc[mod.key] = [];\n    acc[mod.key].push(mod);\n    return acc;\n  }, {});\n  \n  // Apply production modifiers\n  if (modifiersByKey.uptime_mult) {\n    const uptimeModifier = calculateCombinedModifier(modifiersByKey.uptime_mult);\n    newState.production.uptime *= uptimeModifier;\n    appliedModifiers.push({ key: 'uptime_mult', value: uptimeModifier, source: 'policy' });\n  }\n  \n  if (modifiersByKey.throughput_mult) {\n    const throughputModifier = calculateCombinedModifier(modifiersByKey.throughput_mult);\n    newState.production.throughput *= throughputModifier;\n    appliedModifiers.push({ key: 'throughput_mult', value: throughputModifier, source: 'policy' });\n  }\n  \n  // Apply logistics modifiers\n  if (modifiersByKey.capacity_mult) {\n    const capacityModifier = calculateCombinedModifier(modifiersByKey.capacity_mult);\n    newState.logistics.capacity *= capacityModifier;\n    appliedModifiers.push({ key: 'capacity_mult', value: capacityModifier, source: 'policy' });\n  }\n  \n  if (modifiersByKey.risk_delta) {\n    const riskDelta = calculateCombinedDelta(modifiersByKey.risk_delta);\n    newState.logistics.risk += riskDelta;\n    newState.logistics.risk = Math.max(0, Math.min(1, newState.logistics.risk)); // Clamp between 0 and 1\n    appliedModifiers.push({ key: 'risk_delta', value: riskDelta, source: 'policy' });\n  }\n  \n  // Apply price modifiers\n  // ... similar implementation for other modifier types ...\n  \n  // Log all applied modifiers\n  newState.logs.push({\n    type: 'policy_modifiers',\n    timestamp: new Date(),\n    data: { appliedModifiers }\n  });\n  \n  return newState;\n}\n\n// Helper function to calculate combined multiplicative modifiers\nfunction calculateCombinedModifier(modifiers) {\n  return modifiers.reduce((acc, mod) => acc * mod.value, 1);\n}\n\n// Helper function to calculate combined additive deltas\nfunction calculateCombinedDelta(modifiers) {\n  return modifiers.reduce((acc, mod) => acc + mod.value, 0);\n}\n```",
        "testStrategy": "1. Unit test the policyModifierReducer function with various modifier combinations\n2. Test that modifiers are correctly applied within their capped ranges\n3. Verify that the combined effect of multiple modifiers of the same type is calculated correctly\n4. Test that all applied modifiers are properly logged\n5. Integration test to verify that policies created and activated through the API affect the simulation as expected",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Update engine.ts to load active policy modifiers",
            "description": "Modify the simulation engine to fetch active policy modifiers at the beginning of each simulation step.",
            "dependencies": [],
            "details": "Update the step function in engine.ts to import and call getActiveModifiers from the policy repository. Ensure the modifiers are loaded before any reducers are applied. Add appropriate error handling for cases where modifiers cannot be loaded.",
            "status": "pending",
            "testStrategy": "Test that the engine correctly loads active modifiers at the beginning of each step. Verify error handling when the policy repository is unavailable."
          },
          {
            "id": 2,
            "title": "Implement policyModifierReducer function",
            "description": "Create a reducer function that applies policy modifiers to the appropriate game state values.",
            "dependencies": [
              "7.1"
            ],
            "details": "Implement the policyModifierReducer function that takes the current state, active modifiers, and RNG as inputs. Group modifiers by key for easier processing. Apply modifiers to production, logistics, and other relevant game state properties. Return the modified state.",
            "status": "pending",
            "testStrategy": "Unit test the policyModifierReducer with various modifier combinations. Verify that different types of modifiers (multiplicative, additive) are correctly applied to the appropriate state properties."
          },
          {
            "id": 3,
            "title": "Implement modifier capping and validation",
            "description": "Ensure all applied modifiers are within their defined capped ranges.",
            "dependencies": [
              "7.2"
            ],
            "details": "Add validation to ensure that after modifiers are applied, the affected values remain within their allowed ranges. Implement helper functions like calculateCombinedModifier and calculateCombinedDelta to properly combine multiple modifiers of the same type. Add clamping functions to restrict values to their min/max bounds.",
            "status": "pending",
            "testStrategy": "Test that values are properly clamped when modifiers would push them beyond their allowed ranges. Verify that combined modifiers are calculated correctly when multiple modifiers affect the same property."
          },
          {
            "id": 4,
            "title": "Add logging for applied modifiers",
            "description": "Log all applied policy modifiers with provenance information for reproducibility.",
            "dependencies": [
              "7.2",
              "7.3"
            ],
            "details": "Extend the policyModifierReducer to track all applied modifiers in an appliedModifiers array. For each modifier, record its key, calculated value, and source. Add a new log entry to the state.logs array with type 'policy_modifiers' that includes the timestamp and applied modifiers data.",
            "status": "pending",
            "testStrategy": "Verify that all applied modifiers are correctly logged with their provenance information. Test that the logs contain accurate timestamps and modifier details."
          },
          {
            "id": 5,
            "title": "Integrate policyModifierReducer into the simulation pipeline",
            "description": "Update the simulation pipeline to include the policy modifier reducer between existing reducers.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.3",
              "7.4"
            ],
            "details": "Modify the step function to call the policyModifierReducer at the appropriate point in the simulation pipeline. Position it after the readinessAndScienceReducer and before the kpiAndVeziesReducer. Ensure the modified state is passed correctly to subsequent reducers.",
            "status": "pending",
            "testStrategy": "Integration test the full simulation pipeline to verify that policy modifiers are correctly applied during each step. Test that the effects of policy modifiers are properly reflected in the final state and subsequent calculations."
          }
        ]
      },
      {
        "id": 8,
        "title": "Integrate Advisor Actions with Simulation Engine",
        "description": "Extend the simulation engine to process and apply pending advisor actions during each simulation step.",
        "details": "Modify the simulation engine to process pending advisor actions during each simulation step.\n\nImplementation details:\n1. Update the engine.ts file to load approved pending actions at the beginning of each step\n2. Implement domain-specific action handlers for each advisor domain\n3. Mark actions as executed after they are processed\n4. Log all executed actions with their effects\n\nExample implementation:\n```typescript\n// src/server/sim/engine.ts - Add to existing file\nimport { getApprovedPendingActions, markActionsExecuted } from '@/server/repositories/actionRepository';\n\n// Add to step function\nasync function step({ campaignId, seed, actions = [] }) {\n  // ... existing code ...\n  \n  // Load approved pending actions\n  const pendingActions = await getApprovedPendingActions();\n  \n  // Apply pending actions to initial state\n  const stateWithActions = applyPendingActions(state, [...actions, ...pendingActions]);\n  \n  // ... run reducers ...\n  \n  // Mark pending actions as executed\n  await markActionsExecuted(pendingActions.map(a => a.id));\n  \n  // ... existing code ...\n}\n\n// Function to apply pending actions\nfunction applyPendingActions(state, actions) {\n  const newState = { ...state };\n  const executedActions = [];\n  \n  for (const action of actions) {\n    try {\n      switch (action.domain) {\n        case 'economy':\n          applyEconomyAction(newState, action.payload);\n          break;\n        case 'military':\n          applyMilitaryAction(newState, action.payload);\n          break;\n        case 'science':\n          applyScienceAction(newState, action.payload);\n          break;\n        case 'logistics':\n          applyLogisticsAction(newState, action.payload);\n          break;\n        case 'governance':\n          applyGovernanceAction(newState, action.payload);\n          break;\n        case 'diplomacy':\n          applyDiplomacyAction(newState, action.payload);\n          break;\n        default:\n          throw new Error(`Unknown action domain: ${action.domain}`);\n      }\n      \n      executedActions.push({\n        id: action.id,\n        domain: action.domain,\n        payload: action.payload,\n        status: 'executed'\n      });\n    } catch (error) {\n      console.error(`Failed to apply ${action.domain} action:`, error);\n      executedActions.push({\n        id: action.id,\n        domain: action.domain,\n        payload: action.payload,\n        status: 'failed',\n        error: error.message\n      });\n    }\n  }\n  \n  // Log all executed actions\n  newState.logs.push({\n    type: 'executed_actions',\n    timestamp: new Date(),\n    data: { executedActions }\n  });\n  \n  return newState;\n}\n\n// Domain-specific action handlers\nfunction applyEconomyAction(state, payload) {\n  switch (payload.type) {\n    case 'adjust_tariff':\n      state.economy.tariffRate += payload.delta;\n      state.economy.tariffRate = Math.max(0, Math.min(1, state.economy.tariffRate)); // Clamp between 0 and 1\n      break;\n    case 'adjust_subsidy':\n      state.economy.subsidyRate += payload.delta;\n      state.economy.subsidyRate = Math.max(0, Math.min(1, state.economy.subsidyRate)); // Clamp between 0 and 1\n      break;\n    // ... other economy action types ...\n    default:\n      throw new Error(`Unknown economy action type: ${payload.type}`);\n  }\n}\n\n// ... similar implementations for other domains ...\n```",
        "testStrategy": "1. Unit test each domain-specific action handler\n2. Test the applyPendingActions function with various action combinations\n3. Verify that actions are correctly marked as executed after processing\n4. Test error handling for invalid actions\n5. Integration test to verify that advisor actions proposed and approved through the API affect the simulation as expected",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Update engine.ts to load pending actions",
            "description": "Modify the simulation engine to fetch approved pending actions at the beginning of each step and prepare them for processing.",
            "dependencies": [],
            "details": "Update the engine.ts file to import necessary functions from actionRepository. Add code to the step function to fetch approved pending actions using getApprovedPendingActions(). Combine these pending actions with any explicitly passed actions for processing in the simulation step.",
            "status": "pending",
            "testStrategy": "Unit test the modified step function to verify it correctly fetches and combines pending actions. Mock the repository functions to return predefined test actions."
          },
          {
            "id": 2,
            "title": "Implement applyPendingActions function",
            "description": "Create a function that applies a list of actions to the simulation state and tracks their execution status.",
            "dependencies": [
              "8.1"
            ],
            "details": "Implement the applyPendingActions function that takes the current state and a list of actions. The function should create a copy of the state, process each action based on its domain, and track which actions were executed successfully or failed. Return the updated state with all actions applied.",
            "status": "pending",
            "testStrategy": "Test the function with various combinations of actions across different domains. Verify it properly handles errors for invalid actions without affecting other actions' execution."
          },
          {
            "id": 3,
            "title": "Implement domain-specific action handlers",
            "description": "Create handler functions for each advisor domain that apply domain-specific actions to the simulation state.",
            "dependencies": [
              "8.2"
            ],
            "details": "Implement separate handler functions for each domain (economy, military, science, logistics, governance, diplomacy). Each handler should process different action types within its domain and apply the appropriate changes to the simulation state. Include proper validation and error handling for each action type.",
            "status": "pending",
            "testStrategy": "Unit test each domain handler with various action types and payloads. Verify that state changes are applied correctly and that invalid actions throw appropriate errors."
          },
          {
            "id": 4,
            "title": "Add action execution logging",
            "description": "Extend the simulation state to log all executed actions with their effects and status.",
            "dependencies": [
              "8.2",
              "8.3"
            ],
            "details": "Modify the applyPendingActions function to add entries to the state's logs array for all executed actions. Each log entry should include the action ID, domain, payload, execution status (executed/failed), timestamp, and any error messages for failed actions.",
            "status": "pending",
            "testStrategy": "Test that actions are properly logged in the state with correct timestamps and details. Verify both successful and failed actions are logged appropriately."
          },
          {
            "id": 5,
            "title": "Implement action execution marking",
            "description": "Update the repository to mark actions as executed after they are processed by the simulation engine.",
            "dependencies": [
              "8.2",
              "8.4"
            ],
            "details": "After all actions are applied and logged, call the markActionsExecuted function with the IDs of all processed actions. Update the actionRepository implementation to properly mark these actions as executed in the database with an execution timestamp.",
            "status": "pending",
            "testStrategy": "Test that actions are correctly marked as executed in the database after processing. Verify that subsequent simulation steps don't reprocess already executed actions."
          }
        ]
      },
      {
        "id": 9,
        "title": "Implement KPI and Vezies Integration",
        "description": "Integrate KPI tracking and Vezies scoring into the simulation engine and create endpoints for retrieving analytics data.",
        "details": "Implement KPI tracking and Vezies scoring in the simulation engine and update analytics endpoints to use the engine data.\n\nImplementation details:\n1. Create a kpiAndVeziesReducer function in the engine that calculates KPIs and generates Vezies events\n2. Persist KPI snapshots to the kpi_snapshots table\n3. Generate Vezies events for queue completion, planet creation, and production milestones\n4. Update the GET /api/analytics/empire endpoint to use the latest KPI snapshot from the engine\n\nExample implementation:\n```typescript\n// src/server/sim/engine.ts - Add to existing file\nimport { createKpiSnapshot } from '@/server/repositories/kpiRepository';\nimport { createVezyEvent } from '@/server/repositories/vezyRepository';\n\n// KPI and Vezies reducer\nfunction kpiAndVeziesReducer(state, rng) {\n  const newState = { ...state };\n  const vezyEvents = [];\n  \n  // Calculate KPIs\n  const kpis = calculateKpis(newState);\n  newState.kpis = kpis;\n  \n  // Check for queue completions\n  const completedQueues = findCompletedQueues(state, newState);\n  for (const queue of completedQueues) {\n    vezyEvents.push({\n      type: 'queue_completion',\n      source: 'empire',\n      data: { queueId: queue.id, itemType: queue.itemType }\n    });\n  }\n  \n  // Check for new planets\n  const newPlanets = findNewPlanets(state, newState);\n  for (const planet of newPlanets) {\n    vezyEvents.push({\n      type: 'planet_creation',\n      source: 'discovery',\n      data: { planetId: planet.id, systemId: planet.systemId }\n    });\n  }\n  \n  // Check for production milestones\n  const productionMilestones = findProductionMilestones(state, newState);\n  for (const milestone of productionMilestones) {\n    vezyEvents.push({\n      type: 'production_milestone',\n      source: 'empire',\n      data: { resourceType: milestone.resourceType, amount: milestone.amount }\n    });\n  }\n  \n  newState.vezyEvents = vezyEvents;\n  \n  return newState;\n}\n\n// Helper function to calculate KPIs\nfunction calculateKpis(state) {\n  return {\n    economy: {\n      gdp: calculateGdp(state),\n      resourceBalance: calculateResourceBalance(state),\n      tradeVolume: calculateTradeVolume(state)\n    },\n    military: {\n      fleetStrength: calculateFleetStrength(state),\n      readiness: state.military.readiness\n    },\n    science: {\n      researchOutput: calculateResearchOutput(state),\n      techLevel: state.science.techLevel\n    },\n    logistics: {\n      capacity: state.logistics.capacity,\n      efficiency: calculateLogisticsEfficiency(state)\n    },\n    governance: {\n      stability: calculateStability(state),\n      approval: calculateApproval(state)\n    }\n  };\n}\n\n// Helper functions for finding events and calculating KPIs\n// ...\n\n// Update persistKpiSnapshot function\nasync function persistKpiSnapshot(campaignId, kpis, tx) {\n  return createKpiSnapshot({\n    campaignId,\n    timestamp: new Date(),\n    data: kpis\n  }, tx);\n}\n\n// Function to emit Vezies events\nasync function emitVeziesEvents(events, tx) {\n  for (const event of events) {\n    await createVezyEvent({\n      type: event.type,\n      source: event.source,\n      sourceId: event.data.id || null,\n      data: event.data\n    }, tx);\n  }\n}\n```\n\n// Update analytics endpoint\n```typescript\n// src/pages/api/analytics/empire.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { getLatestKpiSnapshot } from '@/server/repositories/kpiRepository';\nimport { getLegacyAnalytics } from '@/server/services/analyticsService';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'GET') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  const { campaignId } = req.query;\n  \n  if (!campaignId) {\n    return res.status(400).json({ error: 'campaignId is required' });\n  }\n\n  try {\n    // Try to get the latest KPI snapshot from the engine\n    const latestSnapshot = await getLatestKpiSnapshot(campaignId);\n    \n    if (latestSnapshot) {\n      return res.status(200).json({\n        success: true,\n        kpis: latestSnapshot.data,\n        timestamp: latestSnapshot.timestamp,\n        source: 'engine'\n      });\n    }\n    \n    // Fall back to legacy analytics if no snapshot exists\n    const legacyAnalytics = await getLegacyAnalytics(campaignId);\n    \n    return res.status(200).json({\n      success: true,\n      kpis: legacyAnalytics,\n      timestamp: new Date(),\n      source: 'legacy'\n    });\n  } catch (error) {\n    console.error('Analytics error:', error);\n    return res.status(500).json({ error: 'Failed to retrieve analytics' });\n  }\n}\n```",
        "testStrategy": "1. Unit test the kpiAndVeziesReducer function to verify KPI calculations\n2. Test the event generation logic for queue completions, new planets, and production milestones\n3. Verify that KPI snapshots are correctly persisted to the database\n4. Test the GET /api/analytics/empire endpoint to ensure it returns the latest KPI snapshot\n5. Verify that the endpoint falls back to legacy analytics when no snapshot exists",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement kpiAndVeziesReducer function",
            "description": "Create a reducer function in the simulation engine that calculates KPIs and generates Vezies events based on state changes.",
            "dependencies": [],
            "details": "Develop the kpiAndVeziesReducer function that takes the current state and returns a new state with updated KPIs and Vezies events. Implement helper functions for calculating various KPIs (economy, military, science, logistics, governance) and detecting events like queue completions, planet creations, and production milestones.",
            "status": "pending",
            "testStrategy": "Write unit tests to verify KPI calculations for different game states. Test event detection logic for queue completions, new planets, and production milestones. Ensure the reducer properly maintains state immutability."
          },
          {
            "id": 2,
            "title": "Implement KPI snapshot persistence",
            "description": "Create functionality to persist KPI snapshots to the database at regular intervals during simulation.",
            "dependencies": [
              "9.1"
            ],
            "details": "Implement the persistKpiSnapshot function that saves KPI data to the kpi_snapshots table. Ensure this function is called at appropriate intervals during the simulation cycle. Include timestamp and campaign ID with each snapshot. Create necessary database repository functions.",
            "status": "pending",
            "testStrategy": "Test that KPI snapshots are correctly persisted to the database with proper timestamps. Verify that snapshots contain all required KPI metrics. Test error handling for database operations."
          },
          {
            "id": 3,
            "title": "Implement Vezies event generation",
            "description": "Create functionality to generate and persist Vezies events for key game milestones.",
            "dependencies": [
              "9.1"
            ],
            "details": "Implement the emitVeziesEvents function that creates Vezies events in the database. Generate events for queue completions, planet creations, and production milestones. Ensure each event has the correct type, source, and data payload. Create necessary database repository functions for the vezy_events table.",
            "status": "pending",
            "testStrategy": "Test that Vezies events are correctly generated for different game state changes. Verify that events contain the proper metadata and payloads. Test error handling for event persistence."
          },
          {
            "id": 4,
            "title": "Update analytics endpoint",
            "description": "Modify the GET /api/analytics/empire endpoint to use the latest KPI snapshot from the engine.",
            "dependencies": [
              "9.2"
            ],
            "details": "Update the analytics endpoint to retrieve the latest KPI snapshot from the database. Implement fallback to legacy analytics if no snapshot exists. Return the KPI data with timestamp and source information. Add proper error handling and validation for the campaignId parameter.",
            "status": "pending",
            "testStrategy": "Test the endpoint with various scenarios including existing snapshots and fallback to legacy analytics. Verify the response format and error handling. Test with invalid campaign IDs and other edge cases."
          },
          {
            "id": 5,
            "title": "Integrate KPI and Vezies with simulation cycle",
            "description": "Integrate the KPI and Vezies functionality into the main simulation cycle.",
            "dependencies": [
              "9.1",
              "9.2",
              "9.3"
            ],
            "details": "Update the main simulation cycle to include the kpiAndVeziesReducer in the processing pipeline. Ensure KPI snapshots are persisted and Vezies events are emitted at appropriate points in the cycle. Add transaction support to ensure data consistency between the simulation state and persisted data.",
            "status": "pending",
            "testStrategy": "Perform integration testing of the full simulation cycle with KPI and Vezies functionality. Verify that KPIs are calculated and persisted correctly during simulation. Test that Vezies events are generated at the right moments. Check for performance impacts on the simulation cycle."
          }
        ]
      },
      {
        "id": 10,
        "title": "Implement HUD Updates and UI Integration",
        "description": "Update the HUD to display simulation results, policy management, and advisor recommendations.",
        "details": "Update the HUD to integrate with the simulation engine, policy management, and advisor systems.\n\nImplementation details:\n1. Add a Step Engine button to /demo/hud that triggers a simulation step\n2. Create a Policies panel for submitting and managing policies\n3. Create an Advisors panel for querying advisors and proposing actions\n4. Update the analytics display to show the latest KPI data\n\nExample implementation:\n```typescript\n// src/components/demo/SimulationControls.tsx\nimport { useState } from 'react';\nimport { Button, Alert } from '@/components/ui';\n\nexport function SimulationControls({ campaignId }) {\n  const [loading, setLoading] = useState(false);\n  const [result, setResult] = useState(null);\n  const [error, setError] = useState(null);\n\n  const handleStepEngine = async () => {\n    setLoading(true);\n    setError(null);\n    \n    try {\n      const response = await fetch('/api/sim/step', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ campaignId })\n      });\n      \n      const data = await response.json();\n      \n      if (!response.ok) {\n        throw new Error(data.error || 'Failed to step engine');\n      }\n      \n      setResult(data);\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"p-4 border rounded-lg\">\n      <h2 className=\"text-xl font-bold mb-4\">Simulation Controls</h2>\n      \n      <Button \n        onClick={handleStepEngine} \n        disabled={loading}\n        className=\"mb-4\"\n      >\n        {loading ? 'Processing...' : 'Step Engine'}\n      </Button>\n      \n      {error && (\n        <Alert variant=\"error\" className=\"mb-4\">\n          {error}\n        </Alert>\n      )}\n      \n      {result && (\n        <div className=\"mt-4\">\n          <h3 className=\"font-semibold\">Last Step Results:</h3>\n          <pre className=\"bg-gray-100 p-2 rounded mt-2 text-xs overflow-auto\">\n            {JSON.stringify(result, null, 2)}\n          </pre>\n        </div>\n      )}\n    </div>\n  );\n}\n\n// src/components/demo/PolicyPanel.tsx\nimport { useState } from 'react';\nimport { Button, TextArea, Input, Select } from '@/components/ui';\n\nexport function PolicyPanel({ campaignId }) {\n  const [title, setTitle] = useState('');\n  const [body, setBody] = useState('');\n  const [scope, setScope] = useState('campaign');\n  const [suggestions, setSuggestions] = useState(null);\n  const [loading, setLoading] = useState(false);\n  const [error, setError] = useState(null);\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    setLoading(true);\n    setError(null);\n    \n    try {\n      const response = await fetch('/api/policies/parse', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ title, body, scope })\n      });\n      \n      const data = await response.json();\n      \n      if (!response.ok) {\n        throw new Error(data.error || 'Failed to parse policy');\n      }\n      \n      setSuggestions(data.suggestedModifiers);\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const handleActivate = async () => {\n    setLoading(true);\n    setError(null);\n    \n    try {\n      // First create the policy\n      const createResponse = await fetch('/api/policies', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ title, body, scope })\n      });\n      \n      const policyData = await createResponse.json();\n      \n      if (!createResponse.ok) {\n        throw new Error(policyData.error || 'Failed to create policy');\n      }\n      \n      // Then activate the modifiers\n      const activateResponse = await fetch('/api/policies/activate', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          policyId: policyData.policy.id,\n          modifiers: suggestions\n        })\n      });\n      \n      const activateData = await activateResponse.json();\n      \n      if (!activateResponse.ok) {\n        throw new Error(activateData.error || 'Failed to activate policy');\n      }\n      \n      // Reset form\n      setTitle('');\n      setBody('');\n      setSuggestions(null);\n      \n      alert('Policy created and activated successfully!');\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"p-4 border rounded-lg\">\n      <h2 className=\"text-xl font-bold mb-4\">Policy Console</h2>\n      \n      <form onSubmit={handleSubmit}>\n        <Input\n          label=\"Title\"\n          value={title}\n          onChange={(e) => setTitle(e.target.value)}\n          required\n          className=\"mb-4\"\n        />\n        \n        <Select\n          label=\"Scope\"\n          value={scope}\n          onChange={(e) => setScope(e.target.value)}\n          options={[\n            { value: 'campaign', label: 'Campaign' },\n            { value: 'region', label: 'Region' },\n            { value: 'system', label: 'System' }\n          ]}\n          className=\"mb-4\"\n        />\n        \n        <TextArea\n          label=\"Policy Text\"\n          value={body}\n          onChange={(e) => setBody(e.target.value)}\n          rows={6}\n          required\n          className=\"mb-4\"\n        />\n        \n        <Button type=\"submit\" disabled={loading}>\n          {loading ? 'Analyzing...' : 'Analyze Policy'}\n        </Button>\n      </form>\n      \n      {error && (\n        <Alert variant=\"error\" className=\"my-4\">\n          {error}\n        </Alert>\n      )}\n      \n      {suggestions && (\n        <div className=\"mt-6\">\n          <h3 className=\"font-semibold mb-2\">Suggested Modifiers:</h3>\n          \n          <ul className=\"mb-4\">\n            {suggestions.map((mod, index) => (\n              <li key={index} className=\"mb-2\">\n                <strong>{mod.key}:</strong> {mod.value} (Range: {mod.cap_min} to {mod.cap_max})\n              </li>\n            ))}\n          </ul>\n          \n          <Button onClick={handleActivate} disabled={loading}>\n            {loading ? 'Activating...' : 'Approve & Activate'}\n          </Button>\n        </div>\n      )}\n    </div>\n  );\n}\n\n// Similar implementation for AdvisorPanel component\n// ...\n\n// Update main HUD component to include these new panels\n```",
        "testStrategy": "1. Playwright UI tests for the Step Engine button functionality\n2. Test the Policies panel flow: submit text → see suggestions → approve → step → KPI change\n3. Test the Advisors panel flow: ask → get recommendation → propose → step → change visible\n4. Verify that the analytics display updates after a simulation step\n5. Test error handling and loading states in all UI components",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement SimulationControls Component",
            "description": "Create a component that allows users to trigger simulation steps and view results",
            "dependencies": [],
            "details": "Develop the SimulationControls.tsx component that includes a 'Step Engine' button to trigger simulation steps. The component should handle API calls to /api/sim/step, display loading states, show errors if they occur, and present the results of the simulation step in a readable format. Include proper error handling and loading indicators.",
            "status": "pending",
            "testStrategy": "Test the API integration with mock responses, verify loading states are correctly displayed, ensure error messages appear when API calls fail, and confirm simulation results are properly rendered."
          },
          {
            "id": 2,
            "title": "Implement PolicyPanel Component",
            "description": "Create a component for submitting and managing policies with modifier suggestions",
            "dependencies": [
              "10.1"
            ],
            "details": "Develop the PolicyPanel.tsx component that allows users to create policies with title, body, and scope. Implement form validation, API integration with /api/policies/parse for analysis, and /api/policies and /api/policies/activate for creation and activation. Display suggested modifiers and provide approval functionality.",
            "status": "pending",
            "testStrategy": "Test form validation, API integration for policy parsing, verify modifier suggestions display correctly, test policy creation and activation flows, and ensure proper error handling throughout the process."
          },
          {
            "id": 3,
            "title": "Implement AdvisorPanel Component",
            "description": "Create a component for querying advisors and proposing actions based on recommendations",
            "dependencies": [
              "10.1"
            ],
            "details": "Develop the AdvisorPanel.tsx component that allows users to query domain-specific advisors and receive recommendations. Implement functionality to ask questions, display advisor responses, and propose actions based on recommendations. Include domain selection, question input, and action proposal confirmation.",
            "status": "pending",
            "testStrategy": "Test advisor query functionality with different domains, verify recommendation display, test action proposal flow, ensure proper error handling, and check that proposed actions are correctly submitted to the API."
          },
          {
            "id": 4,
            "title": "Update Analytics Display Component",
            "description": "Enhance the analytics display to show the latest KPI data from the simulation engine",
            "dependencies": [
              "10.1"
            ],
            "details": "Update the existing analytics display component to fetch and visualize the latest KPI data from the simulation engine. Implement data fetching from the /api/analytics/empire endpoint, create visualizations for key metrics, and ensure the display updates after simulation steps are executed.",
            "status": "pending",
            "testStrategy": "Test data fetching from the analytics API, verify visualizations correctly represent the data, ensure the display updates after simulation steps, and test fallback behavior when data is unavailable."
          },
          {
            "id": 5,
            "title": "Integrate Components into Main HUD",
            "description": "Combine all components into the main HUD interface with proper layout and styling",
            "dependencies": [
              "10.1",
              "10.2",
              "10.3",
              "10.4"
            ],
            "details": "Integrate the SimulationControls, PolicyPanel, AdvisorPanel, and updated Analytics Display components into the main HUD interface. Implement responsive layout, consistent styling, and ensure all components work together seamlessly. Add navigation between different panels if needed and ensure the UI is intuitive.",
            "status": "pending",
            "testStrategy": "Test the integrated HUD with all components, verify responsive behavior across different screen sizes, ensure consistent styling and theme application, test navigation between panels, and conduct end-to-end testing of complete workflows."
          }
        ]
      },
      {
        "id": 11,
        "title": "Implement Synthetic Population Micro-Cohorts",
        "description": "Represent the population as micro-cohorts with belief, trust, and needs embeddings that collapse to deterministic aggregates per simulation tick, integrating with opinion cohorts and media effects.",
        "details": "Implement a synthetic population system using micro-cohorts with the following components:\n\n1. Create a database schema for storing population micro-cohorts:\n```sql\nCREATE TABLE IF NOT EXISTS population_cohorts (\n  id SERIAL PRIMARY KEY,\n  campaign_id INTEGER NOT NULL REFERENCES campaigns(id),\n  region_id INTEGER NOT NULL REFERENCES regions(id),\n  belief_embedding JSONB NOT NULL,\n  trust_embedding JSONB NOT NULL,\n  needs_embedding JSONB NOT NULL,\n  size INTEGER NOT NULL,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS opinion_snapshots (\n  id SERIAL PRIMARY KEY,\n  campaign_id INTEGER NOT NULL REFERENCES campaigns(id),\n  tick INTEGER NOT NULL,\n  region_id INTEGER NOT NULL REFERENCES regions(id),\n  opinion_data JSONB NOT NULL,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n```\n\n2. Implement a cohort reducer in the simulation engine:\n```typescript\n// src/server/sim/reducers/populationReducer.ts\nimport { deterministicShuffle } from '../utils/deterministic';\nimport { applyPolicyModifiers } from './policyModifierReducer';\n\nexport function populationReducer(state, seed) {\n  const prng = new seedrandom(seed);\n  \n  // Process each region's population cohorts\n  const regions = state.regions.map(region => {\n    // Get active speeches and media effects for this region\n    const mediaEffects = getActiveMediaEffects(state, region.id);\n    \n    // Process cohorts with deterministic behavior\n    const cohorts = getCohorts(state, region.id);\n    const processedCohorts = processCohorts(cohorts, mediaEffects, prng);\n    \n    // Apply policy modifiers with zod-capped values\n    const modifiedCohorts = applyPolicyModifiers(processedCohorts, state.activeModifiers);\n    \n    // Generate deterministic opinion aggregates\n    const opinionAggregate = generateOpinionAggregate(modifiedCohorts);\n    \n    // Store the snapshot for this tick\n    storeOpinionSnapshot(state.campaignId, state.currentTick, region.id, opinionAggregate);\n    \n    return {\n      ...region,\n      currentOpinion: opinionAggregate\n    };\n  });\n  \n  return {\n    ...state,\n    regions\n  };\n}\n\n// Helper functions for cohort processing with deterministic behavior\nfunction processCohorts(cohorts, mediaEffects, prng) {\n  // Canonicalize the order of operations to ensure determinism\n  const canonicalCohorts = [...cohorts].sort((a, b) => a.id - b.id);\n  \n  return canonicalCohorts.map(cohort => {\n    // Apply media effects to cohort beliefs and trust\n    const updatedCohort = applyMediaEffects(cohort, mediaEffects, prng);\n    return updatedCohort;\n  });\n}\n```\n\n3. Implement the API endpoints for retrieving opinion data:\n```typescript\n// src/pages/api/opinions/index.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { getOpinionSnapshot } from '@/server/db/opinions';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'GET') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n  \n  const { campaignId, tick, regionId } = req.query;\n  \n  if (!campaignId) {\n    return res.status(400).json({ error: 'Campaign ID is required' });\n  }\n  \n  try {\n    const opinions = await getOpinionSnapshot(\n      Number(campaignId),\n      tick ? Number(tick) : undefined,\n      regionId ? Number(regionId) : undefined\n    );\n    \n    return res.status(200).json(opinions);\n  } catch (error) {\n    console.error('Error fetching opinions:', error);\n    return res.status(500).json({ error: 'Failed to fetch opinions' });\n  }\n}\n```\n\n4. Implement an internal aggregation service for summarizing opinion data:\n```typescript\n// src/server/services/opinionAggregationService.ts\nimport { zod } from 'zod';\n\n// Define schema for opinion modifiers with caps\nconst opinionModifierSchema = zod.object({\n  beliefShift: zod.number().min(-0.2).max(0.2),\n  trustShift: zod.number().min(-0.15).max(0.15),\n  needsImpact: zod.number().min(-0.25).max(0.25)\n});\n\nexport function aggregateOpinions(cohorts) {\n  // Group cohorts by similar beliefs and calculate weighted averages\n  const beliefClusters = clusterByBeliefs(cohorts);\n  \n  // Generate natural language summaries at different zoom levels\n  const summaries = {\n    high: generateHighLevelSummary(beliefClusters),\n    medium: generateMediumLevelSummary(beliefClusters),\n    low: generateDetailedSummary(beliefClusters)\n  };\n  \n  return {\n    clusters: beliefClusters,\n    summaries,\n    metrics: calculateMetrics(cohorts)\n  };\n}\n\n// Helper functions for generating zoomable NL summaries\nfunction generateHighLevelSummary(clusters) {\n  // Generate a high-level summary of the major opinion groups\n  // Example: \"Population is generally supportive (65%) with significant opposition (35%)\"\n}\n```\n\n5. Ensure determinism through canonicalization and seeded operations:\n   - Use deterministic shuffling for any randomized operations\n   - Sort all inputs before processing to ensure consistent order\n   - Use seeded PRNG for any probabilistic calculations\n   - Store the seed with each opinion snapshot for reproducibility\n\n6. Implement integration with the existing simulation engine:\n   - Add the populationReducer to the engine's reducer pipeline\n   - Ensure it runs after policy modifiers are applied but before KPI calculations\n   - Update the engine.step() function to include population processing",
        "testStrategy": "1. Unit test the population cohort reducer:\n   - Test with fixed seed values to verify deterministic behavior\n   - Verify that identical inputs with the same seed produce identical outputs\n   - Test edge cases with extreme belief/trust values\n   - Verify that policy modifiers are correctly applied with capped values\n\n2. Test the opinion aggregation service:\n   - Verify that cohort clustering produces expected groupings\n   - Test that natural language summaries are generated correctly at each zoom level\n   - Verify that metrics calculations are accurate\n\n3. Test the API endpoints:\n   - Test GET /opinions with various query parameters\n   - Verify correct error handling for invalid inputs\n   - Test performance with large numbers of cohorts\n\n4. Test determinism and reproducibility:\n   - Run multiple simulations with the same seed and verify identical outputs\n   - Change inputs slightly and verify that outputs change predictably\n   - Test that canonicalization correctly handles out-of-order inputs\n\n5. Integration tests:\n   - Verify that speeches and media effects correctly influence population opinions\n   - Test that policy modifiers are applied with proper caps\n   - Verify that opinion changes affect KPIs and Vezies events appropriately\n\n6. End-to-end tests:\n   - Create a test campaign with synthetic population\n   - Apply speeches, media effects, and policies\n   - Verify that population opinions change as expected over multiple ticks\n   - Test that the UI correctly displays opinion summaries at different zoom levels",
        "status": "pending",
        "dependencies": [
          1,
          7,
          9
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Implement Game Setup with Hero & Nation Mode Selection",
        "description": "Enable players to select Hero mode, Nation mode, or both during campaign setup, persist these settings, and add a HUD toggle for switching between modes when both are enabled.",
        "details": "Implement the game mode selection functionality with the following components:\n\n1. Update the campaign setup UI to include mode selection options:\n```typescript\n// src/components/campaign/SetupScreen.tsx\nimport { useState } from 'react';\nimport { Checkbox, Button, Flex, Text } from '@chakra-ui/react';\n\nconst GameModeSelector = ({ onChange }) => {\n  const [heroMode, setHeroMode] = useState(true);\n  const [nationMode, setNationMode] = useState(false);\n  \n  const handleHeroChange = (e) => {\n    const newHeroValue = e.target.checked;\n    setHeroMode(newHeroValue);\n    // Ensure at least one mode is selected\n    if (!newHeroValue && !nationMode) {\n      setNationMode(true);\n    }\n    onChange({ heroMode: newHeroValue, nationMode: !newHeroValue ? true : nationMode });\n  };\n  \n  const handleNationChange = (e) => {\n    const newNationValue = e.target.checked;\n    setNationMode(newNationValue);\n    // Ensure at least one mode is selected\n    if (!newNationValue && !heroMode) {\n      setHeroMode(true);\n    }\n    onChange({ nationMode: newNationValue, heroMode: !newNationValue ? true : heroMode });\n  };\n  \n  return (\n    <Flex direction=\"column\" gap={2}>\n      <Text fontWeight=\"bold\">Game Modes</Text>\n      <Checkbox isChecked={heroMode} onChange={handleHeroChange}>Hero Mode</Checkbox>\n      <Checkbox isChecked={nationMode} onChange={handleNationChange}>Nation Mode</Checkbox>\n      <Text fontSize=\"sm\" color=\"gray.500\">\n        {heroMode && nationMode ? 'Both modes enabled - switch between them during gameplay' : \n         heroMode ? 'Hero mode only - focus on character development' : \n         'Nation mode only - focus on empire management'}\n      </Text>\n    </Flex>\n  );\n};\n```\n\n2. Update the campaign database schema to store mode settings:\n```sql\nALTER TABLE campaigns ADD COLUMN hero_mode BOOLEAN NOT NULL DEFAULT TRUE;\nALTER TABLE campaigns ADD COLUMN nation_mode BOOLEAN NOT NULL DEFAULT FALSE;\n```\n\n3. Modify the campaign creation API to save mode selections:\n```typescript\n// src/server/api/campaigns.ts\nrouter.post('/campaigns', async (req, res) => {\n  const { name, seed, heroMode = true, nationMode = false, ...otherParams } = req.body;\n  \n  // Validate that at least one mode is selected\n  if (!heroMode && !nationMode) {\n    return res.status(400).json({ error: 'At least one game mode must be selected' });\n  }\n  \n  const campaign = await db.transaction(async (trx) => {\n    const [id] = await trx('campaigns').insert({\n      name,\n      seed,\n      hero_mode: heroMode,\n      nation_mode: nationMode,\n      // other campaign parameters\n    }).returning('id');\n    \n    // Initialize other campaign data\n    \n    return id;\n  });\n  \n  res.status(201).json({ id: campaign });\n});\n```\n\n4. Add a HUD mode toggle component when both modes are enabled:\n```typescript\n// src/components/hud/ModeToggle.tsx\nimport { useState, useEffect } from 'react';\nimport { Button, Tooltip, useToast } from '@chakra-ui/react';\nimport { FaUser, FaGlobe } from 'react-icons/fa';\n\nconst ModeToggle = ({ campaignId }) => {\n  const [activeMode, setActiveMode] = useState('hero'); // 'hero' or 'nation'\n  const [campaign, setCampaign] = useState(null);\n  const toast = useToast();\n  \n  useEffect(() => {\n    // Fetch campaign settings\n    const fetchCampaign = async () => {\n      const response = await fetch(`/api/campaigns/${campaignId}`);\n      const data = await response.json();\n      setCampaign(data);\n      \n      // Load last active mode from localStorage\n      const savedMode = localStorage.getItem(`campaign_${campaignId}_mode`);\n      if (savedMode && ((savedMode === 'hero' && data.hero_mode) || (savedMode === 'nation' && data.nation_mode))) {\n        setActiveMode(savedMode);\n      } else if (data.hero_mode) {\n        setActiveMode('hero');\n      } else if (data.nation_mode) {\n        setActiveMode('nation');\n      }\n    };\n    \n    fetchCampaign();\n  }, [campaignId]);\n  \n  // Don't render if campaign not loaded or only one mode is enabled\n  if (!campaign || !(campaign.hero_mode && campaign.nation_mode)) {\n    return null;\n  }\n  \n  const toggleMode = () => {\n    const newMode = activeMode === 'hero' ? 'nation' : 'hero';\n    setActiveMode(newMode);\n    localStorage.setItem(`campaign_${campaignId}_mode`, newMode);\n    \n    // Notify user of mode change\n    toast({\n      title: `Switched to ${newMode === 'hero' ? 'Hero' : 'Nation'} Mode`,\n      status: 'info',\n      duration: 2000,\n    });\n    \n    // Trigger UI updates based on mode\n    window.dispatchEvent(new CustomEvent('game-mode-changed', { detail: { mode: newMode } }));\n  };\n  \n  return (\n    <Tooltip label={`Switch to ${activeMode === 'hero' ? 'Nation' : 'Hero'} Mode`}>\n      <Button\n        position=\"absolute\"\n        top=\"16px\"\n        right=\"16px\"\n        size=\"md\"\n        colorScheme={activeMode === 'hero' ? 'blue' : 'green'}\n        leftIcon={activeMode === 'hero' ? <FaUser /> : <FaGlobe />}\n        onClick={toggleMode}\n      >\n        {activeMode === 'hero' ? 'Hero' : 'Nation'}\n      </Button>\n    </Tooltip>\n  );\n};\n```\n\n5. Integrate the mode toggle with the HUD layout:\n```typescript\n// src/components/hud/HUDLayout.tsx\nimport ModeToggle from './ModeToggle';\n\nconst HUDLayout = ({ campaignId, children }) => {\n  return (\n    <Box position=\"relative\" w=\"100%\" h=\"100%\">\n      <ModeToggle campaignId={campaignId} />\n      {children}\n    </Box>\n  );\n};\n```\n\n6. Add event listeners to update UI components based on active mode:\n```typescript\n// src/components/hud/SomeHUDComponent.tsx\nuseEffect(() => {\n  const handleModeChange = (e) => {\n    const { mode } = e.detail;\n    // Update component visibility or behavior based on mode\n    setShowHeroControls(mode === 'hero');\n    setShowNationControls(mode === 'nation');\n  };\n  \n  window.addEventListener('game-mode-changed', handleModeChange);\n  return () => {\n    window.removeEventListener('game-mode-changed', handleModeChange);\n  };\n}, []);\n```\n\n7. Follow the UI design specifications in ui_visual_design.md for visual styling and layout of the mode toggle and selection UI.\n\n8. Ensure that the active mode persists across game sessions by:\n   - Storing the selection in the campaign database record\n   - Saving the current active mode (when both are enabled) in localStorage\n   - Restoring the appropriate mode when the game is loaded",
        "testStrategy": "1. Unit tests:\n   - Test the GameModeSelector component to verify it enforces at least one mode selection\n   - Test the campaign creation API to ensure it validates and stores mode settings correctly\n   - Test the ModeToggle component to verify it correctly loads and persists mode selection\n\n2. Integration tests:\n   - Test the campaign setup flow with different mode combinations:\n     - Hero mode only\n     - Nation mode only\n     - Both modes enabled\n   - Verify that campaign creation correctly persists the selected modes to the database\n   - Test that the HUD mode toggle appears only when both modes are enabled\n\n3. End-to-end tests:\n   - Create a new campaign with both modes enabled\n   - Verify the mode toggle is visible in the HUD\n   - Switch between modes and verify that appropriate UI elements show/hide\n   - Reload the game and verify that the last active mode is restored\n   - Test persistence across different browsers and sessions\n\n4. Visual regression tests:\n   - Compare screenshots of the HUD in different modes against the designs in ui_visual_design.md\n   - Verify that the mode toggle appears in the correct position and with proper styling\n   - Test on different screen sizes to ensure responsive behavior\n\n5. User flow tests:\n   - Record a complete user journey from campaign setup through mode selection and toggling\n   - Verify that all UI elements respond correctly to mode changes\n   - Test keyboard shortcuts for mode switching (if implemented)",
        "status": "pending",
        "dependencies": [
          10
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement GameModeSelector Component",
            "description": "Create the GameModeSelector component for the campaign setup UI that allows players to select Hero mode, Nation mode, or both, ensuring at least one mode is always selected.",
            "dependencies": [],
            "details": "1. Create the GameModeSelector component in src/components/campaign/SetupScreen.tsx\n2. Implement state management for heroMode and nationMode with appropriate defaults\n3. Add checkbox controls for each mode with proper styling\n4. Implement validation logic to ensure at least one mode is selected\n5. Add descriptive text that changes based on selected modes\n6. Ensure the component calls the onChange callback with updated mode values\n7. Follow UI design specifications from ui_visual_design.md",
            "status": "pending",
            "testStrategy": "1. Test that the component renders correctly with default values\n2. Verify that attempting to uncheck both modes forces one to remain checked\n3. Test that the onChange callback is called with correct values when modes are toggled\n4. Verify the descriptive text updates correctly based on selection state"
          },
          {
            "id": 2,
            "title": "Update Database Schema and Campaign API",
            "description": "Modify the database schema to store game mode settings and update the campaign creation API to save these selections.",
            "dependencies": [
              "12.1"
            ],
            "details": "1. Create a database migration to add hero_mode and nation_mode columns to the campaigns table\n2. Update the campaign creation API endpoint in src/server/api/campaigns.ts to accept heroMode and nationMode parameters\n3. Implement validation to ensure at least one mode is selected\n4. Modify the campaign retrieval endpoints to include mode information in responses\n5. Update any existing campaign creation forms to include the new GameModeSelector component\n6. Ensure proper error handling for invalid mode combinations",
            "status": "pending",
            "testStrategy": "1. Test the database migration to verify columns are added correctly\n2. Verify the API rejects requests with both modes set to false\n3. Test that mode settings are correctly saved to the database\n4. Verify that existing campaigns are handled correctly with default mode values"
          },
          {
            "id": 3,
            "title": "Implement ModeToggle Component",
            "description": "Create a HUD toggle component that allows players to switch between Hero and Nation modes during gameplay when both modes are enabled.",
            "dependencies": [
              "12.2"
            ],
            "details": "1. Create the ModeToggle component in src/components/hud/ModeToggle.tsx\n2. Implement fetching of campaign settings to determine if both modes are enabled\n3. Add state management for the active mode with localStorage persistence\n4. Create the toggle button UI with appropriate icons and styling\n5. Implement the mode switching logic with toast notifications\n6. Add a custom event dispatch system for notifying other components of mode changes\n7. Ensure the component only renders when both modes are enabled",
            "status": "pending",
            "testStrategy": "1. Test that the component only renders when both modes are enabled\n2. Verify that the active mode is correctly loaded from localStorage\n3. Test that clicking the toggle button switches modes and updates localStorage\n4. Verify that the custom event is dispatched when modes are switched"
          },
          {
            "id": 4,
            "title": "Integrate ModeToggle with HUD Layout",
            "description": "Add the ModeToggle component to the HUD layout and implement the event listener system for UI components to respond to mode changes.",
            "dependencies": [
              "12.3"
            ],
            "details": "1. Import and add the ModeToggle component to src/components/hud/HUDLayout.tsx\n2. Position the toggle button according to UI specifications\n3. Create a reusable hook (useGameMode) that components can use to react to mode changes\n4. Add documentation for other developers on how to make components mode-aware\n5. Update relevant HUD components to show/hide based on the active mode\n6. Ensure the toggle is accessible and works on all device sizes",
            "status": "pending",
            "testStrategy": "1. Test that the ModeToggle is correctly positioned in the HUD\n2. Verify that components using the useGameMode hook correctly respond to mode changes\n3. Test the HUD layout with different screen sizes to ensure the toggle is accessible\n4. Verify that appropriate components show/hide when modes are switched"
          },
          {
            "id": 5,
            "title": "Implement Mode Persistence and Game State Adaptation",
            "description": "Ensure that game mode selections persist across sessions and that the game state adapts appropriately when switching between modes.",
            "dependencies": [
              "12.2",
              "12.4"
            ],
            "details": "1. Update the game loading process to restore the last active mode\n2. Implement a mode-specific state management system that preserves state when switching modes\n3. Create transition animations or effects when switching between modes\n4. Add mode-specific UI elements that appear/disappear based on active mode\n5. Ensure game mechanics and controls adapt appropriately to the active mode\n6. Implement analytics tracking for mode usage and switching patterns\n7. Add a tutorial or tooltip system to explain mode differences to new players",
            "status": "pending",
            "testStrategy": "1. Test that mode selection persists when reloading the game\n2. Verify that game state is preserved when switching between modes\n3. Test the transition animations for smoothness and visual appeal\n4. Verify that all UI elements correctly adapt to mode changes\n5. Test the complete flow from campaign creation through gameplay with mode switching"
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-14T08:11:02.364Z",
      "updated": "2025-08-14T09:28:34.366Z",
      "description": "Unified Sprint 1: Core Loop + Simulation HUD",
      "copiedFrom": {
        "tag": "sprint-a-sim-engine",
        "date": "2025-08-14T08:11:02.364Z"
      }
    }
  },
  "sprint-4-trade": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Stage Mode Backend Services",
        "description": "Create backend services for Stage Mode including speaker roster management, moderator controls, and approval workflows.",
        "details": "Develop REST API endpoints for /stage with the following functionality:\n- GET /stage - Retrieve current stage status and speaker roster\n- POST /stage/request - Request to join stage (raise hand)\n- PUT /stage/approve/:userId - Approve user to join stage\n- PUT /stage/deny/:userId - Deny user's request to join stage\n- PUT /stage/mute/:userId - Mute/unmute user on stage\n\nImplement WebSocket events for real-time stage updates:\n- stage_update: when speaker roster changes\n- request_approved: when a user's request is approved\n- request_denied: when a user's request is denied\n\nEnsure all endpoints include proper authentication and authorization checks. Implement rate limiting to prevent abuse. Store stage state in a database with appropriate caching for performance.",
        "testStrategy": "Unit tests for each endpoint and WebSocket event. Integration tests for the complete stage workflow. Performance tests simulating 50 concurrent participants with response time measurements. Verify that GM summary median is less than 4.5s at 50 participants as specified in requirements.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and implement database schema for stage management",
            "description": "Create database models and schema for storing stage state, speaker roster, and request queue",
            "dependencies": [],
            "details": "Design database schema to store stage state (active/inactive), speaker roster (users currently on stage with their roles and mute status), and request queue (pending requests to join stage). Implement models with appropriate relationships and indexes for efficient querying. Include fields for timestamps, user metadata, and request status tracking.",
            "status": "pending",
            "testStrategy": "Unit tests for database models and relationships. Performance tests for common query patterns. Verify data integrity constraints and indexing effectiveness."
          },
          {
            "id": 2,
            "title": "Develop REST API endpoints for stage management",
            "description": "Implement the specified REST API endpoints for stage operations with authentication and rate limiting",
            "dependencies": [],
            "details": "Implement all required REST endpoints: GET /stage, POST /stage/request, PUT /stage/approve/:userId, PUT /stage/deny/:userId, and PUT /stage/mute/:userId. Add proper authentication middleware to verify user identity and authorization checks to ensure users have appropriate permissions for each action. Implement rate limiting to prevent abuse, with configurable thresholds for different endpoint types.",
            "status": "pending",
            "testStrategy": "Unit tests for each endpoint with various authentication scenarios. Integration tests for complete workflows. Security tests for authentication bypass attempts. Rate limit verification tests."
          },
          {
            "id": 3,
            "title": "Implement WebSocket events for real-time stage updates",
            "description": "Create WebSocket handlers for stage_update, request_approved, and request_denied events",
            "dependencies": [],
            "details": "Develop WebSocket event handlers that emit stage_update events when the speaker roster changes, request_approved events when a user's request is approved, and request_denied events when a user's request is denied. Implement authentication for WebSocket connections and ensure proper event payload formatting. Create mechanisms to trigger these events from the appropriate API endpoints.",
            "status": "pending",
            "testStrategy": "Unit tests for WebSocket event handlers. Integration tests with simulated clients to verify real-time updates. Latency tests to ensure timely delivery of events."
          },
          {
            "id": 4,
            "title": "Implement caching layer for stage state",
            "description": "Create a caching mechanism for stage state to improve performance under load",
            "dependencies": [],
            "details": "Design and implement a caching strategy for stage state data to reduce database load and improve response times. Use Redis or a similar in-memory cache to store frequently accessed data like current stage status and speaker roster. Implement cache invalidation strategies to ensure data consistency when stage state changes. Add configurable TTL values for different cache types.",
            "status": "pending",
            "testStrategy": "Performance tests comparing cached vs. non-cached responses. Cache hit ratio analysis. Consistency tests to verify cache invalidation works correctly. Load tests simulating concurrent access patterns."
          },
          {
            "id": 5,
            "title": "Create comprehensive testing suite and documentation",
            "description": "Develop unit, integration, and performance tests along with API documentation",
            "dependencies": [],
            "details": "Create a comprehensive test suite covering all endpoints and WebSocket events. Implement unit tests for individual components, integration tests for complete workflows, and performance tests simulating 50 concurrent participants. Document all API endpoints with request/response examples, authentication requirements, and error codes. Include WebSocket event documentation with payload schemas and triggering conditions.",
            "status": "pending",
            "testStrategy": "End-to-end testing of complete stage workflows. Performance testing under load conditions to verify response times meet requirements (GM summary median less than 4.5s at 50 participants). Documentation verification through peer review and automated schema validation."
          }
        ]
      },
      {
        "id": 2,
        "title": "Implement Fireteams Backend Services",
        "description": "Create backend services for Fireteams including CRUD operations for squads and team channel assignment.",
        "details": "Develop REST API endpoints for /fireteams with the following functionality:\n- GET /fireteams - List all fireteams\n- POST /fireteams - Create a new fireteam\n- GET /fireteams/:id - Get details of a specific fireteam\n- PUT /fireteams/:id - Update fireteam details\n- DELETE /fireteams/:id - Delete a fireteam\n- POST /fireteams/:id/members - Add members to a fireteam\n- DELETE /fireteams/:id/members/:userId - Remove a member from a fireteam\n- PUT /fireteams/:id/channel - Assign a voice channel to a fireteam\n\nImplement WebSocket events for real-time fireteam updates:\n- fireteam_created: when a new fireteam is created\n- fireteam_updated: when fireteam details change\n- fireteam_deleted: when a fireteam is deleted\n- member_added: when a member joins a fireteam\n- member_removed: when a member leaves a fireteam\n- channel_assigned: when a voice channel is assigned\n\nImplement action batching for efficient updates across fireteams. Ensure proper database schema design for scalability.",
        "testStrategy": "Unit tests for each endpoint and WebSocket event. Integration tests for complete fireteam workflows. Performance tests with 50 participants divided into multiple fireteams. Verify per-team voice stability under load conditions.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Database Schema for Fireteams",
            "description": "Create a scalable database schema to support fireteams functionality including team details, membership, and channel assignments.",
            "dependencies": [],
            "details": "Design database tables and relationships for fireteams, including: team metadata (name, description, status), member associations with roles, voice channel assignments, and activity timestamps. Implement indexes for efficient querying. Create database migration scripts. Document schema with ERD diagrams.",
            "status": "pending",
            "testStrategy": "Unit tests for database models and relationships. Performance tests with large datasets to verify query efficiency. Validation tests for data integrity constraints."
          },
          {
            "id": 2,
            "title": "Develop Core Fireteams REST API Endpoints",
            "description": "Implement the primary REST API endpoints for fireteam CRUD operations.",
            "dependencies": [
              "2.1"
            ],
            "details": "Implement the following endpoints with proper request validation, error handling, and response formatting: GET /fireteams (with pagination and filtering), POST /fireteams (with validation), GET /fireteams/:id, PUT /fireteams/:id, and DELETE /fireteams/:id. Include authentication middleware and permission checks for each endpoint.",
            "status": "pending",
            "testStrategy": "Unit tests for each endpoint covering success and error cases. Integration tests for complete CRUD workflows. API contract tests to ensure specification compliance."
          },
          {
            "id": 3,
            "title": "Implement Member Management API Endpoints",
            "description": "Create endpoints for adding and removing members from fireteams with proper permission handling.",
            "dependencies": [
              "2.1",
              "2.2"
            ],
            "details": "Implement POST /fireteams/:id/members endpoint with validation for member limits and duplicate prevention. Develop DELETE /fireteams/:id/members/:userId endpoint with proper permission checks. Add logic for handling member roles and permissions within teams. Implement validation for team size limits.",
            "status": "pending",
            "testStrategy": "Unit tests for member addition and removal. Permission tests to verify authorization rules. Edge case tests for team size limits and invalid member operations."
          },
          {
            "id": 4,
            "title": "Implement Voice Channel Assignment System",
            "description": "Create the API endpoint and backend logic for assigning voice channels to fireteams.",
            "dependencies": [
              "2.1",
              "2.2"
            ],
            "details": "Implement PUT /fireteams/:id/channel endpoint for assigning voice channels. Create logic for channel availability checking and conflict resolution. Develop channel release mechanism when fireteams are disbanded. Implement validation to prevent channel double-booking.",
            "status": "pending",
            "testStrategy": "Unit tests for channel assignment and validation. Integration tests with voice service. Conflict resolution tests to verify proper handling of channel assignment disputes."
          },
          {
            "id": 5,
            "title": "Implement WebSocket Events and Action Batching",
            "description": "Create WebSocket event system for real-time fireteam updates with efficient action batching.",
            "dependencies": [
              "2.1",
              "2.2",
              "2.3",
              "2.4"
            ],
            "details": "Implement WebSocket server for real-time events. Create event handlers for fireteam_created, fireteam_updated, fireteam_deleted, member_added, member_removed, and channel_assigned events. Develop action batching system to group similar updates for efficient processing. Implement client connection management and authentication for WebSockets.",
            "status": "pending",
            "testStrategy": "Unit tests for each WebSocket event type. Load tests to verify action batching efficiency. Integration tests with frontend to verify real-time updates. Performance tests with multiple concurrent clients."
          }
        ]
      },
      {
        "id": 3,
        "title": "Develop Stage Mode and Fireteams UI Components",
        "description": "Create UI components for Stage Mode and Fireteams including moderator controls, raise-hand functionality, and per-team voice indicators.",
        "details": "Implement the following UI components:\n\nStage Mode:\n- Moderator control panel with approve/deny/mute actions\n- Participant list with status indicators\n- Raise-hand button and request status for participants\n- Speaker roster display\n- Stage join/leave controls\n\nFireteams:\n- Fireteam creation and management interface\n- Team member list with roles\n- Voice channel assignment controls\n- Per-team voice activity indicators\n- Team switching interface\n\nEnsure all UI components are responsive and accessible. Implement real-time updates using WebSocket connections. Add visual feedback for actions and state changes.",
        "testStrategy": "Unit tests for individual UI components. Integration tests for component interactions. User acceptance testing with different roles (moderator, participant). Accessibility testing. Performance testing with 50 concurrent users to ensure UI remains responsive.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Stage Mode Moderator Controls",
            "description": "Create the moderator control panel with approve/deny/mute actions and participant list with status indicators",
            "dependencies": [],
            "details": "Develop a responsive moderator control panel that includes: 1) Approve/deny buttons for stage access requests, 2) Mute/unmute controls for individual participants, 3) Participant list showing current status (speaking, muted, waiting), 4) Real-time updates via WebSocket connections, 5) Visual feedback for action success/failure states",
            "status": "pending",
            "testStrategy": "Unit tests for individual control components. Integration tests for moderator action flows. Accessibility testing for all controls. Performance testing with 50+ participants in the list to ensure UI responsiveness."
          },
          {
            "id": 2,
            "title": "Develop Stage Mode Participant Interface",
            "description": "Implement raise-hand functionality, speaker roster display, and stage join/leave controls for participants",
            "dependencies": [
              "3.1"
            ],
            "details": "Create participant-facing UI components including: 1) Raise-hand button with visual feedback, 2) Request status indicator showing pending/approved/denied states, 3) Speaker roster showing current active speakers, 4) Stage join/leave controls with appropriate state transitions, 5) Real-time updates for all components",
            "status": "pending",
            "testStrategy": "Unit tests for each participant control. Integration tests for the complete participant workflow (request access, receive approval, join stage, speak, leave). Accessibility testing for all interactive elements."
          },
          {
            "id": 3,
            "title": "Create Fireteam Management Interface",
            "description": "Develop UI for fireteam creation, management, and team member list with roles",
            "dependencies": [],
            "details": "Build the fireteam management interface with: 1) Create new fireteam form with name/description fields, 2) Edit/delete controls for existing fireteams, 3) Team member list showing roles (leader, member), 4) Add/remove member functionality, 5) Role assignment controls, 6) Responsive design for all screen sizes",
            "status": "pending",
            "testStrategy": "Unit tests for fireteam CRUD operations. Integration tests for team creation and member management workflows. Accessibility testing for all form elements and controls."
          },
          {
            "id": 4,
            "title": "Implement Voice Channel Assignment UI",
            "description": "Create interface for voice channel assignment controls and per-team voice activity indicators",
            "dependencies": [
              "3.3"
            ],
            "details": "Develop voice-related UI components including: 1) Channel assignment dropdown/selector for each fireteam, 2) Visual voice activity indicators showing which team members are speaking, 3) Mute/unmute controls for team channels, 4) Volume controls for individual members and teams, 5) Real-time updates via WebSocket for voice activity",
            "status": "pending",
            "testStrategy": "Unit tests for channel assignment controls and voice indicators. Integration tests with mock voice data to verify indicator behavior. Performance testing with multiple simultaneous speakers to ensure UI remains responsive."
          },
          {
            "id": 5,
            "title": "Develop Team Switching Interface",
            "description": "Create UI for users to view available fireteams and switch between them",
            "dependencies": [
              "3.3",
              "3.4"
            ],
            "details": "Implement team switching functionality with: 1) List view of all available fireteams with key information, 2) Join/leave team buttons with appropriate permissions, 3) Current team indicator and status, 4) Team switching confirmation dialog, 5) Visual feedback for successful/failed team switches, 6) Real-time updates when team composition changes",
            "status": "pending",
            "testStrategy": "Unit tests for team listing and switching controls. Integration tests for the complete team switching workflow. User acceptance testing with multiple concurrent users switching teams. Verify proper state updates after team changes."
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement Daily Contracts System",
        "description": "Create a system for daily contracts including rotation, UI surfacing, and rewards distribution for cosmetics, QoL improvements, and alliance resources.",
        "details": "Develop the following components:\n\n1. Contract Definition System:\n- JSON schema for contract definitions\n- Contract types (completion, collection, achievement)\n- Reward types (cosmetics, QoL items, alliance resources)\n\n2. Contract Rotation Service:\n- Daily rotation logic with configurable timing\n- Contract selection algorithm to ensure variety\n- REST API for /live-ops/contracts\n\n3. Contract Progress Tracking:\n- Player progress storage and retrieval\n- Completion validation logic\n- Reward distribution system\n\n4. UI Components:\n- Contract display cards\n- Progress indicators\n- Reward previews\n- Completion celebration\n\nImplement a database schema for storing contract definitions, active contracts, and player progress. Create admin tools for contract management.",
        "testStrategy": "Unit tests for contract rotation logic and progress tracking. Integration tests for the complete contract lifecycle. Verification tests for rotation correctness. Load tests to ensure system handles peak user activity. Test reward distribution accuracy.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Contract Definition System",
            "description": "Create the JSON schema for contract definitions, implement contract types, and define reward types",
            "dependencies": [],
            "details": "Develop a JSON schema for contract definitions that includes fields for contract ID, title, description, type (completion, collection, achievement), requirements, rewards, and duration. Implement the three contract types with appropriate validation rules. Define reward types including cosmetics, QoL items, and alliance resources with proper metadata and distribution parameters.",
            "status": "pending",
            "testStrategy": "Unit tests for schema validation, contract type classification, and reward type definitions. Integration tests to verify contract definitions can be properly created, stored, and retrieved."
          },
          {
            "id": 2,
            "title": "Build Contract Rotation Service",
            "description": "Develop the daily rotation logic, contract selection algorithm, and REST API endpoints",
            "dependencies": [
              "4.1"
            ],
            "details": "Create a service that handles daily contract rotation with configurable timing parameters. Implement a selection algorithm that ensures variety in contract offerings and prevents repetition. Develop REST API endpoints for /live-ops/contracts with GET, POST, PUT, and DELETE operations. Include functionality for admin override of rotation schedule.",
            "status": "pending",
            "testStrategy": "Unit tests for rotation timing logic and selection algorithm. API tests for all endpoints. Integration tests to verify contract rotation occurs correctly at configured times. Load tests to ensure the service handles peak user requests."
          },
          {
            "id": 3,
            "title": "Develop Contract Progress Tracking",
            "description": "Create systems for player progress storage, completion validation, and reward distribution",
            "dependencies": [
              "4.1",
              "4.2"
            ],
            "details": "Implement database schema for storing player progress on active contracts. Create validation logic to verify contract completion based on player actions. Develop a reward distribution system that grants appropriate items upon contract completion. Include transaction handling to ensure rewards are properly delivered even during service interruptions.",
            "status": "pending",
            "testStrategy": "Unit tests for progress tracking and validation logic. Integration tests for the complete contract lifecycle from assignment to completion. Stress tests for concurrent completion events. Data integrity tests to verify progress is never lost."
          },
          {
            "id": 4,
            "title": "Create UI Components for Contracts",
            "description": "Design and implement UI elements for contract display, progress tracking, and rewards",
            "dependencies": [
              "4.1",
              "4.3"
            ],
            "details": "Develop contract display cards showing title, description, requirements, and rewards. Create progress indicators that update in real-time as players complete contract objectives. Implement reward previews with detailed item information. Design and build completion celebration animations and notifications. Ensure UI is responsive and accessible.",
            "status": "pending",
            "testStrategy": "UI component tests for proper rendering and state management. User experience testing for clarity and intuitiveness. Performance tests to ensure UI remains responsive during gameplay. Cross-platform compatibility testing."
          },
          {
            "id": 5,
            "title": "Implement Admin Tools and Database Schema",
            "description": "Create database schema for contracts system and develop admin tools for contract management",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "Design and implement comprehensive database schema for storing contract definitions, active contracts, and player progress. Create admin tools with CRUD operations for contract management, including contract creation, editing, activation/deactivation, and performance analytics. Implement monitoring dashboards for contract engagement metrics and reward distribution statistics.",
            "status": "pending",
            "testStrategy": "Database schema validation tests. Admin tool functionality tests for all CRUD operations. Security tests to ensure proper access controls. Performance tests for database queries under load conditions."
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement Weekly Anomaly System",
        "description": "Create a system for weekly anomalies including activation, teardown, and playlist integration with active mutators.",
        "details": "Develop the following components:\n\n1. Anomaly Definition System:\n- JSON schema for anomaly definitions\n- Mutator types and effects\n- Activation/deactivation rules\n\n2. Anomaly Scheduler Service:\n- Weekly rotation logic with configurable timing\n- Anomaly selection algorithm\n- REST API for /live-ops/anomalies\n\n3. Playlist Integration:\n- Playlist modification based on active anomaly\n- Mutator application to gameplay rules\n- State restoration on anomaly teardown\n\n4. UI Components:\n- Anomaly announcement and description\n- Active anomaly indicators\n- Countdown timers for activation/deactivation\n\nImplement database storage for anomaly definitions and active state. Create admin tools for anomaly management and emergency override.",
        "testStrategy": "Unit tests for anomaly rotation logic and playlist integration. Integration tests for the complete anomaly lifecycle. Verification tests for activation/teardown correctness. Test that anomaly properly applies rules and that teardown restores defaults as specified in requirements.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Anomaly Definition System",
            "description": "Create the JSON schema and core components for defining anomalies, including mutator types, effects, and activation/deactivation rules.",
            "dependencies": [],
            "details": "Develop a comprehensive JSON schema for anomaly definitions that includes fields for name, description, duration, mutator types, and effects. Implement the core logic for different mutator types (gameplay modifiers, visual effects, scoring changes) and their impact on game rules. Create a validation system for anomaly definitions and establish clear activation/deactivation rules including triggers, conditions, and cooldown periods.",
            "status": "pending",
            "testStrategy": "Unit tests for schema validation and mutator effect calculations. Integration tests to verify proper loading of anomaly definitions from database. Test edge cases for activation/deactivation rules under various game states."
          },
          {
            "id": 2,
            "title": "Build Anomaly Scheduler Service",
            "description": "Develop the service responsible for weekly rotation logic, anomaly selection, and exposing the REST API endpoints.",
            "dependencies": [
              "5.1"
            ],
            "details": "Implement a scheduler service that handles weekly rotation with configurable timing parameters. Create an anomaly selection algorithm that ensures variety and prevents repetition. Develop REST API endpoints for /live-ops/anomalies with GET, POST, PUT, and DELETE operations. Include authentication and authorization for admin operations. Implement notification system for upcoming and active anomalies.",
            "status": "pending",
            "testStrategy": "Unit tests for rotation logic and selection algorithms. API endpoint testing with mock requests. Integration tests for the complete scheduling lifecycle including timing accuracy. Test authorization controls for admin operations."
          },
          {
            "id": 3,
            "title": "Develop Playlist Integration System",
            "description": "Create the system that modifies playlists based on active anomalies, applies mutators to gameplay rules, and handles state restoration.",
            "dependencies": [
              "5.1",
              "5.2"
            ],
            "details": "Implement playlist modification logic that dynamically updates available game modes based on active anomalies. Develop the mutator application system that injects rule changes into gameplay sessions. Create state tracking to ensure proper restoration of default settings when anomalies end. Build conflict resolution for cases where multiple anomalies might affect the same gameplay elements.",
            "status": "pending",
            "testStrategy": "Unit tests for playlist modification and mutator application. Integration tests for the complete anomaly lifecycle including activation and teardown. Verification tests to ensure game state properly restores after anomaly conclusion."
          },
          {
            "id": 4,
            "title": "Create UI Components for Anomalies",
            "description": "Develop the user interface elements for anomaly announcements, active indicators, and countdown timers.",
            "dependencies": [
              "5.2",
              "5.3"
            ],
            "details": "Design and implement UI components for anomaly announcements including modal dialogs and notification banners. Create persistent indicators for active anomalies that display in appropriate game screens. Develop countdown timers for activation/deactivation that update in real-time. Implement visual feedback for how anomalies are affecting gameplay. Design UI elements to be responsive across different device types.",
            "status": "pending",
            "testStrategy": "UI component tests for proper rendering and responsiveness. User experience testing for clarity of anomaly information. Integration tests with backend services to verify timers and state indicators accurately reflect server state."
          },
          {
            "id": 5,
            "title": "Implement Database Storage and Admin Tools",
            "description": "Create database schemas for anomaly definitions and active state tracking, plus admin tools for management and emergency override.",
            "dependencies": [
              "5.1",
              "5.2"
            ],
            "details": "Design and implement database schemas for storing anomaly definitions, historical data, and active state information. Develop admin dashboard for creating, editing, and managing anomalies. Implement emergency override functionality for immediate activation or deactivation of anomalies. Create logging and audit trail for all anomaly-related actions. Build analytics tools to track player engagement with different anomaly types.",
            "status": "pending",
            "testStrategy": "Database schema validation tests. Admin tool functionality testing including emergency override procedures. Performance testing for database operations under load. Security testing for admin authentication and authorization controls."
          }
        ]
      },
      {
        "id": 6,
        "title": "Develop Recap Cards Generator",
        "description": "Create a system to automatically generate 3-5 recap beats with hero images, one-click sharing functionality, and seed codes for replay.",
        "details": "Implement the following components:\n\n1. Session Analysis Engine:\n- Identify key moments and significant events\n- Select 3-5 most interesting beats from session\n- Generate descriptive text for each beat\n\n2. Hero Image Generator:\n- Capture or render images for key moments\n- Apply visual styling and formatting\n- Optimize images for sharing\n\n3. Seed Code Generation:\n- Create deterministic seed codes for session replay\n- Compress session state into shareable format\n- Implement seed validation\n\n4. Sharing Integration:\n- One-click share to social platforms\n- Copy to clipboard functionality\n- QR code generation for mobile sharing\n\n5. REST API:\n- POST /recap/generate - Generate recap from session data\n- GET /recap/:id - Retrieve generated recap\n\nStore recap data in database with appropriate TTL. Implement caching for frequently accessed recaps.",
        "testStrategy": "Unit tests for beat selection algorithm and seed generation. Integration tests for the complete recap generation pipeline. Verification tests for recap correctness and seed determinism as specified in requirements. Performance testing for generation speed under various session complexities.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Session Analysis Engine",
            "description": "Develop a system to analyze session data, identify key moments, and select 3-5 most interesting beats with descriptive text.",
            "dependencies": [],
            "details": "Create algorithms to process session data and identify significant events based on player actions, achievements, and game state changes. Implement a scoring system to rank moments by interest level. Develop natural language generation for descriptive text that captures the essence of each moment. Include configuration options for different game modes and event types. Ensure the engine can process sessions of varying lengths efficiently.",
            "status": "pending",
            "testStrategy": "Unit tests for beat selection algorithm and scoring system. Integration tests with sample session data. Performance testing with sessions of varying complexity. Validation tests to ensure selected beats are truly significant and descriptive text is accurate."
          },
          {
            "id": 2,
            "title": "Build Hero Image Generator",
            "description": "Create a system to capture or render images for key moments, apply visual styling, and optimize for sharing.",
            "dependencies": [
              "6.1"
            ],
            "details": "Implement screenshot capture functionality at key moments identified by the Session Analysis Engine. Develop image processing pipeline with filters, overlays, and branding elements. Create templates for different recap card styles. Implement image optimization for web and social media sharing (resolution, file size, format). Support both real-time capture and post-session rendering options.",
            "status": "pending",
            "testStrategy": "Unit tests for image processing functions. Visual regression tests for styling consistency. Performance tests for image generation speed. Compatibility tests across different devices and platforms. File size and quality optimization verification."
          },
          {
            "id": 3,
            "title": "Develop Seed Code Generation System",
            "description": "Create a system to generate deterministic seed codes for session replay, compress session state, and implement validation.",
            "dependencies": [],
            "details": "Design a deterministic algorithm to generate unique seed codes from session data. Implement compression techniques to minimize seed code length while preserving essential replay information. Create encoding/decoding functions for converting between session state and seed codes. Develop validation mechanisms to verify seed code integrity. Implement error handling for invalid or corrupted seeds. Document the seed format specification for potential future extensions.",
            "status": "pending",
            "testStrategy": "Unit tests for encoding/decoding functions. Verification tests for determinism (same input always produces same seed). Compression ratio analysis. Validation tests with valid and invalid seeds. Performance testing for generation and validation speed."
          },
          {
            "id": 4,
            "title": "Implement Sharing Integration",
            "description": "Develop one-click sharing functionality for social platforms, clipboard copying, and QR code generation for mobile sharing.",
            "dependencies": [
              "6.2",
              "6.3"
            ],
            "details": "Integrate with social media APIs (Twitter, Facebook, Discord, etc.) for direct sharing. Implement copy-to-clipboard functionality for seed codes and recap links. Create QR code generation for mobile device sharing. Design sharing templates with preview images and text. Implement tracking for share analytics. Ensure shared content includes appropriate metadata for rich previews on social platforms.",
            "status": "pending",
            "testStrategy": "Integration tests with each social platform API. Cross-browser compatibility tests for clipboard functionality. Mobile device testing for QR code scanning. User acceptance testing for sharing workflow. Analytics verification to ensure tracking is accurate."
          },
          {
            "id": 5,
            "title": "Create REST API and Database Integration",
            "description": "Develop REST API endpoints for recap generation and retrieval, with database storage and caching implementation.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3",
              "6.4"
            ],
            "details": "Implement POST /recap/generate endpoint to accept session data and return generated recap. Create GET /recap/:id endpoint to retrieve previously generated recaps. Design database schema for storing recap data with appropriate TTL. Implement caching layer for frequently accessed recaps to improve performance. Add authentication and rate limiting to protect API endpoints. Create documentation for API usage including request/response formats and error handling.",
            "status": "pending",
            "testStrategy": "Unit tests for individual API endpoints. Load testing to ensure performance under high traffic. Database performance testing for write and read operations. Cache hit ratio analysis. Security testing for authentication and rate limiting. API documentation verification with example requests and responses."
          }
        ]
      },
      {
        "id": 7,
        "title": "Implement Cosmetics and Store System",
        "description": "Create a system for cosmetic entitlements and store UI with local SKUs, ensuring no impact on gameplay balance.",
        "details": "Develop the following components:\n\n1. Cosmetics Catalog:\n- Database schema for cosmetic items\n- Categories, rarity, and visual attributes\n- Preview rendering system\n\n2. Entitlements Service:\n- Player inventory management\n- Entitlement granting/revoking\n- REST API for /entitlements\n\n3. Store Backend:\n- SKU definitions and pricing\n- Rotation and featured items\n- Purchase validation\n- REST API for /store\n\n4. Store UI:\n- Browsable catalog with filtering\n- Item detail views with previews\n- Purchase flow\n- Inventory management\n\nEnsure all cosmetic items are purely visual with no gameplay advantages. Implement proper validation to prevent unauthorized access to entitlements.",
        "testStrategy": "Unit tests for entitlement management and store functionality. Integration tests for the complete purchase flow. Verification tests to ensure entitlement rendering works correctly. Test that cosmetics have no effect on PvP stats as specified in requirements. Security testing for entitlement validation.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop Cosmetics Catalog and Database Schema",
            "description": "Create a comprehensive database schema for cosmetic items with categories, rarity levels, and visual attributes, along with a preview rendering system.",
            "dependencies": [],
            "details": "Implement database tables and relationships for cosmetic items. Define schemas for categories (e.g., outfits, weapons, emotes), rarity levels (common, rare, epic, legendary), and visual attributes. Create a preview rendering system that allows players to see cosmetics before purchase. Ensure proper indexing for efficient queries. Document the schema design and API access patterns.",
            "status": "pending",
            "testStrategy": "Unit tests for database CRUD operations. Integration tests for the preview rendering system. Performance tests for catalog browsing with large numbers of items. Verify that preview rendering works correctly across different cosmetic types."
          },
          {
            "id": 2,
            "title": "Implement Entitlements Service",
            "description": "Build a service to manage player cosmetic inventories with APIs for granting, revoking, and querying entitlements.",
            "dependencies": [
              "7.1"
            ],
            "details": "Develop a RESTful API for /entitlements with endpoints for listing, granting, and revoking cosmetic items. Implement player inventory management with proper validation to prevent unauthorized access. Create database models for tracking ownership history. Ensure proper transaction handling for entitlement operations. Implement caching for frequently accessed inventory data.",
            "status": "pending",
            "testStrategy": "Unit tests for entitlement granting/revoking logic. Security tests to verify authorization controls. Performance tests for inventory queries. Integration tests with the cosmetics catalog to ensure proper item reference integrity."
          },
          {
            "id": 3,
            "title": "Create Store Backend System",
            "description": "Develop the store backend with SKU definitions, pricing, rotation mechanics, and purchase validation.",
            "dependencies": [
              "7.1",
              "7.2"
            ],
            "details": "Implement a store backend with SKU definitions and pricing structure. Create rotation logic for featured items and store sections. Develop purchase validation to prevent fraudulent transactions. Build a RESTful API for /store with endpoints for retrieving available items, featured content, and processing purchases. Implement analytics tracking for store interactions and purchase patterns.",
            "status": "pending",
            "testStrategy": "Unit tests for SKU management and pricing calculations. Integration tests for the complete purchase flow. Security tests for purchase validation. Performance tests for store loading under high traffic. Verify that rotation mechanics work correctly according to configured schedules."
          },
          {
            "id": 4,
            "title": "Design and Implement Store UI",
            "description": "Create a user-friendly store interface with browsable catalog, filtering options, item previews, and purchase flow.",
            "dependencies": [
              "7.3"
            ],
            "details": "Design and implement a browsable store UI with filtering capabilities by category, rarity, and price. Create detailed item view pages with 3D previews of cosmetics. Develop a streamlined purchase flow with confirmation dialogs and feedback. Build inventory management screens for players to view and manage owned items. Ensure responsive design for different screen sizes and platforms.",
            "status": "pending",
            "testStrategy": "UI component tests for store elements. User experience testing for the purchase flow. Cross-browser compatibility tests. A/B testing for different store layouts to optimize conversion. Verify that filtering and sorting options work correctly."
          },
          {
            "id": 5,
            "title": "Implement Validation and Integration Testing",
            "description": "Ensure all cosmetic items have no gameplay impact and integrate the store system with other game components.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.3",
              "7.4"
            ],
            "details": "Implement validation systems to ensure cosmetic items provide no gameplay advantages. Create integration points with other game systems like player profiles and the upcoming Season Pass (Task 8). Develop monitoring tools to track store performance and player engagement. Implement A/B testing framework for store promotions. Create documentation for the entire cosmetics and store system.",
            "status": "pending",
            "testStrategy": "End-to-end tests for the complete store and cosmetics system. Verification tests to confirm cosmetics have no impact on gameplay balance or stats. Integration tests with dependent systems. Load testing to ensure system stability during high-traffic periods like new cosmetic releases."
          }
        ]
      },
      {
        "id": 8,
        "title": "Implement Alliance Season Pass",
        "description": "Create a Season Pass system with cosmetic and QoL tracks, progression tracking, and prestige reset that preserves cosmetics.",
        "details": "Develop the following components:\n\n1. Season Pass Definition:\n- Tiered rewards structure\n- Free and premium tracks\n- Cosmetic and QoL items separation\n\n2. Progression System:\n- XP earning and tracking\n- Level advancement logic\n- Milestone achievements\n\n3. Reward Distribution:\n- Automatic reward granting on level-up\n- Claim UI and notifications\n- Entitlement integration\n\n4. Prestige System:\n- Reset mechanics that preserve cosmetics\n- Prestige benefits and indicators\n- Progress history tracking\n\n5. UI Components:\n- Season pass overview\n- Progress visualization\n- Reward previews\n- Purchase and upgrade options\n\nImplement database schema for season definitions, player progress, and reward status. Create admin tools for season management.",
        "testStrategy": "Unit tests for progression logic and reward distribution. Integration tests for the complete season lifecycle. Verification tests for pass progression as specified in requirements. Test prestige reset to ensure cosmetics are preserved while other elements reset properly.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Season Pass Data Model and Database Schema",
            "description": "Design and implement the database schema for season pass definitions, player progress tracking, and reward status management.",
            "dependencies": [],
            "details": "Create database models for: Season definitions (start/end dates, theme, tiers), Reward tracks (free/premium items at each level), Player progress (XP, current level, purchased status), and Reward status (claimed/unclaimed items). Implement data access layer with CRUD operations. Create admin tools for season configuration and management.",
            "status": "pending",
            "testStrategy": "Unit tests for data model integrity and CRUD operations. Integration tests for database transactions and constraints. Verify proper relationships between season definitions, player progress, and rewards."
          },
          {
            "id": 2,
            "title": "Develop Progression and XP System",
            "description": "Implement the core progression system including XP earning, level advancement logic, and milestone achievements.",
            "dependencies": [
              "8.1"
            ],
            "details": "Create XP calculation algorithms for various player activities. Implement level thresholds and advancement triggers. Design milestone achievement system with event listeners. Build progression tracking service with caching for performance. Develop API endpoints for querying player progress and XP history.",
            "status": "pending",
            "testStrategy": "Unit tests for XP calculations and level advancement logic. Integration tests for the complete progression flow. Performance tests to ensure system handles concurrent XP updates efficiently."
          },
          {
            "id": 3,
            "title": "Build Reward Distribution System",
            "description": "Create the system for automatic reward granting, claim processing, and entitlement integration.",
            "dependencies": [
              "8.1",
              "8.2"
            ],
            "details": "Implement automatic reward triggers on level-up events. Create claim processing service with idempotency guarantees. Develop entitlement integration for adding items to player inventory. Build notification system for new rewards. Implement reward history and status tracking.",
            "status": "pending",
            "testStrategy": "Unit tests for reward distribution logic and entitlement integration. Integration tests for the complete reward flow from earning to claiming. Verification tests to ensure proper reward delivery based on season pass level."
          },
          {
            "id": 4,
            "title": "Implement Prestige System",
            "description": "Develop the prestige reset mechanics that preserve cosmetic rewards while resetting progression.",
            "dependencies": [
              "8.2",
              "8.3"
            ],
            "details": "Create prestige reset logic that preserves cosmetic items but resets progression. Implement prestige benefits (e.g., badges, titles, special rewards). Design progress history tracking across multiple prestige cycles. Build prestige level indicators and UI hooks. Develop migration strategy for existing players entering prestige.",
            "status": "pending",
            "testStrategy": "Unit tests for prestige reset logic and cosmetic preservation. Integration tests for complete prestige cycle. Verification tests to confirm cosmetics are preserved while progression resets properly."
          },
          {
            "id": 5,
            "title": "Develop Season Pass UI Components",
            "description": "Create the user interface components for the season pass including progress visualization, reward previews, and purchase options.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.4"
            ],
            "details": "Design and implement season pass overview screen with tier visualization. Create progress bar and level indicators. Build reward preview cards with item details. Implement purchase and upgrade UI with payment integration. Develop claim buttons and notifications. Create prestige UI elements and indicators.",
            "status": "pending",
            "testStrategy": "UI component tests for rendering and interaction. Integration tests with backend services. Usability tests to ensure clear progression visualization and intuitive reward claiming. Cross-browser and responsive design testing."
          }
        ]
      },
      {
        "id": 9,
        "title": "Implement Cost Telemetry System",
        "description": "Create a telemetry system to track per-turn token counts, STT/TTS seconds, image requests, and generate session-level projections.",
        "details": "Develop the following components:\n\n1. Telemetry Collectors:\n- Token counter for LLM interactions\n- STT/TTS usage timer\n- Image request tracker\n- API call counter\n\n2. Aggregation Service:\n- Real-time metrics collection\n- Session-level aggregation\n- Cost projection algorithms\n\n3. Reporting API:\n- REST endpoints for cost metrics\n- Filtering and time range selection\n- Export functionality\n\n4. Admin Dashboard:\n- Cost visualization by session/user/feature\n- Trend analysis\n- Anomaly detection\n\nImplement efficient storage for high-volume telemetry data. Use time-series database for optimal query performance. Create alerting system for cost anomalies.",
        "testStrategy": "Unit tests for individual collectors and aggregation logic. Integration tests with mock services. Verification tests to ensure counters match provider logs within ±10% as specified in requirements. Performance testing under high load conditions.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Telemetry Collectors",
            "description": "Develop the core telemetry collectors for tracking token counts, STT/TTS usage, image requests, and API calls.",
            "dependencies": [],
            "details": "Create modular collectors that can be integrated at service boundaries to track: 1) Token counter for LLM interactions with input/output token separation, 2) STT/TTS usage timer with millisecond precision, 3) Image request tracker with size and type metadata, 4) API call counter with service categorization. Implement efficient buffering to minimize performance impact. Each collector should have standardized interfaces and configurable sampling rates.",
            "status": "pending",
            "testStrategy": "Unit tests for each collector type with mock services. Integration tests with controlled inputs to verify accuracy. Performance tests to ensure minimal overhead (<1% CPU increase). Comparison tests against provider logs to validate accuracy within ±10%."
          },
          {
            "id": 2,
            "title": "Develop Aggregation Service",
            "description": "Create a service to collect, aggregate, and project cost metrics in real-time and at session level.",
            "dependencies": [
              "9.1"
            ],
            "details": "Implement a scalable aggregation service that: 1) Collects metrics from all telemetry collectors in real-time, 2) Performs session-level aggregation with user and feature attribution, 3) Applies cost projection algorithms based on current pricing models, 4) Supports time-series analysis for trend detection. Use a time-series database (e.g., InfluxDB or TimescaleDB) for efficient storage and querying of high-volume telemetry data.",
            "status": "pending",
            "testStrategy": "Unit tests for aggregation logic and cost projections. Load tests with simulated high-volume telemetry data. Verification tests to ensure aggregated metrics match raw collector data. Performance tests for query response times under various data volumes."
          },
          {
            "id": 3,
            "title": "Build Reporting API",
            "description": "Develop REST endpoints for accessing cost metrics with filtering, time range selection, and export functionality.",
            "dependencies": [
              "9.2"
            ],
            "details": "Create a comprehensive API that provides: 1) REST endpoints for retrieving cost metrics at various granularities (session, user, feature), 2) Filtering capabilities by service type, time range, and user segments, 3) Export functionality in multiple formats (JSON, CSV, Excel), 4) Aggregation endpoints for summary statistics. Implement caching for frequently accessed reports and pagination for large result sets.",
            "status": "pending",
            "testStrategy": "Unit tests for each API endpoint. Integration tests for complex queries and export functionality. Performance tests for response times under load. Security tests to ensure proper access controls for cost data."
          },
          {
            "id": 4,
            "title": "Create Admin Dashboard",
            "description": "Develop a visual dashboard for cost visualization, trend analysis, and anomaly detection.",
            "dependencies": [
              "9.3"
            ],
            "details": "Build an interactive admin dashboard with: 1) Cost visualizations by session/user/feature with drill-down capabilities, 2) Trend analysis tools showing usage patterns over time, 3) Anomaly detection with configurable thresholds and alerts, 4) Projection tools for estimating future costs based on current usage. Use responsive design principles and efficient data visualization libraries to handle large datasets.",
            "status": "pending",
            "testStrategy": "Unit tests for dashboard components. Usability tests with admin personas. Performance tests for dashboard rendering with large datasets. Cross-browser compatibility tests. Verification that anomaly detection correctly identifies unusual patterns."
          },
          {
            "id": 5,
            "title": "Implement Alerting System",
            "description": "Create an alerting system for cost anomalies with configurable thresholds and notification channels.",
            "dependencies": [
              "9.2",
              "9.4"
            ],
            "details": "Develop an alerting system that: 1) Monitors cost metrics in real-time against configurable thresholds, 2) Detects unusual patterns or spikes in usage, 3) Sends notifications through multiple channels (email, Slack, SMS), 4) Provides alert management with acknowledgment and resolution tracking. Implement rate limiting to prevent alert storms and support for escalation policies.",
            "status": "pending",
            "testStrategy": "Unit tests for alert trigger logic. Integration tests with notification services. Simulation tests with artificial anomalies to verify detection. Verification tests for alert delivery timing and content. User acceptance testing for alert management workflow."
          }
        ]
      },
      {
        "id": 10,
        "title": "Implement Single Player Mode",
        "description": "Create solo session scaffolding with pause/resume hooks, companion agent runner, and solo DDA presets.",
        "details": "Develop the following components:\n\n1. Solo Session Manager:\n- Session initialization for single player\n- State persistence and retrieval\n- Pause/resume functionality\n\n2. Companion Agent System:\n- AI agent configuration for solo play\n- Agent behavior customization\n- Performance optimization for solo mode\n\n3. Dynamic Difficulty Adjustment (DDA):\n- Solo-specific DDA presets\n- Difficulty scaling based on player performance\n- Configuration interface\n\n4. UI Components:\n- Solo mode selection\n- Pause menu\n- Session controls\n- Companion settings\n\nImplement efficient state management for paused sessions. Optimize agent performance for single-player scenarios.",
        "testStrategy": "Unit tests for session management and pause/resume functionality. Integration tests for the complete solo experience. Run tests TC034-TC035 as specified in the PRD addenda. Performance testing for agent response times in solo mode.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Solo Session Manager",
            "description": "Create a session manager specifically for single player mode with initialization, state persistence, and pause/resume functionality.",
            "dependencies": [],
            "details": "Develop session initialization logic for single player mode. Implement state persistence and retrieval mechanisms to save and load game progress. Create robust pause/resume functionality that properly suspends and resumes all game systems. Ensure efficient state management for paused sessions with minimal memory overhead. Include session timeout handling and auto-save features.",
            "status": "pending",
            "testStrategy": "Write unit tests for session initialization, state persistence, and pause/resume functionality. Create integration tests to verify proper state management across game systems during pause/resume cycles. Measure memory usage during paused states to ensure efficiency."
          },
          {
            "id": 2,
            "title": "Develop Companion Agent System",
            "description": "Build an AI agent system optimized for solo play with customizable behaviors and performance optimizations.",
            "dependencies": [
              "10.1"
            ],
            "details": "Implement AI agent configuration specifically for solo play scenarios. Create a system for agent behavior customization allowing players to adjust companion behavior. Optimize agent performance for single-player mode by reducing computational overhead. Develop agent response prioritization based on player actions. Include fallback behaviors for edge cases.",
            "status": "pending",
            "testStrategy": "Create unit tests for agent configuration and behavior customization. Perform performance testing to ensure agents respond within acceptable timeframes. Test edge cases to verify fallback behaviors function correctly."
          },
          {
            "id": 3,
            "title": "Implement Solo-Specific DDA System",
            "description": "Create Dynamic Difficulty Adjustment presets and scaling mechanisms specifically for single player mode.",
            "dependencies": [
              "10.1"
            ],
            "details": "Develop solo-specific DDA presets with appropriate challenge levels. Implement difficulty scaling algorithms based on player performance metrics. Create a configuration interface for adjusting DDA parameters. Include real-time difficulty adjustments based on player success/failure rates. Develop persistence for player difficulty profiles across sessions.",
            "status": "pending",
            "testStrategy": "Write unit tests for difficulty scaling algorithms. Create integration tests to verify DDA responds appropriately to player performance. Test persistence of difficulty profiles across multiple game sessions."
          },
          {
            "id": 4,
            "title": "Create Single Player UI Components",
            "description": "Develop UI elements specific to single player mode including mode selection, pause menu, session controls, and companion settings.",
            "dependencies": [
              "10.1",
              "10.2"
            ],
            "details": "Design and implement solo mode selection UI in the main menu. Create a comprehensive pause menu with resume, settings, and exit options. Develop session control UI elements for managing game state. Build companion settings interface for adjusting AI behavior. Ensure all UI elements follow established design patterns and accessibility guidelines.",
            "status": "pending",
            "testStrategy": "Perform UI unit tests to verify component functionality. Conduct usability testing to ensure intuitive navigation. Test accessibility features to ensure compliance with guidelines. Verify UI state consistency during pause/resume cycles."
          },
          {
            "id": 5,
            "title": "Integrate and Optimize Single Player Systems",
            "description": "Connect all single player components and optimize overall performance for the solo experience.",
            "dependencies": [
              "10.1",
              "10.2",
              "10.3",
              "10.4"
            ],
            "details": "Integrate session manager, companion agent system, DDA, and UI components into a cohesive single player experience. Perform end-to-end testing of the complete solo mode workflow. Optimize resource usage for single player scenarios. Implement telemetry to track player engagement with solo features. Create documentation for the single player implementation.",
            "status": "pending",
            "testStrategy": "Run full integration tests for the complete solo experience. Execute tests TC034-TC035 as specified in the PRD addenda. Perform performance testing for agent response times in solo mode. Conduct end-to-end testing of the entire single player experience from launch to exit."
          }
        ]
      },
      {
        "id": 11,
        "title": "Implement Simulation System",
        "description": "Create a simulation system with start/step/stop functionality, snapshot export/import, and reconciliation features.",
        "details": "Develop the following components:\n\n1. Simulation Controller:\n- REST API for /simulation with start/step/stop\n- Simulation state management\n- Execution control flow\n\n2. Snapshot System:\n- State capture at beat boundaries\n- Export/import functionality\n- State hash generation for verification\n\n3. Deterministic Engine:\n- Seed-based randomization\n- Consistent execution ordering\n- Drift detection algorithms\n\n4. Reconciliation Service:\n- State comparison tools\n- Conflict resolution\n- Automatic correction strategies\n\n5. UI Components:\n- Simulation controls\n- State visualization\n- Snapshot management\n- Drift indicators\n\nImplement efficient serialization for state snapshots. Ensure deterministic execution across different environments.",
        "testStrategy": "Unit tests for simulation control and snapshot functionality. Integration tests for the complete simulation lifecycle. Run tests TC036-TC041 as specified in the PRD addenda. Verification tests for deterministic seeds, beat-boundary snapshots with state hash, and drift detection.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Simulation Controller",
            "description": "Develop the REST API for simulation control with start/step/stop functionality and state management",
            "dependencies": [],
            "details": "Create a RESTful API with endpoints for /simulation/start, /simulation/step, and /simulation/stop. Implement simulation state management including current state tracking, execution flow control, and proper error handling. Design the controller to maintain simulation integrity across API calls and implement proper authentication and authorization for simulation control.",
            "status": "pending",
            "testStrategy": "Write unit tests for each API endpoint. Test state transitions between start, step, and stop operations. Verify proper error handling for invalid state transitions. Create integration tests for complete simulation lifecycle."
          },
          {
            "id": 2,
            "title": "Build Snapshot System",
            "description": "Create functionality to capture, export, and import simulation state at beat boundaries",
            "dependencies": [
              "11.1"
            ],
            "details": "Implement state capture mechanism that triggers at beat boundaries. Develop efficient serialization/deserialization for state snapshots. Create export functionality to save snapshots to files or database. Implement import functionality to restore simulation from snapshots. Add state hash generation for verification of snapshot integrity.",
            "status": "pending",
            "testStrategy": "Test snapshot creation at beat boundaries. Verify export/import functionality preserves all state details. Test hash generation and verification. Ensure snapshots can be properly restored across different environments."
          },
          {
            "id": 3,
            "title": "Develop Deterministic Engine",
            "description": "Create a deterministic execution engine with seed-based randomization and consistent ordering",
            "dependencies": [
              "11.1"
            ],
            "details": "Implement seed-based randomization that produces consistent results across environments. Create execution ordering system that ensures operations occur in the same sequence regardless of timing or environment. Develop drift detection algorithms to identify when simulations diverge from expected state. Ensure all random elements use the seeded generator.",
            "status": "pending",
            "testStrategy": "Test that identical seeds produce identical simulation results. Verify execution ordering remains consistent across different environments. Test drift detection by introducing controlled variations and ensuring they're detected."
          },
          {
            "id": 4,
            "title": "Create Reconciliation Service",
            "description": "Implement tools for state comparison, conflict resolution, and automatic correction",
            "dependencies": [
              "11.2",
              "11.3"
            ],
            "details": "Develop state comparison tools that can identify differences between two simulation states. Create conflict resolution strategies for handling divergent states. Implement automatic correction mechanisms that can repair simulation drift when detected. Design logging system to track reconciliation actions for debugging purposes.",
            "status": "pending",
            "testStrategy": "Test state comparison with various types of differences. Verify conflict resolution correctly identifies and resolves issues. Test automatic correction strategies with simulated drift scenarios. Ensure reconciliation actions are properly logged."
          },
          {
            "id": 5,
            "title": "Implement UI Components",
            "description": "Create user interface elements for simulation control, visualization, and snapshot management",
            "dependencies": [
              "11.1",
              "11.2",
              "11.4"
            ],
            "details": "Design and implement UI controls for simulation start/step/stop. Create visualization components for current simulation state. Develop snapshot management interface for saving, loading, and comparing snapshots. Add drift indicators that visually highlight when simulations diverge from expected state. Ensure UI is responsive and provides clear feedback on simulation operations.",
            "status": "pending",
            "testStrategy": "Perform usability testing of simulation controls. Verify state visualization accurately represents simulation data. Test snapshot management UI for saving and loading snapshots. Ensure drift indicators clearly show when and where simulation divergence occurs."
          }
        ]
      },
      {
        "id": 12,
        "title": "Implement Performance Optimization for 50-Player Sessions",
        "description": "Optimize system performance to support 50 concurrent players with acceptable response times and stability.",
        "details": "Implement the following optimizations:\n\n1. Action Batching:\n- Group similar actions for efficient processing\n- Prioritize critical real-time updates\n- Optimize WebSocket message frequency\n\n2. Database Optimization:\n- Index tuning for common queries\n- Connection pooling configuration\n- Query optimization for high-volume operations\n\n3. Caching Strategy:\n- Implement multi-level caching\n- Cache invalidation policies\n- Distributed cache for session data\n\n4. Load Testing Framework:\n- Simulate 50-player sessions\n- Measure response times and resource usage\n- Identify and resolve bottlenecks\n\n5. Monitoring System:\n- Real-time performance metrics\n- Alerting for degraded performance\n- Diagnostic tools for issue resolution\n\nImplement horizontal scaling for key services. Optimize network communication patterns for reduced latency.",
        "testStrategy": "Load tests with simulated 50-player sessions. Performance profiling to identify bottlenecks. Verification that GM summary median is less than 4.5s at 50 participants as specified in requirements. Stability testing for voice communication across teams.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Action Batching System",
            "description": "Develop a system to group similar actions for efficient processing, prioritize critical real-time updates, and optimize WebSocket message frequency.",
            "dependencies": [],
            "details": "Create a batching mechanism that groups similar player actions to reduce processing overhead. Implement priority queues for critical real-time updates. Optimize WebSocket communication by reducing message frequency through intelligent bundling. Include configuration parameters for batch size and timing thresholds. Develop fallback mechanisms for high-priority actions that cannot be delayed.",
            "status": "pending",
            "testStrategy": "Measure message throughput with and without batching. Verify critical actions are processed with appropriate priority. Test with simulated high-frequency actions from 50 concurrent players."
          },
          {
            "id": 2,
            "title": "Optimize Database Performance",
            "description": "Tune database indexes for common queries, configure connection pooling, and optimize queries for high-volume operations.",
            "dependencies": [
              "12.1"
            ],
            "details": "Analyze query patterns and create appropriate indexes for frequently accessed data. Configure connection pooling parameters for optimal resource utilization. Rewrite high-volume queries to minimize execution time and resource consumption. Implement query caching where appropriate. Consider database sharding strategies for horizontal scaling of player data.",
            "status": "pending",
            "testStrategy": "Benchmark query performance before and after optimization. Test connection pool under simulated load of 50 concurrent players. Verify query execution plans are optimal for common operations."
          },
          {
            "id": 3,
            "title": "Implement Multi-level Caching Strategy",
            "description": "Design and implement a multi-level caching system with appropriate invalidation policies and distributed cache for session data.",
            "dependencies": [
              "12.2"
            ],
            "details": "Implement in-memory caching for frequently accessed data. Set up distributed cache using Redis or similar technology for session data. Define cache invalidation policies based on data update patterns. Create cache warming mechanisms for predictable data access. Implement cache hit/miss metrics for performance monitoring.",
            "status": "pending",
            "testStrategy": "Measure system performance with and without caching enabled. Test cache invalidation correctness under various update scenarios. Verify distributed cache consistency across multiple server instances."
          },
          {
            "id": 4,
            "title": "Develop Load Testing Framework",
            "description": "Create a framework to simulate 50-player sessions, measure response times and resource usage, and identify performance bottlenecks.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.3"
            ],
            "details": "Develop automated load testing scripts that simulate realistic player behavior. Implement metrics collection for response times, CPU/memory usage, and network throughput. Create visualization tools for performance data analysis. Design tests for specific scenarios like combat, inventory management, and social interactions. Include gradual scaling tests from 10 to 50 players to identify scaling issues.",
            "status": "pending",
            "testStrategy": "Run load tests with increasing player counts to identify scaling limits. Verify GM summary median is less than 4.5s at 50 participants. Test stability of voice communication across teams under load."
          },
          {
            "id": 5,
            "title": "Implement Performance Monitoring System",
            "description": "Set up real-time performance metrics, alerting for degraded performance, and diagnostic tools for issue resolution.",
            "dependencies": [
              "12.4"
            ],
            "details": "Integrate APM (Application Performance Monitoring) tools to track system performance in real-time. Configure alerting thresholds for key metrics like response time, error rates, and resource utilization. Develop custom dashboards for visualizing performance data. Implement logging enhancements for easier troubleshooting. Create automated reports for performance trends over time.",
            "status": "pending",
            "testStrategy": "Verify alerts trigger appropriately when performance degrades. Test diagnostic tools by introducing controlled performance issues. Confirm monitoring system can handle the additional load without significant performance impact."
          }
        ]
      },
      {
        "id": 13,
        "title": "Implement Voice/NL Interaction UX System",
        "description": "Develop a comprehensive voice and natural language interaction system with multi-speaker diarization, real-time speech-to-text, voice activity detection, and text-to-speech capabilities with multiple personas.",
        "details": "Implement the following components for the Voice/NL Interaction UX system:\n\n1. Multi-Speaker Diarization:\n   - Implement speaker identification and separation algorithms\n   - Create speaker embeddings for unique voice fingerprinting\n   - Develop real-time speaker tracking during conversations\n   - Store speaker profiles for consistent identification across sessions\n\n2. Real-Time Speech-to-Text (STT):\n   - Integrate a high-performance STT engine with low latency\n   - Implement Voice Activity Detection (VAD) for detecting speech segments\n   - Create barge-in functionality to allow interruptions during conversations\n   - Develop turn-taking mechanisms to manage conversation flow\n   - Implement hotword detection for \"Prime Minister\" activation\n\n3. Natural Language Command Processing:\n   - Create a command parser for live NL commands\n   - Implement specific command handlers for:\n     - \"Call emergency cabinet\" functionality\n     - \"Draft two-minute address\" generation\n     - \"Summarize last quarter P&L\" data retrieval and formatting\n   - Design an extensible framework for adding new commands\n\n4. Text-to-Speech (TTS) System:\n   - Implement multiple TTS personas with distinct voice characteristics\n   - Create tone adjustment capabilities (formal, casual, urgent, etc.)\n   - Support multiple languages and accents\n   - Develop a voice selection interface for users\n\n5. Integration Adapters:\n   - Create WebSocket-based real-time audio streaming\n   - Implement REST APIs for voice configuration and management\n   - Develop service connectors for third-party STT/TTS providers\n   - Build caching mechanisms for frequently used voice assets\n\n6. Demo UI and Endpoints:\n   - Create a demonstration interface for voice interaction testing\n   - Implement visualization tools for diarization and turn-taking\n   - Develop sample applications showcasing NL commands\n   - Create documentation and examples for developer integration\n\nTechnical considerations:\n- Optimize for low latency (< 200ms) for real-time interactions\n- Implement fallback mechanisms for network disruptions\n- Consider privacy implications and add user consent workflows\n- Design for accessibility and multilingual support\n- Implement token usage tracking for cost management",
        "testStrategy": "1. Unit Testing:\n   - Test each component (diarization, STT, command processing, TTS) in isolation\n   - Verify hotword detection accuracy with various accents and background noise\n   - Test command parser with different phrasings and variations\n   - Validate TTS output quality across different personas and tones\n\n2. Integration Testing:\n   - Test end-to-end voice interaction flows\n   - Verify correct speaker identification in multi-user scenarios\n   - Test barge-in functionality during ongoing speech\n   - Validate turn-taking mechanisms in group conversations\n   - Verify command execution accuracy and response time\n\n3. Performance Testing:\n   - Measure STT latency under various network conditions\n   - Test system performance with multiple concurrent speakers\n   - Benchmark TTS generation time for different personas\n   - Verify system stability during extended usage sessions\n\n4. User Acceptance Testing:\n   - Conduct tests with diverse speaker demographics\n   - Verify accuracy with different accents and speech patterns\n   - Test in environments with varying noise levels\n   - Validate accessibility features for users with speech impairments\n\n5. Specific Test Cases:\n   - Verify \"Prime Minister\" hotword detection with 95%+ accuracy\n   - Test emergency cabinet call functionality end-to-end\n   - Validate two-minute address generation for coherence and formatting\n   - Test P&L summary accuracy against source data\n   - Verify that voice interaction works correctly with 50 concurrent users\n\n6. Documentation Verification:\n   - Review API documentation for completeness\n   - Verify demo endpoints functionality\n   - Test developer integration examples",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Implement Player-to-People Communications (Speeches) System",
        "description": "Develop a system that parses natural language speeches into deterministic modifiers with caps, decay, and backfire effects, implements a cohort opinions model, and integrates with the tick pipeline.",
        "details": "Implement the following components for the Player-to-People Communications (Speeches) system:\n\n1. Speech Parser:\n   - Create a natural language processing module to analyze player speeches\n   - Implement bounded deterministic modifiers with configurable parameters:\n     - Maximum effect caps to prevent exploitation\n     - Temporal decay functions to model diminishing influence over time\n     - Backfire mechanics for poorly received or contradictory speeches\n   - Design a classification system for speech intent and emotional content\n   - Develop context-aware parsing that considers game state and history\n\n2. Cohort Opinions Model:\n   - Implement a multi-dimensional opinion matrix for different NPC cohorts\n   - Create demographic-based response variations to the same speech\n   - Model opinion spread and influence between related cohort groups\n   - Develop opinion persistence with appropriate state storage\n   - Implement opinion thresholds that trigger gameplay events\n\n3. Audit Logging System:\n   - Create comprehensive logging of all speech inputs and resulting modifiers\n   - Implement searchable history of player communications\n   - Design visualization tools for opinion shifts over time\n   - Store raw inputs alongside parsed interpretations for debugging\n\n4. HTML Demo Interface:\n   - Develop a simple web interface to demonstrate speech effects\n   - Create visual representations of opinion changes\n   - Implement real-time feedback on speech parsing\n   - Design interactive elements to test different speech approaches\n\n5. Tick Pipeline Integration:\n   - Connect speech effects to the main simulation tick system\n   - Ensure proper sequencing of opinion updates within the game loop\n   - Implement efficient state updates that minimize performance impact\n   - Design appropriate hooks for event triggers based on opinion thresholds\n\n6. Performance Considerations:\n   - Optimize NLP processing for minimal latency\n   - Implement batching for multiple speeches when appropriate\n   - Design efficient data structures for opinion storage and retrieval\n   - Create appropriate caching mechanisms for frequently accessed opinion data",
        "testStrategy": "1. Unit Testing:\n   - Test speech parser with various input types, lengths, and emotional content\n   - Verify modifier bounds are properly enforced with extreme inputs\n   - Test decay functions over multiple time periods\n   - Validate backfire mechanics trigger appropriately for contradictory inputs\n   - Verify cohort opinion model updates correctly based on inputs\n\n2. Integration Testing:\n   - Test end-to-end flow from speech input to opinion changes\n   - Verify proper integration with the tick pipeline\n   - Test multi-user scenarios with overlapping speeches\n   - Validate opinion spread mechanics between related cohorts\n   - Ensure audit logging captures all relevant data\n\n3. Performance Testing:\n   - Benchmark speech parsing performance under load\n   - Test system with concurrent speech processing\n   - Verify opinion model updates don't impact tick performance\n   - Measure memory usage during extended gameplay sessions\n\n4. User Acceptance Testing:\n   - Conduct playtests focusing on speech mechanics\n   - Gather feedback on perceived impact of speeches\n   - Test with various speech styles and approaches\n   - Verify HTML demo provides clear visualization of effects\n\n5. Specific Test Cases:\n   - TC-S01: Verify speech with positive sentiment increases relevant opinion metrics\n   - TC-S02: Confirm contradictory speeches trigger backfire mechanics\n   - TC-S03: Test opinion decay over multiple game sessions\n   - TC-S04: Validate opinion thresholds trigger appropriate game events\n   - TC-S05: Verify audit log contains searchable history of all speeches",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Speech Parser with NLP Module",
            "description": "Create a natural language processing module that analyzes player speeches and converts them into deterministic modifiers with appropriate bounds and effects.",
            "dependencies": [],
            "details": "Develop a speech parsing module that uses NLP techniques to analyze player speeches. Implement a classification system for speech intent (persuasive, threatening, inspiring, etc.) and emotional content. Create configurable parameters for maximum effect caps, temporal decay functions, and backfire mechanics. Integrate with Task 20's canonicalization pipeline to ensure consistent input processing. Design the parser to be context-aware by considering game state and history when interpreting speeches.",
            "status": "pending",
            "testStrategy": "Test the parser with various speech inputs of different lengths, tones, and content. Verify that modifier bounds are properly enforced with extreme inputs. Test that decay functions work correctly over multiple time periods. Validate that backfire mechanics trigger appropriately for contradictory inputs."
          },
          {
            "id": 2,
            "title": "Develop Cohort Opinions Model",
            "description": "Implement a multi-dimensional opinion matrix that tracks how different NPC cohorts respond to player speeches with demographic-based variations.",
            "dependencies": [
              "14.1"
            ],
            "details": "Create a data structure to store and update opinions for different NPC cohorts. Implement demographic-based response variations so the same speech affects different groups differently. Model opinion spread and influence between related cohort groups using configurable parameters. Develop opinion persistence with appropriate state storage in the database. Implement opinion thresholds that trigger gameplay events when crossed. Design the model to efficiently update multiple cohorts simultaneously.",
            "status": "pending",
            "testStrategy": "Test opinion updates with various demographic configurations. Verify that opinion spread works correctly between related groups. Test persistence by ensuring opinions are properly saved and loaded. Validate that threshold events trigger at the correct opinion levels."
          },
          {
            "id": 3,
            "title": "Create Comprehensive Audit Logging System",
            "description": "Develop a logging system that records all speech inputs, resulting modifiers, and opinion changes for debugging and analysis.",
            "dependencies": [
              "14.1",
              "14.2"
            ],
            "details": "Implement comprehensive logging of all speech inputs and resulting modifiers. Create a searchable history of player communications with timestamps and context information. Design visualization tools for tracking opinion shifts over time. Store raw inputs alongside parsed interpretations for debugging purposes. Ensure logs are efficiently stored and can be queried for analysis. Implement appropriate log rotation and archiving to manage storage requirements.",
            "status": "pending",
            "testStrategy": "Test log creation with various speech inputs. Verify that logs contain all required information. Test search functionality with different query parameters. Validate that visualization tools accurately represent opinion changes."
          },
          {
            "id": 4,
            "title": "Develop HTML Demo Interface for Speech System",
            "description": "Create a web interface that demonstrates the speech effects system with visual representations of opinion changes and real-time feedback.",
            "dependencies": [
              "14.1",
              "14.2",
              "14.3"
            ],
            "details": "Build a simple web interface to demonstrate the speech effects system. Implement visual representations of opinion changes using charts or graphs. Create real-time feedback on speech parsing to show users how their input is interpreted. Design interactive elements to test different speech approaches and see resulting effects. Include a history view to compare previous speeches and their impacts. Make the interface responsive and user-friendly.",
            "status": "pending",
            "testStrategy": "Test the interface with various speech inputs. Verify that visual representations accurately reflect opinion changes. Test real-time feedback for accuracy and responsiveness. Validate that the interface works correctly across different browsers and screen sizes."
          },
          {
            "id": 5,
            "title": "Integrate Speech System with Tick Pipeline",
            "description": "Connect the speech effects system to the main simulation tick system to ensure proper sequencing of opinion updates within the game loop.",
            "dependencies": [
              "14.1",
              "14.2"
            ],
            "details": "Integrate the speech system with the main simulation tick pipeline from Task 11. Ensure proper sequencing of opinion updates within the game loop. Implement efficient state updates that minimize performance impact. Design appropriate hooks for event triggers based on opinion thresholds. Create a mechanism for speeches to influence simulation state over time through the decay functions. Implement proper synchronization to prevent race conditions when multiple speeches are processed.",
            "status": "pending",
            "testStrategy": "Test integration with the simulation system through various tick rates. Verify that opinion updates occur in the correct sequence. Test performance under load with multiple simultaneous speeches. Validate that event triggers fire correctly during simulation execution."
          },
          {
            "id": 6,
            "title": "Optimize Speech System Performance",
            "description": "Implement performance optimizations for the speech system including efficient NLP processing, batching, data structures, and caching mechanisms.",
            "dependencies": [
              "14.1",
              "14.2",
              "14.5"
            ],
            "details": "Optimize NLP processing to minimize latency when analyzing speeches. Implement batching for processing multiple speeches when appropriate. Design efficient data structures for opinion storage and retrieval. Create appropriate caching mechanisms for frequently accessed opinion data. Implement background processing for computationally intensive operations. Profile the system to identify and address performance bottlenecks. Ensure the system can handle the expected volume of speeches without degrading game performance.",
            "status": "pending",
            "testStrategy": "Conduct performance testing with various speech volumes and complexities. Measure and verify latency improvements from optimizations. Test batching with different batch sizes to find optimal configuration. Validate that caching correctly improves access times for frequently used data."
          }
        ]
      },
      {
        "id": 15,
        "title": "Implement Cabinet Voice Meetings System",
        "description": "Develop a cabinet voice meetings pipeline that processes multi-speaker conversations with diarization, transcription, AI natural language summarization, and validated bounded modifiers for coordination, readiness, alignment, and messaging coherence.",
        "details": "Implement the following components for the Cabinet Voice Meetings System:\n\n1. Voice Meeting Pipeline:\n   - Integrate with the existing Voice/NL Interaction UX System for multi-speaker diarization\n   - Implement real-time transcription with speaker identification\n   - Create a deterministic hashing mechanism for canonical transcripts to ensure integrity and non-repudiation\n   - Develop WebSocket indicators for live roster tracking and participant status\n\n2. AI Natural Language Summarization:\n   - Design and implement an AI model to analyze meeting transcripts\n   - Extract key discussion points, decisions, and action items\n   - Generate concise, structured summaries with categorized content\n   - Implement caching mechanisms for efficient retrieval of summaries\n\n3. Validated Bounded Modifiers System:\n   - Create a framework for extracting and quantifying cabinet meeting outcomes:\n     - Coordination: Measure of how well cabinet members are working together\n     - Readiness: Assessment of preparedness for upcoming challenges\n     - Alignment: Degree of agreement on strategic direction\n     - Messaging Coherence: Consistency of communication strategy\n   - Implement validation rules to ensure modifiers remain within realistic bounds\n   - Design decay functions for modifier effects over time\n   - Create feedback mechanisms to adjust modifiers based on subsequent meetings\n\n4. Integration with Simulation System:\n   - Connect meeting outcomes to the simulation state\n   - Apply validated modifiers to relevant game systems\n   - Ensure deterministic application of meeting effects\n   - Implement snapshot compatibility for meeting state\n\n5. User Interface Components:\n   - Design meeting scheduling and management interface\n   - Create visualization for live meeting status and participant roster\n   - Develop dashboard for historical meetings and their outcomes\n   - Implement notification system for scheduled meetings",
        "testStrategy": "1. Unit Testing:\n   - Test diarization accuracy with multiple speakers in various acoustic environments\n   - Verify transcript hashing produces consistent results for identical inputs\n   - Validate summarization quality against human-generated summaries\n   - Test bounded modifier extraction with various meeting scenarios\n   - Verify WebSocket indicators correctly reflect participant status\n\n2. Integration Testing:\n   - Test end-to-end pipeline from voice input to modifier application\n   - Verify integration with the simulation system\n   - Test snapshot export/import with meeting data\n   - Validate that meeting effects properly influence game state\n\n3. Performance Testing:\n   - Measure transcription latency with multiple concurrent speakers\n   - Test system performance with cabinet meetings of various durations\n   - Verify summarization processing time meets requirements\n   - Benchmark WebSocket performance with full participant roster\n\n4. User Acceptance Testing:\n   - Conduct simulated cabinet meetings with test users\n   - Gather feedback on summary quality and accuracy\n   - Verify that modifier effects align with meeting content\n   - Test usability of meeting scheduling and management interface\n\n5. Regression Testing:\n   - Ensure voice meeting functionality doesn't interfere with other voice interactions\n   - Verify that modifier application doesn't disrupt simulation stability\n   - Test compatibility with existing player-to-people communications system",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Multi-Speaker Diarization and Transcription Pipeline",
            "description": "Develop the core voice processing pipeline that handles multi-speaker conversations with accurate speaker identification and real-time transcription.",
            "dependencies": [],
            "details": "1. Integrate with the existing Voice/NL Interaction UX System to capture multi-speaker audio streams.\n2. Implement speaker diarization using a pre-trained model to identify and separate different speakers.\n3. Create a real-time transcription service that converts speech to text with speaker attribution.\n4. Develop a deterministic hashing mechanism for canonical transcripts using SHA-256 to ensure integrity.\n5. Implement WebSocket-based live roster tracking that shows active participants and their speaking status.\n6. Create a persistent storage mechanism for the processed transcripts with speaker metadata.",
            "status": "pending",
            "testStrategy": "Test diarization accuracy with recordings of multiple speakers in various acoustic environments. Verify transcript accuracy against known speech samples. Test the hashing mechanism to ensure identical inputs produce identical hashes. Verify WebSocket indicators update correctly when speakers change."
          },
          {
            "id": 2,
            "title": "Develop AI Natural Language Summarization Module",
            "description": "Create an AI-powered system that analyzes meeting transcripts to extract key points, decisions, and action items, generating structured summaries.",
            "dependencies": [
              "15.1"
            ],
            "details": "1. Design and implement an AI model pipeline using transformer-based architecture for transcript analysis.\n2. Create extraction algorithms for key discussion points, decisions, and action items from the transcripts.\n3. Develop a structured summary generator that categorizes content into relevant sections.\n4. Implement caching mechanisms using Redis for efficient retrieval of summaries.\n5. Create an API endpoint for requesting and retrieving meeting summaries.\n6. Add metadata tagging to summaries for improved searchability.",
            "status": "pending",
            "testStrategy": "Compare AI-generated summaries against human-generated ones for accuracy and completeness. Test with various meeting types and lengths to ensure consistent quality. Verify caching mechanisms improve retrieval performance. Test with edge cases like meetings with technical jargon or unusual discussion patterns."
          },
          {
            "id": 3,
            "title": "Build Validated Bounded Modifiers System",
            "description": "Implement a framework for extracting and quantifying cabinet meeting outcomes through coordination, readiness, alignment, and messaging coherence metrics.",
            "dependencies": [
              "15.2"
            ],
            "details": "1. Design data structures for the four key modifiers: coordination, readiness, alignment, and messaging coherence.\n2. Implement natural language processing algorithms to extract sentiment and agreement indicators from meeting transcripts.\n3. Create validation rules to ensure modifiers remain within realistic bounds (e.g., 0-100 scale).\n4. Develop decay functions that reduce modifier effects over time using exponential decay.\n5. Implement feedback mechanisms that adjust modifiers based on subsequent meetings.\n6. Create a persistent storage system for tracking modifier history and changes.",
            "status": "pending",
            "testStrategy": "Test modifier extraction with various meeting transcripts to verify accuracy. Validate that bounds are properly enforced for all modifiers. Test decay functions over simulated time periods to ensure proper reduction of effects. Verify feedback mechanisms correctly adjust modifiers based on new meeting data."
          },
          {
            "id": 4,
            "title": "Integrate with Simulation System",
            "description": "Connect the Cabinet Voice Meetings System with the existing Simulation System to apply meeting outcomes to the game state.",
            "dependencies": [
              "15.3"
            ],
            "details": "1. Create integration points with the Simulation System API (Task 11) for applying meeting effects.\n2. Implement logic to translate validated modifiers into simulation state changes.\n3. Ensure deterministic application of meeting effects to maintain simulation integrity.\n4. Develop snapshot compatibility for meeting state to work with the simulation snapshot system.\n5. Create event listeners for simulation state changes that might affect meeting outcomes.\n6. Implement rollback mechanisms for meeting effects if simulation state is reverted.",
            "status": "pending",
            "testStrategy": "Test integration with the Simulation System using mock simulation states. Verify that modifiers correctly affect the simulation as expected. Test snapshot compatibility by creating and restoring snapshots with meeting data. Verify deterministic behavior by ensuring identical inputs produce identical simulation effects."
          },
          {
            "id": 5,
            "title": "Create User Interface for Meeting Management",
            "description": "Develop the frontend components for scheduling, managing, and reviewing cabinet voice meetings.",
            "dependencies": [
              "15.1",
              "15.2",
              "15.3"
            ],
            "details": "1. Design and implement a meeting scheduling interface with calendar integration.\n2. Create a real-time meeting dashboard showing live status and participant roster.\n3. Develop visualization components for historical meetings and their outcomes using charts and graphs.\n4. Implement a notification system for scheduled meetings with configurable reminders.\n5. Create a meeting review interface that displays transcripts, summaries, and extracted modifiers.\n6. Develop user controls for managing meeting recordings and sharing meeting outcomes.",
            "status": "pending",
            "testStrategy": "Conduct usability testing with representative users to ensure interface clarity. Test responsive design across different device sizes. Verify that real-time updates appear correctly during live meetings. Test notification delivery across different platforms and timing scenarios."
          }
        ]
      },
      {
        "id": 16,
        "title": "Implement Government Archetypes and Cabinet HR System",
        "description": "Develop a system that models different government archetypes (democracy, technocracy, corporate, federation, autocracy) as constitutional state machines, with cabinet roles having personality traits that affect governance and a personnel management system for appointments and scandals.",
        "details": "Implement the following components for the Government Archetypes and Cabinet HR System:\n\n1. Constitutional State Machines:\n   - Design and implement state machine models for each government archetype:\n     - Democracy: Electoral cycles, approval ratings, parliamentary procedures\n     - Technocracy: Merit-based advancement, expertise weighting, efficiency metrics\n     - Corporate: Shareholder value, executive authority, profit-driven decision making\n     - Federation: Distributed authority, regional autonomy, consensus mechanisms\n     - Autocracy: Centralized power, loyalty systems, succession planning\n   - Create transition rules between government types based on stability metrics, popular support, and crisis events\n   - Implement constitutional constraints that limit or enable specific actions based on government type\n   - Design event handlers for constitutional crises and reform opportunities\n\n2. Cabinet Role System:\n   - Define a comprehensive set of cabinet positions with:\n     - Core responsibilities and domain influence\n     - Power dynamics and reporting relationships\n     - Archetype-specific variations (e.g., Ministers vs Directors vs Secretaries)\n   - Implement personality trait modeling for cabinet members:\n     - Primary traits: Integrity (resistance to corruption) and Ambition (proactivity/risk-taking)\n     - Secondary traits: Competence, Loyalty, Public Appeal, Factional Alignment\n     - Hidden traits: Corruptibility, Blackmail Vulnerability, Scandal Risk\n   - Create interaction patterns between cabinet members based on personality compatibility\n\n3. Cabinet HR Management:\n   - Appointment system with:\n     - Candidate generation based on government type and player network\n     - Vetting process with incomplete information (hidden traits)\n     - Confirmation/approval mechanics based on government type\n   - Personnel management features:\n     - Performance evaluation metrics tied to domain outcomes\n     - Loyalty and satisfaction modeling\n     - Relationship development between cabinet members\n   - Crisis management:\n     - Scandal generation system with probability tied to hidden traits\n     - Leak mechanics with information propagation models\n     - Media response options and public opinion impact\n   - Cabinet reshuffling tools:\n     - Impact analysis on government stability\n     - Factional balance considerations\n     - Transition costs and institutional memory modeling\n\n4. System Effects and Constraints:\n   - Implement bounded systemic effects for all cabinet actions:\n     - Domain-specific influence caps\n     - Cross-domain interference patterns\n     - Temporal decay of influence\n   - Create feedback loops between:\n     - Cabinet performance and government stability\n     - Personnel decisions and factional support\n     - Scandals and constitutional reform pressure\n   - Design risk assessment tools for player decision support\n\n5. Integration Points:\n   - Connect with Task 15's Cabinet Voice Meetings for policy formation\n   - Interface with Task 14's Communications System for public messaging\n   - Utilize Task 13's Voice/NL system for cabinet member interactions\n   - Ensure compatibility with Task 11's Simulation System for state tracking",
        "testStrategy": "1. Unit Testing:\n   - Test each government archetype state machine for correct transitions and constraints\n   - Verify personality trait generation and interaction models produce realistic outcomes\n   - Test appointment, firing, and reshuffling mechanics for proper systemic effects\n   - Validate scandal and leak generation systems for appropriate probability distributions\n   - Verify bounded effects are properly enforced across all cabinet actions\n\n2. Integration Testing:\n   - Test integration with Cabinet Voice Meetings (Task 15) for proper policy formation\n   - Verify compatibility with Communications System (Task 14) for public messaging\n   - Test voice interactions with cabinet members using Voice/NL system (Task 13)\n   - Validate state persistence and restoration through the Simulation System (Task 11)\n   - Test performance under 50-player load conditions (Task 12)\n\n3. Scenario Testing:\n   - Run complete government lifecycle scenarios from formation to dissolution\n   - Test cabinet crisis scenarios with cascading effects\n   - Verify transition between government types maintains appropriate state\n   - Test extreme scenarios (full cabinet resignation, constitutional crisis)\n   - Validate long-term stability metrics across multiple game sessions\n\n4. Balance Testing:\n   - Verify no single government archetype is inherently superior\n   - Test that personality traits create meaningful trade-offs\n   - Validate that scandal risk scales appropriately with cabinet member power\n   - Ensure reshuffling has appropriate costs and benefits\n   - Test that bounded effects prevent exploitation while allowing meaningful player agency\n\n5. Acceptance Testing:\n   - Verify all requirements from R-063 are implemented correctly\n   - Test usability of cabinet management interfaces\n   - Validate that government archetypes create distinctly different gameplay experiences\n   - Ensure cabinet HR decisions feel consequential but not overwhelming",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "Implement Media & Press Systems",
        "description": "Develop a system that models press freedom and state media influence, parses press briefings to create bounded effects mediated by freedom/reputation, and implements leak/backfire mechanics when claims contradict KPIs.",
        "details": "Implement the following components for the Media & Press Systems:\n\n1. Press Freedom and State Media Model:\n   - Create a numerical model for press_freedom (0-100 scale) that reflects the independence of media\n   - Implement state_media_influence (0-100 scale) to represent government control over media narratives\n   - Design dynamic modifiers that affect these values based on player actions and government type\n   - Develop formulas for how these values interact with message propagation and public opinion\n\n2. Press Briefing Parser:\n   - Create an NLP module to analyze player-generated press briefings\n   - Extract key claims, promises, and policy statements\n   - Implement bounded effect generators with the following characteristics:\n     - Effects scaled by press_freedom and government reputation\n     - Diminishing returns for repeated messaging\n     - Credibility tracking for consistent/inconsistent messaging\n   - Design a classification system for briefing tone and content categories\n\n3. Leak and Backfire Mechanics:\n   - Implement a comparison system between press briefing claims and actual KPIs\n   - Create probability curves for leaks based on discrepancy magnitude and press_freedom\n   - Design backfire effects that damage government credibility when contradictions are exposed\n   - Develop a \"press memory\" system that tracks historical claims for future reference\n\n4. Press Briefing API:\n   - Create a REST endpoint at /press/briefings for submitting and retrieving briefings\n   - Implement authentication and authorization for press secretary role\n   - Design response schemas that include effect predictions and historical context\n   - Add support for scheduling future briefings and embargo periods\n\n5. Press Briefing Demo:\n   - Create a sample UI for press briefing submission and monitoring\n   - Implement visualizations for press freedom, media influence, and briefing effects\n   - Design a dashboard showing historical briefings and their measured impacts\n   - Include a \"press reaction\" simulator for testing briefing effectiveness\n\n6. Integration with Existing Systems:\n   - Connect with the Cabinet Voice Meetings System for coordinated messaging\n   - Integrate with the Player-to-People Communications System to ensure consistent narrative\n   - Link to the Government Archetypes system to reflect constitutional constraints on media\n   - Utilize the Simulation System for deterministic outcomes and state tracking",
        "testStrategy": "1. Unit Testing:\n   - Test press_freedom and state_media_influence models with various inputs and government types\n   - Verify press briefing parser correctly extracts claims and generates appropriate bounded effects\n   - Test leak probability calculations against expected outcomes for different scenarios\n   - Validate backfire mechanics trigger appropriately when claims contradict KPIs\n   - Verify REST API endpoints for correct authentication, authorization, and data handling\n\n2. Integration Testing:\n   - Test integration with Cabinet Voice Meetings System for message consistency\n   - Verify coordination with Player-to-People Communications System\n   - Test how different government archetypes affect press freedom and media influence\n   - Validate that the simulation system correctly captures and restores media state\n\n3. Scenario Testing:\n   - Create test scenarios with varying levels of press freedom and state control\n   - Test the full lifecycle of press briefings from creation to public opinion effects\n   - Simulate contradictory claims and verify appropriate leak and backfire mechanics\n   - Test long-term effects of consistent vs. inconsistent messaging strategies\n\n4. Performance Testing:\n   - Verify press briefing parsing performance under load\n   - Test system stability with multiple concurrent briefings\n   - Measure response times for the press briefing API endpoints\n\n5. Acceptance Testing:\n   - Verify the press briefing demo correctly visualizes all relevant metrics\n   - Test that effects on public opinion align with design specifications\n   - Validate that the system produces realistic outcomes based on real-world media dynamics",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 18,
        "title": "Implement NPC Agent System with Goal-Driven Behavior",
        "description": "Develop a multi-agent system for NPCs representing media outlets, opposition parties, lobbies, think tanks, and foreign leaders with autonomous goal-driven behavior, tool usage capabilities, and interaction through a negotiation/treaty domain-specific language.",
        "details": "Implement the following components for the NPC Agent System:\n\n1. Agent Architecture:\n   - Design a flexible agent architecture with the following components:\n     - Belief system: Internal representation of world state and other agents\n     - Goal framework: Hierarchical goal structure with priorities and satisfaction conditions\n     - Planning module: Ability to formulate plans to achieve goals\n     - Action selection: Decision-making process for choosing optimal actions\n     - Memory system: Short and long-term memory for experiences and knowledge\n   - Implement different agent archetypes with specialized behaviors:\n     - Media outlets: Information dissemination, audience growth, credibility management\n     - Opposition parties: Power acquisition, policy influence, coalition building\n     - Lobbies: Policy influence, resource accumulation, relationship management\n     - Think tanks: Knowledge production, influence on discourse, funding acquisition\n     - Foreign leaders: Diplomatic relations, resource competition, internal stability\n\n2. Tool Usage Framework:\n   - Develop a tool abstraction layer allowing agents to:\n     - Discover available tools through capability inspection\n     - Select appropriate tools based on goals and context\n     - Execute tools with proper parameters\n     - Evaluate tool effectiveness and learn from outcomes\n   - Implement domain-specific tools for each agent type:\n     - Media: Article publication, investigation, interview, fact-checking\n     - Opposition: Rally organization, policy proposal, coalition negotiation\n     - Lobbies: Campaign funding, expert testimony, regulatory comment\n     - Think tanks: Research publication, policy brief, expert panel\n     - Foreign leaders: Diplomatic communiqué, trade negotiation, alliance formation\n\n3. Negotiation/Treaty Domain-Specific Language:\n   - Design a DSL for structured commitments with:\n     - Natural language to formal commitment translation\n     - Commitment types: trade, alliance, non-aggression, information sharing\n     - Temporal conditions: duration, renewal terms, phase-in periods\n     - Enforcement mechanisms: penalties, verification procedures, arbitration\n     - Escape clauses and conditional obligations\n   - Implement a parser to convert natural language proposals to structured commitments\n   - Create a commitment execution engine to monitor and enforce agreements\n   - Develop reputation and trust systems affected by commitment adherence\n\n4. Rumor and Propaganda Network:\n   - Implement an information diffusion model with:\n     - Source credibility ratings that evolve based on accuracy history\n     - Information types: facts, opinions, rumors, propaganda\n     - Propagation mechanics based on network topology and agent relationships\n     - Fact-checking cycles with variable latency and effectiveness\n   - Create information attribution and provenance tracking\n   - Develop audience belief models influenced by:\n     - Prior beliefs and confirmation bias\n     - Source credibility and repetition effects\n     - Emotional resonance and narrative coherence\n     - Social proof and authority signals\n\n5. Agent Interaction System:\n   - Design protocols for inter-agent communication:\n     - Formal diplomatic channels\n     - Public statements and responses\n     - Back-channel negotiations\n     - Information sharing and intelligence gathering\n   - Implement coalition formation mechanics with:\n     - Interest alignment calculation\n     - Power dynamics and hierarchy\n     - Resource sharing agreements\n     - Joint action coordination\n\n6. Integration with Existing Systems:\n   - Connect to the Media & Press Systems (Task 17) for information dissemination\n   - Interface with Government Archetypes (Task 16) for political interactions\n   - Utilize Voice/NL Interaction (Task 13) for agent communication\n   - Integrate with Player-to-People Communications (Task 14) for response generation\n   - Implement hooks into the game's tick system for autonomous agent actions",
        "testStrategy": "1. Unit Testing:\n   - Test agent belief system updates with various information inputs\n   - Verify goal prioritization and satisfaction conditions function correctly\n   - Test planning module generates valid action sequences for different goals\n   - Validate tool selection logic chooses appropriate tools for given contexts\n   - Test DSL parser with various negotiation statements and verify correct structured output\n   - Verify commitment enforcement triggers appropriate penalties when conditions are violated\n   - Test information diffusion model with different network topologies\n   - Validate fact-checking system correctly identifies true and false information\n\n2. Integration Testing:\n   - Test agent interactions with the Media & Press Systems\n   - Verify proper integration with Government Archetypes system\n   - Test coalition formation between multiple agent types\n   - Validate information flow between agents and player systems\n   - Test treaty negotiation and enforcement across multiple game ticks\n   - Verify rumor propagation and fact-checking cycles across the agent network\n\n3. Scenario Testing:\n   - Create test scenarios for each agent type pursuing their primary goals\n   - Test complex multi-agent scenarios with competing and aligned interests\n   - Validate diplomatic crisis scenarios with treaty negotiations\n   - Test media campaign scenarios with rumor and fact-checking cycles\n   - Verify lobby influence campaigns on government policy\n   - Test foreign leader response to player diplomatic initiatives\n\n4. Performance Testing:\n   - Benchmark agent decision-making performance with varying numbers of agents\n   - Test system scalability with up to 100 active NPC agents\n   - Measure memory usage during complex multi-agent negotiations\n   - Profile CPU usage during information propagation across large networks\n   - Test system performance during simultaneous agent actions\n\n5. User Experience Testing:\n   - Evaluate perceived intelligence of agent behaviors through playtesting\n   - Test readability and understandability of treaty DSL outputs\n   - Verify player ability to track information sources and credibility\n   - Validate that agent actions create meaningful gameplay challenges\n   - Test player ability to influence agent behavior through various mechanisms",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 19,
        "title": "Implement Explainability System for Causal Chains",
        "description": "Develop endpoints to explain causal chains for KPI or price changes with natural language narratives and numeric contributions, supporting counterfactual re-simulation capabilities.",
        "details": "Implement the following components for the Explainability System:\n\n1. Causal Chain Analyzer:\n   - Create a graph-based representation of cause-effect relationships between system variables\n   - Implement traversal algorithms to identify paths between input changes and output effects\n   - Develop attribution models to quantify the contribution of each factor in the chain\n   - Support both forward analysis (what effects will this change have) and backward analysis (what caused this outcome)\n\n2. Natural Language Generation:\n   - Design templates for converting causal chains into coherent narratives\n   - Implement context-aware explanation generation with appropriate technical depth\n   - Support different explanation styles based on user role and expertise level\n   - Include confidence levels and uncertainty indicators in explanations\n\n3. Counterfactual Re-simulation Engine:\n   - Create an API for \"what-if\" scenario generation by removing or modifying causal factors\n   - Implement efficient delta-based re-computation that only recalculates affected portions of the simulation\n   - Develop comparison visualizations between original and counterfactual scenarios\n   - Support multiple simultaneous counterfactual scenarios for comparison\n\n4. REST API Endpoints:\n   - `/api/v1/explain/kpi/{kpi_id}` - Generate explanations for changes in specific KPIs\n   - `/api/v1/explain/price/{item_id}` - Generate explanations for price fluctuations\n   - `/api/v1/explain/counterfactual` - Run and retrieve results from counterfactual simulations\n   - Include query parameters for time ranges, detail levels, and format options\n\n5. UI Demonstration Components:\n   - Implement interactive causal chain visualization with node-link diagrams\n   - Create tabular views showing factor contributions with sortable columns\n   - Design narrative panels for textual explanations with expandable details\n   - Develop controls for creating and comparing counterfactual scenarios\n\n6. Integration with Existing Systems:\n   - Connect to the Simulation System (Task 11) for state access and counterfactual execution\n   - Leverage Government Archetypes (Task 16) for context-aware explanations\n   - Utilize NPC Agent System (Task 18) data for agent-based explanations when relevant",
        "testStrategy": "1. Unit Testing:\n   - Test causal chain identification with known input-output relationships\n   - Verify attribution calculations produce correct contribution percentages\n   - Test natural language generation for grammatical correctness and factual accuracy\n   - Validate counterfactual engine produces consistent results for identical inputs\n\n2. Integration Testing:\n   - Verify correct integration with the Simulation System for state access\n   - Test end-to-end flow from user query to explanation generation\n   - Validate counterfactual scenarios correctly modify simulation state\n   - Test performance under load with multiple simultaneous explanation requests\n\n3. Acceptance Testing:\n   - Verify explanations are understandable and accurate for domain experts\n   - Test with real-world scenarios from historical simulation data\n   - Validate that removing factors in counterfactual scenarios produces expected changes\n   - Ensure UI components render explanations correctly across different devices\n\n4. Specific Test Cases:\n   - TC-E01: Verify explanation of inflation rate changes identifies monetary policy factors\n   - TC-E02: Test counterfactual removal of a major policy decision shows correct alternative outcomes\n   - TC-E03: Validate that narrative explanations correctly describe complex multi-step causal chains\n   - TC-E04: Ensure attribution percentages sum to 100% for all explanation requests\n   - TC-E05: Test performance - explanation generation should complete in under 3 seconds for standard queries",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 20,
        "title": "Implement NL Input Canonicalization and Safety Pipeline",
        "description": "Implement a deterministic pipeline for canonicalizing all natural language inputs, including normalization, stripping, segmentation, hashing, and content safety checks with comprehensive audit logging.",
        "details": "Implement the following components for the NL Input Canonicalization and Safety Pipeline:\n\n1. Input Canonicalization Module:\n   - Develop text normalization functions to standardize character encodings, whitespace, and punctuation\n   - Implement stripping functions to remove irrelevant or potentially harmful content (HTML, scripts, etc.)\n   - Create text segmentation algorithms to break inputs into logical units for processing\n   - Design a deterministic hashing system that generates consistent fingerprints for identical inputs\n   - Implement seeded substreams for reproducible randomization when needed\n\n2. Input Validation Framework:\n   - Integrate Zod schema validation for all NL inputs with strict type checking\n   - Define comprehensive validation schemas with appropriate constraints for different input types\n   - Implement custom validators for domain-specific requirements\n   - Create helpful error messages for validation failures\n   - Design a validation pipeline that can be configured per input type\n\n3. Content Safety System:\n   - Implement content moderation checks for inappropriate language, harmful content, etc.\n   - Create configurable safety thresholds and policies\n   - Design fallback mechanisms for potentially problematic inputs\n   - Implement rate limiting and abuse prevention measures\n   - Develop a quarantine system for flagged inputs requiring human review\n\n4. Audit Logging Infrastructure:\n   - Create a comprehensive logging system that captures:\n     - Original input text\n     - Canonicalization steps applied\n     - Hash values generated\n     - Validation schemas used\n     - Safety checks performed and results\n     - Final processed output\n   - Implement provenance tracking to maintain the complete history of input transformations\n   - Design secure storage for audit logs with appropriate retention policies\n   - Create query interfaces for log analysis and investigation\n\n5. Integration with Existing Systems:\n   - Modify the Voice/NL Interaction UX System to use the canonicalization pipeline\n   - Update the Player-to-People Communications System to incorporate safety checks\n   - Integrate with the Simulation System to ensure deterministic processing\n   - Connect to the Explainability System to provide transparency into input processing\n\n6. Configuration Management:\n   - Create a centralized configuration system for all pipeline components\n   - Implement environment-specific settings (development, testing, production)\n   - Design a mechanism for updating safety rules without code changes\n   - Develop documentation for configuration options and best practices",
        "testStrategy": "1. Unit Testing:\n   - Test each canonicalization function with diverse inputs including edge cases\n   - Verify hashing produces consistent results for identical inputs after normalization\n   - Test Zod schema validation with valid and invalid inputs\n   - Verify safety checks correctly identify problematic content\n   - Test audit logging captures all required information accurately\n\n2. Integration Testing:\n   - Test the complete pipeline with various input types and sources\n   - Verify integration with Voice/NL Interaction UX System\n   - Test integration with Player-to-People Communications System\n   - Verify deterministic behavior when integrated with Simulation System\n   - Test audit log querying and analysis functionality\n\n3. Determinism Testing:\n   - Run identical inputs through the pipeline multiple times to verify consistent outputs\n   - Test with different system states to ensure context doesn't affect processing\n   - Verify seeded substreams produce reproducible results\n   - Test across different environments to ensure consistent behavior\n\n4. Security Testing:\n   - Perform penetration testing on the input processing pipeline\n   - Test with malicious inputs designed to bypass safety checks\n   - Verify audit logs cannot be tampered with\n   - Test rate limiting and abuse prevention mechanisms\n\n5. Performance Testing:\n   - Measure throughput and latency of the pipeline under various loads\n   - Test with large volumes of concurrent inputs\n   - Identify and optimize bottlenecks in the processing pipeline\n   - Verify performance meets requirements for real-time interactions\n\n6. Acceptance Testing:\n   - Verify all requirements from R-067 are satisfied\n   - Test end-to-end scenarios with real user inputs\n   - Validate audit logs provide sufficient information for compliance and debugging\n   - Confirm safety checks meet content moderation requirements",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 21,
        "title": "Implement Research Proposal Validation and Knowledge Management System",
        "description": "Develop a system for validating natural language research proposals into programs, tracking knowledge diffusion, managing patent races, monitoring espionage risks, and implementing expertise ladders with spillover effects and brain drain mechanics.",
        "details": "Implement the following components for the Research Proposal Validation and Knowledge Management System:\n\n1. Research Proposal Parser and Validator:\n   - Develop NL processing pipeline to extract key elements from research proposals (objectives, methodology, resources, timeline, expected outcomes)\n   - Implement validation rules to assess proposal feasibility, resource requirements, and alignment with technological capabilities\n   - Create a scoring system that evaluates proposals based on innovation potential, resource efficiency, and strategic alignment\n   - Design a conversion process that transforms validated proposals into executable research programs with defined milestones\n\n2. Knowledge Diffusion Engine:\n   - Implement a graph-based knowledge representation system that models technological domains and their interconnections\n   - Create diffusion algorithms that simulate how knowledge spreads between entities (corporations, nations, research institutions)\n   - Model knowledge transfer rates based on communication channels, collaborative relationships, and information security measures\n   - Implement visualization tools to track knowledge flow and identify critical knowledge hubs\n\n3. Patent Race Simulator:\n   - Design a competitive race system where multiple entities can pursue similar technological breakthroughs\n   - Implement progress tracking with probabilistic advancement based on expertise levels and resource allocation\n   - Create patent protection mechanics that provide competitive advantages to race winners\n   - Model strategic decisions including resource allocation, collaboration opportunities, and espionage attempts\n\n4. Espionage Risk Management:\n   - Develop risk assessment algorithms that evaluate the vulnerability of research programs to espionage\n   - Implement counterintelligence measures with associated costs and effectiveness ratings\n   - Create detection systems for identifying potential espionage activities with false positive/negative rates\n   - Design consequence models for successful/failed espionage attempts including diplomatic, economic, and technological impacts\n\n5. Expertise Ladder System:\n   - Implement hierarchical expertise levels across different technological domains\n   - Create progression mechanics for expertise advancement based on research activities and knowledge acquisition\n   - Model spillover effects where expertise in one domain influences capabilities in related domains\n   - Implement brain drain mechanics where experts can be recruited by competing entities based on incentives and conditions\n\n6. Deterministic Caps and Audit System:\n   - Implement hard caps on technological advancement rates to ensure predictable progression\n   - Create comprehensive audit logging for all research activities, knowledge transfers, and expertise changes\n   - Design verification systems to ensure deterministic outcomes for identical inputs\n   - Implement reporting tools to track technological progress against historical benchmarks\n\n7. Integration with Existing Systems:\n   - Connect with the NL Input Canonicalization pipeline for processing research proposals\n   - Integrate with Government Archetypes to model different research governance approaches\n   - Link to the Explainability System to provide causal narratives for research outcomes\n   - Interface with NPC Agent System to model research institutions and their behaviors",
        "testStrategy": "1. Unit Testing:\n   - Test research proposal parser with diverse proposal formats and content\n   - Verify validation rules correctly identify feasible and infeasible proposals\n   - Test knowledge diffusion algorithms with controlled network configurations\n   - Validate patent race mechanics produce expected outcomes based on inputs\n   - Test espionage risk calculations against known vulnerability patterns\n   - Verify expertise progression follows expected advancement curves\n   - Test deterministic caps maintain consistent technological boundaries\n   - Validate audit logging captures all relevant system events\n\n2. Integration Testing:\n   - Test end-to-end flow from proposal submission to research program execution\n   - Verify knowledge diffusion properly interacts with expertise systems\n   - Test patent race outcomes influence knowledge distribution correctly\n   - Validate espionage attempts properly affect knowledge states\n   - Test expertise spillovers create expected cross-domain effects\n   - Verify brain drain mechanics correctly transfer expertise between entities\n   - Test integration with NL canonicalization pipeline for proposal processing\n   - Validate connections with government archetype systems\n\n3. Simulation Testing:\n   - Run multi-entity simulations with competing research agendas\n   - Test long-term knowledge diffusion patterns against historical models\n   - Verify technological advancement rates remain within deterministic caps\n   - Validate complex interactions between all system components\n   - Test system response to extreme scenarios (massive investment, complete isolation, etc.)\n   - Verify audit system can reconstruct causal chains for all outcomes\n\n4. Performance Testing:\n   - Benchmark system performance with large numbers of concurrent research programs\n   - Test knowledge graph operations with complex technological landscapes\n   - Verify response times for proposal validation remain within acceptable limits\n   - Validate system stability under high transaction volumes\n\n5. Security Testing:\n   - Verify access controls protect sensitive research information\n   - Test audit system's ability to detect unauthorized access attempts\n   - Validate data integrity mechanisms prevent tampering with research records",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 22,
        "title": "Implement Accessibility & Internationalization Support",
        "description": "Develop multilingual speech-to-text, text-to-speech, translation capabilities, captions, and accent-robust ASR across supported locales with appropriate adapters, tests, and demo toggles.",
        "details": "Implement the following components for the Accessibility & Internationalization system:\n\n1. Multilingual Speech Processing Core:\n   - Integrate speech-to-text (STT) engines supporting multiple languages and accents\n   - Implement text-to-speech (TTS) capabilities with natural-sounding voices for all supported locales\n   - Develop accent-robust Automatic Speech Recognition (ASR) that maintains high accuracy across regional accents\n   - Create a unified API layer that abstracts the underlying speech processing engines\n\n2. Translation Services:\n   - Implement real-time translation between supported language pairs\n   - Develop context-aware translation that preserves meaning across cultural contexts\n   - Create fallback mechanisms for handling untranslatable idioms or culturally-specific references\n   - Implement quality metrics to evaluate translation accuracy\n\n3. Caption Generation System:\n   - Develop automatic caption generation for audio content\n   - Implement timing synchronization between audio and captions\n   - Support multiple caption formats (SRT, WebVTT, etc.)\n   - Create styling options for captions to enhance readability\n\n4. Internationalization Framework:\n   - Implement i18n adapters for all user-facing text elements\n   - Create a locale management system that handles language switching without application restart\n   - Develop right-to-left (RTL) layout support for appropriate languages\n   - Implement locale-specific formatting for dates, numbers, and currencies\n\n5. Accessibility Features:\n   - Implement screen reader compatibility throughout the application\n   - Create high-contrast modes and adjustable text sizing\n   - Develop keyboard navigation alternatives for all interactive elements\n   - Implement ARIA attributes and semantic HTML for assistive technology support\n\n6. Demo and Testing Infrastructure:\n   - Create toggleable demo modes to showcase internationalization features\n   - Implement A/B testing framework for accessibility improvements\n   - Develop automated testing for language switching and locale changes\n   - Create performance benchmarks for speech processing across different languages\n\n7. Documentation and Guidelines:\n   - Develop comprehensive documentation for adding new languages\n   - Create accessibility compliance checklists based on WCAG standards\n   - Implement style guides for internationalized content\n   - Provide developer guidelines for maintaining accessibility during feature development",
        "testStrategy": "1. Unit Testing:\n   - Test STT/TTS engines with samples from each supported language and accent\n   - Verify translation accuracy using standardized language proficiency tests\n   - Test caption generation timing and accuracy across different audio samples\n   - Validate locale switching functionality in isolated components\n   - Verify RTL layout rendering in appropriate language contexts\n\n2. Integration Testing:\n   - Test end-to-end workflows involving speech input, processing, and output\n   - Verify seamless transitions between languages throughout the application\n   - Test accessibility features with actual assistive technologies\n   - Validate internationalization adapters work correctly with the UI components\n   - Test performance under load for simultaneous translation and speech processing\n\n3. Accessibility Compliance Testing:\n   - Conduct automated accessibility audits using tools like Axe or Lighthouse\n   - Perform manual testing with screen readers (NVDA, JAWS, VoiceOver)\n   - Verify keyboard navigation works for all interactive elements\n   - Test color contrast ratios meet WCAG AA/AAA standards\n   - Validate that all form elements have appropriate labels and instructions\n\n4. Localization Testing:\n   - Verify all user-facing text is properly translated in each supported locale\n   - Test date, time, number, and currency formatting across locales\n   - Verify that UI layouts adapt appropriately to text expansion/contraction\n   - Test with native speakers to validate natural language quality\n   - Verify cultural appropriateness of icons, colors, and imagery\n\n5. Performance Testing:\n   - Benchmark STT/TTS processing times across different languages\n   - Measure translation latency for real-time conversations\n   - Test memory usage when switching between multiple languages\n   - Verify application responsiveness during intensive language processing tasks\n   - Measure load times for different localized content\n\n6. User Acceptance Testing:\n   - Conduct testing with users who have different accessibility needs\n   - Test with native speakers of each supported language\n   - Gather feedback on accent recognition accuracy from speakers with regional accents\n   - Validate caption readability and usefulness with deaf or hard-of-hearing users",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 23,
        "title": "Implement On-Device ASR and Model Cascading System",
        "description": "Develop an on-device/edge Automatic Speech Recognition (ASR) system with cascading model strategies and summarization layers to optimize performance while maintaining cost controls.",
        "details": "Implement the following components for the On-Device ASR and Model Cascading System:\n\n1. On-Device ASR Engine:\n   - Integrate lightweight ASR models optimized for edge deployment\n   - Implement voice activity detection to minimize processing of non-speech audio\n   - Create adaptive noise cancellation for varying environmental conditions\n   - Develop fallback mechanisms when recognition confidence is low\n   - Support offline operation with periodic model updates\n\n2. Cascading Model Strategy Framework:\n   - Design a tiered approach that starts with small, efficient models and escalates to larger, more accurate models only when necessary\n   - Implement confidence scoring to determine when to escalate to larger models\n   - Create decision logic for model selection based on:\n     - Speech complexity/ambiguity\n     - Available device resources\n     - Network conditions\n     - Cost budgets\n   - Support dynamic thresholds that adapt to user patterns and application context\n\n3. Summarization Layer:\n   - Develop token-capping mechanisms that preserve semantic meaning\n   - Implement deterministic summarization algorithms to ensure consistent outputs\n   - Create content prioritization rules based on domain-specific importance\n   - Support configurable token budgets at the session and request level\n\n4. Cost Control System:\n   - Implement budget enforcement mechanisms with configurable thresholds\n   - Create detailed telemetry integration with the existing cost telemetry system\n   - Develop real-time budget monitoring and automatic fallback triggers\n   - Support graceful degradation of service when approaching budget limits\n\n5. Performance Optimization:\n   - Implement model quantization for reduced memory footprint\n   - Create model caching strategies for frequently used speech patterns\n   - Develop batching mechanisms for efficient processing\n   - Support hardware acceleration where available (CPU/GPU/NPU)\n\n6. Configuration and Management:\n   - Create APIs for dynamic configuration of cascading thresholds\n   - Implement A/B testing framework for model selection strategies\n   - Develop monitoring dashboards for performance and cost metrics\n   - Support remote configuration updates without requiring app updates",
        "testStrategy": "1. Unit Testing:\n   - Test each ASR model individually with standardized speech samples\n   - Verify cascading logic correctly escalates based on confidence thresholds\n   - Test summarization algorithms preserve critical information while reducing tokens\n   - Validate budget enforcement mechanisms correctly limit resource usage\n   - Verify fallback mechanisms activate appropriately under various conditions\n\n2. Integration Testing:\n   - Test end-to-end speech recognition pipeline with the complete cascading strategy\n   - Verify integration with the cost telemetry system (Task 9)\n   - Test performance under varying network conditions and device capabilities\n   - Validate internationalization support works with on-device ASR (integration with Task 22)\n\n3. Performance Testing:\n   - Benchmark speech recognition accuracy across device types\n   - Measure latency for different model tiers and cascading scenarios\n   - Test memory usage under sustained operation\n   - Verify battery impact on mobile devices\n\n4. Cost Efficiency Testing:\n   - Compare token usage with and without summarization layers\n   - Measure cost savings from on-device processing vs. cloud-only approach\n   - Verify budget controls prevent cost overruns in high-usage scenarios\n   - Test accuracy vs. cost tradeoffs across different cascading configurations\n\n5. Acceptance Testing:\n   - Conduct user studies to assess perceived latency and accuracy\n   - Verify accessibility requirements are met across supported languages\n   - Test with realistic user scenarios and speech patterns\n   - Validate deterministic behavior across multiple runs with identical inputs",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 24,
        "title": "Implement Infrastructure Network System v1",
        "description": "Develop a system to represent transportation infrastructure (roads, rails, ports) with capacity and condition attributes, maintenance functionality, and effects on logistics/trade routes with appropriate API endpoints.",
        "details": "Implement the following components for the Infrastructure Network System v1:\n\n1. Infrastructure Data Model:\n   - Design database schema for infrastructure elements (roads, railways, ports)\n   - Implement attributes for capacity (throughput, load limits, passenger/cargo capacity)\n   - Create condition tracking system with degradation models over time\n   - Develop maintenance history and scheduling capabilities\n   - Establish relationships between infrastructure elements to form networks\n\n2. Network Capacity and Condition System:\n   - Implement algorithms to calculate overall network capacity based on individual elements\n   - Create bottleneck identification logic to highlight network constraints\n   - Develop condition propagation effects (how poor condition affects capacity)\n   - Implement time-based degradation models for infrastructure condition\n   - Design capacity caps and constraints based on technology levels and physical limitations\n\n3. Maintenance System:\n   - Create maintenance action definitions with costs, duration, and effectiveness\n   - Implement scheduling system for planned maintenance activities\n   - Develop emergency/reactive maintenance capabilities for sudden failures\n   - Design maintenance budget management and allocation algorithms\n   - Implement maintenance prioritization based on network importance and condition\n\n4. Logistics and Trade Route Integration:\n   - Create interfaces between infrastructure network and logistics/trade systems\n   - Implement capacity constraints on trade route throughput\n   - Develop algorithms for calculating transport efficiency based on infrastructure quality\n   - Design rerouting capabilities when infrastructure elements are unavailable\n   - Implement cost modifiers for logistics based on infrastructure condition\n\n5. API Development:\n   - Implement GET /infrastructure/status endpoint:\n     - Query parameters for filtering by type, region, condition threshold\n     - Response format with detailed infrastructure attributes\n     - Aggregation capabilities for network-level statistics\n   - Implement POST /infrastructure/maintain endpoint:\n     - Request body schema for maintenance action details\n     - Validation for budget constraints and prerequisites\n     - Response with updated infrastructure status and maintenance results\n   - Create comprehensive API documentation with examples\n\n6. Deterministic Effects System:\n   - Ensure all infrastructure changes have predictable, reproducible effects\n   - Implement transaction logging for all maintenance actions\n   - Create audit trails for infrastructure condition changes\n   - Design deterministic degradation models with configurable parameters",
        "testStrategy": "1. Unit Testing:\n   - Test infrastructure data models with various attribute combinations\n   - Verify condition calculation algorithms produce expected results\n   - Test maintenance action effects on infrastructure condition\n   - Validate capacity constraint calculations for different network configurations\n   - Verify API endpoints return correct data structures and status codes\n\n2. Integration Testing:\n   - Test interaction between infrastructure system and logistics/trade routes\n   - Verify maintenance actions properly update infrastructure condition\n   - Test network capacity calculations with complex infrastructure graphs\n   - Validate budget accounting for maintenance activities\n   - Test degradation models over simulated time periods\n\n3. Performance Testing:\n   - Benchmark API response times with large infrastructure networks\n   - Test system performance with concurrent maintenance operations\n   - Verify capacity calculation efficiency for complex network topologies\n   - Measure database query performance for infrastructure status retrieval\n\n4. Determinism Testing:\n   - Create test scenarios with predefined infrastructure configurations\n   - Execute identical maintenance sequences and verify identical outcomes\n   - Test degradation models with fixed time increments for reproducibility\n   - Verify that random elements (if any) can be seeded for deterministic results\n\n5. Regression Testing:\n   - Develop automated test suite covering core infrastructure functionality\n   - Create benchmark scenarios for maintenance effects and capacity calculations\n   - Implement test cases for API contract validation\n   - Develop integration tests with dependent systems",
        "status": "pending",
        "dependencies": [
          19,
          20
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Infrastructure Data Model",
            "description": "Create the database schema and models for infrastructure elements (roads, railways, ports) with all required attributes and relationships.",
            "dependencies": [],
            "details": "1. Design database schema with tables for infrastructure types (roads, railways, ports)\n2. Implement attributes for each infrastructure type including capacity metrics (throughput, load limits, passenger/cargo capacity)\n3. Create condition tracking fields with current/max values and degradation rate parameters\n4. Add maintenance history tracking with timestamps and effect records\n5. Establish relationships between infrastructure elements using foreign keys or graph relationships\n6. Implement serialization/deserialization methods for API responses\n7. Create database migrations and seed data for testing",
            "status": "pending",
            "testStrategy": "Unit test each model with various attribute combinations. Verify relationships between infrastructure elements. Test serialization/deserialization. Validate database constraints and indexes."
          },
          {
            "id": 2,
            "title": "Implement Network Capacity and Condition System",
            "description": "Develop algorithms to calculate network capacity, identify bottlenecks, and model condition degradation over time.",
            "dependencies": [
              "24.1"
            ],
            "details": "1. Create capacity calculation algorithms that aggregate individual element capacities\n2. Implement bottleneck identification logic that finds the weakest links in connected networks\n3. Develop condition propagation effects that model how poor condition in one element affects connected elements\n4. Build time-based degradation models with configurable parameters\n5. Implement capacity constraints based on technology levels and physical limitations\n6. Create utility functions to query network status and capacity at different points\n7. Design caching mechanisms for expensive network calculations",
            "status": "pending",
            "testStrategy": "Unit test capacity calculations with known network configurations. Test bottleneck identification with various network topologies. Verify degradation models produce expected results over simulated time periods."
          },
          {
            "id": 3,
            "title": "Develop Maintenance System",
            "description": "Create a comprehensive maintenance system with action definitions, scheduling, emergency repairs, and budget management.",
            "dependencies": [
              "24.1",
              "24.2"
            ],
            "details": "1. Define maintenance action types with costs, duration, and effectiveness parameters\n2. Implement scheduling system for planned maintenance with calendar functionality\n3. Create emergency/reactive maintenance capabilities triggered by condition thresholds\n4. Develop budget management system with allocation and spending tracking\n5. Implement prioritization algorithms based on network importance and condition\n6. Create maintenance queue management with execution logic\n7. Design maintenance outcome calculation with deterministic results",
            "status": "pending",
            "testStrategy": "Test maintenance actions with various infrastructure conditions. Verify budget constraints are enforced. Test scheduling system with overlapping maintenance activities. Validate prioritization algorithms produce expected results."
          },
          {
            "id": 4,
            "title": "Implement Logistics and Trade Route Integration",
            "description": "Create interfaces between infrastructure network and logistics/trade systems with capacity constraints and efficiency calculations.",
            "dependencies": [
              "24.2",
              "24.3"
            ],
            "details": "1. Design interfaces between infrastructure network and existing logistics/trade systems\n2. Implement capacity constraint checks for trade route throughput\n3. Develop algorithms for calculating transport efficiency based on infrastructure quality\n4. Create rerouting capabilities when infrastructure elements are unavailable or at capacity\n5. Implement cost modifiers for logistics based on infrastructure condition\n6. Design caching for frequently accessed route calculations\n7. Create events system for infrastructure changes that affect logistics",
            "status": "pending",
            "testStrategy": "Test trade route capacity constraints with various infrastructure conditions. Verify efficiency calculations produce expected results. Test rerouting algorithms with simulated infrastructure failures. Validate cost modifiers reflect infrastructure quality."
          },
          {
            "id": 5,
            "title": "Develop API Endpoints for Infrastructure Management",
            "description": "Implement REST API endpoints for querying infrastructure status and performing maintenance actions.",
            "dependencies": [
              "24.1",
              "24.3"
            ],
            "details": "1. Implement GET /infrastructure/status endpoint with filtering by type, region, condition\n2. Create response format with detailed infrastructure attributes and network statistics\n3. Implement POST /infrastructure/maintain endpoint for scheduling maintenance\n4. Design request validation for maintenance actions including budget checks\n5. Create response format for maintenance results and updated infrastructure status\n6. Implement error handling for all API endpoints\n7. Generate comprehensive API documentation with examples and schemas",
            "status": "pending",
            "testStrategy": "Test API endpoints with valid and invalid requests. Verify filtering works correctly. Test maintenance endpoint with various action types. Validate error responses are appropriate and informative."
          },
          {
            "id": 6,
            "title": "Implement Deterministic Effects System",
            "description": "Ensure all infrastructure changes have predictable, reproducible effects with comprehensive logging and audit trails.",
            "dependencies": [
              "24.3",
              "24.4",
              "24.5"
            ],
            "details": "1. Implement transaction logging for all maintenance actions and infrastructure changes\n2. Create audit trails with timestamps, actors, and before/after states\n3. Design deterministic degradation models with seed-based parameters\n4. Implement replay capability for infrastructure changes\n5. Create verification tools to ensure deterministic behavior\n6. Design configuration system for degradation parameters\n7. Implement state hash generation for infrastructure network snapshots",
            "status": "pending",
            "testStrategy": "Verify identical inputs produce identical outputs across multiple runs. Test transaction logs capture all relevant information. Validate replay functionality reproduces the same infrastructure state."
          }
        ]
      },
      {
        "id": 25,
        "title": "Implement Entrepreneurs & Private Innovation System",
        "description": "Develop a system for tracking private innovation through startup registry, R&D activities, patent management, and innovation KPIs with deterministic modifiers and diffusion mechanics.",
        "details": "Implement the following components for the Entrepreneurs & Private Innovation System:\n\n1. Startup Registry Module:\n   - Design database schema for startup entities with attributes for industry, founding date, funding rounds, team size, and technology focus\n   - Implement registration workflow with validation rules for new startup entries\n   - Create classification system to categorize startups by sector, technology readiness level, and innovation potential\n   - Develop relationships between startups and research institutions/existing companies\n   - Build API endpoint POST /innovation/startup for registering and updating startup information\n\n2. Private R&D Mechanics:\n   - Implement deterministic modifiers for private research and development activities\n   - Create hooks to connect private R&D efforts with public research adoption\n   - Design bounded modifier system to ensure R&D impacts remain within realistic parameters\n   - Develop diffusion models for how private innovations spread through the economy\n   - Implement resource allocation mechanics for R&D investments with risk/reward profiles\n   - Ensure all R&D calculations are deterministic and reproducible with the same inputs\n\n3. Patent Management System:\n   - Design patent data model with attributes for invention description, claims, filing date, and expiration\n   - Implement patent application, review, and granting workflows\n   - Create patent value assessment algorithms based on market potential and technological significance\n   - Develop patent event system for tracking licensing, litigation, and technology transfer\n   - Build API endpoint POST /innovation/patent for registering and managing patent information\n   - Implement patent race mechanics that interact with the research system\n\n4. Innovation KPI Dashboard:\n   - Design key performance indicators for measuring innovation across sectors\n   - Implement metrics for startup formation rate, patent activity, R&D investment, and technology adoption\n   - Create visualization components for tracking innovation trends over time\n   - Develop comparative analytics for benchmarking innovation performance\n   - Build API endpoint GET /innovation/kpis for retrieving innovation metrics\n   - Ensure all KPI calculations are deterministic and capped appropriately\n\n5. Integration with Research System:\n   - Create interfaces between private innovation and the research proposal/knowledge management system\n   - Implement mechanics for knowledge transfer between academic and private sectors\n   - Develop spillover effects from private R&D to public knowledge base\n   - Build connections between patent activities and research advancement\n\n6. System Constraints and Balancing:\n   - Implement caps on innovation effects to prevent unrealistic economic outcomes\n   - Create balanced diffusion rates for how quickly innovations spread\n   - Design deterministic formulas for all innovation impacts with appropriate bounds\n   - Develop configuration system for adjusting innovation parameters without code changes",
        "testStrategy": "1. Unit Testing:\n   - Test startup registration with valid and invalid data inputs\n   - Verify patent registration workflow handles all edge cases correctly\n   - Test deterministic modifiers produce consistent results with identical inputs\n   - Validate KPI calculations against manually computed expected values\n   - Verify diffusion mechanics operate within defined boundaries\n   - Test all API endpoints with various request payloads\n\n2. Integration Testing:\n   - Verify startup registry integrates correctly with research system\n   - Test patent events trigger appropriate updates in innovation KPIs\n   - Validate R&D hooks properly connect to research adoption mechanics\n   - Test end-to-end workflows from startup creation through innovation diffusion\n   - Verify system constraints properly limit extreme outcomes\n\n3. Performance Testing:\n   - Benchmark API endpoints under various load conditions\n   - Test KPI calculation performance with large datasets\n   - Verify diffusion calculations scale efficiently with increasing network size\n\n4. Determinism Testing:\n   - Create test suite specifically for verifying deterministic behavior\n   - Run identical innovation scenarios multiple times to confirm consistent outcomes\n   - Test boundary conditions to ensure caps are properly enforced\n   - Verify that random seed initialization produces reproducible results\n\n5. Regression Testing:\n   - Develop automated test suite covering all innovation mechanics\n   - Create benchmark scenarios to detect unintended changes in innovation outcomes\n   - Test backward compatibility with existing data models\n\n6. User Acceptance Testing:\n   - Create demo scenarios showcasing startup lifecycle and innovation diffusion\n   - Prepare visualization of KPIs for stakeholder review\n   - Document expected behaviors for all innovation mechanics",
        "status": "pending",
        "dependencies": [
          20,
          21
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Startup Registry Database Schema and API",
            "description": "Create the database schema for startup entities and implement the API endpoint for registering and updating startup information.",
            "dependencies": [],
            "details": "1. Design a database schema for startup entities with the following attributes: id, name, industry, founding_date, funding_rounds (array of objects with amount, date, investor_ids), team_size, technology_focus, sector, technology_readiness_level, innovation_potential, and relationships to research institutions and existing companies.\n2. Implement data validation rules using Zod schemas to ensure all startup entries meet required criteria.\n3. Create a classification system to categorize startups by sector, technology readiness level, and innovation potential.\n4. Develop the POST /innovation/startup API endpoint for registering new startups and updating existing startup information.\n5. Implement proper error handling and response formatting for the API endpoint.\n6. Ensure all database operations are properly optimized and indexed.",
            "status": "pending",
            "testStrategy": "1. Unit test the Zod validation schemas with valid and invalid startup data.\n2. Test the API endpoint with various input combinations including edge cases.\n3. Verify proper classification of startups based on provided attributes.\n4. Test relationship creation between startups and research institutions/companies.\n5. Perform load testing on the API endpoint to ensure it can handle multiple concurrent requests."
          },
          {
            "id": 2,
            "title": "Implement Private R&D Mechanics and Diffusion Models",
            "description": "Develop the deterministic modifiers for private R&D activities and create diffusion models for how innovations spread through the economy.",
            "dependencies": [
              "25.1"
            ],
            "details": "1. Implement deterministic modifier functions that calculate R&D effectiveness based on inputs like funding amount, team expertise, technology focus, and market conditions.\n2. Create a bounded modifier system with min/max caps to ensure R&D impacts remain within realistic parameters.\n3. Develop diffusion models that determine how private innovations spread through different economic sectors over time.\n4. Implement resource allocation mechanics for R&D investments with configurable risk/reward profiles.\n5. Create hooks to connect private R&D efforts with public research adoption.\n6. Ensure all calculations are deterministic and reproducible with the same inputs by using fixed seeds for any randomization.",
            "status": "pending",
            "testStrategy": "1. Unit test each modifier function to verify deterministic outputs with identical inputs.\n2. Test boundary conditions to ensure modifiers respect min/max caps.\n3. Verify diffusion models correctly propagate innovations across sectors at expected rates.\n4. Test integration between R&D mechanics and the startup registry system.\n5. Create benchmark tests to ensure performance at scale with many simultaneous R&D calculations."
          },
          {
            "id": 3,
            "title": "Design and Implement Patent Management System",
            "description": "Create the patent data model and implement the workflows for patent application, review, granting, and management.",
            "dependencies": [
              "25.1"
            ],
            "details": "1. Design a patent data model with attributes for id, title, invention_description, claims (array), filing_date, grant_date, expiration_date, inventor_ids, assignee_id, status, and technology_classification.\n2. Implement the patent application workflow with validation rules for required information.\n3. Create the patent review and granting process with configurable approval criteria.\n4. Develop a patent value assessment algorithm based on market potential, technological significance, and claim breadth.\n5. Implement a patent event system for tracking licensing, litigation, and technology transfer activities.\n6. Build the POST /innovation/patent API endpoint for registering and managing patent information.\n7. Implement patent race mechanics that interact with the research system.",
            "status": "pending",
            "testStrategy": "1. Unit test the patent data model with various attribute combinations.\n2. Test the patent application workflow with valid and invalid submissions.\n3. Verify the patent value assessment algorithm produces consistent results.\n4. Test the patent event system with different event types.\n5. Validate the API endpoint handles all patent management operations correctly.\n6. Test patent race mechanics under various competitive scenarios."
          },
          {
            "id": 4,
            "title": "Develop Innovation KPI Dashboard and Metrics",
            "description": "Design and implement key performance indicators for measuring innovation across sectors with visualization components and API endpoints.",
            "dependencies": [
              "25.1",
              "25.2",
              "25.3"
            ],
            "details": "1. Design a comprehensive set of key performance indicators for measuring innovation, including startup formation rate, patent activity, R&D investment levels, and technology adoption rates.\n2. Implement calculation functions for each KPI with appropriate normalization and capping to prevent unrealistic values.\n3. Create time-series data structures to track innovation trends over configurable time periods.\n4. Develop comparative analytics for benchmarking innovation performance across different sectors or regions.\n5. Build visualization data preparation functions that format metrics for frontend display.\n6. Implement the GET /innovation/kpis API endpoint for retrieving innovation metrics with filtering and aggregation options.\n7. Ensure all KPI calculations are deterministic and properly bounded.",
            "status": "pending",
            "testStrategy": "1. Unit test each KPI calculation function with various input scenarios.\n2. Verify time-series data correctly tracks changes over different time periods.\n3. Test the API endpoint with different query parameters for filtering and aggregation.\n4. Validate that all metrics remain within realistic bounds even with extreme input values.\n5. Benchmark the performance of KPI calculations with large datasets."
          },
          {
            "id": 5,
            "title": "Integrate Private Innovation with Research System",
            "description": "Create interfaces between private innovation and the research proposal/knowledge management system with mechanics for knowledge transfer and spillover effects.",
            "dependencies": [
              "25.2",
              "25.3",
              "25.4"
            ],
            "details": "1. Create interface adapters between the private innovation system and the existing research proposal/knowledge management system.\n2. Implement mechanics for knowledge transfer between academic and private sectors with configurable transfer rates.\n3. Develop spillover effect calculations that determine how private R&D contributes to the public knowledge base.\n4. Build connection logic between patent activities and research advancement, including how patents can accelerate or block research progress.\n5. Implement technology transfer mechanics from research institutions to startups.\n6. Create event listeners that react to changes in either system and propagate appropriate effects.\n7. Ensure all integration points use well-defined interfaces that can accommodate future changes to either system.",
            "status": "pending",
            "testStrategy": "1. Unit test each integration point between the private innovation and research systems.\n2. Verify knowledge transfer mechanics produce expected outcomes under various scenarios.\n3. Test spillover effects to ensure they appropriately impact the public knowledge base.\n4. Validate that patent activities correctly influence research advancement.\n5. Perform integration tests that simulate complete workflows across both systems."
          },
          {
            "id": 6,
            "title": "Implement System Constraints and Configuration Management",
            "description": "Develop caps on innovation effects, balanced diffusion rates, and a configuration system for adjusting innovation parameters without code changes.",
            "dependencies": [
              "25.2",
              "25.3",
              "25.4",
              "25.5"
            ],
            "details": "1. Implement a comprehensive constraint system that caps innovation effects to prevent unrealistic economic outcomes.\n2. Create balanced diffusion rate formulas that model how quickly innovations spread through different sectors based on their characteristics.\n3. Design deterministic formulas for all innovation impacts with appropriate upper and lower bounds.\n4. Develop a configuration management system that allows adjusting innovation parameters without code changes.\n5. Implement a validation layer for configuration changes to ensure they maintain system balance.\n6. Create a configuration versioning system to track changes and allow rollbacks if needed.\n7. Build admin API endpoints for authorized users to view and modify system configurations.\n8. Implement proper logging of all configuration changes for audit purposes.",
            "status": "pending",
            "testStrategy": "1. Unit test the constraint system with extreme values to verify proper capping.\n2. Test diffusion rate formulas with various innovation types and sector combinations.\n3. Verify configuration changes correctly propagate throughout the system.\n4. Test the validation layer with valid and invalid configuration changes.\n5. Perform system-wide tests to ensure all components respect the configured constraints.\n6. Validate that configuration versioning correctly tracks changes and enables rollbacks."
          }
        ]
      },
      {
        "id": 26,
        "title": "Implement Logistics & Transport System",
        "description": "Develop a logistics and transport system for land, sea, and space shipments with deterministic routing, capacity management, transit time calculation, and in-flight inventory tracking that affects settlement.",
        "details": "Implement the following components for the Logistics & Transport system:\n\n1. Shipment Model:\n   - Design a comprehensive database schema for shipments with attributes including origin, destination, cargo type, volume, weight, priority, and transport mode (land/sea/space)\n   - Implement versioning for shipment status changes to maintain audit trail\n   - Create relationships between shipments and inventory items to track goods in transit\n   - Support batch shipments and split deliveries for optimization\n\n2. Deterministic Routing Engine:\n   - Develop route calculation algorithms for different transport modes with consistent results\n   - Implement capacity constraints for various transport corridors and hubs\n   - Create queuing system for shipments when capacity is exceeded\n   - Design fallback routing options when primary routes are unavailable\n   - Ensure deterministic ETA calculations based on distance, mode, and current network conditions\n\n3. Transit Time Calculator:\n   - Implement formulas for calculating transit times based on distance, mode, and current conditions\n   - Account for loading/unloading times at terminals and transfer points\n   - Model delays from congestion, weather, or other external factors\n   - Provide confidence intervals for arrival times\n\n4. In-flight Inventory Management:\n   - Track ownership and value of goods during transit\n   - Implement settlement rules for goods changing ownership while in transit\n   - Create inventory snapshots at simulation tick boundaries\n   - Support inventory queries that include both warehouse and in-transit goods\n\n5. API Endpoints:\n   - POST /logistics/shipment: Create new shipment with validation for required fields\n     - Request body: origin, destination, cargo details, transport preferences\n     - Response: shipment ID, estimated route, ETA, capacity confirmation\n   - GET /logistics/status: Query shipment status with filtering options\n     - Query parameters: shipment_id, origin, destination, status, date_range\n     - Response: detailed shipment information including current location, status, and updated ETA\n\n6. Integration Points:\n   - Connect with inventory system to update stock levels when shipments are created or delivered\n   - Integrate with settlement system to handle ownership transfers of in-flight goods\n   - Hook into simulation tick system to update shipment positions and status",
        "testStrategy": "1. Unit Testing:\n   - Test shipment creation with valid and invalid input combinations\n   - Verify routing algorithms produce consistent results with identical inputs\n   - Test capacity constraints correctly queue or reject shipments when limits are reached\n   - Validate transit time calculations against manually computed examples\n   - Verify in-flight inventory correctly affects settlement calculations\n\n2. Integration Testing:\n   - Test end-to-end shipment lifecycle from creation to delivery\n   - Verify API endpoints return correct status codes and response formats\n   - Test integration with inventory system for stock level updates\n   - Validate settlement system correctly processes ownership changes for in-transit goods\n\n3. Determinism Testing:\n   - Run multiple simulations with identical inputs to verify consistent routing and ETA results\n   - Test with varying load conditions to ensure queuing behavior is predictable\n   - Verify that random external factors (like weather) are properly seeded for reproducibility\n\n4. Performance Testing:\n   - Benchmark system with large volumes of concurrent shipments\n   - Test query performance for status lookups with various filter combinations\n   - Verify system can handle realistic shipment volumes within performance constraints\n\n5. Scenario Testing:\n   - Test capacity overflow scenarios to verify queuing behavior\n   - Simulate route disruptions to test fallback routing\n   - Create scenarios with ownership transfers during transit to verify settlement logic",
        "status": "pending",
        "dependencies": [
          11,
          20
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Shipment Model and Database Schema",
            "description": "Design and implement the database schema for shipments with all required attributes and relationships. Create models for tracking goods in transit with versioning support for status changes.",
            "dependencies": [],
            "details": "Create database models for shipments with fields for origin, destination, cargo type, volume, weight, priority, and transport mode (land/sea/space). Implement versioning tables to track shipment status changes with timestamps. Establish relationships between shipments and inventory items using foreign keys. Add support for batch shipments by implementing parent-child relationships between shipments. Include fields for split deliveries tracking original and derived shipments.",
            "status": "pending",
            "testStrategy": "Unit test the model with various shipment types and attributes. Verify versioning correctly tracks status changes. Test batch shipment creation and split delivery functionality. Ensure proper relationships between shipments and inventory items."
          },
          {
            "id": 2,
            "title": "Develop Deterministic Routing Engine",
            "description": "Create a routing system that calculates consistent routes for different transport modes while respecting capacity constraints and providing fallback options.",
            "dependencies": [
              "26.1"
            ],
            "details": "Implement route calculation algorithms for land, sea, and space transport that produce consistent results with the same inputs. Create data structures to represent transport corridors with capacity limits. Develop a priority queue system for shipments when capacity is exceeded. Design fallback routing logic that activates when primary routes are unavailable. Ensure all calculations are deterministic by using fixed seeds for any randomization needed.",
            "status": "pending",
            "testStrategy": "Test routing algorithms with identical inputs to verify consistent results. Verify capacity constraints correctly queue shipments when limits are reached. Test fallback routing activates appropriately when primary routes are unavailable. Benchmark routing performance with large numbers of simultaneous shipments."
          },
          {
            "id": 3,
            "title": "Build Transit Time Calculator",
            "description": "Implement a system to calculate accurate transit times based on distance, mode, and conditions, including loading/unloading times and potential delays.",
            "dependencies": [
              "26.2"
            ],
            "details": "Create formulas for calculating transit times based on distance and transport mode (land/sea/space). Implement functions to account for loading/unloading times at terminals and transfer points. Develop models for delays from congestion, weather, or other external factors. Build a confidence interval calculator for arrival time predictions. Ensure all calculations remain deterministic across simulation runs.",
            "status": "pending",
            "testStrategy": "Test transit time calculations against known routes and expected times. Verify loading/unloading times are correctly incorporated. Test delay models with various external factors. Validate confidence intervals provide accurate predictions across different scenarios."
          },
          {
            "id": 4,
            "title": "Implement In-flight Inventory Management",
            "description": "Develop a system to track ownership and value of goods during transit, with settlement rules for ownership changes and integration with inventory snapshots.",
            "dependencies": [
              "26.1",
              "26.3"
            ],
            "details": "Create a tracking system for goods ownership and value during transit. Implement settlement rules that handle ownership transfers while goods are in transit. Develop inventory snapshot functionality that captures in-transit goods at simulation tick boundaries. Build query capabilities that include both warehouse and in-transit goods in inventory reports. Ensure proper synchronization with the simulation system for consistent state updates.",
            "status": "pending",
            "testStrategy": "Test ownership tracking through complete shipment lifecycles. Verify settlement rules correctly transfer ownership during transit. Test inventory snapshots at simulation tick boundaries contain accurate in-transit data. Validate inventory queries correctly include both warehouse and in-transit goods."
          },
          {
            "id": 5,
            "title": "Create API Endpoints for Logistics System",
            "description": "Develop RESTful API endpoints for shipment creation, status queries, and management with proper validation and response formatting.",
            "dependencies": [
              "26.1",
              "26.2",
              "26.3",
              "26.4"
            ],
            "details": "Implement POST /logistics/shipment endpoint with validation for required fields (origin, destination, cargo details, transport preferences). Create response structure with shipment ID, estimated route, ETA, and capacity confirmation. Develop GET /logistics/status endpoint with filtering options (shipment_id, origin, destination, status, date_range). Format response with detailed shipment information including current location, status, and updated ETA. Add additional endpoints for shipment cancellation, modification, and batch operations.",
            "status": "pending",
            "testStrategy": "Test API endpoints with valid and invalid request payloads. Verify validation correctly identifies and reports missing or invalid fields. Test filtering functionality returns appropriate results. Measure API performance under load with concurrent requests."
          },
          {
            "id": 6,
            "title": "Integrate with External Systems",
            "description": "Connect the logistics system with inventory, settlement, and simulation systems to ensure proper updates and synchronization across the platform.",
            "dependencies": [
              "26.4",
              "26.5"
            ],
            "details": "Integrate with inventory system to update stock levels when shipments are created or delivered. Connect with settlement system to handle ownership transfers of in-flight goods. Hook into simulation tick system to update shipment positions and status at each tick. Implement event listeners for relevant external system events that affect shipments. Create notification mechanisms for shipment status changes that other systems can subscribe to.",
            "status": "pending",
            "testStrategy": "Test integration with inventory system verifies stock levels update correctly. Verify settlement system correctly processes ownership transfers. Test simulation tick integration updates shipment positions accurately. Perform end-to-end tests across all integrated systems to ensure proper synchronization."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-14T06:39:07.520Z",
      "updated": "2025-08-14T09:44:35.027Z",
      "description": "Tasks for feature-live-ops context"
    }
  },
  "sprint-6-live-ops": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Stage Mode Backend Services",
        "description": "Create backend services for Stage Mode including speaker roster management, moderator controls, and approval workflows.",
        "details": "Develop REST API endpoints for /stage with the following functionality:\n- GET /stage - Retrieve current stage status and speaker roster\n- POST /stage/request - Request to join stage (raise hand)\n- PUT /stage/approve/:userId - Approve user to join stage\n- PUT /stage/deny/:userId - Deny user's request to join stage\n- PUT /stage/mute/:userId - Mute/unmute user on stage\n\nImplement WebSocket events for real-time stage updates:\n- stage_update: when speaker roster changes\n- request_approved: when a user's request is approved\n- request_denied: when a user's request is denied\n\nEnsure all endpoints include proper authentication and authorization checks. Implement rate limiting to prevent abuse. Store stage state in a database with appropriate caching for performance.",
        "testStrategy": "Unit tests for each endpoint and WebSocket event. Integration tests for the complete stage workflow. Performance tests simulating 50 concurrent participants with response time measurements. Verify that GM summary median is less than 4.5s at 50 participants as specified in requirements.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and implement database schema for stage management",
            "description": "Create database models and schema for storing stage state, speaker roster, and request queue",
            "dependencies": [],
            "details": "Design database schema to store stage state (active/inactive), speaker roster (users currently on stage with their roles and mute status), and request queue (pending requests to join stage). Implement models with appropriate relationships and indexes for efficient querying. Include fields for timestamps, user metadata, and request status tracking.",
            "status": "pending",
            "testStrategy": "Unit tests for database models and relationships. Performance tests for common query patterns. Verify data integrity constraints and indexing effectiveness."
          },
          {
            "id": 2,
            "title": "Develop REST API endpoints for stage management",
            "description": "Implement the specified REST API endpoints for stage operations with authentication and rate limiting",
            "dependencies": [],
            "details": "Implement all required REST endpoints: GET /stage, POST /stage/request, PUT /stage/approve/:userId, PUT /stage/deny/:userId, and PUT /stage/mute/:userId. Add proper authentication middleware to verify user identity and authorization checks to ensure users have appropriate permissions for each action. Implement rate limiting to prevent abuse, with configurable thresholds for different endpoint types.",
            "status": "pending",
            "testStrategy": "Unit tests for each endpoint with various authentication scenarios. Integration tests for complete workflows. Security tests for authentication bypass attempts. Rate limit verification tests."
          },
          {
            "id": 3,
            "title": "Implement WebSocket events for real-time stage updates",
            "description": "Create WebSocket handlers for stage_update, request_approved, and request_denied events",
            "dependencies": [],
            "details": "Develop WebSocket event handlers that emit stage_update events when the speaker roster changes, request_approved events when a user's request is approved, and request_denied events when a user's request is denied. Implement authentication for WebSocket connections and ensure proper event payload formatting. Create mechanisms to trigger these events from the appropriate API endpoints.",
            "status": "pending",
            "testStrategy": "Unit tests for WebSocket event handlers. Integration tests with simulated clients to verify real-time updates. Latency tests to ensure timely delivery of events."
          },
          {
            "id": 4,
            "title": "Implement caching layer for stage state",
            "description": "Create a caching mechanism for stage state to improve performance under load",
            "dependencies": [],
            "details": "Design and implement a caching strategy for stage state data to reduce database load and improve response times. Use Redis or a similar in-memory cache to store frequently accessed data like current stage status and speaker roster. Implement cache invalidation strategies to ensure data consistency when stage state changes. Add configurable TTL values for different cache types.",
            "status": "pending",
            "testStrategy": "Performance tests comparing cached vs. non-cached responses. Cache hit ratio analysis. Consistency tests to verify cache invalidation works correctly. Load tests simulating concurrent access patterns."
          },
          {
            "id": 5,
            "title": "Create comprehensive testing suite and documentation",
            "description": "Develop unit, integration, and performance tests along with API documentation",
            "dependencies": [],
            "details": "Create a comprehensive test suite covering all endpoints and WebSocket events. Implement unit tests for individual components, integration tests for complete workflows, and performance tests simulating 50 concurrent participants. Document all API endpoints with request/response examples, authentication requirements, and error codes. Include WebSocket event documentation with payload schemas and triggering conditions.",
            "status": "pending",
            "testStrategy": "End-to-end testing of complete stage workflows. Performance testing under load conditions to verify response times meet requirements (GM summary median less than 4.5s at 50 participants). Documentation verification through peer review and automated schema validation."
          }
        ]
      },
      {
        "id": 2,
        "title": "Implement Fireteams Backend Services",
        "description": "Create backend services for Fireteams including CRUD operations for squads and team channel assignment.",
        "details": "Develop REST API endpoints for /fireteams with the following functionality:\n- GET /fireteams - List all fireteams\n- POST /fireteams - Create a new fireteam\n- GET /fireteams/:id - Get details of a specific fireteam\n- PUT /fireteams/:id - Update fireteam details\n- DELETE /fireteams/:id - Delete a fireteam\n- POST /fireteams/:id/members - Add members to a fireteam\n- DELETE /fireteams/:id/members/:userId - Remove a member from a fireteam\n- PUT /fireteams/:id/channel - Assign a voice channel to a fireteam\n\nImplement WebSocket events for real-time fireteam updates:\n- fireteam_created: when a new fireteam is created\n- fireteam_updated: when fireteam details change\n- fireteam_deleted: when a fireteam is deleted\n- member_added: when a member joins a fireteam\n- member_removed: when a member leaves a fireteam\n- channel_assigned: when a voice channel is assigned\n\nImplement action batching for efficient updates across fireteams. Ensure proper database schema design for scalability.",
        "testStrategy": "Unit tests for each endpoint and WebSocket event. Integration tests for complete fireteam workflows. Performance tests with 50 participants divided into multiple fireteams. Verify per-team voice stability under load conditions.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Database Schema for Fireteams",
            "description": "Create a scalable database schema to support fireteams functionality including team details, membership, and channel assignments.",
            "dependencies": [],
            "details": "Design database tables and relationships for fireteams, including: team metadata (name, description, status), member associations with roles, voice channel assignments, and activity timestamps. Implement indexes for efficient querying. Create database migration scripts. Document schema with ERD diagrams.",
            "status": "pending",
            "testStrategy": "Unit tests for database models and relationships. Performance tests with large datasets to verify query efficiency. Validation tests for data integrity constraints."
          },
          {
            "id": 2,
            "title": "Develop Core Fireteams REST API Endpoints",
            "description": "Implement the primary REST API endpoints for fireteam CRUD operations.",
            "dependencies": [
              "2.1"
            ],
            "details": "Implement the following endpoints with proper request validation, error handling, and response formatting: GET /fireteams (with pagination and filtering), POST /fireteams (with validation), GET /fireteams/:id, PUT /fireteams/:id, and DELETE /fireteams/:id. Include authentication middleware and permission checks for each endpoint.",
            "status": "pending",
            "testStrategy": "Unit tests for each endpoint covering success and error cases. Integration tests for complete CRUD workflows. API contract tests to ensure specification compliance."
          },
          {
            "id": 3,
            "title": "Implement Member Management API Endpoints",
            "description": "Create endpoints for adding and removing members from fireteams with proper permission handling.",
            "dependencies": [
              "2.1",
              "2.2"
            ],
            "details": "Implement POST /fireteams/:id/members endpoint with validation for member limits and duplicate prevention. Develop DELETE /fireteams/:id/members/:userId endpoint with proper permission checks. Add logic for handling member roles and permissions within teams. Implement validation for team size limits.",
            "status": "pending",
            "testStrategy": "Unit tests for member addition and removal. Permission tests to verify authorization rules. Edge case tests for team size limits and invalid member operations."
          },
          {
            "id": 4,
            "title": "Implement Voice Channel Assignment System",
            "description": "Create the API endpoint and backend logic for assigning voice channels to fireteams.",
            "dependencies": [
              "2.1",
              "2.2"
            ],
            "details": "Implement PUT /fireteams/:id/channel endpoint for assigning voice channels. Create logic for channel availability checking and conflict resolution. Develop channel release mechanism when fireteams are disbanded. Implement validation to prevent channel double-booking.",
            "status": "pending",
            "testStrategy": "Unit tests for channel assignment and validation. Integration tests with voice service. Conflict resolution tests to verify proper handling of channel assignment disputes."
          },
          {
            "id": 5,
            "title": "Implement WebSocket Events and Action Batching",
            "description": "Create WebSocket event system for real-time fireteam updates with efficient action batching.",
            "dependencies": [
              "2.1",
              "2.2",
              "2.3",
              "2.4"
            ],
            "details": "Implement WebSocket server for real-time events. Create event handlers for fireteam_created, fireteam_updated, fireteam_deleted, member_added, member_removed, and channel_assigned events. Develop action batching system to group similar updates for efficient processing. Implement client connection management and authentication for WebSockets.",
            "status": "pending",
            "testStrategy": "Unit tests for each WebSocket event type. Load tests to verify action batching efficiency. Integration tests with frontend to verify real-time updates. Performance tests with multiple concurrent clients."
          }
        ]
      },
      {
        "id": 3,
        "title": "Develop Stage Mode and Fireteams UI Components",
        "description": "Create UI components for Stage Mode and Fireteams including moderator controls, raise-hand functionality, and per-team voice indicators.",
        "details": "Implement the following UI components:\n\nStage Mode:\n- Moderator control panel with approve/deny/mute actions\n- Participant list with status indicators\n- Raise-hand button and request status for participants\n- Speaker roster display\n- Stage join/leave controls\n\nFireteams:\n- Fireteam creation and management interface\n- Team member list with roles\n- Voice channel assignment controls\n- Per-team voice activity indicators\n- Team switching interface\n\nEnsure all UI components are responsive and accessible. Implement real-time updates using WebSocket connections. Add visual feedback for actions and state changes.",
        "testStrategy": "Unit tests for individual UI components. Integration tests for component interactions. User acceptance testing with different roles (moderator, participant). Accessibility testing. Performance testing with 50 concurrent users to ensure UI remains responsive.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Stage Mode Moderator Controls",
            "description": "Create the moderator control panel with approve/deny/mute actions and participant list with status indicators",
            "dependencies": [],
            "details": "Develop a responsive moderator control panel that includes: 1) Approve/deny buttons for stage access requests, 2) Mute/unmute controls for individual participants, 3) Participant list showing current status (speaking, muted, waiting), 4) Real-time updates via WebSocket connections, 5) Visual feedback for action success/failure states",
            "status": "pending",
            "testStrategy": "Unit tests for individual control components. Integration tests for moderator action flows. Accessibility testing for all controls. Performance testing with 50+ participants in the list to ensure UI responsiveness."
          },
          {
            "id": 2,
            "title": "Develop Stage Mode Participant Interface",
            "description": "Implement raise-hand functionality, speaker roster display, and stage join/leave controls for participants",
            "dependencies": [
              "3.1"
            ],
            "details": "Create participant-facing UI components including: 1) Raise-hand button with visual feedback, 2) Request status indicator showing pending/approved/denied states, 3) Speaker roster showing current active speakers, 4) Stage join/leave controls with appropriate state transitions, 5) Real-time updates for all components",
            "status": "pending",
            "testStrategy": "Unit tests for each participant control. Integration tests for the complete participant workflow (request access, receive approval, join stage, speak, leave). Accessibility testing for all interactive elements."
          },
          {
            "id": 3,
            "title": "Create Fireteam Management Interface",
            "description": "Develop UI for fireteam creation, management, and team member list with roles",
            "dependencies": [],
            "details": "Build the fireteam management interface with: 1) Create new fireteam form with name/description fields, 2) Edit/delete controls for existing fireteams, 3) Team member list showing roles (leader, member), 4) Add/remove member functionality, 5) Role assignment controls, 6) Responsive design for all screen sizes",
            "status": "pending",
            "testStrategy": "Unit tests for fireteam CRUD operations. Integration tests for team creation and member management workflows. Accessibility testing for all form elements and controls."
          },
          {
            "id": 4,
            "title": "Implement Voice Channel Assignment UI",
            "description": "Create interface for voice channel assignment controls and per-team voice activity indicators",
            "dependencies": [
              "3.3"
            ],
            "details": "Develop voice-related UI components including: 1) Channel assignment dropdown/selector for each fireteam, 2) Visual voice activity indicators showing which team members are speaking, 3) Mute/unmute controls for team channels, 4) Volume controls for individual members and teams, 5) Real-time updates via WebSocket for voice activity",
            "status": "pending",
            "testStrategy": "Unit tests for channel assignment controls and voice indicators. Integration tests with mock voice data to verify indicator behavior. Performance testing with multiple simultaneous speakers to ensure UI remains responsive."
          },
          {
            "id": 5,
            "title": "Develop Team Switching Interface",
            "description": "Create UI for users to view available fireteams and switch between them",
            "dependencies": [
              "3.3",
              "3.4"
            ],
            "details": "Implement team switching functionality with: 1) List view of all available fireteams with key information, 2) Join/leave team buttons with appropriate permissions, 3) Current team indicator and status, 4) Team switching confirmation dialog, 5) Visual feedback for successful/failed team switches, 6) Real-time updates when team composition changes",
            "status": "pending",
            "testStrategy": "Unit tests for team listing and switching controls. Integration tests for the complete team switching workflow. User acceptance testing with multiple concurrent users switching teams. Verify proper state updates after team changes."
          }
        ]
      },
      {
        "id": 14,
        "title": "Implement Player-to-People Communications (Speeches) System",
        "description": "Develop a system that parses natural language speeches into deterministic modifiers with caps, decay, and backfire effects, implements a cohort opinions model, and integrates with the tick pipeline.",
        "details": "Implement the following components for the Player-to-People Communications (Speeches) system:\n\n1. Speech Parser:\n   - Create a natural language processing module to analyze player speeches\n   - Implement bounded deterministic modifiers with configurable parameters:\n     - Maximum effect caps to prevent exploitation\n     - Temporal decay functions to model diminishing influence over time\n     - Backfire mechanics for poorly received or contradictory speeches\n   - Design a classification system for speech intent and emotional content\n   - Develop context-aware parsing that considers game state and history\n\n2. Cohort Opinions Model:\n   - Implement a multi-dimensional opinion matrix for different NPC cohorts\n   - Create demographic-based response variations to the same speech\n   - Model opinion spread and influence between related cohort groups\n   - Develop opinion persistence with appropriate state storage\n   - Implement opinion thresholds that trigger gameplay events\n\n3. Audit Logging System:\n   - Create comprehensive logging of all speech inputs and resulting modifiers\n   - Implement searchable history of player communications\n   - Design visualization tools for opinion shifts over time\n   - Store raw inputs alongside parsed interpretations for debugging\n\n4. HTML Demo Interface:\n   - Develop a simple web interface to demonstrate speech effects\n   - Create visual representations of opinion changes\n   - Implement real-time feedback on speech parsing\n   - Design interactive elements to test different speech approaches\n\n5. Tick Pipeline Integration:\n   - Connect speech effects to the main simulation tick system\n   - Ensure proper sequencing of opinion updates within the game loop\n   - Implement efficient state updates that minimize performance impact\n   - Design appropriate hooks for event triggers based on opinion thresholds\n\n6. Performance Considerations:\n   - Optimize NLP processing for minimal latency\n   - Implement batching for multiple speeches when appropriate\n   - Design efficient data structures for opinion storage and retrieval\n   - Create appropriate caching mechanisms for frequently accessed opinion data",
        "testStrategy": "1. Unit Testing:\n   - Test speech parser with various input types, lengths, and emotional content\n   - Verify modifier bounds are properly enforced with extreme inputs\n   - Test decay functions over multiple time periods\n   - Validate backfire mechanics trigger appropriately for contradictory inputs\n   - Verify cohort opinion model updates correctly based on inputs\n\n2. Integration Testing:\n   - Test end-to-end flow from speech input to opinion changes\n   - Verify proper integration with the tick pipeline\n   - Test multi-user scenarios with overlapping speeches\n   - Validate opinion spread mechanics between related cohorts\n   - Ensure audit logging captures all relevant data\n\n3. Performance Testing:\n   - Benchmark speech parsing performance under load\n   - Test system with concurrent speech processing\n   - Verify opinion model updates don't impact tick performance\n   - Measure memory usage during extended gameplay sessions\n\n4. User Acceptance Testing:\n   - Conduct playtests focusing on speech mechanics\n   - Gather feedback on perceived impact of speeches\n   - Test with various speech styles and approaches\n   - Verify HTML demo provides clear visualization of effects\n\n5. Specific Test Cases:\n   - TC-S01: Verify speech with positive sentiment increases relevant opinion metrics\n   - TC-S02: Confirm contradictory speeches trigger backfire mechanics\n   - TC-S03: Test opinion decay over multiple game sessions\n   - TC-S04: Validate opinion thresholds trigger appropriate game events\n   - TC-S05: Verify audit log contains searchable history of all speeches",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Implement Cabinet Voice Meetings System",
        "description": "Develop a cabinet voice meetings pipeline that processes multi-speaker conversations with diarization, transcription, AI natural language summarization, and validated bounded modifiers for coordination, readiness, alignment, and messaging coherence.",
        "details": "Implement the following components for the Cabinet Voice Meetings System:\n\n1. Voice Meeting Pipeline:\n   - Integrate with the existing Voice/NL Interaction UX System for multi-speaker diarization\n   - Implement real-time transcription with speaker identification\n   - Create a deterministic hashing mechanism for canonical transcripts to ensure integrity and non-repudiation\n   - Develop WebSocket indicators for live roster tracking and participant status\n\n2. AI Natural Language Summarization:\n   - Design and implement an AI model to analyze meeting transcripts\n   - Extract key discussion points, decisions, and action items\n   - Generate concise, structured summaries with categorized content\n   - Implement caching mechanisms for efficient retrieval of summaries\n\n3. Validated Bounded Modifiers System:\n   - Create a framework for extracting and quantifying cabinet meeting outcomes:\n     - Coordination: Measure of how well cabinet members are working together\n     - Readiness: Assessment of preparedness for upcoming challenges\n     - Alignment: Degree of agreement on strategic direction\n     - Messaging Coherence: Consistency of communication strategy\n   - Implement validation rules to ensure modifiers remain within realistic bounds\n   - Design decay functions for modifier effects over time\n   - Create feedback mechanisms to adjust modifiers based on subsequent meetings\n\n4. Integration with Simulation System:\n   - Connect meeting outcomes to the simulation state\n   - Apply validated modifiers to relevant game systems\n   - Ensure deterministic application of meeting effects\n   - Implement snapshot compatibility for meeting state\n\n5. User Interface Components:\n   - Design meeting scheduling and management interface\n   - Create visualization for live meeting status and participant roster\n   - Develop dashboard for historical meetings and their outcomes\n   - Implement notification system for scheduled meetings",
        "testStrategy": "1. Unit Testing:\n   - Test diarization accuracy with multiple speakers in various acoustic environments\n   - Verify transcript hashing produces consistent results for identical inputs\n   - Validate summarization quality against human-generated summaries\n   - Test bounded modifier extraction with various meeting scenarios\n   - Verify WebSocket indicators correctly reflect participant status\n\n2. Integration Testing:\n   - Test end-to-end pipeline from voice input to modifier application\n   - Verify integration with the simulation system\n   - Test snapshot export/import with meeting data\n   - Validate that meeting effects properly influence game state\n\n3. Performance Testing:\n   - Measure transcription latency with multiple concurrent speakers\n   - Test system performance with cabinet meetings of various durations\n   - Verify summarization processing time meets requirements\n   - Benchmark WebSocket performance with full participant roster\n\n4. User Acceptance Testing:\n   - Conduct simulated cabinet meetings with test users\n   - Gather feedback on summary quality and accuracy\n   - Verify that modifier effects align with meeting content\n   - Test usability of meeting scheduling and management interface\n\n5. Regression Testing:\n   - Ensure voice meeting functionality doesn't interfere with other voice interactions\n   - Verify that modifier application doesn't disrupt simulation stability\n   - Test compatibility with existing player-to-people communications system",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Implement Press Conferences System with Reporter Q&A",
        "description": "Develop a press conferences system that enables live Q&A sessions with reporter personas, leader/cabinet answers, canonicalized transcripts, and validator-capped effects mediated by press freedom and credibility metrics.",
        "details": "Implement the following components for the Press Conferences System:\n\n1. Core Press Conference Functionality:\n   - Create REST API endpoints for press conference management:\n     - POST /gov/press/conference/start - Initialize a new press conference session\n     - POST /gov/press/conference/end - Conclude an active press conference\n     - POST /gov/press/question - Submit reporter questions to the queue\n     - POST /gov/press/answer - Record leader/cabinet responses to questions\n     - GET /gov/press/transcript/:id - Retrieve canonicalized transcript of a press conference\n   - Implement WebSocket channel (press.conference.live) for real-time updates during conferences\n\n2. Reporter Persona System:\n   - Design reporter persona generation with varied political leanings, specializations, and credibility ratings\n   - Implement question queueing mechanism with priority weighting based on reporter attributes\n   - Create deterministic question generation influenced by current game state and recent events\n\n3. Answer Processing Pipeline:\n   - Develop natural language processing for leader/cabinet answers\n   - Implement canonicalization of transcripts with deterministic hashing for integrity\n   - Create bounded modifier system with effects on public opinion, media relations, and government transparency\n\n4. Press Freedom and Credibility Mechanics:\n   - Implement press_freedom metric that influences question diversity and aggressiveness\n   - Create reporter credibility system that affects question impact and public reception\n   - Design validator-capped effects to prevent exploitation while maintaining realistic impact\n\n5. Integration Points:\n   - Connect with Cabinet Voice Meetings System for cabinet member participation\n   - Integrate with Player-to-People Communications for consistent public opinion modeling\n   - Ensure compatibility with the tick pipeline for time-based effects and decay\n\n6. Data Persistence:\n   - Store press conference transcripts with metadata for historical reference\n   - Maintain reporter persona profiles with evolving credibility metrics\n   - Track press freedom indices over time to show governance impact",
        "testStrategy": "1. Unit Testing:\n   - Test each API endpoint with valid and invalid inputs\n   - Verify WebSocket events are properly emitted during conference lifecycle\n   - Validate transcript canonicalization produces consistent results\n   - Test reporter question generation for determinism with identical inputs\n   - Verify validator caps correctly limit extreme opinion shifts\n\n2. Integration Testing:\n   - Test complete press conference workflow from start to end\n   - Verify integration with Cabinet Voice Meetings for multi-speaker scenarios\n   - Test interaction between press freedom metrics and question generation\n   - Validate that reporter credibility properly influences question impact\n   - Ensure transcript retrieval works correctly with various conference types\n\n3. Performance Testing:\n   - Benchmark WebSocket performance with 50+ concurrent viewers\n   - Test system under load with rapid question submission\n   - Measure response times for transcript generation and retrieval\n   - Verify system stability during extended press conferences\n\n4. Determinism Testing:\n   - Verify identical inputs produce identical question sets and effects\n   - Test reproducibility of press conference outcomes with controlled inputs\n   - Validate that random seeds produce consistent but varied reporter behavior\n\n5. Cap Validation Testing:\n   - Test extreme positive and negative answers to ensure caps are enforced\n   - Verify that cumulative effects respect maximum bounds\n   - Test interactions between press freedom, credibility, and effect magnitudes\n   - Validate that effect decay functions work as expected over time",
        "status": "pending",
        "dependencies": [
          14,
          15
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Core Press Conference API Endpoints",
            "description": "Create the REST API endpoints for managing press conferences, including starting/ending conferences, submitting questions, recording answers, and retrieving transcripts.",
            "dependencies": [],
            "details": "Develop the following REST API endpoints:\n1. POST /gov/press/conference/start - Create a new press conference with metadata (topic, participants, scheduled time)\n2. POST /gov/press/conference/end - End an active press conference and finalize transcript\n3. POST /gov/press/question - Add reporter questions to the queue with metadata\n4. POST /gov/press/answer - Record leader/cabinet responses to questions\n5. GET /gov/press/transcript/:id - Retrieve canonicalized transcript\n\nImplement request validation, error handling, and authentication middleware. Create database models for conferences, questions, and answers. Ensure proper transaction handling for data consistency.",
            "status": "pending",
            "testStrategy": "Unit test each endpoint with valid and invalid inputs. Test authentication and authorization rules. Verify proper error responses for edge cases. Integration tests for complete conference lifecycle."
          },
          {
            "id": 2,
            "title": "Implement WebSocket Channel for Live Conference Updates",
            "description": "Create a WebSocket channel to provide real-time updates during press conferences, including question queue changes, speaker status, and transcript updates.",
            "dependencies": [
              "16.1"
            ],
            "details": "Implement the WebSocket channel 'press.conference.live' with the following event types:\n1. conference_started - When a new conference begins\n2. question_queued - When a new reporter question is added\n3. question_selected - When a question is chosen to be answered\n4. answer_recorded - When an answer is provided\n5. conference_ended - When the conference concludes\n\nEnsure proper authentication for WebSocket connections. Implement room-based subscriptions so clients only receive updates for conferences they're participating in. Add throttling to prevent flooding.",
            "status": "pending",
            "testStrategy": "Test WebSocket connection establishment, authentication, and event emission. Verify clients receive appropriate events based on their roles. Test reconnection handling and missed event recovery."
          },
          {
            "id": 3,
            "title": "Develop Reporter Persona Generation System",
            "description": "Create a system to generate and manage reporter personas with varied political leanings, specializations, credibility ratings, and question generation capabilities.",
            "dependencies": [
              "16.1"
            ],
            "details": "Implement a reporter persona system with the following components:\n1. Reporter profile generator with configurable attributes:\n   - Political leaning (spectrum from -1.0 to 1.0)\n   - Specialization areas (economy, foreign policy, health, etc.)\n   - Credibility rating (0.0-1.0)\n   - Aggressiveness factor (0.0-1.0)\n2. Question generation algorithm that considers:\n   - Current game state and recent events\n   - Reporter's specialization and political leaning\n   - Press freedom level in the game\n3. Priority queueing mechanism that weights questions based on reporter attributes and relevance\n\nStore reporter profiles in the database with unique identifiers and historical interaction data.",
            "status": "pending",
            "testStrategy": "Test persona generation for diversity and appropriate attribute distribution. Verify question generation produces relevant and varied questions based on game state. Test priority queueing with different reporter configurations."
          },
          {
            "id": 4,
            "title": "Implement Answer Processing and Transcript Canonicalization",
            "description": "Develop the pipeline for processing leader/cabinet answers, canonicalizing transcripts, and implementing the bounded modifier system for game effects.",
            "dependencies": [
              "16.2",
              "16.3"
            ],
            "details": "Create an answer processing pipeline with these components:\n1. Natural language processing for leader/cabinet answers:\n   - Extract key statements and positions\n   - Detect tone and confidence levels\n   - Identify contradictions with previous statements\n2. Transcript canonicalization:\n   - Format Q&A pairs with metadata\n   - Generate deterministic hash for integrity verification\n   - Store in searchable format with timestamps\n3. Bounded modifier system:\n   - Calculate effects on public opinion (capped at configurable limits)\n   - Determine media relations impact based on answer quality\n   - Update government transparency metrics\n   - Apply effects to game state through the tick pipeline",
            "status": "pending",
            "testStrategy": "Test NLP accuracy with various answer types. Verify canonicalization produces consistent results for identical inputs. Test modifier calculations with boundary cases to ensure caps are enforced. Validate effect application through the tick pipeline."
          },
          {
            "id": 5,
            "title": "Implement Press Freedom and Credibility Mechanics",
            "description": "Create systems to track and update press freedom metrics and reporter credibility, which influence question diversity, aggressiveness, and impact on public opinion.",
            "dependencies": [
              "16.3",
              "16.4"
            ],
            "details": "Implement the following mechanics:\n1. Press freedom metric:\n   - Initialize based on government type and starting conditions\n   - Update based on government actions and policies\n   - Influence question diversity, critical tone, and follow-up probability\n   - Scale from 0.0 (heavily restricted) to 1.0 (completely free)\n2. Reporter credibility system:\n   - Track accuracy of reporter statements over time\n   - Update based on fact-checking results and public reception\n   - Affect question impact on public opinion\n   - Implement decay and recovery mechanisms\n3. Validator-capped effects:\n   - Create configurable limits on opinion shifts from single conferences\n   - Implement diminishing returns for repeated messaging\n   - Design backfire mechanics for detected falsehoods",
            "status": "pending",
            "testStrategy": "Test press freedom updates based on various government actions. Verify credibility changes appropriately with different reporter behaviors. Test validator caps prevent exploitation while maintaining realistic impact. Validate diminishing returns and backfire mechanics."
          },
          {
            "id": 6,
            "title": "Integrate Press Conference System with Related Game Systems",
            "description": "Connect the Press Conference System with Cabinet Voice Meetings, Player-to-People Communications, and implement data persistence for historical reference.",
            "dependencies": [
              "16.4",
              "16.5"
            ],
            "details": "Implement the following integration points:\n1. Cabinet Voice Meetings System integration:\n   - Allow cabinet members to participate in press conferences\n   - Share transcript data between systems\n   - Coordinate modifier effects for consistency\n2. Player-to-People Communications integration:\n   - Ensure consistent public opinion modeling\n   - Coordinate messaging effects and contradictions\n3. Tick pipeline integration:\n   - Register time-based effects and decay functions\n   - Schedule periodic press freedom updates\n4. Data persistence:\n   - Store complete press conference transcripts with metadata\n   - Maintain historical reporter profiles and credibility metrics\n   - Track press freedom indices over time\n   - Implement data access methods for UI components and reporting",
            "status": "pending",
            "testStrategy": "Test integration with Cabinet Voice Meetings using mock interfaces. Verify consistent public opinion modeling with Player-to-People Communications. Test tick pipeline integration for proper timing of effects. Validate data persistence with long-running scenarios and data integrity checks."
          }
        ]
      },
      {
        "id": 17,
        "title": "UI Spec: Press Conferences Reporter Q&A Interface",
        "description": "Design and create wireframes, flows, and component specifications for the Press Conferences Reporter Q&A interface, including accessibility considerations and test-ids for all components.",
        "details": "Develop comprehensive UI specifications for the Press Conferences Reporter Q&A system with the following deliverables:\n\n1. Wireframes and User Flows:\n   - Create detailed wireframes for all Press Conference UI states:\n     - Conference lobby/waiting room\n     - Active Q&A session with question queue\n     - Reporter view with question submission interface\n     - Leader/cabinet answer interface\n     - Audience/viewer experience\n   - Document user flows for all participant roles (reporters, leaders, moderators, audience)\n   - Include responsive designs for desktop, tablet, and mobile views\n\n2. Component Inventory:\n   - Question Queue Component:\n     - Visual representation of pending questions\n     - Status indicators (approved, denied, answered)\n     - Sorting/filtering controls for moderators\n   - Reporter Interface:\n     - Question submission form with character limits\n     - Credibility indicator display\n     - Question history and status tracking\n   - Leader/Cabinet Answer Interface:\n     - Question display with context\n     - Response input with formatting options\n     - Time remaining indicators\n   - Transcript Display:\n     - Real-time transcript updates\n     - Q&A pairing visualization\n     - Searchable/filterable transcript archive\n\n3. Props/State Specifications:\n   - Document all component props with types and default values\n   - Define state management approach for:\n     - Conference lifecycle states\n     - Question queue state\n     - User role permissions\n     - Real-time updates via WebSockets\n   - Include data flow diagrams showing state propagation\n\n4. Accessibility Requirements:\n   - Define ARIA roles and attributes for all components\n   - Specify keyboard navigation patterns\n   - Document color contrast requirements\n   - Include screen reader considerations\n   - Provide focus management guidelines\n\n5. Test-ID Implementation:\n   - Create a consistent test-id naming convention\n   - Document test-ids for all interactive elements\n   - Include test-id mapping to component hierarchy\n\n6. Integration with Design System:\n   - Reference appropriate components from design/ui_visual_design.md\n   - Document any new components needed for the Press Conferences UI\n   - Ensure consistency with Nation Mode Panels design patterns\n\n7. Deliverables:\n   - Clickable prototype using Figma or similar tool\n   - Component specification document with props/state details\n   - Implementation checklist for developers\n   - Accessibility compliance checklist\n   - Test-id reference sheet for QA",
        "testStrategy": "1. Design Review:\n   - Conduct a design review session with stakeholders to validate wireframes and flows\n   - Verify alignment with visual design guidelines in design/ui_visual_design.md\n   - Confirm all required functionality is represented in the UI specifications\n\n2. Prototype Testing:\n   - Create a clickable prototype in Figma or similar tool\n   - Conduct usability testing with representatives from each user role:\n     - Reporters submitting questions\n     - Leaders/cabinet members answering questions\n     - Moderators managing the question queue\n     - General audience members viewing the conference\n   - Document and address usability issues identified during testing\n\n3. Accessibility Evaluation:\n   - Perform an accessibility audit of the prototype using WCAG 2.1 AA standards\n   - Test keyboard navigation paths for all user flows\n   - Verify color contrast meets minimum requirements\n   - Review screen reader compatibility of proposed component structure\n   - Document any accessibility issues to be addressed\n\n4. Component Specification Validation:\n   - Review props/state specifications with frontend developers\n   - Verify all required data is available from the backend (Task #16)\n   - Confirm test-id implementation follows project standards\n   - Validate that all UI states are properly documented\n\n5. Implementation Readiness:\n   - Create a checklist of all components needed for implementation\n   - Verify that the design system has all required base components\n   - Document any new components that need to be created\n   - Prioritize components for phased implementation if needed\n\n6. Final Deliverable Verification:\n   - Ensure all required deliverables are complete and properly formatted\n   - Verify that the clickable prototype covers all user flows\n   - Confirm that the component specifications are detailed enough for implementation\n   - Validate that the test-id reference sheet is comprehensive for QA testing",
        "status": "pending",
        "dependencies": [
          16,
          3
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 18,
        "title": "Implement Intelligence Brief & Risk Indices System",
        "description": "Develop a system that provides daily intelligence briefings and calculates deterministic risk indices based on a canonicalized corpus, with appropriate access controls and no covert operations functionality.",
        "details": "Implement the following components for the Intelligence Brief & Risk Indices system:\n\n1. Intelligence Brief API:\n   - Create REST API endpoint: GET /intel/brief\n     - Returns the current daily intelligence brief with structured sections\n     - Implements pagination and filtering options for historical briefs\n     - Ensures deterministic generation based on canonicalized game state\n   - Design a data model for intelligence briefs with:\n     - Timestamp and unique identifier\n     - Categorized sections (economic, diplomatic, security, etc.)\n     - Severity indicators for highlighted issues\n     - Source attribution where appropriate\n     - Links to related risk indices\n\n2. Risk Indices API:\n   - Create REST API endpoint: GET /intel/risks\n     - Returns current calculated risk indices with historical trends\n     - Supports filtering by risk category and time period\n     - Includes metadata about calculation parameters\n   - Implement deterministic risk index computation:\n     - Define a canonicalization process for the input corpus\n     - Create mathematical models for each risk category\n     - Implement bounded indices (0-100 scale) with clear thresholds\n     - Document the exact algorithm for each index calculation\n     - Ensure reproducibility with identical inputs\n\n3. Access Control Layer:\n   - Implement role-based permissions for intelligence data\n   - Create granular access controls for different risk categories\n   - Log all access to intelligence information\n   - Implement proper authentication checks on all endpoints\n\n4. Integration with Game State:\n   - Subscribe to relevant game state changes to update intelligence\n   - Implement efficient caching strategy for intelligence briefs\n   - Create hooks for the tick pipeline to trigger intelligence updates\n   - Ensure all calculations are deterministic based on game state\n\n5. Frontend Data Providers:\n   - Create data providers for intelligence brief panels\n   - Implement visualization components for risk indices\n   - Design interactive elements for exploring intelligence data\n   - Support real-time updates when new intelligence becomes available",
        "testStrategy": "1. Unit Testing:\n   - Test each API endpoint with valid and invalid inputs\n   - Verify deterministic behavior by comparing outputs with identical inputs\n   - Test boundary conditions for risk indices (0, 100, and edge cases)\n   - Validate access control by testing with different user roles\n   - Verify proper error handling for all endpoints\n\n2. Integration Testing:\n   - Test integration with the game state system\n   - Verify intelligence updates correctly when game state changes\n   - Test the tick pipeline integration for scheduled updates\n   - Validate that frontend components correctly display intelligence data\n   - Test caching mechanisms for performance optimization\n\n3. Determinism Testing:\n   - Create a test suite specifically for verifying deterministic behavior\n   - Generate multiple intelligence briefs with identical inputs\n   - Compare outputs to ensure bit-for-bit identical results\n   - Test with varying game states to ensure predictable changes\n\n4. Cap and Backfire Testing:\n   - Verify risk indices remain within bounded limits (0-100)\n   - Test extreme scenarios to ensure caps are properly enforced\n   - Validate that backfire mechanics work as expected when applicable\n   - Test edge cases where multiple factors influence the same risk index\n\n5. Access Control Testing:\n   - Test each endpoint with users having different permission levels\n   - Verify unauthorized access attempts are properly rejected\n   - Test that partial access shows only permitted information\n   - Validate that access logs are correctly maintained\n\n6. Performance Testing:\n   - Measure response times for intelligence brief generation\n   - Test system under load with multiple concurrent requests\n   - Verify caching mechanisms improve performance as expected\n   - Benchmark risk index calculations for optimization opportunities",
        "status": "pending",
        "dependencies": [
          14,
          16
        ],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-08-14T08:11:25.619Z",
      "updated": "2025-08-14T09:24:31.277Z",
      "description": "Unified Sprint 6: Live Ops Core (Stage/Fireteams/Speech/Cabinet)",
      "copiedFrom": {
        "tag": "feature-live-ops",
        "date": "2025-08-14T08:11:25.619Z"
      }
    }
  },
  "sprint-7-live-loops": {
    "tasks": [
      {
        "id": 4,
        "title": "Implement Daily Contracts System",
        "description": "Create a system for daily contracts including rotation, UI surfacing, and rewards distribution for cosmetics, QoL improvements, and alliance resources.",
        "details": "Develop the following components:\n\n1. Contract Definition System:\n- JSON schema for contract definitions\n- Contract types (completion, collection, achievement)\n- Reward types (cosmetics, QoL items, alliance resources)\n\n2. Contract Rotation Service:\n- Daily rotation logic with configurable timing\n- Contract selection algorithm to ensure variety\n- REST API for /live-ops/contracts\n\n3. Contract Progress Tracking:\n- Player progress storage and retrieval\n- Completion validation logic\n- Reward distribution system\n\n4. UI Components:\n- Contract display cards\n- Progress indicators\n- Reward previews\n- Completion celebration\n\nImplement a database schema for storing contract definitions, active contracts, and player progress. Create admin tools for contract management.",
        "testStrategy": "Unit tests for contract rotation logic and progress tracking. Integration tests for the complete contract lifecycle. Verification tests for rotation correctness. Load tests to ensure system handles peak user activity. Test reward distribution accuracy.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Contract Definition System",
            "description": "Create the JSON schema for contract definitions, implement contract types, and define reward types",
            "dependencies": [],
            "details": "Develop a JSON schema for contract definitions that includes fields for contract ID, title, description, type (completion, collection, achievement), requirements, rewards, and duration. Implement the three contract types with appropriate validation rules. Define reward types including cosmetics, QoL items, and alliance resources with proper metadata and distribution parameters.",
            "status": "pending",
            "testStrategy": "Unit tests for schema validation, contract type classification, and reward type definitions. Integration tests to verify contract definitions can be properly created, stored, and retrieved."
          },
          {
            "id": 2,
            "title": "Build Contract Rotation Service",
            "description": "Develop the daily rotation logic, contract selection algorithm, and REST API endpoints",
            "dependencies": [
              "4.1"
            ],
            "details": "Create a service that handles daily contract rotation with configurable timing parameters. Implement a selection algorithm that ensures variety in contract offerings and prevents repetition. Develop REST API endpoints for /live-ops/contracts with GET, POST, PUT, and DELETE operations. Include functionality for admin override of rotation schedule.",
            "status": "pending",
            "testStrategy": "Unit tests for rotation timing logic and selection algorithm. API tests for all endpoints. Integration tests to verify contract rotation occurs correctly at configured times. Load tests to ensure the service handles peak user requests."
          },
          {
            "id": 3,
            "title": "Develop Contract Progress Tracking",
            "description": "Create systems for player progress storage, completion validation, and reward distribution",
            "dependencies": [
              "4.1",
              "4.2"
            ],
            "details": "Implement database schema for storing player progress on active contracts. Create validation logic to verify contract completion based on player actions. Develop a reward distribution system that grants appropriate items upon contract completion. Include transaction handling to ensure rewards are properly delivered even during service interruptions.",
            "status": "pending",
            "testStrategy": "Unit tests for progress tracking and validation logic. Integration tests for the complete contract lifecycle from assignment to completion. Stress tests for concurrent completion events. Data integrity tests to verify progress is never lost."
          },
          {
            "id": 4,
            "title": "Create UI Components for Contracts",
            "description": "Design and implement UI elements for contract display, progress tracking, and rewards",
            "dependencies": [
              "4.1",
              "4.3"
            ],
            "details": "Develop contract display cards showing title, description, requirements, and rewards. Create progress indicators that update in real-time as players complete contract objectives. Implement reward previews with detailed item information. Design and build completion celebration animations and notifications. Ensure UI is responsive and accessible.",
            "status": "pending",
            "testStrategy": "UI component tests for proper rendering and state management. User experience testing for clarity and intuitiveness. Performance tests to ensure UI remains responsive during gameplay. Cross-platform compatibility testing."
          },
          {
            "id": 5,
            "title": "Implement Admin Tools and Database Schema",
            "description": "Create database schema for contracts system and develop admin tools for contract management",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "Design and implement comprehensive database schema for storing contract definitions, active contracts, and player progress. Create admin tools with CRUD operations for contract management, including contract creation, editing, activation/deactivation, and performance analytics. Implement monitoring dashboards for contract engagement metrics and reward distribution statistics.",
            "status": "pending",
            "testStrategy": "Database schema validation tests. Admin tool functionality tests for all CRUD operations. Security tests to ensure proper access controls. Performance tests for database queries under load conditions."
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement Weekly Anomaly System",
        "description": "Create a system for weekly anomalies including activation, teardown, and playlist integration with active mutators.",
        "details": "Develop the following components:\n\n1. Anomaly Definition System:\n- JSON schema for anomaly definitions\n- Mutator types and effects\n- Activation/deactivation rules\n\n2. Anomaly Scheduler Service:\n- Weekly rotation logic with configurable timing\n- Anomaly selection algorithm\n- REST API for /live-ops/anomalies\n\n3. Playlist Integration:\n- Playlist modification based on active anomaly\n- Mutator application to gameplay rules\n- State restoration on anomaly teardown\n\n4. UI Components:\n- Anomaly announcement and description\n- Active anomaly indicators\n- Countdown timers for activation/deactivation\n\nImplement database storage for anomaly definitions and active state. Create admin tools for anomaly management and emergency override.",
        "testStrategy": "Unit tests for anomaly rotation logic and playlist integration. Integration tests for the complete anomaly lifecycle. Verification tests for activation/teardown correctness. Test that anomaly properly applies rules and that teardown restores defaults as specified in requirements.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Anomaly Definition System",
            "description": "Create the JSON schema and core components for defining anomalies, including mutator types, effects, and activation/deactivation rules.",
            "dependencies": [],
            "details": "Develop a comprehensive JSON schema for anomaly definitions that includes fields for name, description, duration, mutator types, and effects. Implement the core logic for different mutator types (gameplay modifiers, visual effects, scoring changes) and their impact on game rules. Create a validation system for anomaly definitions and establish clear activation/deactivation rules including triggers, conditions, and cooldown periods.",
            "status": "pending",
            "testStrategy": "Unit tests for schema validation and mutator effect calculations. Integration tests to verify proper loading of anomaly definitions from database. Test edge cases for activation/deactivation rules under various game states."
          },
          {
            "id": 2,
            "title": "Build Anomaly Scheduler Service",
            "description": "Develop the service responsible for weekly rotation logic, anomaly selection, and exposing the REST API endpoints.",
            "dependencies": [
              "5.1"
            ],
            "details": "Implement a scheduler service that handles weekly rotation with configurable timing parameters. Create an anomaly selection algorithm that ensures variety and prevents repetition. Develop REST API endpoints for /live-ops/anomalies with GET, POST, PUT, and DELETE operations. Include authentication and authorization for admin operations. Implement notification system for upcoming and active anomalies.",
            "status": "pending",
            "testStrategy": "Unit tests for rotation logic and selection algorithms. API endpoint testing with mock requests. Integration tests for the complete scheduling lifecycle including timing accuracy. Test authorization controls for admin operations."
          },
          {
            "id": 3,
            "title": "Develop Playlist Integration System",
            "description": "Create the system that modifies playlists based on active anomalies, applies mutators to gameplay rules, and handles state restoration.",
            "dependencies": [
              "5.1",
              "5.2"
            ],
            "details": "Implement playlist modification logic that dynamically updates available game modes based on active anomalies. Develop the mutator application system that injects rule changes into gameplay sessions. Create state tracking to ensure proper restoration of default settings when anomalies end. Build conflict resolution for cases where multiple anomalies might affect the same gameplay elements.",
            "status": "pending",
            "testStrategy": "Unit tests for playlist modification and mutator application. Integration tests for the complete anomaly lifecycle including activation and teardown. Verification tests to ensure game state properly restores after anomaly conclusion."
          },
          {
            "id": 4,
            "title": "Create UI Components for Anomalies",
            "description": "Develop the user interface elements for anomaly announcements, active indicators, and countdown timers.",
            "dependencies": [
              "5.2",
              "5.3"
            ],
            "details": "Design and implement UI components for anomaly announcements including modal dialogs and notification banners. Create persistent indicators for active anomalies that display in appropriate game screens. Develop countdown timers for activation/deactivation that update in real-time. Implement visual feedback for how anomalies are affecting gameplay. Design UI elements to be responsive across different device types.",
            "status": "pending",
            "testStrategy": "UI component tests for proper rendering and responsiveness. User experience testing for clarity of anomaly information. Integration tests with backend services to verify timers and state indicators accurately reflect server state."
          },
          {
            "id": 5,
            "title": "Implement Database Storage and Admin Tools",
            "description": "Create database schemas for anomaly definitions and active state tracking, plus admin tools for management and emergency override.",
            "dependencies": [
              "5.1",
              "5.2"
            ],
            "details": "Design and implement database schemas for storing anomaly definitions, historical data, and active state information. Develop admin dashboard for creating, editing, and managing anomalies. Implement emergency override functionality for immediate activation or deactivation of anomalies. Create logging and audit trail for all anomaly-related actions. Build analytics tools to track player engagement with different anomaly types.",
            "status": "pending",
            "testStrategy": "Database schema validation tests. Admin tool functionality testing including emergency override procedures. Performance testing for database operations under load. Security testing for admin authentication and authorization controls."
          }
        ]
      },
      {
        "id": 6,
        "title": "Develop Recap Cards Generator",
        "description": "Create a system to automatically generate 3-5 recap beats with hero images, one-click sharing functionality, and seed codes for replay.",
        "details": "Implement the following components:\n\n1. Session Analysis Engine:\n- Identify key moments and significant events\n- Select 3-5 most interesting beats from session\n- Generate descriptive text for each beat\n\n2. Hero Image Generator:\n- Capture or render images for key moments\n- Apply visual styling and formatting\n- Optimize images for sharing\n\n3. Seed Code Generation:\n- Create deterministic seed codes for session replay\n- Compress session state into shareable format\n- Implement seed validation\n\n4. Sharing Integration:\n- One-click share to social platforms\n- Copy to clipboard functionality\n- QR code generation for mobile sharing\n\n5. REST API:\n- POST /recap/generate - Generate recap from session data\n- GET /recap/:id - Retrieve generated recap\n\nStore recap data in database with appropriate TTL. Implement caching for frequently accessed recaps.",
        "testStrategy": "Unit tests for beat selection algorithm and seed generation. Integration tests for the complete recap generation pipeline. Verification tests for recap correctness and seed determinism as specified in requirements. Performance testing for generation speed under various session complexities.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Session Analysis Engine",
            "description": "Develop a system to analyze session data, identify key moments, and select 3-5 most interesting beats with descriptive text.",
            "dependencies": [],
            "details": "Create algorithms to process session data and identify significant events based on player actions, achievements, and game state changes. Implement a scoring system to rank moments by interest level. Develop natural language generation for descriptive text that captures the essence of each moment. Include configuration options for different game modes and event types. Ensure the engine can process sessions of varying lengths efficiently.",
            "status": "pending",
            "testStrategy": "Unit tests for beat selection algorithm and scoring system. Integration tests with sample session data. Performance testing with sessions of varying complexity. Validation tests to ensure selected beats are truly significant and descriptive text is accurate."
          },
          {
            "id": 2,
            "title": "Build Hero Image Generator",
            "description": "Create a system to capture or render images for key moments, apply visual styling, and optimize for sharing.",
            "dependencies": [
              "6.1"
            ],
            "details": "Implement screenshot capture functionality at key moments identified by the Session Analysis Engine. Develop image processing pipeline with filters, overlays, and branding elements. Create templates for different recap card styles. Implement image optimization for web and social media sharing (resolution, file size, format). Support both real-time capture and post-session rendering options.",
            "status": "pending",
            "testStrategy": "Unit tests for image processing functions. Visual regression tests for styling consistency. Performance tests for image generation speed. Compatibility tests across different devices and platforms. File size and quality optimization verification."
          },
          {
            "id": 3,
            "title": "Develop Seed Code Generation System",
            "description": "Create a system to generate deterministic seed codes for session replay, compress session state, and implement validation.",
            "dependencies": [],
            "details": "Design a deterministic algorithm to generate unique seed codes from session data. Implement compression techniques to minimize seed code length while preserving essential replay information. Create encoding/decoding functions for converting between session state and seed codes. Develop validation mechanisms to verify seed code integrity. Implement error handling for invalid or corrupted seeds. Document the seed format specification for potential future extensions.",
            "status": "pending",
            "testStrategy": "Unit tests for encoding/decoding functions. Verification tests for determinism (same input always produces same seed). Compression ratio analysis. Validation tests with valid and invalid seeds. Performance testing for generation and validation speed."
          },
          {
            "id": 4,
            "title": "Implement Sharing Integration",
            "description": "Develop one-click sharing functionality for social platforms, clipboard copying, and QR code generation for mobile sharing.",
            "dependencies": [
              "6.2",
              "6.3"
            ],
            "details": "Integrate with social media APIs (Twitter, Facebook, Discord, etc.) for direct sharing. Implement copy-to-clipboard functionality for seed codes and recap links. Create QR code generation for mobile device sharing. Design sharing templates with preview images and text. Implement tracking for share analytics. Ensure shared content includes appropriate metadata for rich previews on social platforms.",
            "status": "pending",
            "testStrategy": "Integration tests with each social platform API. Cross-browser compatibility tests for clipboard functionality. Mobile device testing for QR code scanning. User acceptance testing for sharing workflow. Analytics verification to ensure tracking is accurate."
          },
          {
            "id": 5,
            "title": "Create REST API and Database Integration",
            "description": "Develop REST API endpoints for recap generation and retrieval, with database storage and caching implementation.",
            "dependencies": [
              "6.1",
              "6.2",
              "6.3",
              "6.4"
            ],
            "details": "Implement POST /recap/generate endpoint to accept session data and return generated recap. Create GET /recap/:id endpoint to retrieve previously generated recaps. Design database schema for storing recap data with appropriate TTL. Implement caching layer for frequently accessed recaps to improve performance. Add authentication and rate limiting to protect API endpoints. Create documentation for API usage including request/response formats and error handling.",
            "status": "pending",
            "testStrategy": "Unit tests for individual API endpoints. Load testing to ensure performance under high traffic. Database performance testing for write and read operations. Cache hit ratio analysis. Security testing for authentication and rate limiting. API documentation verification with example requests and responses."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-14T08:16:56.374Z",
      "updated": "2025-08-14T08:16:56.374Z",
      "description": "Unified Sprint 7: Daily Contracts, Anomalies, Recap",
      "copiedFrom": {
        "tag": "feature-live-ops",
        "date": "2025-08-14T08:16:56.374Z"
      }
    }
  },
  "sprint-8-cosmetics-pass": {
    "tasks": [
      {
        "id": 7,
        "title": "Implement Cosmetics and Store System",
        "description": "Create a system for cosmetic entitlements and store UI with local SKUs, ensuring no impact on gameplay balance.",
        "details": "Develop the following components:\n\n1. Cosmetics Catalog:\n- Database schema for cosmetic items\n- Categories, rarity, and visual attributes\n- Preview rendering system\n\n2. Entitlements Service:\n- Player inventory management\n- Entitlement granting/revoking\n- REST API for /entitlements\n\n3. Store Backend:\n- SKU definitions and pricing\n- Rotation and featured items\n- Purchase validation\n- REST API for /store\n\n4. Store UI:\n- Browsable catalog with filtering\n- Item detail views with previews\n- Purchase flow\n- Inventory management\n\nEnsure all cosmetic items are purely visual with no gameplay advantages. Implement proper validation to prevent unauthorized access to entitlements.",
        "testStrategy": "Unit tests for entitlement management and store functionality. Integration tests for the complete purchase flow. Verification tests to ensure entitlement rendering works correctly. Test that cosmetics have no effect on PvP stats as specified in requirements. Security testing for entitlement validation.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop Cosmetics Catalog and Database Schema",
            "description": "Create a comprehensive database schema for cosmetic items with categories, rarity levels, and visual attributes, along with a preview rendering system.",
            "dependencies": [],
            "details": "Implement database tables and relationships for cosmetic items. Define schemas for categories (e.g., outfits, weapons, emotes), rarity levels (common, rare, epic, legendary), and visual attributes. Create a preview rendering system that allows players to see cosmetics before purchase. Ensure proper indexing for efficient queries. Document the schema design and API access patterns.",
            "status": "pending",
            "testStrategy": "Unit tests for database CRUD operations. Integration tests for the preview rendering system. Performance tests for catalog browsing with large numbers of items. Verify that preview rendering works correctly across different cosmetic types."
          },
          {
            "id": 2,
            "title": "Implement Entitlements Service",
            "description": "Build a service to manage player cosmetic inventories with APIs for granting, revoking, and querying entitlements.",
            "dependencies": [
              "7.1"
            ],
            "details": "Develop a RESTful API for /entitlements with endpoints for listing, granting, and revoking cosmetic items. Implement player inventory management with proper validation to prevent unauthorized access. Create database models for tracking ownership history. Ensure proper transaction handling for entitlement operations. Implement caching for frequently accessed inventory data.",
            "status": "pending",
            "testStrategy": "Unit tests for entitlement granting/revoking logic. Security tests to verify authorization controls. Performance tests for inventory queries. Integration tests with the cosmetics catalog to ensure proper item reference integrity."
          },
          {
            "id": 3,
            "title": "Create Store Backend System",
            "description": "Develop the store backend with SKU definitions, pricing, rotation mechanics, and purchase validation.",
            "dependencies": [
              "7.1",
              "7.2"
            ],
            "details": "Implement a store backend with SKU definitions and pricing structure. Create rotation logic for featured items and store sections. Develop purchase validation to prevent fraudulent transactions. Build a RESTful API for /store with endpoints for retrieving available items, featured content, and processing purchases. Implement analytics tracking for store interactions and purchase patterns.",
            "status": "pending",
            "testStrategy": "Unit tests for SKU management and pricing calculations. Integration tests for the complete purchase flow. Security tests for purchase validation. Performance tests for store loading under high traffic. Verify that rotation mechanics work correctly according to configured schedules."
          },
          {
            "id": 4,
            "title": "Design and Implement Store UI",
            "description": "Create a user-friendly store interface with browsable catalog, filtering options, item previews, and purchase flow.",
            "dependencies": [
              "7.3"
            ],
            "details": "Design and implement a browsable store UI with filtering capabilities by category, rarity, and price. Create detailed item view pages with 3D previews of cosmetics. Develop a streamlined purchase flow with confirmation dialogs and feedback. Build inventory management screens for players to view and manage owned items. Ensure responsive design for different screen sizes and platforms.",
            "status": "pending",
            "testStrategy": "UI component tests for store elements. User experience testing for the purchase flow. Cross-browser compatibility tests. A/B testing for different store layouts to optimize conversion. Verify that filtering and sorting options work correctly."
          },
          {
            "id": 5,
            "title": "Implement Validation and Integration Testing",
            "description": "Ensure all cosmetic items have no gameplay impact and integrate the store system with other game components.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.3",
              "7.4"
            ],
            "details": "Implement validation systems to ensure cosmetic items provide no gameplay advantages. Create integration points with other game systems like player profiles and the upcoming Season Pass (Task 8). Develop monitoring tools to track store performance and player engagement. Implement A/B testing framework for store promotions. Create documentation for the entire cosmetics and store system.",
            "status": "pending",
            "testStrategy": "End-to-end tests for the complete store and cosmetics system. Verification tests to confirm cosmetics have no impact on gameplay balance or stats. Integration tests with dependent systems. Load testing to ensure system stability during high-traffic periods like new cosmetic releases."
          }
        ]
      },
      {
        "id": 8,
        "title": "Implement Alliance Season Pass",
        "description": "Create a Season Pass system with cosmetic and QoL tracks, progression tracking, and prestige reset that preserves cosmetics.",
        "details": "Develop the following components:\n\n1. Season Pass Definition:\n- Tiered rewards structure\n- Free and premium tracks\n- Cosmetic and QoL items separation\n\n2. Progression System:\n- XP earning and tracking\n- Level advancement logic\n- Milestone achievements\n\n3. Reward Distribution:\n- Automatic reward granting on level-up\n- Claim UI and notifications\n- Entitlement integration\n\n4. Prestige System:\n- Reset mechanics that preserve cosmetics\n- Prestige benefits and indicators\n- Progress history tracking\n\n5. UI Components:\n- Season pass overview\n- Progress visualization\n- Reward previews\n- Purchase and upgrade options\n\nImplement database schema for season definitions, player progress, and reward status. Create admin tools for season management.",
        "testStrategy": "Unit tests for progression logic and reward distribution. Integration tests for the complete season lifecycle. Verification tests for pass progression as specified in requirements. Test prestige reset to ensure cosmetics are preserved while other elements reset properly.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Season Pass Data Model and Database Schema",
            "description": "Design and implement the database schema for season pass definitions, player progress tracking, and reward status management.",
            "dependencies": [],
            "details": "Create database models for: Season definitions (start/end dates, theme, tiers), Reward tracks (free/premium items at each level), Player progress (XP, current level, purchased status), and Reward status (claimed/unclaimed items). Implement data access layer with CRUD operations. Create admin tools for season configuration and management.",
            "status": "pending",
            "testStrategy": "Unit tests for data model integrity and CRUD operations. Integration tests for database transactions and constraints. Verify proper relationships between season definitions, player progress, and rewards."
          },
          {
            "id": 2,
            "title": "Develop Progression and XP System",
            "description": "Implement the core progression system including XP earning, level advancement logic, and milestone achievements.",
            "dependencies": [
              "8.1"
            ],
            "details": "Create XP calculation algorithms for various player activities. Implement level thresholds and advancement triggers. Design milestone achievement system with event listeners. Build progression tracking service with caching for performance. Develop API endpoints for querying player progress and XP history.",
            "status": "pending",
            "testStrategy": "Unit tests for XP calculations and level advancement logic. Integration tests for the complete progression flow. Performance tests to ensure system handles concurrent XP updates efficiently."
          },
          {
            "id": 3,
            "title": "Build Reward Distribution System",
            "description": "Create the system for automatic reward granting, claim processing, and entitlement integration.",
            "dependencies": [
              "8.1",
              "8.2"
            ],
            "details": "Implement automatic reward triggers on level-up events. Create claim processing service with idempotency guarantees. Develop entitlement integration for adding items to player inventory. Build notification system for new rewards. Implement reward history and status tracking.",
            "status": "pending",
            "testStrategy": "Unit tests for reward distribution logic and entitlement integration. Integration tests for the complete reward flow from earning to claiming. Verification tests to ensure proper reward delivery based on season pass level."
          },
          {
            "id": 4,
            "title": "Implement Prestige System",
            "description": "Develop the prestige reset mechanics that preserve cosmetic rewards while resetting progression.",
            "dependencies": [
              "8.2",
              "8.3"
            ],
            "details": "Create prestige reset logic that preserves cosmetic items but resets progression. Implement prestige benefits (e.g., badges, titles, special rewards). Design progress history tracking across multiple prestige cycles. Build prestige level indicators and UI hooks. Develop migration strategy for existing players entering prestige.",
            "status": "pending",
            "testStrategy": "Unit tests for prestige reset logic and cosmetic preservation. Integration tests for complete prestige cycle. Verification tests to confirm cosmetics are preserved while progression resets properly."
          },
          {
            "id": 5,
            "title": "Develop Season Pass UI Components",
            "description": "Create the user interface components for the season pass including progress visualization, reward previews, and purchase options.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.4"
            ],
            "details": "Design and implement season pass overview screen with tier visualization. Create progress bar and level indicators. Build reward preview cards with item details. Implement purchase and upgrade UI with payment integration. Develop claim buttons and notifications. Create prestige UI elements and indicators.",
            "status": "pending",
            "testStrategy": "UI component tests for rendering and interaction. Integration tests with backend services. Usability tests to ensure clear progression visualization and intuitive reward claiming. Cross-browser and responsive design testing."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-14T08:16:57.660Z",
      "updated": "2025-08-14T08:16:57.660Z",
      "description": "Unified Sprint 8: Cosmetics & Store + Alliance Season Pass",
      "copiedFrom": {
        "tag": "feature-live-ops",
        "date": "2025-08-14T08:16:57.660Z"
      }
    }
  },
  "sprint-9-cost-telemetry": {
    "tasks": [
      {
        "id": 9,
        "title": "Implement Cost Telemetry System",
        "description": "Create a telemetry system to track per-turn token counts, STT/TTS seconds, image requests, and generate session-level projections.",
        "details": "Develop the following components:\n\n1. Telemetry Collectors:\n- Token counter for LLM interactions\n- STT/TTS usage timer\n- Image request tracker\n- API call counter\n\n2. Aggregation Service:\n- Real-time metrics collection\n- Session-level aggregation\n- Cost projection algorithms\n\n3. Reporting API:\n- REST endpoints for cost metrics\n- Filtering and time range selection\n- Export functionality\n\n4. Admin Dashboard:\n- Cost visualization by session/user/feature\n- Trend analysis\n- Anomaly detection\n\nImplement efficient storage for high-volume telemetry data. Use time-series database for optimal query performance. Create alerting system for cost anomalies.",
        "testStrategy": "Unit tests for individual collectors and aggregation logic. Integration tests with mock services. Verification tests to ensure counters match provider logs within ±10% as specified in requirements. Performance testing under high load conditions.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Telemetry Collectors",
            "description": "Develop the core telemetry collectors for tracking token counts, STT/TTS usage, image requests, and API calls.",
            "dependencies": [],
            "details": "Create modular collectors that can be integrated at service boundaries to track: 1) Token counter for LLM interactions with input/output token separation, 2) STT/TTS usage timer with millisecond precision, 3) Image request tracker with size and type metadata, 4) API call counter with service categorization. Implement efficient buffering to minimize performance impact. Each collector should have standardized interfaces and configurable sampling rates.",
            "status": "pending",
            "testStrategy": "Unit tests for each collector type with mock services. Integration tests with controlled inputs to verify accuracy. Performance tests to ensure minimal overhead (<1% CPU increase). Comparison tests against provider logs to validate accuracy within ±10%."
          },
          {
            "id": 2,
            "title": "Develop Aggregation Service",
            "description": "Create a service to collect, aggregate, and project cost metrics in real-time and at session level.",
            "dependencies": [
              "9.1"
            ],
            "details": "Implement a scalable aggregation service that: 1) Collects metrics from all telemetry collectors in real-time, 2) Performs session-level aggregation with user and feature attribution, 3) Applies cost projection algorithms based on current pricing models, 4) Supports time-series analysis for trend detection. Use a time-series database (e.g., InfluxDB or TimescaleDB) for efficient storage and querying of high-volume telemetry data.",
            "status": "pending",
            "testStrategy": "Unit tests for aggregation logic and cost projections. Load tests with simulated high-volume telemetry data. Verification tests to ensure aggregated metrics match raw collector data. Performance tests for query response times under various data volumes."
          },
          {
            "id": 3,
            "title": "Build Reporting API",
            "description": "Develop REST endpoints for accessing cost metrics with filtering, time range selection, and export functionality.",
            "dependencies": [
              "9.2"
            ],
            "details": "Create a comprehensive API that provides: 1) REST endpoints for retrieving cost metrics at various granularities (session, user, feature), 2) Filtering capabilities by service type, time range, and user segments, 3) Export functionality in multiple formats (JSON, CSV, Excel), 4) Aggregation endpoints for summary statistics. Implement caching for frequently accessed reports and pagination for large result sets.",
            "status": "pending",
            "testStrategy": "Unit tests for each API endpoint. Integration tests for complex queries and export functionality. Performance tests for response times under load. Security tests to ensure proper access controls for cost data."
          },
          {
            "id": 4,
            "title": "Create Admin Dashboard",
            "description": "Develop a visual dashboard for cost visualization, trend analysis, and anomaly detection.",
            "dependencies": [
              "9.3"
            ],
            "details": "Build an interactive admin dashboard with: 1) Cost visualizations by session/user/feature with drill-down capabilities, 2) Trend analysis tools showing usage patterns over time, 3) Anomaly detection with configurable thresholds and alerts, 4) Projection tools for estimating future costs based on current usage. Use responsive design principles and efficient data visualization libraries to handle large datasets.",
            "status": "pending",
            "testStrategy": "Unit tests for dashboard components. Usability tests with admin personas. Performance tests for dashboard rendering with large datasets. Cross-browser compatibility tests. Verification that anomaly detection correctly identifies unusual patterns."
          },
          {
            "id": 5,
            "title": "Implement Alerting System",
            "description": "Create an alerting system for cost anomalies with configurable thresholds and notification channels.",
            "dependencies": [
              "9.2",
              "9.4"
            ],
            "details": "Develop an alerting system that: 1) Monitors cost metrics in real-time against configurable thresholds, 2) Detects unusual patterns or spikes in usage, 3) Sends notifications through multiple channels (email, Slack, SMS), 4) Provides alert management with acknowledgment and resolution tracking. Implement rate limiting to prevent alert storms and support for escalation policies.",
            "status": "pending",
            "testStrategy": "Unit tests for alert trigger logic. Integration tests with notification services. Simulation tests with artificial anomalies to verify detection. Verification tests for alert delivery timing and content. User acceptance testing for alert management workflow."
          }
        ]
      },
      {
        "id": 10,
        "title": "Implement Reign Summary & Leaderboards",
        "description": "Develop deterministic reign summary computation from snapshots/event logs and implement API endpoints for reign summaries and leaderboards with privacy opt-in functionality.",
        "details": "Implement the following components:\n\n1. Reign Summary Computation Engine:\n   - Create a deterministic algorithm to calculate reign metrics from snapshots/event logs\n   - Implement calculations for: tenure_days, crises_resolved, GDPΔ, inflation_avg, approval_avg, wars_won, treaties_signed, reforms_passed\n   - Ensure consistent results regardless of when computation occurs\n   - Add caching mechanism to avoid recalculating unchanged reigns\n\n2. Profile API Endpoint:\n   - Implement GET /profile/:leaderId/reign-summary endpoint\n   - Include authentication and authorization checks\n   - Return comprehensive reign statistics in a structured format\n   - Handle edge cases (incomplete reigns, missing data)\n   - Add appropriate error handling and validation\n\n3. Leaderboards System:\n   - Implement GET /leaderboards/reign endpoint\n   - Create database schema for storing leaderboard data\n   - Develop ranking algorithm based on weighted reign metrics\n   - Implement privacy opt-in mechanism (users must explicitly consent)\n   - Add pagination and filtering options (time period, metric focus)\n\n4. Privacy Controls:\n   - Create user settings for leaderboard participation\n   - Default to opt-out for privacy protection\n   - Store consent status in user profile\n   - Provide clear UI indicators for opt-in status\n\n5. Performance Considerations:\n   - Optimize computation for large datasets\n   - Implement background processing for leaderboard updates\n   - Consider caching strategies for frequently accessed leaderboards\n   - Monitor query performance and optimize as needed\n\n6. Integration with Telemetry:\n   - Track API usage for these endpoints\n   - Monitor computation resource usage\n   - Integrate with the cost telemetry system",
        "testStrategy": "1. Unit Tests:\n   - Test deterministic computation with fixed input datasets\n   - Verify all reign metrics calculate correctly\n   - Test privacy opt-in/opt-out functionality\n   - Validate leaderboard ranking algorithms\n\n2. Integration Tests:\n   - Verify API endpoints return correct data\n   - Test authentication and authorization\n   - Ensure leaderboard updates correctly when new data is added\n   - Validate pagination and filtering\n\n3. Determinism Tests:\n   - Run computation multiple times on same dataset to verify identical results\n   - Test with different execution orders to confirm deterministic behavior\n   - Verify results match after system restarts or deployments\n\n4. Privacy Tests:\n   - Confirm opt-out users don't appear in leaderboards\n   - Verify opt-in status changes are immediately reflected\n   - Test privacy settings persistence\n\n5. Performance Tests:\n   - Benchmark computation time for various dataset sizes\n   - Load test leaderboard API with concurrent requests\n   - Verify caching mechanisms work as expected\n\n6. End-to-End Tests:\n   - Complete flow from reign events to leaderboard display\n   - Verify correct ranking and sorting\n   - Test with real-world data scenarios",
        "status": "pending",
        "dependencies": [
          9
        ],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-08-14T08:16:58.872Z",
      "updated": "2025-08-14T09:09:20.574Z",
      "description": "Unified Sprint 9: Cost Telemetry",
      "copiedFrom": {
        "tag": "feature-live-ops",
        "date": "2025-08-14T08:16:58.872Z"
      }
    }
  },
  "sprint-10-single-player": {
    "tasks": [
      {
        "id": 10,
        "title": "Implement Single Player Mode",
        "description": "Create solo session scaffolding with pause/resume hooks, companion agent runner, and solo DDA presets.",
        "details": "Develop the following components:\n\n1. Solo Session Manager:\n- Session initialization for single player\n- State persistence and retrieval\n- Pause/resume functionality\n\n2. Companion Agent System:\n- AI agent configuration for solo play\n- Agent behavior customization\n- Performance optimization for solo mode\n\n3. Dynamic Difficulty Adjustment (DDA):\n- Solo-specific DDA presets\n- Difficulty scaling based on player performance\n- Configuration interface\n\n4. UI Components:\n- Solo mode selection\n- Pause menu\n- Session controls\n- Companion settings\n\nImplement efficient state management for paused sessions. Optimize agent performance for single-player scenarios.",
        "testStrategy": "Unit tests for session management and pause/resume functionality. Integration tests for the complete solo experience. Run tests TC034-TC035 as specified in the PRD addenda. Performance testing for agent response times in solo mode.",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Solo Session Manager",
            "description": "Create a session manager specifically for single player mode with initialization, state persistence, and pause/resume functionality.",
            "dependencies": [],
            "details": "Develop session initialization logic for single player mode. Implement state persistence and retrieval mechanisms to save and load game progress. Create robust pause/resume functionality that properly suspends and resumes all game systems. Ensure efficient state management for paused sessions with minimal memory overhead. Include session timeout handling and auto-save features.",
            "status": "pending",
            "testStrategy": "Write unit tests for session initialization, state persistence, and pause/resume functionality. Create integration tests to verify proper state management across game systems during pause/resume cycles. Measure memory usage during paused states to ensure efficiency."
          },
          {
            "id": 2,
            "title": "Develop Companion Agent System",
            "description": "Build an AI agent system optimized for solo play with customizable behaviors and performance optimizations.",
            "dependencies": [
              "10.1"
            ],
            "details": "Implement AI agent configuration specifically for solo play scenarios. Create a system for agent behavior customization allowing players to adjust companion behavior. Optimize agent performance for single-player mode by reducing computational overhead. Develop agent response prioritization based on player actions. Include fallback behaviors for edge cases.",
            "status": "pending",
            "testStrategy": "Create unit tests for agent configuration and behavior customization. Perform performance testing to ensure agents respond within acceptable timeframes. Test edge cases to verify fallback behaviors function correctly."
          },
          {
            "id": 3,
            "title": "Implement Solo-Specific DDA System",
            "description": "Create Dynamic Difficulty Adjustment presets and scaling mechanisms specifically for single player mode.",
            "dependencies": [
              "10.1"
            ],
            "details": "Develop solo-specific DDA presets with appropriate challenge levels. Implement difficulty scaling algorithms based on player performance metrics. Create a configuration interface for adjusting DDA parameters. Include real-time difficulty adjustments based on player success/failure rates. Develop persistence for player difficulty profiles across sessions.",
            "status": "pending",
            "testStrategy": "Write unit tests for difficulty scaling algorithms. Create integration tests to verify DDA responds appropriately to player performance. Test persistence of difficulty profiles across multiple game sessions."
          },
          {
            "id": 4,
            "title": "Create Single Player UI Components",
            "description": "Develop UI elements specific to single player mode including mode selection, pause menu, session controls, and companion settings.",
            "dependencies": [
              "10.1",
              "10.2"
            ],
            "details": "Design and implement solo mode selection UI in the main menu. Create a comprehensive pause menu with resume, settings, and exit options. Develop session control UI elements for managing game state. Build companion settings interface for adjusting AI behavior. Ensure all UI elements follow established design patterns and accessibility guidelines.",
            "status": "pending",
            "testStrategy": "Perform UI unit tests to verify component functionality. Conduct usability testing to ensure intuitive navigation. Test accessibility features to ensure compliance with guidelines. Verify UI state consistency during pause/resume cycles."
          },
          {
            "id": 5,
            "title": "Integrate and Optimize Single Player Systems",
            "description": "Connect all single player components and optimize overall performance for the solo experience.",
            "dependencies": [
              "10.1",
              "10.2",
              "10.3",
              "10.4"
            ],
            "details": "Integrate session manager, companion agent system, DDA, and UI components into a cohesive single player experience. Perform end-to-end testing of the complete solo mode workflow. Optimize resource usage for single player scenarios. Implement telemetry to track player engagement with solo features. Create documentation for the single player implementation.",
            "status": "pending",
            "testStrategy": "Run full integration tests for the complete solo experience. Execute tests TC034-TC035 as specified in the PRD addenda. Perform performance testing for agent response times in solo mode. Conduct end-to-end testing of the entire single player experience from launch to exit."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-14T08:17:00.181Z",
      "updated": "2025-08-14T08:17:00.181Z",
      "description": "Unified Sprint 10: Single Player Mode",
      "copiedFrom": {
        "tag": "feature-live-ops",
        "date": "2025-08-14T08:17:00.181Z"
      }
    }
  },
  "sprint-11-sim-advanced": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Core Simulation Engine",
        "description": "Create the core simulation engine that advances campaign state on a fixed tick with deterministic behavior.",
        "details": "Create src/server/sim/engine.ts with step({campaignId, seed, actions[]}) function that processes game state in a deterministic manner.\n\nImplementation details:\n1. Use a seeded PRNG (like seedrandom library) to ensure deterministic outcomes\n2. Implement the reducer pipeline in the specified order: production -> queues -> logistics cap -> prices -> readiness/science proxies -> apply policy/tax modifiers -> KPIs + Vezies\n3. Ensure all operations are idempotent and wrapped in a database transaction\n4. Create helper functions for each reducer step\n5. Persist KPI snapshots to kpi_snapshots table\n6. Emit Vezies events for queue completion and new planet discoveries\n\nExample code structure:\n```typescript\nimport { seedrandom } from 'seedrandom';\n\nexport async function step({ campaignId, seed, actions = [] }) {\n  // Initialize PRNG with seed\n  const rng = seedrandom(seed);\n  \n  // Start transaction\n  return db.transaction(async (tx) => {\n    // Load campaign state\n    const state = await loadCampaignState(campaignId, tx);\n    \n    // Apply pending actions\n    const stateWithActions = applyPendingActions(state, actions);\n    \n    // Run reducers in sequence\n    const afterProduction = productionReducer(stateWithActions, rng);\n    const afterQueues = queueReducer(afterProduction, rng);\n    const afterLogistics = logisticsReducer(afterQueues, rng);\n    const afterPrices = priceReducer(afterLogistics, rng);\n    const afterProxies = readinessAndScienceReducer(afterPrices, rng);\n    const afterPolicies = policyModifierReducer(afterProxies, rng);\n    const finalState = kpiAndVeziesReducer(afterPolicies, rng);\n    \n    // Persist state changes and KPI snapshots\n    await persistStateChanges(finalState, tx);\n    await persistKpiSnapshot(campaignId, finalState.kpis, tx);\n    \n    // Emit Vezies events\n    await emitVeziesEvents(finalState.veziesEvents, tx);\n    \n    return finalState;\n  });\n}\n```",
        "testStrategy": "1. Unit tests for each reducer function to verify correct behavior with controlled inputs\n2. Integration test for the step function to ensure all reducers are called in the correct order\n3. API test for POST /api/sim/step endpoint to verify 200 response and KPI snapshot creation\n4. Determinism test: verify that the same seed and inputs always produce identical outputs\n5. Transaction test: verify that failed steps don't persist partial state changes",
        "priority": "high",
        "dependencies": [],
        "status": "in-progress",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up the simulation engine structure",
            "description": "Create the basic structure for the simulation engine including the main step function and PRNG initialization",
            "dependencies": [],
            "details": "Create src/server/sim/engine.ts with the step function that accepts campaignId, seed, and actions parameters. Set up the seeded PRNG using the seedrandom library. Implement the transaction wrapper and state loading functions. Create skeleton functions for each reducer step that will be implemented in subsequent tasks.",
            "status": "in-progress",
            "testStrategy": "Write unit tests to verify the PRNG initialization with different seeds produces consistent results. Test the transaction wrapper to ensure proper error handling and rollback functionality."
          },
          {
            "id": 2,
            "title": "Implement production and queue reducers",
            "description": "Create the first two reducers in the pipeline: production and queue processing",
            "dependencies": [],
            "details": "Implement the productionReducer function that calculates resource production based on current state. Create the queueReducer function that processes building and research queues, advancing progress and completing items when finished. Both reducers should use the seeded RNG for any random operations to ensure deterministic behavior.",
            "status": "pending",
            "testStrategy": "Create unit tests with mock campaign states to verify production calculations are correct. Test queue processing with various queue states to ensure items complete at the expected time and trigger appropriate state changes."
          },
          {
            "id": 3,
            "title": "Implement logistics, price, and proxy reducers",
            "description": "Create the middle reducers in the pipeline: logistics capacity, price adjustments, and readiness/science proxies",
            "dependencies": [],
            "details": "Implement the logisticsReducer to calculate and enforce logistics capacity limits. Create the priceReducer to adjust resource prices based on supply and demand. Develop the readinessAndScienceReducer to calculate military readiness and science progress proxies based on current state.",
            "status": "pending",
            "testStrategy": "Test logistics capacity enforcement with states that exceed capacity. Verify price adjustments respond correctly to different supply/demand scenarios. Ensure readiness and science calculations properly reflect the current game state."
          },
          {
            "id": 4,
            "title": "Implement policy modifiers and KPI/Vezies reducers",
            "description": "Create the final reducers in the pipeline: policy/tax modifiers and KPI/Vezies calculations",
            "dependencies": [],
            "details": "Implement the policyModifierReducer to apply active policy and tax effects to the game state. Create the kpiAndVeziesReducer to calculate key performance indicators and generate Vezies events. Ensure all KPI data is properly formatted for storage in the kpi_snapshots table.",
            "status": "pending",
            "testStrategy": "Test policy modifier application with various policy configurations. Verify KPI calculations match expected values for given states. Test Vezies event generation for queue completions and planet discoveries."
          },
          {
            "id": 5,
            "title": "Implement state persistence and event emission",
            "description": "Create functions to persist state changes, KPI snapshots, and emit Vezies events",
            "dependencies": [],
            "details": "Implement the persistStateChanges function to save the updated game state to the database. Create the persistKpiSnapshot function to store KPI data in the kpi_snapshots table. Develop the emitVeziesEvents function to process and emit events generated during simulation. Ensure all operations are idempotent and properly handled within the database transaction.",
            "status": "pending",
            "testStrategy": "Test state persistence with various state changes to verify correct database updates. Verify KPI snapshots are properly stored with correct timestamps and values. Test event emission to ensure events are properly formatted and delivered."
          }
        ]
      },
      {
        "id": 2,
        "title": "Create Simulation API Endpoint",
        "description": "Implement the API endpoint for triggering simulation steps and retrieving simulation results.",
        "details": "Create a new API endpoint at POST /api/sim/step that triggers the simulation engine to advance the game state by one tick.\n\nImplementation details:\n1. Create a new route handler in the API routes directory\n2. Accept campaignId and optional seed parameter (generate one if not provided)\n3. Call the engine.step() function with the provided parameters\n4. Return the updated KPI snapshot and any Vezies events\n5. Include appropriate error handling and validation\n6. Mark as dev-only in production environments\n\nExample implementation:\n```typescript\n// src/pages/api/sim/step.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { step } from '@/server/sim/engine';\nimport { generateSeed } from '@/utils/random';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (process.env.NODE_ENV === 'production' && !process.env.ENABLE_DEV_ENDPOINTS) {\n    return res.status(403).json({ error: 'Endpoint disabled in production' });\n  }\n\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  try {\n    const { campaignId, seed = generateSeed(), actions = [] } = req.body;\n    \n    if (!campaignId) {\n      return res.status(400).json({ error: 'campaignId is required' });\n    }\n    \n    const result = await step({ campaignId, seed, actions });\n    \n    return res.status(200).json({\n      success: true,\n      seed,\n      kpiSnapshot: result.kpiSnapshot,\n      veziesEvents: result.veziesEvents\n    });\n  } catch (error) {\n    console.error('Simulation step error:', error);\n    return res.status(500).json({ error: 'Failed to process simulation step' });\n  }\n}\n```",
        "testStrategy": "1. API test to verify the endpoint returns 200 with valid inputs\n2. Test that the endpoint rejects non-POST methods with 405\n3. Test that the endpoint requires campaignId parameter\n4. Test that the endpoint is disabled in production unless explicitly enabled\n5. Verify that the response contains the expected KPI snapshot and Vezies events",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create API route handler file structure",
            "description": "Set up the basic file structure for the simulation API endpoint in the API routes directory",
            "dependencies": [],
            "details": "Create the file src/pages/api/sim/step.ts with the basic Next.js API route handler structure. Import necessary types and dependencies including NextApiRequest, NextApiResponse, and the simulation engine. Set up the handler function with proper method checking for POST requests.",
            "status": "pending",
            "testStrategy": "Verify the file structure is correctly set up and imports are working. Test that the endpoint returns 405 for non-POST methods."
          },
          {
            "id": 2,
            "title": "Implement request validation and parameter handling",
            "description": "Add validation for required parameters and handle optional parameters with defaults",
            "dependencies": [
              "2.1"
            ],
            "details": "Extract and validate the campaignId parameter from the request body, ensuring it's required. Implement optional seed parameter handling with fallback to generateSeed() function if not provided. Set up the actions array parameter with a default empty array. Add appropriate error responses for missing required parameters.",
            "status": "pending",
            "testStrategy": "Test that the endpoint requires campaignId parameter and returns 400 if missing. Verify that seed is generated when not provided. Test with various combinations of parameters to ensure proper validation."
          },
          {
            "id": 3,
            "title": "Integrate with simulation engine",
            "description": "Connect the API endpoint to the core simulation engine to process simulation steps",
            "dependencies": [
              "2.2"
            ],
            "details": "Call the engine.step() function with the validated parameters (campaignId, seed, actions). Ensure the function call is properly awaited and wrapped in a try-catch block. Structure the response to include the updated KPI snapshot and Vezies events returned from the engine.",
            "status": "pending",
            "testStrategy": "Test that the endpoint correctly calls the simulation engine with the right parameters. Verify that the response contains the expected data structure with KPI snapshot and Vezies events."
          },
          {
            "id": 4,
            "title": "Implement error handling and logging",
            "description": "Add comprehensive error handling and logging for the API endpoint",
            "dependencies": [
              "2.3"
            ],
            "details": "Implement try-catch block to handle any errors that occur during the simulation step. Log errors with appropriate context information using console.error or a dedicated logging service. Return standardized error responses with appropriate HTTP status codes (400 for client errors, 500 for server errors).",
            "status": "pending",
            "testStrategy": "Test error scenarios by mocking the simulation engine to throw errors. Verify that errors are properly caught, logged, and returned with appropriate status codes. Test with various error types to ensure comprehensive handling."
          },
          {
            "id": 5,
            "title": "Add production environment safeguards",
            "description": "Implement safeguards to disable the endpoint in production unless explicitly enabled",
            "dependencies": [
              "2.1"
            ],
            "details": "Add environment checking logic to disable the endpoint in production environments unless explicitly enabled via ENABLE_DEV_ENDPOINTS environment variable. Return a 403 Forbidden response with an appropriate error message when the endpoint is accessed in production without the flag enabled.",
            "status": "pending",
            "testStrategy": "Test the endpoint behavior in different environments by mocking process.env.NODE_ENV and process.env.ENABLE_DEV_ENDPOINTS. Verify that the endpoint returns 403 in production without the flag and works correctly when the flag is enabled."
          }
        ]
      },
      {
        "id": 3,
        "title": "Implement Policy Storage and Management",
        "description": "Create database schema and API endpoints for storing and managing free-form policies with their associated modifiers.",
        "details": "Implement the storage and management of free-form policies that can be parsed into game modifiers.\n\nImplementation details:\n1. Create database migrations for the policies and policy_modifiers tables:\n```sql\nCREATE TABLE IF NOT EXISTS policies (\n  id SERIAL PRIMARY KEY,\n  title VARCHAR(255) NOT NULL,\n  body TEXT NOT NULL,\n  scope VARCHAR(50) NOT NULL CHECK (scope IN ('campaign', 'region', 'system')),\n  tags JSONB DEFAULT '[]',\n  effective_at TIMESTAMP WITH TIME ZONE,\n  expires_at TIMESTAMP WITH TIME ZONE,\n  author VARCHAR(255),\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS policy_modifiers (\n  id SERIAL PRIMARY KEY,\n  policy_id INTEGER REFERENCES policies(id) ON DELETE CASCADE,\n  key VARCHAR(255) NOT NULL,\n  value NUMERIC NOT NULL,\n  cap_min NUMERIC NOT NULL,\n  cap_max NUMERIC NOT NULL,\n  approved_at TIMESTAMP WITH TIME ZONE,\n  approved_by VARCHAR(255),\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n```\n\n2. Create API endpoints:\n- GET /api/policies - List all policies\n- GET /api/policies/:id - Get a specific policy\n- POST /api/policies - Create a new policy\n- PUT /api/policies/:id - Update a policy\n- DELETE /api/policies/:id - Delete a policy\n- GET /api/policies/active - Get all active policies with approved modifiers\n\n3. Implement database access functions in a repository pattern:\n```typescript\n// src/server/repositories/policyRepository.ts\nexport async function createPolicy(policy) {\n  return db.query(\n    'INSERT INTO policies (title, body, scope, tags, effective_at, expires_at, author) VALUES ($1, $2, $3, $4, $5, $6, $7) RETURNING *',\n    [policy.title, policy.body, policy.scope, JSON.stringify(policy.tags), policy.effective_at, policy.expires_at, policy.author]\n  );\n}\n\nexport async function getActiveModifiers() {\n  const now = new Date();\n  return db.query(\n    `SELECT pm.* FROM policy_modifiers pm\n     JOIN policies p ON pm.policy_id = p.id\n     WHERE pm.approved_at IS NOT NULL\n     AND p.effective_at <= $1\n     AND (p.expires_at IS NULL OR p.expires_at > $1)`,\n    [now]\n  );\n}\n```",
        "testStrategy": "1. Unit tests for database repository functions\n2. API tests for each endpoint to verify CRUD operations\n3. Integration test to verify that active policies are correctly filtered by effective/expiry dates\n4. Test that policy modifiers are correctly associated with policies\n5. Verify that the cap_min and cap_max constraints are enforced",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Database Migrations",
            "description": "Implement database schema for policies and policy_modifiers tables",
            "dependencies": [],
            "details": "Create migration files for the policies table with fields for id, title, body, scope, tags, effective_at, expires_at, author, and created_at. Create migration files for the policy_modifiers table with fields for id, policy_id (foreign key to policies), key, value, cap_min, cap_max, approved_at, approved_by, and created_at. Ensure proper constraints are set including the scope CHECK constraint.",
            "status": "pending",
            "testStrategy": "Verify migrations run successfully and create tables with correct schema. Test constraints by attempting to insert invalid data. Verify foreign key relationships work correctly."
          },
          {
            "id": 2,
            "title": "Implement Policy Repository Functions",
            "description": "Create database access functions using repository pattern for policy operations",
            "dependencies": [
              "3.1"
            ],
            "details": "Implement repository functions for CRUD operations on policies and policy_modifiers: createPolicy, getPolicy, updatePolicy, deletePolicy, listPolicies, createPolicyModifier, getActivePolicies, and getActiveModifiers. Ensure proper error handling and transaction management for operations that affect multiple tables.",
            "status": "pending",
            "testStrategy": "Unit test each repository function with mock database responses. Test edge cases like non-existent records, duplicate entries, and constraint violations. Verify active policies are correctly filtered by dates."
          },
          {
            "id": 3,
            "title": "Create API Endpoints for Policy Management",
            "description": "Implement REST API endpoints for policy CRUD operations",
            "dependencies": [
              "3.2"
            ],
            "details": "Create API handlers for GET /api/policies, GET /api/policies/:id, POST /api/policies, PUT /api/policies/:id, and DELETE /api/policies/:id. Implement request validation, error handling, and appropriate HTTP status codes. Ensure endpoints use the repository functions for database access.",
            "status": "pending",
            "testStrategy": "Test each endpoint with valid and invalid requests. Verify correct HTTP status codes and response formats. Test authentication/authorization if applicable. Verify database operations are performed correctly."
          },
          {
            "id": 4,
            "title": "Implement Active Policies Endpoint",
            "description": "Create endpoint to retrieve active policies with approved modifiers",
            "dependencies": [
              "3.3"
            ],
            "details": "Implement GET /api/policies/active endpoint that returns all currently active policies (based on effective_at and expires_at dates) along with their approved modifiers. Filter out policies without approved modifiers and ensure only active policies are returned.",
            "status": "pending",
            "testStrategy": "Test with policies having various effective/expiry dates. Verify only active policies with approved modifiers are returned. Test with empty database and with policies having no approved modifiers."
          },
          {
            "id": 5,
            "title": "Create Policy Validation and Error Handling",
            "description": "Implement validation logic and error handling for policy operations",
            "dependencies": [
              "3.3",
              "3.4"
            ],
            "details": "Create validation functions for policy and policy_modifier objects. Implement proper error handling for all API endpoints. Ensure modifiers are validated against their cap_min and cap_max values. Create custom error types and consistent error response format across all endpoints.",
            "status": "pending",
            "testStrategy": "Test validation with valid and invalid policy data. Verify error responses have consistent format and appropriate HTTP status codes. Test boundary conditions for modifier caps. Verify validation catches all required fields and format issues."
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement AI Policy Parser",
        "description": "Create an AI-powered endpoint that parses free-form policy text and suggests appropriate game modifiers within capped ranges.",
        "details": "Implement an AI service that analyzes policy text and suggests appropriate modifiers within the specified caps.\n\nImplementation details:\n1. Create a new endpoint POST /api/policies/parse that accepts policy text and returns suggested modifiers\n2. Integrate with an AI service (OpenAI API or similar) to analyze the policy text\n3. Ensure suggested modifiers are within the capped ranges specified in the PRD:\n   - Production: uptime_mult (0.8–1.1), throughput_mult (0.8–1.1)\n   - Logistics: capacity_mult (0.8–1.2), risk_delta (−0.1–0.1)\n   - Prices: tariff_delta (−0.1–0.2), subsidy_delta (−0.15–0.15)\n   - Science: velocity_mult (0.8–1.2)\n   - Military: readiness_mult (0.9–1.1)\n4. Implement a fallback mechanism for when AI is disabled\n\nExample implementation:\n```typescript\n// src/pages/api/policies/parse.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { Configuration, OpenAIApi } from 'openai';\n\nconst MODIFIER_CAPS = {\n  uptime_mult: { min: 0.8, max: 1.1 },\n  throughput_mult: { min: 0.8, max: 1.1 },\n  capacity_mult: { min: 0.8, max: 1.2 },\n  risk_delta: { min: -0.1, max: 0.1 },\n  tariff_delta: { min: -0.1, max: 0.2 },\n  subsidy_delta: { min: -0.15, max: 0.15 },\n  velocity_mult: { min: 0.8, max: 1.2 },\n  readiness_mult: { min: 0.9, max: 1.1 }\n};\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  const { title, body, scope } = req.body;\n  \n  if (!title || !body) {\n    return res.status(400).json({ error: 'Title and body are required' });\n  }\n\n  try {\n    // If AI is disabled, return template suggestions\n    if (!process.env.OPENAI_API_KEY) {\n      return res.status(200).json({\n        suggestedModifiers: [\n          { key: 'uptime_mult', value: 1.05, cap_min: 0.8, cap_max: 1.1 },\n          { key: 'tariff_delta', value: 0.05, cap_min: -0.1, cap_max: 0.2 }\n        ]\n      });\n    }\n\n    // Initialize OpenAI\n    const configuration = new Configuration({\n      apiKey: process.env.OPENAI_API_KEY,\n    });\n    const openai = new OpenAIApi(configuration);\n\n    // Prepare prompt for the AI\n    const prompt = `Analyze this policy and suggest appropriate modifiers within the specified ranges:\\n\\nTitle: ${title}\\nBody: ${body}\\nScope: ${scope}\\n\\nAvailable modifiers and their ranges:\\n${JSON.stringify(MODIFIER_CAPS, null, 2)}\\n\\nReturn only the modifiers that are relevant to this policy, with values within the specified ranges.`;\n\n    // Call OpenAI API\n    const completion = await openai.createCompletion({\n      model: \"text-davinci-003\",\n      prompt,\n      max_tokens: 500,\n    });\n\n    // Parse the AI response and validate modifiers\n    const aiSuggestions = JSON.parse(completion.data.choices[0].text);\n    const validatedModifiers = aiSuggestions.map(mod => ({\n      key: mod.key,\n      value: Math.max(MODIFIER_CAPS[mod.key].min, Math.min(mod.value, MODIFIER_CAPS[mod.key].max)),\n      cap_min: MODIFIER_CAPS[mod.key].min,\n      cap_max: MODIFIER_CAPS[mod.key].max\n    }));\n\n    return res.status(200).json({ suggestedModifiers: validatedModifiers });\n  } catch (error) {\n    console.error('Policy parsing error:', error);\n    return res.status(500).json({ error: 'Failed to parse policy' });\n  }\n}\n```",
        "testStrategy": "1. Unit test the modifier validation logic to ensure values are capped correctly\n2. Mock the AI service response for testing\n3. Test the endpoint with various policy texts and verify the suggested modifiers\n4. Test the fallback mechanism when AI is disabled\n5. Verify that the endpoint rejects requests with missing title or body",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create API Endpoint Structure",
            "description": "Set up the basic structure for the POST /api/policies/parse endpoint that will accept policy text and return suggested modifiers.",
            "dependencies": [],
            "details": "Create the API endpoint file structure in src/pages/api/policies/parse.ts. Implement request validation for required fields (title, body). Set up error handling for invalid requests and server errors. Define the response structure for suggested modifiers that includes key, value, cap_min, and cap_max properties.",
            "status": "pending",
            "testStrategy": "Test endpoint with valid and invalid requests. Verify proper HTTP status codes are returned. Ensure the endpoint rejects non-POST methods with 405 status code. Test validation logic for required fields."
          },
          {
            "id": 2,
            "title": "Define Modifier Caps and Validation Logic",
            "description": "Implement the validation logic to ensure all suggested modifiers are within the specified capped ranges.",
            "dependencies": [
              "4.1"
            ],
            "details": "Create a MODIFIER_CAPS constant that defines the min/max values for each modifier type according to the PRD. Implement a validation function that ensures suggested modifier values are capped within their allowed ranges. The validation should handle all modifier types: production (uptime_mult, throughput_mult), logistics (capacity_mult, risk_delta), prices (tariff_delta, subsidy_delta), science (velocity_mult), and military (readiness_mult).",
            "status": "pending",
            "testStrategy": "Unit test the validation logic with values above, below, and at the cap limits. Verify that values outside the range are properly capped. Test with all modifier types to ensure complete coverage."
          },
          {
            "id": 3,
            "title": "Integrate OpenAI API",
            "description": "Set up the integration with OpenAI API to analyze policy text and suggest appropriate modifiers.",
            "dependencies": [
              "4.1",
              "4.2"
            ],
            "details": "Install and configure the OpenAI SDK. Create a prompt template that effectively communicates the policy analysis task to the AI. Implement the API call to OpenAI with appropriate model selection and parameters. Parse the AI response and convert it to the expected modifier format. Implement error handling for API failures and response parsing issues.",
            "status": "pending",
            "testStrategy": "Mock the OpenAI API responses for testing. Test with various policy texts to verify prompt effectiveness. Verify error handling when the API returns unexpected responses or fails."
          },
          {
            "id": 4,
            "title": "Implement Fallback Mechanism",
            "description": "Create a fallback mechanism that provides default modifier suggestions when AI integration is disabled or unavailable.",
            "dependencies": [
              "4.2"
            ],
            "details": "Implement logic to detect when the OpenAI API key is not available or when the AI service fails. Create a function that generates reasonable default modifier suggestions based on the policy scope. Ensure the fallback suggestions are also within the capped ranges. The fallback should provide at least 2-3 relevant modifiers to give users a starting point.",
            "status": "pending",
            "testStrategy": "Test the fallback mechanism by intentionally disabling the AI integration. Verify that default suggestions are provided and are within the capped ranges. Test with different policy scopes to ensure appropriate defaults are generated."
          },
          {
            "id": 5,
            "title": "Add Environment Configuration and Documentation",
            "description": "Set up environment variables for API keys and add comprehensive documentation for the endpoint.",
            "dependencies": [
              "4.1",
              "4.3",
              "4.4"
            ],
            "details": "Configure environment variables for the OpenAI API key. Add detailed comments explaining the endpoint functionality, expected request/response formats, and the AI integration. Create a README section for the policy parser API with usage examples. Implement logging for debugging and monitoring purposes. Add type definitions for all request and response objects.",
            "status": "pending",
            "testStrategy": "Verify that the endpoint works correctly with and without environment variables set. Review documentation for completeness and accuracy. Test logging functionality to ensure important events are properly recorded."
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement Policy Activation Endpoint",
        "description": "Create an endpoint for approving and activating policy modifiers that will be applied by the simulation engine.",
        "details": "Implement an endpoint to approve and activate policy modifiers that will affect the simulation.\n\nImplementation details:\n1. Create a new endpoint POST /api/policies/activate that accepts policy ID and approved modifiers\n2. Update the policy_modifiers table to mark modifiers as approved\n3. Ensure modifiers are within the capped ranges before approval\n4. Add authentication/authorization checks\n\nExample implementation:\n```typescript\n// src/pages/api/policies/activate.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { getSession } from 'next-auth/react';\nimport { updatePolicyModifiers } from '@/server/repositories/policyRepository';\n\nconst MODIFIER_CAPS = {\n  uptime_mult: { min: 0.8, max: 1.1 },\n  throughput_mult: { min: 0.8, max: 1.1 },\n  capacity_mult: { min: 0.8, max: 1.2 },\n  risk_delta: { min: -0.1, max: 0.1 },\n  tariff_delta: { min: -0.1, max: 0.2 },\n  subsidy_delta: { min: -0.15, max: 0.15 },\n  velocity_mult: { min: 0.8, max: 1.2 },\n  readiness_mult: { min: 0.9, max: 1.1 }\n};\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  // Get user session for authorization\n  const session = await getSession({ req });\n  if (!session) {\n    return res.status(401).json({ error: 'Unauthorized' });\n  }\n\n  const { policyId, modifiers } = req.body;\n  \n  if (!policyId || !modifiers || !Array.isArray(modifiers)) {\n    return res.status(400).json({ error: 'Policy ID and modifiers array are required' });\n  }\n\n  try {\n    // Validate modifiers are within caps\n    const validatedModifiers = modifiers.map(mod => {\n      const caps = MODIFIER_CAPS[mod.key];\n      if (!caps) {\n        throw new Error(`Invalid modifier key: ${mod.key}`);\n      }\n      \n      const value = Math.max(caps.min, Math.min(mod.value, caps.max));\n      \n      return {\n        policy_id: policyId,\n        key: mod.key,\n        value,\n        cap_min: caps.min,\n        cap_max: caps.max,\n        approved_at: new Date(),\n        approved_by: session.user.email\n      };\n    });\n\n    // Update or insert approved modifiers\n    await updatePolicyModifiers(policyId, validatedModifiers);\n\n    return res.status(200).json({\n      success: true,\n      message: 'Policy modifiers activated successfully',\n      modifiers: validatedModifiers\n    });\n  } catch (error) {\n    console.error('Policy activation error:', error);\n    return res.status(500).json({ error: 'Failed to activate policy modifiers' });\n  }\n}\n```",
        "testStrategy": "1. Test that the endpoint correctly validates and caps modifier values\n2. Verify that unauthorized users cannot activate modifiers\n3. Test that modifiers are correctly stored in the database with approval timestamp\n4. Verify that the endpoint rejects invalid modifier keys\n5. Integration test to ensure activated modifiers are applied in the next simulation step",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create API endpoint structure",
            "description": "Set up the basic structure for the POST /api/policies/activate endpoint that will handle policy activation requests.",
            "dependencies": [],
            "details": "Create the endpoint file at src/pages/api/policies/activate.ts. Implement the basic request handler with method validation (POST only). Set up the request body type definition for policyId and modifiers array. Add error handling structure and response formatting.",
            "status": "pending",
            "testStrategy": "Test that the endpoint rejects non-POST methods with 405 status code. Verify the endpoint structure handles basic error cases correctly."
          },
          {
            "id": 2,
            "title": "Implement authentication and authorization",
            "description": "Add user authentication checks to ensure only authorized users can activate policy modifiers.",
            "dependencies": [
              "5.1"
            ],
            "details": "Integrate NextAuth session validation to verify user is logged in. Add authorization logic to check if the user has permission to activate policies. Return appropriate 401 Unauthorized responses for unauthenticated requests.",
            "status": "pending",
            "testStrategy": "Test that unauthenticated requests are rejected with 401 status code. Verify that users with different permission levels are handled correctly."
          },
          {
            "id": 3,
            "title": "Implement modifier validation and capping",
            "description": "Create logic to validate incoming modifiers and ensure they are within the specified capped ranges.",
            "dependencies": [
              "5.1"
            ],
            "details": "Define the MODIFIER_CAPS constant with min/max values for each modifier type. Implement validation logic to check that all submitted modifiers have valid keys. Create capping logic to ensure modifier values are within allowed ranges. Handle validation errors with appropriate error messages.",
            "status": "pending",
            "testStrategy": "Test validation with various modifier values both within and outside allowed ranges. Verify that invalid modifier keys are rejected. Confirm that values outside caps are properly adjusted to the min/max bounds."
          },
          {
            "id": 4,
            "title": "Implement database update functionality",
            "description": "Create the functionality to update the policy_modifiers table with approved modifiers.",
            "dependencies": [
              "5.2",
              "5.3"
            ],
            "details": "Import or implement the updatePolicyModifiers repository function. Add logic to format validated modifiers with approval metadata (timestamp, approver). Ensure proper error handling for database operations. Return appropriate success/error responses based on database operation results.",
            "status": "pending",
            "testStrategy": "Test that modifiers are correctly stored in the database with approval timestamp and approver information. Verify error handling for database failures. Test with various valid modifier combinations."
          },
          {
            "id": 5,
            "title": "Integration testing and documentation",
            "description": "Perform integration testing of the complete endpoint and add documentation for API consumers.",
            "dependencies": [
              "5.4"
            ],
            "details": "Create comprehensive integration tests covering the full endpoint functionality. Add JSDoc comments to document the endpoint's purpose, parameters, and responses. Create example requests and responses for documentation. Ensure the endpoint works correctly with the simulation engine by testing end-to-end flows.",
            "status": "pending",
            "testStrategy": "Perform end-to-end testing with the simulation engine to verify that activated modifiers are correctly applied. Test edge cases like concurrent modifications to the same policy. Document all test scenarios and expected behaviors."
          }
        ]
      },
      {
        "id": 6,
        "title": "Implement AI Advisors System",
        "description": "Create AI advisors for different domains that can provide recommendations and propose actions based on the current game state.",
        "details": "Implement a system of AI advisors that can provide domain-specific recommendations and propose actions.\n\nImplementation details:\n1. Create database migration for the pending_actions table:\n```sql\nCREATE TABLE IF NOT EXISTS pending_actions (\n  id SERIAL PRIMARY KEY,\n  domain VARCHAR(50) NOT NULL CHECK (domain IN ('economy', 'military', 'science', 'logistics', 'governance', 'diplomacy')),\n  payload JSONB NOT NULL,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  approved_at TIMESTAMP WITH TIME ZONE,\n  executed_at TIMESTAMP WITH TIME ZONE\n);\n```\n\n2. Implement advisor endpoints:\n- POST /api/advisors/:domain/query - Ask a question to an advisor\n- POST /api/advisors/:domain/propose - Propose an action for approval\n\n3. Create advisor service with domain-specific logic:\n```typescript\n// src/server/services/advisorService.ts\nimport { Configuration, OpenAIApi } from 'openai';\nimport { getCampaignState } from '@/server/repositories/campaignRepository';\nimport { createPendingAction } from '@/server/repositories/actionRepository';\n\nconst DOMAINS = ['economy', 'military', 'science', 'logistics', 'governance', 'diplomacy'];\n\nexport async function queryAdvisor(domain, campaignId, question) {\n  if (!DOMAINS.includes(domain)) {\n    throw new Error(`Invalid advisor domain: ${domain}`);\n  }\n  \n  // Get current campaign state for context\n  const state = await getCampaignState(campaignId);\n  \n  // If AI is disabled, return template recommendations\n  if (!process.env.OPENAI_API_KEY) {\n    return getTemplateRecommendations(domain, state);\n  }\n  \n  // Initialize OpenAI\n  const configuration = new Configuration({\n    apiKey: process.env.OPENAI_API_KEY,\n  });\n  const openai = new OpenAIApi(configuration);\n  \n  // Prepare domain-specific context\n  const context = getDomainContext(domain, state);\n  \n  // Call OpenAI API\n  const completion = await openai.createCompletion({\n    model: \"text-davinci-003\",\n    prompt: `You are a ${domain} advisor in a space strategy game. The current state is:\\n${JSON.stringify(context, null, 2)}\\n\\nQuestion: ${question}\\n\\nProvide 3 specific recommendations with projected impact on KPIs.`,\n    max_tokens: 500,\n  });\n  \n  // Parse and structure the response\n  const aiResponse = completion.data.choices[0].text;\n  const recommendations = parseRecommendations(aiResponse);\n  \n  return {\n    recommendations,\n    projectedImpact: calculateProjectedImpact(recommendations, state)\n  };\n}\n\nexport async function proposeAction(domain, campaignId, action) {\n  if (!DOMAINS.includes(domain)) {\n    throw new Error(`Invalid advisor domain: ${domain}`);\n  }\n  \n  // Validate the action is appropriate for the domain\n  validateDomainAction(domain, action);\n  \n  // Create a pending action\n  const pendingAction = await createPendingAction({\n    domain,\n    payload: action\n  });\n  \n  return {\n    success: true,\n    pendingActionId: pendingAction.id,\n    message: `Action proposed and pending approval`\n  };\n}\n\n// Helper functions for template responses, context preparation, etc.\n```",
        "testStrategy": "1. Unit tests for each advisor domain to verify recommendation logic\n2. Test the query endpoint with various questions and verify the response format\n3. Test the propose endpoint and verify that pending actions are correctly stored\n4. Integration test to ensure proposed actions are executed in the next simulation step when approved\n5. Verify that the endpoints handle invalid domains appropriately",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Database Migration for Pending Actions",
            "description": "Implement the database migration script for the pending_actions table that will store proposed actions from AI advisors.",
            "dependencies": [],
            "details": "Create a migration file that implements the pending_actions table with the specified schema including id, domain (with domain validation), payload, created_at, approved_at, and executed_at fields. Ensure proper indexing for efficient querying by domain and status.",
            "status": "pending",
            "testStrategy": "Verify the migration runs successfully and creates the table with correct constraints. Test inserting valid and invalid domain values to confirm the CHECK constraint works properly. Verify timestamp fields default correctly."
          },
          {
            "id": 2,
            "title": "Implement Domain-Specific Advisor Logic",
            "description": "Create the core advisor service with specialized logic for each domain (economy, military, science, logistics, governance, diplomacy).",
            "dependencies": [
              "6.1"
            ],
            "details": "Implement the advisor service with domain-specific context preparation, recommendation generation, and impact calculation functions. Create helper functions for each domain that understand the relevant game state metrics and can provide appropriate recommendations. Include fallback template recommendations when AI is disabled.",
            "status": "pending",
            "testStrategy": "Unit test each domain's recommendation logic with various game states. Verify that recommendations are relevant to the domain. Test the fallback mechanism when OpenAI integration is disabled."
          },
          {
            "id": 3,
            "title": "Implement Advisor API Endpoints",
            "description": "Create the API endpoints for querying advisors and proposing actions based on their recommendations.",
            "dependencies": [
              "6.2"
            ],
            "details": "Implement the POST /api/advisors/:domain/query endpoint for asking questions to domain-specific advisors and POST /api/advisors/:domain/propose for submitting actions for approval. Include proper validation for domain parameters and request payloads. Ensure authentication and rate limiting are implemented.",
            "status": "pending",
            "testStrategy": "Test both endpoints with valid and invalid domains. Verify query responses contain structured recommendations. Test action proposals are correctly stored in the pending_actions table. Verify error handling for invalid requests."
          },
          {
            "id": 4,
            "title": "Implement Action Approval and Execution System",
            "description": "Create the system for reviewing, approving, and executing pending actions proposed by advisors.",
            "dependencies": [
              "6.1",
              "6.3"
            ],
            "details": "Implement endpoints for listing pending actions (GET /api/pending-actions), approving actions (POST /api/pending-actions/:id/approve), and rejecting actions (POST /api/pending-actions/:id/reject). Create a service that executes approved actions by updating the appropriate game state based on the action domain and payload.",
            "status": "pending",
            "testStrategy": "Test the approval workflow from proposal to execution. Verify that approved_at and executed_at timestamps are correctly updated. Test that rejected actions are properly handled. Verify that executed actions correctly modify the game state."
          },
          {
            "id": 5,
            "title": "Implement AI Integration with OpenAI",
            "description": "Integrate the advisor system with OpenAI's API to generate intelligent, context-aware recommendations.",
            "dependencies": [
              "6.2",
              "6.3"
            ],
            "details": "Implement the OpenAI API integration for generating advisor recommendations. Create prompt templates for each domain that include relevant game state context. Implement response parsing to extract structured recommendations from AI completions. Add error handling and retry logic for API failures.",
            "status": "pending",
            "testStrategy": "Test the OpenAI integration with mock responses. Verify that prompts include appropriate context for each domain. Test the parsing logic with various AI responses. Verify graceful degradation when the API is unavailable."
          }
        ]
      },
      {
        "id": 7,
        "title": "Integrate Policy Modifiers with Simulation Engine",
        "description": "Extend the simulation engine to apply active policy modifiers during each step of the simulation.",
        "details": "Modify the simulation engine to read and apply active policy modifiers during each simulation step.\n\nImplementation details:\n1. Update the engine.ts file to load active policy modifiers at the beginning of each step\n2. Implement a policyModifierReducer function that applies the modifiers to the appropriate game state values\n3. Ensure modifiers are applied within their capped ranges\n4. Log all applied modifiers with provenance for reproducibility\n\nExample implementation:\n```typescript\n// src/server/sim/engine.ts - Add to existing file\nimport { getActiveModifiers } from '@/server/repositories/policyRepository';\n\n// Add to step function\nasync function step({ campaignId, seed, actions = [] }) {\n  // ... existing code ...\n  \n  // Load active policy modifiers\n  const activeModifiers = await getActiveModifiers();\n  \n  // ... run reducers ...\n  const afterProxies = readinessAndScienceReducer(afterPrices, rng);\n  const afterPolicies = policyModifierReducer(afterProxies, activeModifiers, rng);\n  const finalState = kpiAndVeziesReducer(afterPolicies, rng);\n  \n  // ... existing code ...\n}\n\n// Policy modifier reducer\nfunction policyModifierReducer(state, modifiers, rng) {\n  const newState = { ...state };\n  const appliedModifiers = [];\n  \n  // Group modifiers by key for easier processing\n  const modifiersByKey = modifiers.reduce((acc, mod) => {\n    if (!acc[mod.key]) acc[mod.key] = [];\n    acc[mod.key].push(mod);\n    return acc;\n  }, {});\n  \n  // Apply production modifiers\n  if (modifiersByKey.uptime_mult) {\n    const uptimeModifier = calculateCombinedModifier(modifiersByKey.uptime_mult);\n    newState.production.uptime *= uptimeModifier;\n    appliedModifiers.push({ key: 'uptime_mult', value: uptimeModifier, source: 'policy' });\n  }\n  \n  if (modifiersByKey.throughput_mult) {\n    const throughputModifier = calculateCombinedModifier(modifiersByKey.throughput_mult);\n    newState.production.throughput *= throughputModifier;\n    appliedModifiers.push({ key: 'throughput_mult', value: throughputModifier, source: 'policy' });\n  }\n  \n  // Apply logistics modifiers\n  if (modifiersByKey.capacity_mult) {\n    const capacityModifier = calculateCombinedModifier(modifiersByKey.capacity_mult);\n    newState.logistics.capacity *= capacityModifier;\n    appliedModifiers.push({ key: 'capacity_mult', value: capacityModifier, source: 'policy' });\n  }\n  \n  if (modifiersByKey.risk_delta) {\n    const riskDelta = calculateCombinedDelta(modifiersByKey.risk_delta);\n    newState.logistics.risk += riskDelta;\n    newState.logistics.risk = Math.max(0, Math.min(1, newState.logistics.risk)); // Clamp between 0 and 1\n    appliedModifiers.push({ key: 'risk_delta', value: riskDelta, source: 'policy' });\n  }\n  \n  // Apply price modifiers\n  // ... similar implementation for other modifier types ...\n  \n  // Log all applied modifiers\n  newState.logs.push({\n    type: 'policy_modifiers',\n    timestamp: new Date(),\n    data: { appliedModifiers }\n  });\n  \n  return newState;\n}\n\n// Helper function to calculate combined multiplicative modifiers\nfunction calculateCombinedModifier(modifiers) {\n  return modifiers.reduce((acc, mod) => acc * mod.value, 1);\n}\n\n// Helper function to calculate combined additive deltas\nfunction calculateCombinedDelta(modifiers) {\n  return modifiers.reduce((acc, mod) => acc + mod.value, 0);\n}\n```",
        "testStrategy": "1. Unit test the policyModifierReducer function with various modifier combinations\n2. Test that modifiers are correctly applied within their capped ranges\n3. Verify that the combined effect of multiple modifiers of the same type is calculated correctly\n4. Test that all applied modifiers are properly logged\n5. Integration test to verify that policies created and activated through the API affect the simulation as expected",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Update engine.ts to load active policy modifiers",
            "description": "Modify the simulation engine to fetch active policy modifiers at the beginning of each simulation step.",
            "dependencies": [],
            "details": "Update the step function in engine.ts to import and call getActiveModifiers from the policy repository. Ensure the modifiers are loaded before any reducers are applied. Add appropriate error handling for cases where modifiers cannot be loaded.",
            "status": "pending",
            "testStrategy": "Test that the engine correctly loads active modifiers at the beginning of each step. Verify error handling when the policy repository is unavailable."
          },
          {
            "id": 2,
            "title": "Implement policyModifierReducer function",
            "description": "Create a reducer function that applies policy modifiers to the appropriate game state values.",
            "dependencies": [
              "7.1"
            ],
            "details": "Implement the policyModifierReducer function that takes the current state, active modifiers, and RNG as inputs. Group modifiers by key for easier processing. Apply modifiers to production, logistics, and other relevant game state properties. Return the modified state.",
            "status": "pending",
            "testStrategy": "Unit test the policyModifierReducer with various modifier combinations. Verify that different types of modifiers (multiplicative, additive) are correctly applied to the appropriate state properties."
          },
          {
            "id": 3,
            "title": "Implement modifier capping and validation",
            "description": "Ensure all applied modifiers are within their defined capped ranges.",
            "dependencies": [
              "7.2"
            ],
            "details": "Add validation to ensure that after modifiers are applied, the affected values remain within their allowed ranges. Implement helper functions like calculateCombinedModifier and calculateCombinedDelta to properly combine multiple modifiers of the same type. Add clamping functions to restrict values to their min/max bounds.",
            "status": "pending",
            "testStrategy": "Test that values are properly clamped when modifiers would push them beyond their allowed ranges. Verify that combined modifiers are calculated correctly when multiple modifiers affect the same property."
          },
          {
            "id": 4,
            "title": "Add logging for applied modifiers",
            "description": "Log all applied policy modifiers with provenance information for reproducibility.",
            "dependencies": [
              "7.2",
              "7.3"
            ],
            "details": "Extend the policyModifierReducer to track all applied modifiers in an appliedModifiers array. For each modifier, record its key, calculated value, and source. Add a new log entry to the state.logs array with type 'policy_modifiers' that includes the timestamp and applied modifiers data.",
            "status": "pending",
            "testStrategy": "Verify that all applied modifiers are correctly logged with their provenance information. Test that the logs contain accurate timestamps and modifier details."
          },
          {
            "id": 5,
            "title": "Integrate policyModifierReducer into the simulation pipeline",
            "description": "Update the simulation pipeline to include the policy modifier reducer between existing reducers.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.3",
              "7.4"
            ],
            "details": "Modify the step function to call the policyModifierReducer at the appropriate point in the simulation pipeline. Position it after the readinessAndScienceReducer and before the kpiAndVeziesReducer. Ensure the modified state is passed correctly to subsequent reducers.",
            "status": "pending",
            "testStrategy": "Integration test the full simulation pipeline to verify that policy modifiers are correctly applied during each step. Test that the effects of policy modifiers are properly reflected in the final state and subsequent calculations."
          }
        ]
      },
      {
        "id": 8,
        "title": "Integrate Advisor Actions with Simulation Engine",
        "description": "Extend the simulation engine to process and apply pending advisor actions during each simulation step.",
        "details": "Modify the simulation engine to process pending advisor actions during each simulation step.\n\nImplementation details:\n1. Update the engine.ts file to load approved pending actions at the beginning of each step\n2. Implement domain-specific action handlers for each advisor domain\n3. Mark actions as executed after they are processed\n4. Log all executed actions with their effects\n\nExample implementation:\n```typescript\n// src/server/sim/engine.ts - Add to existing file\nimport { getApprovedPendingActions, markActionsExecuted } from '@/server/repositories/actionRepository';\n\n// Add to step function\nasync function step({ campaignId, seed, actions = [] }) {\n  // ... existing code ...\n  \n  // Load approved pending actions\n  const pendingActions = await getApprovedPendingActions();\n  \n  // Apply pending actions to initial state\n  const stateWithActions = applyPendingActions(state, [...actions, ...pendingActions]);\n  \n  // ... run reducers ...\n  \n  // Mark pending actions as executed\n  await markActionsExecuted(pendingActions.map(a => a.id));\n  \n  // ... existing code ...\n}\n\n// Function to apply pending actions\nfunction applyPendingActions(state, actions) {\n  const newState = { ...state };\n  const executedActions = [];\n  \n  for (const action of actions) {\n    try {\n      switch (action.domain) {\n        case 'economy':\n          applyEconomyAction(newState, action.payload);\n          break;\n        case 'military':\n          applyMilitaryAction(newState, action.payload);\n          break;\n        case 'science':\n          applyScienceAction(newState, action.payload);\n          break;\n        case 'logistics':\n          applyLogisticsAction(newState, action.payload);\n          break;\n        case 'governance':\n          applyGovernanceAction(newState, action.payload);\n          break;\n        case 'diplomacy':\n          applyDiplomacyAction(newState, action.payload);\n          break;\n        default:\n          throw new Error(`Unknown action domain: ${action.domain}`);\n      }\n      \n      executedActions.push({\n        id: action.id,\n        domain: action.domain,\n        payload: action.payload,\n        status: 'executed'\n      });\n    } catch (error) {\n      console.error(`Failed to apply ${action.domain} action:`, error);\n      executedActions.push({\n        id: action.id,\n        domain: action.domain,\n        payload: action.payload,\n        status: 'failed',\n        error: error.message\n      });\n    }\n  }\n  \n  // Log all executed actions\n  newState.logs.push({\n    type: 'executed_actions',\n    timestamp: new Date(),\n    data: { executedActions }\n  });\n  \n  return newState;\n}\n\n// Domain-specific action handlers\nfunction applyEconomyAction(state, payload) {\n  switch (payload.type) {\n    case 'adjust_tariff':\n      state.economy.tariffRate += payload.delta;\n      state.economy.tariffRate = Math.max(0, Math.min(1, state.economy.tariffRate)); // Clamp between 0 and 1\n      break;\n    case 'adjust_subsidy':\n      state.economy.subsidyRate += payload.delta;\n      state.economy.subsidyRate = Math.max(0, Math.min(1, state.economy.subsidyRate)); // Clamp between 0 and 1\n      break;\n    // ... other economy action types ...\n    default:\n      throw new Error(`Unknown economy action type: ${payload.type}`);\n  }\n}\n\n// ... similar implementations for other domains ...\n```",
        "testStrategy": "1. Unit test each domain-specific action handler\n2. Test the applyPendingActions function with various action combinations\n3. Verify that actions are correctly marked as executed after processing\n4. Test error handling for invalid actions\n5. Integration test to verify that advisor actions proposed and approved through the API affect the simulation as expected",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Update engine.ts to load pending actions",
            "description": "Modify the simulation engine to fetch approved pending actions at the beginning of each step and prepare them for processing.",
            "dependencies": [],
            "details": "Update the engine.ts file to import necessary functions from actionRepository. Add code to the step function to fetch approved pending actions using getApprovedPendingActions(). Combine these pending actions with any explicitly passed actions for processing in the simulation step.",
            "status": "pending",
            "testStrategy": "Unit test the modified step function to verify it correctly fetches and combines pending actions. Mock the repository functions to return predefined test actions."
          },
          {
            "id": 2,
            "title": "Implement applyPendingActions function",
            "description": "Create a function that applies a list of actions to the simulation state and tracks their execution status.",
            "dependencies": [
              "8.1"
            ],
            "details": "Implement the applyPendingActions function that takes the current state and a list of actions. The function should create a copy of the state, process each action based on its domain, and track which actions were executed successfully or failed. Return the updated state with all actions applied.",
            "status": "pending",
            "testStrategy": "Test the function with various combinations of actions across different domains. Verify it properly handles errors for invalid actions without affecting other actions' execution."
          },
          {
            "id": 3,
            "title": "Implement domain-specific action handlers",
            "description": "Create handler functions for each advisor domain that apply domain-specific actions to the simulation state.",
            "dependencies": [
              "8.2"
            ],
            "details": "Implement separate handler functions for each domain (economy, military, science, logistics, governance, diplomacy). Each handler should process different action types within its domain and apply the appropriate changes to the simulation state. Include proper validation and error handling for each action type.",
            "status": "pending",
            "testStrategy": "Unit test each domain handler with various action types and payloads. Verify that state changes are applied correctly and that invalid actions throw appropriate errors."
          },
          {
            "id": 4,
            "title": "Add action execution logging",
            "description": "Extend the simulation state to log all executed actions with their effects and status.",
            "dependencies": [
              "8.2",
              "8.3"
            ],
            "details": "Modify the applyPendingActions function to add entries to the state's logs array for all executed actions. Each log entry should include the action ID, domain, payload, execution status (executed/failed), timestamp, and any error messages for failed actions.",
            "status": "pending",
            "testStrategy": "Test that actions are properly logged in the state with correct timestamps and details. Verify both successful and failed actions are logged appropriately."
          },
          {
            "id": 5,
            "title": "Implement action execution marking",
            "description": "Update the repository to mark actions as executed after they are processed by the simulation engine.",
            "dependencies": [
              "8.2",
              "8.4"
            ],
            "details": "After all actions are applied and logged, call the markActionsExecuted function with the IDs of all processed actions. Update the actionRepository implementation to properly mark these actions as executed in the database with an execution timestamp.",
            "status": "pending",
            "testStrategy": "Test that actions are correctly marked as executed in the database after processing. Verify that subsequent simulation steps don't reprocess already executed actions."
          }
        ]
      },
      {
        "id": 9,
        "title": "Implement KPI and Vezies Integration",
        "description": "Integrate KPI tracking and Vezies scoring into the simulation engine and create endpoints for retrieving analytics data.",
        "details": "Implement KPI tracking and Vezies scoring in the simulation engine and update analytics endpoints to use the engine data.\n\nImplementation details:\n1. Create a kpiAndVeziesReducer function in the engine that calculates KPIs and generates Vezies events\n2. Persist KPI snapshots to the kpi_snapshots table\n3. Generate Vezies events for queue completion, planet creation, and production milestones\n4. Update the GET /api/analytics/empire endpoint to use the latest KPI snapshot from the engine\n\nExample implementation:\n```typescript\n// src/server/sim/engine.ts - Add to existing file\nimport { createKpiSnapshot } from '@/server/repositories/kpiRepository';\nimport { createVezyEvent } from '@/server/repositories/vezyRepository';\n\n// KPI and Vezies reducer\nfunction kpiAndVeziesReducer(state, rng) {\n  const newState = { ...state };\n  const vezyEvents = [];\n  \n  // Calculate KPIs\n  const kpis = calculateKpis(newState);\n  newState.kpis = kpis;\n  \n  // Check for queue completions\n  const completedQueues = findCompletedQueues(state, newState);\n  for (const queue of completedQueues) {\n    vezyEvents.push({\n      type: 'queue_completion',\n      source: 'empire',\n      data: { queueId: queue.id, itemType: queue.itemType }\n    });\n  }\n  \n  // Check for new planets\n  const newPlanets = findNewPlanets(state, newState);\n  for (const planet of newPlanets) {\n    vezyEvents.push({\n      type: 'planet_creation',\n      source: 'discovery',\n      data: { planetId: planet.id, systemId: planet.systemId }\n    });\n  }\n  \n  // Check for production milestones\n  const productionMilestones = findProductionMilestones(state, newState);\n  for (const milestone of productionMilestones) {\n    vezyEvents.push({\n      type: 'production_milestone',\n      source: 'empire',\n      data: { resourceType: milestone.resourceType, amount: milestone.amount }\n    });\n  }\n  \n  newState.vezyEvents = vezyEvents;\n  \n  return newState;\n}\n\n// Helper function to calculate KPIs\nfunction calculateKpis(state) {\n  return {\n    economy: {\n      gdp: calculateGdp(state),\n      resourceBalance: calculateResourceBalance(state),\n      tradeVolume: calculateTradeVolume(state)\n    },\n    military: {\n      fleetStrength: calculateFleetStrength(state),\n      readiness: state.military.readiness\n    },\n    science: {\n      researchOutput: calculateResearchOutput(state),\n      techLevel: state.science.techLevel\n    },\n    logistics: {\n      capacity: state.logistics.capacity,\n      efficiency: calculateLogisticsEfficiency(state)\n    },\n    governance: {\n      stability: calculateStability(state),\n      approval: calculateApproval(state)\n    }\n  };\n}\n\n// Helper functions for finding events and calculating KPIs\n// ...\n\n// Update persistKpiSnapshot function\nasync function persistKpiSnapshot(campaignId, kpis, tx) {\n  return createKpiSnapshot({\n    campaignId,\n    timestamp: new Date(),\n    data: kpis\n  }, tx);\n}\n\n// Function to emit Vezies events\nasync function emitVeziesEvents(events, tx) {\n  for (const event of events) {\n    await createVezyEvent({\n      type: event.type,\n      source: event.source,\n      sourceId: event.data.id || null,\n      data: event.data\n    }, tx);\n  }\n}\n```\n\n// Update analytics endpoint\n```typescript\n// src/pages/api/analytics/empire.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { getLatestKpiSnapshot } from '@/server/repositories/kpiRepository';\nimport { getLegacyAnalytics } from '@/server/services/analyticsService';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'GET') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  const { campaignId } = req.query;\n  \n  if (!campaignId) {\n    return res.status(400).json({ error: 'campaignId is required' });\n  }\n\n  try {\n    // Try to get the latest KPI snapshot from the engine\n    const latestSnapshot = await getLatestKpiSnapshot(campaignId);\n    \n    if (latestSnapshot) {\n      return res.status(200).json({\n        success: true,\n        kpis: latestSnapshot.data,\n        timestamp: latestSnapshot.timestamp,\n        source: 'engine'\n      });\n    }\n    \n    // Fall back to legacy analytics if no snapshot exists\n    const legacyAnalytics = await getLegacyAnalytics(campaignId);\n    \n    return res.status(200).json({\n      success: true,\n      kpis: legacyAnalytics,\n      timestamp: new Date(),\n      source: 'legacy'\n    });\n  } catch (error) {\n    console.error('Analytics error:', error);\n    return res.status(500).json({ error: 'Failed to retrieve analytics' });\n  }\n}\n```",
        "testStrategy": "1. Unit test the kpiAndVeziesReducer function to verify KPI calculations\n2. Test the event generation logic for queue completions, new planets, and production milestones\n3. Verify that KPI snapshots are correctly persisted to the database\n4. Test the GET /api/analytics/empire endpoint to ensure it returns the latest KPI snapshot\n5. Verify that the endpoint falls back to legacy analytics when no snapshot exists",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement kpiAndVeziesReducer function",
            "description": "Create a reducer function in the simulation engine that calculates KPIs and generates Vezies events based on state changes.",
            "dependencies": [],
            "details": "Develop the kpiAndVeziesReducer function that takes the current state and returns a new state with updated KPIs and Vezies events. Implement helper functions for calculating various KPIs (economy, military, science, logistics, governance) and detecting events like queue completions, planet creations, and production milestones.",
            "status": "pending",
            "testStrategy": "Write unit tests to verify KPI calculations for different game states. Test event detection logic for queue completions, new planets, and production milestones. Ensure the reducer properly maintains state immutability."
          },
          {
            "id": 2,
            "title": "Implement KPI snapshot persistence",
            "description": "Create functionality to persist KPI snapshots to the database at regular intervals during simulation.",
            "dependencies": [
              "9.1"
            ],
            "details": "Implement the persistKpiSnapshot function that saves KPI data to the kpi_snapshots table. Ensure this function is called at appropriate intervals during the simulation cycle. Include timestamp and campaign ID with each snapshot. Create necessary database repository functions.",
            "status": "pending",
            "testStrategy": "Test that KPI snapshots are correctly persisted to the database with proper timestamps. Verify that snapshots contain all required KPI metrics. Test error handling for database operations."
          },
          {
            "id": 3,
            "title": "Implement Vezies event generation",
            "description": "Create functionality to generate and persist Vezies events for key game milestones.",
            "dependencies": [
              "9.1"
            ],
            "details": "Implement the emitVeziesEvents function that creates Vezies events in the database. Generate events for queue completions, planet creations, and production milestones. Ensure each event has the correct type, source, and data payload. Create necessary database repository functions for the vezy_events table.",
            "status": "pending",
            "testStrategy": "Test that Vezies events are correctly generated for different game state changes. Verify that events contain the proper metadata and payloads. Test error handling for event persistence."
          },
          {
            "id": 4,
            "title": "Update analytics endpoint",
            "description": "Modify the GET /api/analytics/empire endpoint to use the latest KPI snapshot from the engine.",
            "dependencies": [
              "9.2"
            ],
            "details": "Update the analytics endpoint to retrieve the latest KPI snapshot from the database. Implement fallback to legacy analytics if no snapshot exists. Return the KPI data with timestamp and source information. Add proper error handling and validation for the campaignId parameter.",
            "status": "pending",
            "testStrategy": "Test the endpoint with various scenarios including existing snapshots and fallback to legacy analytics. Verify the response format and error handling. Test with invalid campaign IDs and other edge cases."
          },
          {
            "id": 5,
            "title": "Integrate KPI and Vezies with simulation cycle",
            "description": "Integrate the KPI and Vezies functionality into the main simulation cycle.",
            "dependencies": [
              "9.1",
              "9.2",
              "9.3"
            ],
            "details": "Update the main simulation cycle to include the kpiAndVeziesReducer in the processing pipeline. Ensure KPI snapshots are persisted and Vezies events are emitted at appropriate points in the cycle. Add transaction support to ensure data consistency between the simulation state and persisted data.",
            "status": "pending",
            "testStrategy": "Perform integration testing of the full simulation cycle with KPI and Vezies functionality. Verify that KPIs are calculated and persisted correctly during simulation. Test that Vezies events are generated at the right moments. Check for performance impacts on the simulation cycle."
          }
        ]
      },
      {
        "id": 10,
        "title": "Implement HUD Updates and UI Integration",
        "description": "Update the HUD to display simulation results, policy management, and advisor recommendations.",
        "details": "Update the HUD to integrate with the simulation engine, policy management, and advisor systems.\n\nImplementation details:\n1. Add a Step Engine button to /demo/hud that triggers a simulation step\n2. Create a Policies panel for submitting and managing policies\n3. Create an Advisors panel for querying advisors and proposing actions\n4. Update the analytics display to show the latest KPI data\n\nExample implementation:\n```typescript\n// src/components/demo/SimulationControls.tsx\nimport { useState } from 'react';\nimport { Button, Alert } from '@/components/ui';\n\nexport function SimulationControls({ campaignId }) {\n  const [loading, setLoading] = useState(false);\n  const [result, setResult] = useState(null);\n  const [error, setError] = useState(null);\n\n  const handleStepEngine = async () => {\n    setLoading(true);\n    setError(null);\n    \n    try {\n      const response = await fetch('/api/sim/step', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ campaignId })\n      });\n      \n      const data = await response.json();\n      \n      if (!response.ok) {\n        throw new Error(data.error || 'Failed to step engine');\n      }\n      \n      setResult(data);\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"p-4 border rounded-lg\">\n      <h2 className=\"text-xl font-bold mb-4\">Simulation Controls</h2>\n      \n      <Button \n        onClick={handleStepEngine} \n        disabled={loading}\n        className=\"mb-4\"\n      >\n        {loading ? 'Processing...' : 'Step Engine'}\n      </Button>\n      \n      {error && (\n        <Alert variant=\"error\" className=\"mb-4\">\n          {error}\n        </Alert>\n      )}\n      \n      {result && (\n        <div className=\"mt-4\">\n          <h3 className=\"font-semibold\">Last Step Results:</h3>\n          <pre className=\"bg-gray-100 p-2 rounded mt-2 text-xs overflow-auto\">\n            {JSON.stringify(result, null, 2)}\n          </pre>\n        </div>\n      )}\n    </div>\n  );\n}\n\n// src/components/demo/PolicyPanel.tsx\nimport { useState } from 'react';\nimport { Button, TextArea, Input, Select } from '@/components/ui';\n\nexport function PolicyPanel({ campaignId }) {\n  const [title, setTitle] = useState('');\n  const [body, setBody] = useState('');\n  const [scope, setScope] = useState('campaign');\n  const [suggestions, setSuggestions] = useState(null);\n  const [loading, setLoading] = useState(false);\n  const [error, setError] = useState(null);\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    setLoading(true);\n    setError(null);\n    \n    try {\n      const response = await fetch('/api/policies/parse', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ title, body, scope })\n      });\n      \n      const data = await response.json();\n      \n      if (!response.ok) {\n        throw new Error(data.error || 'Failed to parse policy');\n      }\n      \n      setSuggestions(data.suggestedModifiers);\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  const handleActivate = async () => {\n    setLoading(true);\n    setError(null);\n    \n    try {\n      // First create the policy\n      const createResponse = await fetch('/api/policies', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ title, body, scope })\n      });\n      \n      const policyData = await createResponse.json();\n      \n      if (!createResponse.ok) {\n        throw new Error(policyData.error || 'Failed to create policy');\n      }\n      \n      // Then activate the modifiers\n      const activateResponse = await fetch('/api/policies/activate', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          policyId: policyData.policy.id,\n          modifiers: suggestions\n        })\n      });\n      \n      const activateData = await activateResponse.json();\n      \n      if (!activateResponse.ok) {\n        throw new Error(activateData.error || 'Failed to activate policy');\n      }\n      \n      // Reset form\n      setTitle('');\n      setBody('');\n      setSuggestions(null);\n      \n      alert('Policy created and activated successfully!');\n    } catch (err) {\n      setError(err.message);\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    <div className=\"p-4 border rounded-lg\">\n      <h2 className=\"text-xl font-bold mb-4\">Policy Console</h2>\n      \n      <form onSubmit={handleSubmit}>\n        <Input\n          label=\"Title\"\n          value={title}\n          onChange={(e) => setTitle(e.target.value)}\n          required\n          className=\"mb-4\"\n        />\n        \n        <Select\n          label=\"Scope\"\n          value={scope}\n          onChange={(e) => setScope(e.target.value)}\n          options={[\n            { value: 'campaign', label: 'Campaign' },\n            { value: 'region', label: 'Region' },\n            { value: 'system', label: 'System' }\n          ]}\n          className=\"mb-4\"\n        />\n        \n        <TextArea\n          label=\"Policy Text\"\n          value={body}\n          onChange={(e) => setBody(e.target.value)}\n          rows={6}\n          required\n          className=\"mb-4\"\n        />\n        \n        <Button type=\"submit\" disabled={loading}>\n          {loading ? 'Analyzing...' : 'Analyze Policy'}\n        </Button>\n      </form>\n      \n      {error && (\n        <Alert variant=\"error\" className=\"my-4\">\n          {error}\n        </Alert>\n      )}\n      \n      {suggestions && (\n        <div className=\"mt-6\">\n          <h3 className=\"font-semibold mb-2\">Suggested Modifiers:</h3>\n          \n          <ul className=\"mb-4\">\n            {suggestions.map((mod, index) => (\n              <li key={index} className=\"mb-2\">\n                <strong>{mod.key}:</strong> {mod.value} (Range: {mod.cap_min} to {mod.cap_max})\n              </li>\n            ))}\n          </ul>\n          \n          <Button onClick={handleActivate} disabled={loading}>\n            {loading ? 'Activating...' : 'Approve & Activate'}\n          </Button>\n        </div>\n      )}\n    </div>\n  );\n}\n\n// Similar implementation for AdvisorPanel component\n// ...\n\n// Update main HUD component to include these new panels\n```",
        "testStrategy": "1. Playwright UI tests for the Step Engine button functionality\n2. Test the Policies panel flow: submit text → see suggestions → approve → step → KPI change\n3. Test the Advisors panel flow: ask → get recommendation → propose → step → change visible\n4. Verify that the analytics display updates after a simulation step\n5. Test error handling and loading states in all UI components",
        "priority": "medium",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement SimulationControls Component",
            "description": "Create a component that allows users to trigger simulation steps and view results",
            "dependencies": [],
            "details": "Develop the SimulationControls.tsx component that includes a 'Step Engine' button to trigger simulation steps. The component should handle API calls to /api/sim/step, display loading states, show errors if they occur, and present the results of the simulation step in a readable format. Include proper error handling and loading indicators.",
            "status": "pending",
            "testStrategy": "Test the API integration with mock responses, verify loading states are correctly displayed, ensure error messages appear when API calls fail, and confirm simulation results are properly rendered."
          },
          {
            "id": 2,
            "title": "Implement PolicyPanel Component",
            "description": "Create a component for submitting and managing policies with modifier suggestions",
            "dependencies": [
              "10.1"
            ],
            "details": "Develop the PolicyPanel.tsx component that allows users to create policies with title, body, and scope. Implement form validation, API integration with /api/policies/parse for analysis, and /api/policies and /api/policies/activate for creation and activation. Display suggested modifiers and provide approval functionality.",
            "status": "pending",
            "testStrategy": "Test form validation, API integration for policy parsing, verify modifier suggestions display correctly, test policy creation and activation flows, and ensure proper error handling throughout the process."
          },
          {
            "id": 3,
            "title": "Implement AdvisorPanel Component",
            "description": "Create a component for querying advisors and proposing actions based on recommendations",
            "dependencies": [
              "10.1"
            ],
            "details": "Develop the AdvisorPanel.tsx component that allows users to query domain-specific advisors and receive recommendations. Implement functionality to ask questions, display advisor responses, and propose actions based on recommendations. Include domain selection, question input, and action proposal confirmation.",
            "status": "pending",
            "testStrategy": "Test advisor query functionality with different domains, verify recommendation display, test action proposal flow, ensure proper error handling, and check that proposed actions are correctly submitted to the API."
          },
          {
            "id": 4,
            "title": "Update Analytics Display Component",
            "description": "Enhance the analytics display to show the latest KPI data from the simulation engine",
            "dependencies": [
              "10.1"
            ],
            "details": "Update the existing analytics display component to fetch and visualize the latest KPI data from the simulation engine. Implement data fetching from the /api/analytics/empire endpoint, create visualizations for key metrics, and ensure the display updates after simulation steps are executed.",
            "status": "pending",
            "testStrategy": "Test data fetching from the analytics API, verify visualizations correctly represent the data, ensure the display updates after simulation steps, and test fallback behavior when data is unavailable."
          },
          {
            "id": 5,
            "title": "Integrate Components into Main HUD",
            "description": "Combine all components into the main HUD interface with proper layout and styling",
            "dependencies": [
              "10.1",
              "10.2",
              "10.3",
              "10.4"
            ],
            "details": "Integrate the SimulationControls, PolicyPanel, AdvisorPanel, and updated Analytics Display components into the main HUD interface. Implement responsive layout, consistent styling, and ensure all components work together seamlessly. Add navigation between different panels if needed and ensure the UI is intuitive.",
            "status": "pending",
            "testStrategy": "Test the integrated HUD with all components, verify responsive behavior across different screen sizes, ensure consistent styling and theme application, test navigation between panels, and conduct end-to-end testing of complete workflows."
          }
        ]
      },
      {
        "id": 11,
        "title": "Implement Diplomacy System with Envoys and Treaties",
        "description": "Create a diplomacy system with envoys, embassies, deterministic diplomat personas, and diplomatic actions that can modify game state within validator-capped ranges, along with treaty DSL integration.",
        "details": "Implement a comprehensive diplomacy system with the following components:\n\n1. Database schema for diplomatic entities:\n```sql\nCREATE TABLE IF NOT EXISTS diplomats (\n  id SERIAL PRIMARY KEY,\n  empire_id INTEGER NOT NULL REFERENCES empires(id),\n  name VARCHAR(255) NOT NULL,\n  persona_seed VARCHAR(64) NOT NULL,\n  traits JSONB NOT NULL,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS embassies (\n  id SERIAL PRIMARY KEY,\n  host_empire_id INTEGER NOT NULL REFERENCES empires(id),\n  guest_empire_id INTEGER NOT NULL REFERENCES empires(id),\n  status VARCHAR(50) NOT NULL CHECK (status IN ('pending', 'active', 'closed')),\n  established_at TIMESTAMP WITH TIME ZONE,\n  UNIQUE(host_empire_id, guest_empire_id)\n);\n\nCREATE TABLE IF NOT EXISTS diplomatic_actions (\n  id SERIAL PRIMARY KEY,\n  embassy_id INTEGER NOT NULL REFERENCES embassies(id),\n  action_type VARCHAR(50) NOT NULL CHECK (action_type IN ('parley', 'protest', 'concession', 'cbm')),\n  initiator_empire_id INTEGER NOT NULL REFERENCES empires(id),\n  target_empire_id INTEGER NOT NULL REFERENCES empires(id),\n  payload JSONB NOT NULL,\n  modifiers JSONB NOT NULL,\n  executed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS treaties (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  dsl_definition TEXT NOT NULL,\n  status VARCHAR(50) NOT NULL CHECK (status IN ('draft', 'proposed', 'active', 'terminated')),\n  signatories JSONB NOT NULL,\n  effects JSONB NOT NULL,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  ratified_at TIMESTAMP WITH TIME ZONE\n);\n```\n\n2. Implement deterministic diplomat persona generation:\n```typescript\n// src/server/diplomacy/personas.ts\nimport seedrandom from 'seedrandom';\n\nexport function generateDiplomatPersona(seed: string) {\n  const rng = seedrandom(seed);\n  \n  // Generate deterministic traits based on seed\n  return {\n    aggressiveness: Math.floor(rng() * 100),\n    trustworthiness: Math.floor(rng() * 100),\n    flexibility: Math.floor(rng() * 100),\n    risktaking: Math.floor(rng() * 100),\n    specialization: ['trade', 'military', 'science', 'culture'][Math.floor(rng() * 4)]\n  };\n}\n```\n\n3. Implement diplomatic action handlers with validator-capped modifiers:\n```typescript\n// src/server/diplomacy/actions.ts\nimport { validateModifiers } from '../utils/validators';\n\nconst MODIFIER_CAPS = {\n  'parley': {\n    'relation_mult': { min: 0.95, max: 1.05 },\n    'trade_bonus': { min: 0, max: 0.03 }\n  },\n  'protest': {\n    'relation_mult': { min: 0.9, max: 1.0 },\n    'production_penalty': { min: 0, max: 0.02 }\n  },\n  'concession': {\n    'relation_mult': { min: 1.0, max: 1.1 },\n    'resource_transfer': { min: 0, max: 500 }\n  },\n  'cbm': { // Confidence Building Measures\n    'relation_mult': { min: 1.0, max: 1.05 },\n    'military_transparency': { min: 0, max: 0.1 }\n  }\n};\n\nexport async function executeDiplomaticAction(actionType, payload, initiatorId, targetId) {\n  // Calculate base modifiers based on action type and payload\n  const baseModifiers = calculateBaseModifiers(actionType, payload);\n  \n  // Apply caps to ensure modifiers are within allowed ranges\n  const validatedModifiers = validateModifiers(baseModifiers, MODIFIER_CAPS[actionType]);\n  \n  // Store the action in the database\n  const action = await db.diplomaticActions.create({\n    action_type: actionType,\n    initiator_empire_id: initiatorId,\n    target_empire_id: targetId,\n    payload,\n    modifiers: validatedModifiers\n  });\n  \n  // Return the validated modifiers that will be applied\n  return validatedModifiers;\n}\n```\n\n4. Implement Treaty DSL parser and executor:\n```typescript\n// src/server/diplomacy/treaties.ts\nimport { parse } from './treatyDSL';\n\nexport async function createTreaty(name, dslDefinition, signatories) {\n  // Parse the DSL to validate and extract effects\n  const parsedTreaty = parse(dslDefinition);\n  \n  // Validate the treaty structure\n  if (!parsedTreaty.valid) {\n    throw new Error(`Invalid treaty DSL: ${parsedTreaty.errors.join(', ')}`);\n  }\n  \n  // Create the treaty in draft status\n  const treaty = await db.treaties.create({\n    name,\n    dsl_definition: dslDefinition,\n    status: 'draft',\n    signatories,\n    effects: parsedTreaty.effects\n  });\n  \n  return treaty;\n}\n\nexport function generateCounterfactual(treatyId, gameState) {\n  // Retrieve the treaty\n  const treaty = await db.treaties.findById(treatyId);\n  \n  // Clone the game state\n  const counterfactualState = JSON.parse(JSON.stringify(gameState));\n  \n  // Apply treaty effects to the cloned state\n  const effects = treaty.effects;\n  applyTreatyEffects(counterfactualState, effects);\n  \n  // Return the modified state for preview\n  return counterfactualState;\n}\n```\n\n5. Implement API endpoints:\n```typescript\n// src/pages/api/diplomacy/brief.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { getDiplomaticBrief } from '../../../server/diplomacy/briefs';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n  \n  const { empireId } = req.body;\n  \n  try {\n    const brief = await getDiplomaticBrief(empireId);\n    return res.status(200).json(brief);\n  } catch (error) {\n    return res.status(500).json({ error: error.message });\n  }\n}\n\n// src/pages/api/diplomacy/action.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { executeDiplomaticAction } from '../../../server/diplomacy/actions';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n  \n  const { actionType, payload, initiatorId, targetId } = req.body;\n  \n  try {\n    const result = await executeDiplomaticAction(actionType, payload, initiatorId, targetId);\n    return res.status(200).json(result);\n  } catch (error) {\n    return res.status(500).json({ error: error.message });\n  }\n}\n\n// src/pages/api/diplomacy/treaties.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { getTreaties } from '../../../server/diplomacy/treaties';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'GET') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n  \n  const { empireId, status } = req.query;\n  \n  try {\n    const treaties = await getTreaties(empireId, status);\n    return res.status(200).json(treaties);\n  } catch (error) {\n    return res.status(500).json({ error: error.message });\n  }\n}\n\n// src/pages/api/diplomacy/stance.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { getDiplomaticStance } from '../../../server/diplomacy/stance';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'GET') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n  \n  const { empireId, targetId } = req.query;\n  \n  try {\n    const stance = await getDiplomaticStance(empireId, targetId);\n    return res.status(200).json(stance);\n  } catch (error) {\n    return res.status(500).json({ error: error.message });\n  }\n}\n```\n\n6. Integrate with the simulation engine:\n```typescript\n// Add to src/server/sim/engine.ts\nimport { applyDiplomaticModifiers } from '../diplomacy/modifiers';\n\n// Add to the reducer pipeline\nfunction step({ campaignId, seed, actions = [] }) {\n  // ... existing code ...\n  \n  // Apply diplomatic modifiers after policy modifiers\n  state = applyDiplomaticModifiers(state, activeDiplomaticActions);\n  \n  // ... rest of the pipeline ...\n}\n```",
        "testStrategy": "1. Unit test the diplomat persona generation to verify determinism:\n   - Generate personas with the same seed multiple times and verify they are identical\n   - Generate personas with different seeds and verify they are different\n   - Test edge cases for seed values\n\n2. Test diplomatic action validators and caps:\n   - Verify that modifiers exceeding caps are properly constrained\n   - Test each action type with various payload combinations\n   - Verify that invalid action types are rejected\n   - Test edge cases at the boundaries of the caps\n\n3. Test the Treaty DSL parser:\n   - Verify that valid treaty definitions are correctly parsed\n   - Test error handling for invalid syntax\n   - Verify that treaty effects are correctly extracted\n   - Test complex treaty conditions and clauses\n\n4. Test counterfactual preview generation:\n   - Verify that treaty effects are correctly applied to the cloned state\n   - Compare original and counterfactual states to ensure only expected changes occur\n   - Test with various treaty types and game states\n\n5. API endpoint tests:\n   - Test POST /diplomacy/brief with valid and invalid empire IDs\n   - Test POST /diplomacy/action with all action types and verify proper modifier application\n   - Test GET /diplomacy/treaties with various filters and verify correct results\n   - Test GET /diplomacy/stance with different empire combinations\n\n6. Integration tests:\n   - Verify that diplomatic actions correctly modify the simulation state\n   - Test that treaties with active status apply their effects during simulation steps\n   - Verify that diplomatic relations change appropriately based on actions and treaties\n\n7. Determinism tests:\n   - Run multiple simulations with the same seed and diplomatic actions\n   - Verify that the resulting diplomatic states are identical\n   - Test with complex scenarios involving multiple empires and actions\n\n8. Database tests:\n   - Verify that all diplomatic entities are correctly stored and retrieved\n   - Test the constraints on the database tables\n   - Verify that relationship constraints between tables are enforced",
        "status": "pending",
        "dependencies": [
          1,
          6,
          7
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Implement Hero Exploration and National Quests System",
        "description": "Create a system for hero exploration actions (survey, scan, map, first contact) and national quests with deterministic effects, along with corresponding API endpoints for exploration and quest management.",
        "details": "Implement a comprehensive hero exploration and national quest system with the following components:\n\n1. Database schema for exploration and quests:\n```sql\nCREATE TABLE IF NOT EXISTS hero_exploration (\n  id SERIAL PRIMARY KEY,\n  hero_id INTEGER NOT NULL REFERENCES heroes(id),\n  location_id INTEGER NOT NULL REFERENCES locations(id),\n  action_type VARCHAR(50) NOT NULL CHECK (action_type IN ('survey', 'scan', 'map', 'first_contact')),\n  result_data JSONB NOT NULL,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS hero_maps (\n  id SERIAL PRIMARY KEY,\n  hero_id INTEGER NOT NULL REFERENCES heroes(id),\n  map_data JSONB NOT NULL,\n  last_updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS national_quests (\n  id SERIAL PRIMARY KEY,\n  title VARCHAR(255) NOT NULL,\n  description TEXT NOT NULL,\n  quest_type VARCHAR(50) NOT NULL CHECK (quest_type IN ('military', 'economic')),\n  requirements JSONB NOT NULL,\n  rewards JSONB NOT NULL,\n  status VARCHAR(50) NOT NULL DEFAULT 'available' CHECK (status IN ('available', 'accepted', 'completed', 'failed')),\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  completed_at TIMESTAMP WITH TIME ZONE\n);\n\nCREATE TABLE IF NOT EXISTS hero_quest_assignments (\n  id SERIAL PRIMARY KEY,\n  hero_id INTEGER NOT NULL REFERENCES heroes(id),\n  quest_id INTEGER NOT NULL REFERENCES national_quests(id),\n  assigned_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  UNIQUE(hero_id, quest_id)\n);\n```\n\n2. Implement exploration action endpoints:\n   - POST /hero/explore: Execute exploration actions with deterministic outcomes\n   - GET /hero/map: Retrieve the hero's current map data\n\n```typescript\n// src/pages/api/hero/explore.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { prisma } from '@/lib/prisma';\nimport { deterministic } from '@/lib/deterministic';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  const { heroId, locationId, actionType, seed } = req.body;\n  \n  if (!heroId || !locationId || !actionType) {\n    return res.status(400).json({ error: 'Missing required parameters' });\n  }\n  \n  // Validate action type\n  if (!['survey', 'scan', 'map', 'first_contact'].includes(actionType)) {\n    return res.status(400).json({ error: 'Invalid action type' });\n  }\n  \n  try {\n    // Generate deterministic result based on action type, location, and seed\n    const resultData = await generateExplorationResult(actionType, locationId, seed);\n    \n    // Store exploration result\n    const exploration = await prisma.hero_exploration.create({\n      data: {\n        hero_id: heroId,\n        location_id: locationId,\n        action_type: actionType,\n        result_data: resultData\n      }\n    });\n    \n    // Update hero's map if action is 'map'\n    if (actionType === 'map') {\n      await updateHeroMap(heroId, locationId, resultData);\n    }\n    \n    // Add explainability metadata\n    const explainability = generateExplainabilityData(actionType, resultData);\n    \n    return res.status(200).json({ \n      exploration, \n      explainability,\n      logistics_impact: calculateLogisticsImpact(actionType),\n      restoration_cost: calculateRestorationCost(actionType)\n    });\n  } catch (error) {\n    console.error('Exploration action failed:', error);\n    return res.status(500).json({ error: 'Failed to execute exploration action' });\n  }\n}\n\n// Helper functions for deterministic outcomes\nfunction generateExplorationResult(actionType, locationId, seed) {\n  // Use deterministic PRNG with seed\n  const rng = deterministic.createRNG(seed);\n  \n  // Generate bounded, deterministic results based on action type\n  switch(actionType) {\n    case 'survey':\n      return generateSurveyResult(locationId, rng);\n    case 'scan':\n      return generateScanResult(locationId, rng);\n    case 'map':\n      return generateMapResult(locationId, rng);\n    case 'first_contact':\n      return generateFirstContactResult(locationId, rng);\n  }\n}\n```\n\n3. Implement national quest DSL (Domain Specific Language) for military and economic quests:\n\n```typescript\n// src/lib/questDSL.ts\nexport interface QuestRequirement {\n  type: string;\n  target: number;\n  current: number;\n}\n\nexport interface QuestReward {\n  type: string;\n  amount: number;\n}\n\nexport class QuestDSL {\n  // Military quest factory methods\n  static createDefenseMission(difficulty: number, seed: string): any {\n    // Generate deterministic defense mission with bounded effects\n    return {\n      title: `Defend Sector ${generateSectorName(seed)}`,\n      description: `Protect our interests in sector ${generateSectorName(seed)} from hostile forces.`,\n      quest_type: 'military',\n      requirements: {\n        combat_power: 100 * difficulty,\n        time_limit: 48 // hours\n      },\n      rewards: {\n        reputation: 50 * difficulty,\n        resources: {\n          credits: 1000 * difficulty,\n          materials: 500 * difficulty\n        }\n      }\n    };\n  }\n  \n  // Economic quest factory methods\n  static createTradeRoute(difficulty: number, seed: string): any {\n    // Generate deterministic trade route quest with bounded effects\n    return {\n      title: `Establish Trade Route to ${generateLocationName(seed)}`,\n      description: `Create a profitable trade route to ${generateLocationName(seed)}.`,\n      quest_type: 'economic',\n      requirements: {\n        logistics_capacity: 200 * difficulty,\n        diplomatic_standing: 25 * difficulty\n      },\n      rewards: {\n        economic_growth: 5 * difficulty,\n        resources: {\n          credits: 2000 * difficulty,\n          rare_materials: 200 * difficulty\n        }\n      }\n    };\n  }\n  \n  // Quest validation and progression methods\n  static validateQuestCompletion(quest, heroStats): boolean {\n    // Deterministic validation of quest completion requirements\n    if (quest.quest_type === 'military') {\n      return heroStats.combat_power >= quest.requirements.combat_power;\n    } else if (quest.quest_type === 'economic') {\n      return heroStats.logistics_capacity >= quest.requirements.logistics_capacity &&\n             heroStats.diplomatic_standing >= quest.requirements.diplomatic_standing;\n    }\n    return false;\n  }\n}\n```\n\n4. Implement quest management endpoints:\n   - GET /quests: List available and active quests\n   - POST /quests/accept: Accept a quest\n   - POST /quests/complete: Complete a quest\n\n```typescript\n// src/pages/api/quests/index.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { prisma } from '@/lib/prisma';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'GET') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  const { heroId, status } = req.query;\n  \n  try {\n    let quests;\n    \n    if (heroId) {\n      // Get quests for specific hero\n      quests = await prisma.national_quests.findMany({\n        where: {\n          hero_quest_assignments: {\n            some: {\n              hero_id: Number(heroId)\n            }\n          },\n          ...(status ? { status } : {})\n        }\n      });\n    } else {\n      // Get all quests with optional status filter\n      quests = await prisma.national_quests.findMany({\n        where: status ? { status: String(status) } : {}\n      });\n    }\n    \n    return res.status(200).json({ quests });\n  } catch (error) {\n    console.error('Failed to fetch quests:', error);\n    return res.status(500).json({ error: 'Failed to fetch quests' });\n  }\n}\n```\n\n5. Integration with logistics, restoration, and explainability systems:\n\n```typescript\n// src/lib/exploration/logistics.ts\nexport function calculateLogisticsImpact(actionType: string): any {\n  // Calculate bounded, deterministic logistics impact\n  const baseImpact = {\n    'survey': { fuel: 10, supplies: 5 },\n    'scan': { fuel: 15, supplies: 5 },\n    'map': { fuel: 25, supplies: 10 },\n    'first_contact': { fuel: 20, supplies: 20 }\n  };\n  \n  return baseImpact[actionType] || { fuel: 0, supplies: 0 };\n}\n\n// src/lib/exploration/restoration.ts\nexport function calculateRestorationCost(actionType: string): any {\n  // Calculate bounded, deterministic restoration costs\n  const baseCost = {\n    'survey': { time: 1, resources: 50 },\n    'scan': { time: 2, resources: 100 },\n    'map': { time: 4, resources: 200 },\n    'first_contact': { time: 6, resources: 300 }\n  };\n  \n  return baseCost[actionType] || { time: 0, resources: 0 };\n}\n\n// src/lib/exploration/explainability.ts\nexport function generateExplainabilityData(actionType: string, resultData: any): any {\n  // Generate explainability metadata for exploration actions\n  return {\n    action: actionType,\n    timestamp: new Date().toISOString(),\n    factors: extractRelevantFactors(actionType, resultData),\n    confidence: calculateConfidenceScore(resultData)\n  };\n}\n```\n\n6. Implement tests for determinism and caps:\n\n```typescript\n// src/tests/exploration.test.ts\nimport { generateExplorationResult } from '@/lib/exploration';\n\ndescribe('Exploration Determinism Tests', () => {\n  test('Same seed produces same survey results', () => {\n    const result1 = generateExplorationResult('survey', 123, 'test-seed-1');\n    const result2 = generateExplorationResult('survey', 123, 'test-seed-1');\n    expect(result1).toEqual(result2);\n  });\n  \n  test('Different seeds produce different survey results', () => {\n    const result1 = generateExplorationResult('survey', 123, 'test-seed-1');\n    const result2 = generateExplorationResult('survey', 123, 'test-seed-2');\n    expect(result1).not.toEqual(result2);\n  });\n  \n  test('Resource discoveries are within capped ranges', () => {\n    const result = generateExplorationResult('survey', 123, 'test-seed-1');\n    expect(result.resources.minerals).toBeGreaterThanOrEqual(0);\n    expect(result.resources.minerals).toBeLessThanOrEqual(1000);\n    expect(result.resources.energy).toBeGreaterThanOrEqual(0);\n    expect(result.resources.energy).toBeLessThanOrEqual(1000);\n  });\n});\n\n// src/tests/quests.test.ts\nimport { QuestDSL } from '@/lib/questDSL';\n\ndescribe('Quest DSL Tests', () => {\n  test('Military quests have bounded rewards', () => {\n    const quest = QuestDSL.createDefenseMission(3, 'test-seed');\n    expect(quest.rewards.reputation).toBeLessThanOrEqual(500);\n    expect(quest.rewards.resources.credits).toBeLessThanOrEqual(10000);\n  });\n  \n  test('Economic quests have bounded requirements', () => {\n    const quest = QuestDSL.createTradeRoute(5, 'test-seed');\n    expect(quest.requirements.logistics_capacity).toBeLessThanOrEqual(2000);\n    expect(quest.requirements.diplomatic_standing).toBeLessThanOrEqual(500);\n  });\n  \n  test('Same seed produces identical quests', () => {\n    const quest1 = QuestDSL.createDefenseMission(2, 'test-seed');\n    const quest2 = QuestDSL.createDefenseMission(2, 'test-seed');\n    expect(quest1).toEqual(quest2);\n  });\n});\n```",
        "testStrategy": "1. Unit test the exploration action functions:\n   - Test each exploration action type (survey, scan, map, first contact) with various seeds\n   - Verify that results are deterministic when using the same seed\n   - Confirm that different seeds produce different but valid results\n   - Check that all resource discoveries and effects are within capped ranges\n\n2. Test the quest DSL implementation:\n   - Verify that military and economic quest generation is deterministic\n   - Test that quest requirements and rewards scale appropriately with difficulty\n   - Ensure quest validation logic correctly determines completion status\n   - Confirm that quest effects are bounded within specified caps\n\n3. API endpoint testing:\n   - Test POST /hero/explore with valid and invalid parameters\n   - Verify GET /hero/map returns correct and consistent map data\n   - Test GET /quests with various filters\n   - Verify POST /quests/accept correctly assigns quests to heroes\n   - Test POST /quests/complete with both valid and invalid completion attempts\n\n4. Integration testing:\n   - Verify exploration actions correctly impact hero logistics\n   - Test that restoration costs are applied correctly\n   - Confirm that explainability metadata is generated for all actions\n   - Test the full quest lifecycle from generation to completion\n\n5. Performance and boundary testing:\n   - Test with maximum map sizes to ensure performance\n   - Verify system behavior with edge case inputs\n   - Test concurrent exploration actions to ensure consistency\n   - Verify that quest completion validation remains deterministic under load\n\n6. End-to-end testing:\n   - Create a test scenario that includes hero exploration, map building, quest acceptance, and completion\n   - Verify that all components work together correctly\n   - Test the integration with the simulation engine to ensure exploration and quest effects are properly applied",
        "status": "pending",
        "dependencies": [
          1,
          6,
          7,
          9
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Database Schema for Exploration and Quests",
            "description": "Implement the database schema for hero exploration actions, hero maps, national quests, and hero quest assignments.",
            "dependencies": [],
            "details": "Create a migration file that implements the tables as specified in the requirements:\n- hero_exploration: Stores exploration action results\n- hero_maps: Stores hero's map data\n- national_quests: Stores quest information\n- hero_quest_assignments: Tracks hero assignments to quests\n\nEnsure all tables have appropriate constraints, foreign keys, and indexes for performance.",
            "status": "pending",
            "testStrategy": "Verify the migration runs successfully and creates all tables with proper constraints. Test inserting and querying sample data to ensure relationships work correctly."
          },
          {
            "id": 2,
            "title": "Implement Exploration Action Logic",
            "description": "Create the core logic for handling different exploration actions (survey, scan, map, first contact) with deterministic outcomes.",
            "dependencies": [
              "12.1"
            ],
            "details": "Create a module in src/lib/exploration.ts that implements:\n- generateExplorationResult function that produces deterministic results based on action type, location, and seed\n- Helper functions for each action type (generateSurveyResult, generateScanResult, etc.)\n- Logic to update hero maps when mapping actions are performed\n- Ensure all results are bounded within appropriate ranges",
            "status": "pending",
            "testStrategy": "Unit test each exploration function with fixed seeds to verify determinism. Test that different seeds produce different but valid results. Verify that resource discoveries and other outcomes are within expected bounds."
          },
          {
            "id": 3,
            "title": "Implement Exploration API Endpoints",
            "description": "Create API endpoints for executing exploration actions and retrieving hero map data.",
            "dependencies": [
              "12.1",
              "12.2"
            ],
            "details": "Implement the following API endpoints:\n1. POST /hero/explore - Execute exploration actions\n   - Validate input parameters (heroId, locationId, actionType, seed)\n   - Call exploration logic to generate results\n   - Store results in the database\n   - Return results with explainability metadata\n\n2. GET /hero/map - Retrieve hero's map data\n   - Accept heroId as a parameter\n   - Return the hero's current map data from hero_maps table",
            "status": "pending",
            "testStrategy": "Test API endpoints with valid and invalid inputs. Verify proper error handling and status codes. Test that exploration results are correctly stored in the database and that map data is correctly retrieved."
          },
          {
            "id": 4,
            "title": "Implement Quest DSL for Military and Economic Quests",
            "description": "Create a Domain Specific Language for defining and managing national quests with deterministic properties.",
            "dependencies": [
              "12.1"
            ],
            "details": "Implement a QuestDSL class in src/lib/questDSL.ts with:\n- Factory methods for creating different quest types (military, economic)\n- Methods to generate deterministic quest properties based on difficulty and seed\n- Validation logic for quest completion requirements\n- Helper functions for quest progression tracking\n\nEnsure all quest rewards and requirements are properly bounded within game-balanced ranges.",
            "status": "pending",
            "testStrategy": "Test quest generation with fixed seeds to verify determinism. Verify that quest requirements and rewards scale appropriately with difficulty. Test quest validation logic with various hero stats."
          },
          {
            "id": 5,
            "title": "Implement Quest Management API Endpoints",
            "description": "Create API endpoints for listing, accepting, and completing national quests.",
            "dependencies": [
              "12.1",
              "12.4"
            ],
            "details": "Implement the following API endpoints:\n1. GET /quests - List available and active quests\n   - Support filtering by heroId and status\n   - Return quest details with requirements and rewards\n\n2. POST /quests/accept - Accept a quest\n   - Validate hero eligibility for the quest\n   - Create hero_quest_assignment record\n   - Update quest status\n\n3. POST /quests/complete - Complete a quest\n   - Validate quest completion requirements\n   - Update quest status\n   - Apply quest rewards to hero/nation",
            "status": "pending",
            "testStrategy": "Test each endpoint with valid and invalid inputs. Verify proper error handling and status codes. Test the complete quest flow from listing to acceptance to completion."
          },
          {
            "id": 6,
            "title": "Implement Logistics and Restoration Integration",
            "description": "Integrate exploration and quest systems with logistics impact and restoration cost calculations.",
            "dependencies": [
              "12.2",
              "12.3"
            ],
            "details": "Create utility modules for:\n1. src/lib/exploration/logistics.ts\n   - calculateLogisticsImpact function for different action types\n   - Track resource consumption for exploration actions\n\n2. src/lib/exploration/restoration.ts\n   - calculateRestorationCost function for different action types\n   - Define time and resource costs for recovery\n\nIntegrate these calculations into the exploration API endpoints to return impact and cost data.",
            "status": "pending",
            "testStrategy": "Unit test logistics impact and restoration cost calculations for each action type. Verify that values are within expected ranges. Test integration with exploration endpoints."
          },
          {
            "id": 7,
            "title": "Implement Explainability System for Exploration Results",
            "description": "Create a system that provides explanations for exploration outcomes to improve player understanding.",
            "dependencies": [
              "12.2",
              "12.3"
            ],
            "details": "Implement explainability features in src/lib/exploration/explainability.ts:\n- generateExplainabilityData function that creates metadata about exploration results\n- extractRelevantFactors function to identify key factors affecting outcomes\n- calculateConfidenceScore function to indicate reliability of results\n\nIntegrate this with exploration endpoints to return explainability data alongside results.",
            "status": "pending",
            "testStrategy": "Test that explainability data is generated correctly for different exploration actions. Verify that the data provides meaningful context about the results. Test integration with exploration endpoints."
          },
          {
            "id": 8,
            "title": "Implement Comprehensive Tests for Determinism and Caps",
            "description": "Create a test suite to verify deterministic behavior and proper capping of exploration and quest outcomes.",
            "dependencies": [
              "12.2",
              "12.4",
              "12.6",
              "12.7"
            ],
            "details": "Implement test files for:\n1. src/tests/exploration.test.ts\n   - Test determinism of exploration results with same/different seeds\n   - Verify resource discoveries are within capped ranges\n   - Test logistics impact and restoration cost calculations\n\n2. src/tests/quests.test.ts\n   - Test determinism of quest generation\n   - Verify quest requirements and rewards are properly bounded\n   - Test quest completion validation logic\n\nInclude integration tests for the full exploration and quest workflows.",
            "status": "pending",
            "testStrategy": "Run tests with fixed seeds to verify deterministic behavior. Test edge cases for all capped values. Verify that different seeds produce different but valid results within expected bounds."
          }
        ]
      },
      {
        "id": 13,
        "title": "Implement FTL Jump Network and Routing System",
        "description": "Create a deterministic FTL jump network with nodes, lanes, capacities, and risk factors, along with routing algorithms for space logistics, and implement corresponding API endpoints.",
        "details": "Implement a comprehensive FTL jump network and routing system with the following components:\n\n1. Database schema for the FTL jump network:\n```sql\nCREATE TABLE IF NOT EXISTS ftl_nodes (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  coordinates JSONB NOT NULL, -- {x: float, y: float, z: float}\n  capacity INTEGER NOT NULL,\n  risk_factor FLOAT NOT NULL,\n  seed VARCHAR(64) NOT NULL,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS ftl_lanes (\n  id SERIAL PRIMARY KEY,\n  source_node_id INTEGER NOT NULL REFERENCES ftl_nodes(id),\n  target_node_id INTEGER NOT NULL REFERENCES ftl_nodes(id),\n  capacity INTEGER NOT NULL,\n  risk_factor FLOAT NOT NULL,\n  travel_time INTEGER NOT NULL, -- in minutes\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  CONSTRAINT unique_lane UNIQUE(source_node_id, target_node_id)\n);\n```\n\n2. Implement a seeded jump graph generator in `src/server/logistics/ftl/network.ts`:\n```typescript\nimport seedrandom from 'seedrandom';\n\nexport function generateJumpNetwork(seed: string, density: number = 0.6) {\n  const rng = seedrandom(seed);\n  \n  // Generate nodes based on seed\n  const nodes = [];\n  const nodeCount = Math.floor(rng() * 20) + 30; // 30-50 nodes\n  \n  for (let i = 0; i < nodeCount; i++) {\n    nodes.push({\n      id: i,\n      name: generateNodeName(rng),\n      coordinates: {\n        x: rng() * 1000 - 500,\n        y: rng() * 1000 - 500,\n        z: rng() * 200 - 100\n      },\n      capacity: Math.floor(rng() * 900) + 100, // 100-1000 capacity\n      risk_factor: rng() * 0.5 // 0-0.5 risk factor\n    });\n  }\n  \n  // Generate lanes between nodes\n  const lanes = [];\n  for (let i = 0; i < nodes.length; i++) {\n    for (let j = i + 1; j < nodes.length; j++) {\n      if (rng() < density) {\n        const distance = calculateDistance(nodes[i].coordinates, nodes[j].coordinates);\n        lanes.push({\n          source_node_id: i,\n          target_node_id: j,\n          capacity: Math.floor(rng() * 500) + 50, // 50-550 capacity\n          risk_factor: (rng() * 0.3) + (distance / 2000), // Base risk + distance factor\n          travel_time: Math.floor(distance * (0.8 + rng() * 0.4)) // Distance-based travel time with variation\n        });\n      }\n    }\n  }\n  \n  return { nodes, lanes };\n}\n\nfunction calculateDistance(coord1, coord2) {\n  return Math.sqrt(\n    Math.pow(coord1.x - coord2.x, 2) +\n    Math.pow(coord1.y - coord2.y, 2) +\n    Math.pow(coord1.z - coord2.z, 2)\n  );\n}\n\nfunction generateNodeName(rng) {\n  // Implementation of deterministic node name generator\n}\n```\n\n3. Implement routing algorithms in `src/server/logistics/ftl/routing.ts`:\n```typescript\nexport function findOptimalRoute(\n  sourceNodeId: number,\n  targetNodeId: number,\n  nodes: any[],\n  lanes: any[],\n  priorityFactor: 'speed' | 'safety' | 'capacity' = 'speed'\n) {\n  // Build adjacency graph\n  const graph = buildGraph(nodes, lanes);\n  \n  // Different cost functions based on priority\n  const getCost = (lane) => {\n    switch (priorityFactor) {\n      case 'speed':\n        return lane.travel_time;\n      case 'safety':\n        return lane.risk_factor * 1000;\n      case 'capacity':\n        return 1000 / lane.capacity;\n      default:\n        return lane.travel_time;\n    }\n  };\n  \n  // Dijkstra's algorithm implementation\n  const { path, totalTime, totalRisk, minCapacity } = dijkstra(\n    graph, \n    sourceNodeId, \n    targetNodeId, \n    getCost\n  );\n  \n  return {\n    path,\n    stats: {\n      totalTime,\n      totalRisk,\n      minCapacity,\n      hops: path.length - 1\n    }\n  };\n}\n\nfunction buildGraph(nodes, lanes) {\n  // Implementation of graph builder from nodes and lanes\n}\n\nfunction dijkstra(graph, start, end, costFn) {\n  // Implementation of Dijkstra's algorithm with custom cost function\n}\n```\n\n4. Create API endpoints in `src/pages/api/logistics/ftl/map.ts` and `src/pages/api/logistics/ftl/route.ts`:\n```typescript\n// src/pages/api/logistics/ftl/map.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { prisma } from '@/lib/prisma';\nimport { generateJumpNetwork } from '@/server/logistics/ftl/network';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'GET') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n  \n  const { campaignId, regenerate } = req.query;\n  \n  if (!campaignId) {\n    return res.status(400).json({ error: 'Campaign ID is required' });\n  }\n  \n  try {\n    // Get campaign seed\n    const campaign = await prisma.campaign.findUnique({\n      where: { id: Number(campaignId) },\n      select: { seed: true }\n    });\n    \n    if (!campaign) {\n      return res.status(404).json({ error: 'Campaign not found' });\n    }\n    \n    let nodes = [];\n    let lanes = [];\n    \n    // Check if we need to regenerate or fetch existing\n    if (regenerate === 'true') {\n      // Generate new network\n      const network = generateJumpNetwork(`${campaign.seed}-ftl-network`);\n      \n      // Clear existing network\n      await prisma.$transaction([\n        prisma.ftl_lanes.deleteMany({ where: { ftl_nodes: { campaign_id: Number(campaignId) } } }),\n        prisma.ftl_nodes.deleteMany({ where: { campaign_id: Number(campaignId) } })\n      ]);\n      \n      // Store new network\n      for (const node of network.nodes) {\n        const createdNode = await prisma.ftl_nodes.create({\n          data: {\n            ...node,\n            campaign_id: Number(campaignId)\n          }\n        });\n        nodes.push(createdNode);\n      }\n      \n      for (const lane of network.lanes) {\n        const createdLane = await prisma.ftl_lanes.create({\n          data: {\n            ...lane,\n            source_node_id: nodes[lane.source_node_id].id,\n            target_node_id: nodes[lane.target_node_id].id\n          }\n        });\n        lanes.push(createdLane);\n      }\n    } else {\n      // Fetch existing network\n      nodes = await prisma.ftl_nodes.findMany({\n        where: { campaign_id: Number(campaignId) }\n      });\n      \n      lanes = await prisma.ftl_lanes.findMany({\n        where: { \n          OR: [\n            { source_node: { campaign_id: Number(campaignId) } },\n            { target_node: { campaign_id: Number(campaignId) } }\n          ]\n        }\n      });\n    }\n    \n    return res.status(200).json({ nodes, lanes });\n  } catch (error) {\n    console.error('Error fetching FTL network:', error);\n    return res.status(500).json({ error: 'Failed to fetch FTL network' });\n  }\n}\n\n// src/pages/api/logistics/ftl/route.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { prisma } from '@/lib/prisma';\nimport { findOptimalRoute } from '@/server/logistics/ftl/routing';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n  \n  const { campaignId, sourceNodeId, targetNodeId, priorityFactor } = req.body;\n  \n  if (!campaignId || !sourceNodeId || !targetNodeId) {\n    return res.status(400).json({ error: 'Campaign ID, source node ID, and target node ID are required' });\n  }\n  \n  try {\n    // Fetch nodes and lanes\n    const nodes = await prisma.ftl_nodes.findMany({\n      where: { campaign_id: Number(campaignId) }\n    });\n    \n    const lanes = await prisma.ftl_lanes.findMany({\n      where: { \n        OR: [\n          { source_node: { campaign_id: Number(campaignId) } },\n          { target_node: { campaign_id: Number(campaignId) } }\n        ]\n      }\n    });\n    \n    // Find optimal route\n    const route = findOptimalRoute(\n      Number(sourceNodeId),\n      Number(targetNodeId),\n      nodes,\n      lanes,\n      priorityFactor || 'speed'\n    );\n    \n    return res.status(200).json(route);\n  } catch (error) {\n    console.error('Error finding FTL route:', error);\n    return res.status(500).json({ error: 'Failed to find FTL route' });\n  }\n}\n```\n\n5. Integrate with the simulation engine by adding an FTL logistics reducer:\n```typescript\n// src/server/sim/reducers/ftlLogistics.ts\nexport function ftlLogisticsReducer(state, actions) {\n  // Process logistics actions through the FTL network\n  // Apply capacity constraints\n  // Calculate travel times and risks\n  // Update resource distributions\n  \n  return updatedState;\n}\n```\n\n6. Update the simulation engine to include the FTL logistics reducer in the pipeline:\n```typescript\n// In src/server/sim/engine.ts\nimport { ftlLogisticsReducer } from './reducers/ftlLogistics';\n\n// Add to the reducer pipeline\nconst reducerPipeline = [\n  productionReducer,\n  queueReducer,\n  logisticsCapReducer,\n  ftlLogisticsReducer, // Add FTL logistics reducer\n  // ... other reducers\n];\n```",
        "testStrategy": "1. Unit test the FTL network generation:\n   - Test with multiple seeds to verify deterministic generation\n   - Verify that the same seed always produces the same network\n   - Check that node and lane properties are within expected ranges\n   - Verify that the network is connected (no isolated nodes)\n\n2. Test the routing algorithm:\n   - Test route finding between various node pairs\n   - Verify that different priority factors (speed, safety, capacity) produce different routes\n   - Test edge cases like routing to the same node, or between disconnected nodes\n   - Benchmark performance with large networks\n\n3. API endpoint tests:\n   - Test GET /logistics/ftl/map:\n     - Verify it returns the correct structure with nodes and lanes\n     - Test with and without the regenerate flag\n     - Verify error handling for invalid campaign IDs\n   - Test POST /logistics/ftl/route:\n     - Verify it returns valid routes between nodes\n     - Test with different priority factors\n     - Verify error handling for invalid node IDs\n     - Test performance with complex routing requests\n\n4. Integration tests:\n   - Verify that the FTL logistics reducer correctly applies capacity constraints\n   - Test that resource distribution is correctly updated based on FTL routes\n   - Verify that travel times are deterministic and bounded\n   - Test that risk factors correctly influence outcomes\n\n5. Simulation integration tests:\n   - Verify that the FTL logistics reducer is correctly integrated in the simulation pipeline\n   - Test the impact of FTL network on resource distribution across multiple simulation steps\n   - Verify that capacity constraints are properly enforced over time\n\n6. Database tests:\n   - Test the database schema for FTL nodes and lanes\n   - Verify that constraints are properly enforced\n   - Test performance with large networks",
        "status": "pending",
        "dependencies": [
          1,
          2
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Database Schema for FTL Jump Network",
            "description": "Implement the database schema for FTL nodes and lanes that will form the foundation of the jump network system.",
            "dependencies": [],
            "details": "Create a migration file to add the ftl_nodes and ftl_lanes tables to the database schema. Ensure the tables include all required fields such as coordinates, capacity, risk factors, and proper foreign key relationships. Add a campaign_id field to the ftl_nodes table to associate nodes with specific campaigns. Implement appropriate indexes for performance optimization.",
            "status": "pending",
            "testStrategy": "Verify the migration runs successfully and creates the expected tables. Test the constraints by attempting to insert invalid data. Confirm foreign key relationships work correctly."
          },
          {
            "id": 2,
            "title": "Implement Jump Network Generator",
            "description": "Create a deterministic network generator that produces FTL nodes and lanes based on a seed value.",
            "dependencies": [
              "13.1"
            ],
            "details": "Implement the generateJumpNetwork function in src/server/logistics/ftl/network.ts that creates a deterministic network of nodes and lanes based on a seed. Include helper functions for calculating distances between nodes and generating node names. Ensure the generator creates a connected graph with appropriate density and realistic properties for nodes and lanes.",
            "status": "pending",
            "testStrategy": "Test with multiple seeds to verify deterministic generation. Ensure the same seed always produces identical networks. Verify node and lane properties are within expected ranges. Check that the generated network is fully connected."
          },
          {
            "id": 3,
            "title": "Implement Routing Algorithms",
            "description": "Create algorithms for finding optimal routes through the FTL network based on different priority factors.",
            "dependencies": [
              "13.2"
            ],
            "details": "Implement the routing algorithms in src/server/logistics/ftl/routing.ts, including the findOptimalRoute function that can optimize for speed, safety, or capacity. Create helper functions for building the graph representation and implementing Dijkstra's algorithm with custom cost functions. Include functionality to calculate route statistics such as total time, risk, and minimum capacity.",
            "status": "pending",
            "testStrategy": "Test routing with different priority factors to ensure appropriate paths are selected. Verify edge cases like disconnected nodes or identical source/target. Test performance with large networks. Confirm route statistics are calculated correctly."
          },
          {
            "id": 4,
            "title": "Create FTL Network API Endpoints",
            "description": "Implement API endpoints for retrieving the FTL network map and calculating optimal routes.",
            "dependencies": [
              "13.1",
              "13.2",
              "13.3"
            ],
            "details": "Create two API endpoints: 1) GET /api/logistics/ftl/map.ts to retrieve or regenerate the FTL network for a campaign, and 2) POST /api/logistics/ftl/route.ts to calculate optimal routes between nodes. Implement proper error handling, input validation, and database interactions. Ensure the endpoints handle campaign-specific data correctly.",
            "status": "pending",
            "testStrategy": "Test API endpoints with valid and invalid inputs. Verify proper error responses for missing parameters. Test regeneration functionality. Confirm route calculations match expected results from the routing algorithm."
          },
          {
            "id": 5,
            "title": "Implement FTL Logistics Reducer",
            "description": "Create a simulation reducer that processes logistics actions through the FTL network.",
            "dependencies": [
              "13.3"
            ],
            "details": "Implement the ftlLogisticsReducer in src/server/sim/reducers/ftlLogistics.ts that processes logistics actions through the FTL network. Apply capacity constraints, calculate travel times and risks, and update resource distributions based on the network properties. Handle edge cases like network congestion or route failures.",
            "status": "pending",
            "testStrategy": "Unit test the reducer with various logistics actions. Verify capacity constraints are properly applied. Test edge cases like network congestion or route failures. Confirm resource distributions are updated correctly."
          },
          {
            "id": 6,
            "title": "Integrate FTL System with Simulation Engine",
            "description": "Update the simulation engine to include the FTL logistics reducer in the pipeline.",
            "dependencies": [
              "13.5"
            ],
            "details": "Modify the simulation engine in src/server/sim/engine.ts to include the FTL logistics reducer in the reducer pipeline. Ensure proper ordering of reducers to handle dependencies correctly. Update any related simulation state interfaces to include FTL logistics data. Test the integration to ensure the simulation engine correctly processes FTL logistics actions.",
            "status": "pending",
            "testStrategy": "Run integration tests with the full simulation pipeline. Verify FTL logistics actions are processed correctly. Test interaction with other reducers. Confirm simulation state is updated appropriately after FTL logistics processing."
          }
        ]
      },
      {
        "id": 14,
        "title": "Implement Ancient Artifacts System",
        "description": "Create a system for ancient artifacts that can be discovered in exploration locations, with activation mechanics requiring research/stabilizers, deterministic effects, and comprehensive safety logging.",
        "details": "Implement a comprehensive ancient artifacts system with the following components:\n\n1. Database schema for artifacts and interactions:\n```sql\nCREATE TABLE IF NOT EXISTS artifacts (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  description TEXT NOT NULL,\n  location_id INTEGER NOT NULL REFERENCES exploration_locations(id),\n  discovery_status VARCHAR(50) NOT NULL DEFAULT 'undiscovered' CHECK (discovery_status IN ('undiscovered', 'discovered', 'activated', 'stabilized')),\n  effect_type VARCHAR(100) NOT NULL,\n  effect_magnitude FLOAT NOT NULL,\n  effect_bounds JSONB NOT NULL, -- {min: float, max: float}\n  seed VARCHAR(64) NOT NULL,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS artifact_activations (\n  id SERIAL PRIMARY KEY,\n  artifact_id INTEGER NOT NULL REFERENCES artifacts(id),\n  empire_id INTEGER NOT NULL REFERENCES empires(id),\n  activation_time TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  stabilizer_used BOOLEAN NOT NULL DEFAULT FALSE,\n  research_level INTEGER NOT NULL,\n  effect_applied JSONB NOT NULL,\n  safety_log TEXT NOT NULL\n);\n```\n\n2. Implement seeded artifact placement:\n   - Create a deterministic artifact generation function that uses a seed to place artifacts in exploration locations\n   - Ensure artifacts have bounded effect ranges that are deterministic based on the seed\n   - Implement different artifact types with varying effects (production boosts, research acceleration, resource generation, etc.)\n\n3. Implement artifact discovery API endpoint:\n```typescript\n// src/pages/api/artifacts/discover.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { prisma } from '@/lib/prisma';\nimport { getServerSession } from 'next-auth';\nimport { authOptions } from '@/pages/api/auth/[...nextauth]';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  const session = await getServerSession(req, res, authOptions);\n  if (!session) {\n    return res.status(401).json({ error: 'Unauthorized' });\n  }\n\n  const { locationId } = req.body;\n  if (!locationId) {\n    return res.status(400).json({ error: 'Location ID is required' });\n  }\n\n  try {\n    // Check if there's an artifact at this location\n    const artifact = await prisma.artifacts.findFirst({\n      where: {\n        location_id: locationId,\n        discovery_status: 'undiscovered'\n      }\n    });\n\n    if (!artifact) {\n      return res.status(404).json({ error: 'No artifact found at this location' });\n    }\n\n    // Update artifact status to discovered\n    const updatedArtifact = await prisma.artifacts.update({\n      where: { id: artifact.id },\n      data: { discovery_status: 'discovered' }\n    });\n\n    return res.status(200).json({ \n      message: 'Artifact discovered',\n      artifact: {\n        id: updatedArtifact.id,\n        name: updatedArtifact.name,\n        description: updatedArtifact.description,\n        effectType: updatedArtifact.effect_type\n      }\n    });\n  } catch (error) {\n    console.error('Error discovering artifact:', error);\n    return res.status(500).json({ error: 'Failed to discover artifact' });\n  }\n}\n```\n\n4. Implement artifact activation API endpoint with research/stabilizer gating:\n```typescript\n// src/pages/api/artifacts/activate.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { prisma } from '@/lib/prisma';\nimport { getServerSession } from 'next-auth';\nimport { authOptions } from '@/pages/api/auth/[...nextauth]';\nimport { seedrandom } from 'seedrandom';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  const session = await getServerSession(req, res, authOptions);\n  if (!session) {\n    return res.status(401).json({ error: 'Unauthorized' });\n  }\n\n  const { artifactId, useStabilizer } = req.body;\n  if (!artifactId) {\n    return res.status(400).json({ error: 'Artifact ID is required' });\n  }\n\n  try {\n    // Get the artifact\n    const artifact = await prisma.artifacts.findUnique({\n      where: { id: artifactId }\n    });\n\n    if (!artifact) {\n      return res.status(404).json({ error: 'Artifact not found' });\n    }\n\n    if (artifact.discovery_status !== 'discovered') {\n      return res.status(400).json({ error: 'Artifact cannot be activated in its current state' });\n    }\n\n    // Get empire research level\n    const empire = await prisma.empires.findUnique({\n      where: { id: session.user.empireId },\n      select: { research_level: true }\n    });\n\n    if (!empire) {\n      return res.status(404).json({ error: 'Empire not found' });\n    }\n\n    // Check if research level is sufficient (minimum level 3 required)\n    if (empire.research_level < 3) {\n      return res.status(400).json({ error: 'Insufficient research level to activate artifact' });\n    }\n\n    // Calculate effect based on seed, research level, and stabilizer use\n    const rng = seedrandom(artifact.seed + session.user.empireId.toString());\n    let effectMultiplier = rng() * (artifact.effect_bounds.max - artifact.effect_bounds.min) + artifact.effect_bounds.min;\n    \n    // Stabilizers reduce randomness and push toward max bound\n    if (useStabilizer) {\n      effectMultiplier = (effectMultiplier + artifact.effect_bounds.max) / 2;\n    }\n\n    // Apply research level bonus (5% per level above minimum)\n    const researchBonus = 1 + Math.max(0, (empire.research_level - 3) * 0.05);\n    effectMultiplier *= researchBonus;\n\n    // Cap at maximum bound\n    effectMultiplier = Math.min(effectMultiplier, artifact.effect_bounds.max * 1.5);\n\n    // Calculate final effect\n    const effectApplied = {\n      type: artifact.effect_type,\n      magnitude: artifact.effect_magnitude * effectMultiplier\n    };\n\n    // Generate safety log\n    const safetyLog = JSON.stringify({\n      timestamp: new Date().toISOString(),\n      artifactId: artifact.id,\n      empireId: session.user.empireId,\n      researchLevel: empire.research_level,\n      stabilizer: useStabilizer,\n      seed: artifact.seed,\n      calculatedEffect: effectApplied,\n      activationParameters: req.body\n    });\n\n    // Record activation\n    await prisma.artifact_activations.create({\n      data: {\n        artifact_id: artifact.id,\n        empire_id: session.user.empireId,\n        stabilizer_used: !!useStabilizer,\n        research_level: empire.research_level,\n        effect_applied: effectApplied,\n        safety_log: safetyLog\n      }\n    });\n\n    // Update artifact status\n    await prisma.artifacts.update({\n      where: { id: artifact.id },\n      data: { discovery_status: useStabilizer ? 'stabilized' : 'activated' }\n    });\n\n    // Apply effect to game state (this would integrate with the simulation engine)\n    // Implementation depends on effect type\n\n    return res.status(200).json({\n      message: 'Artifact activated successfully',\n      effect: effectApplied,\n      status: useStabilizer ? 'stabilized' : 'activated'\n    });\n  } catch (error) {\n    console.error('Error activating artifact:', error);\n    return res.status(500).json({ error: 'Failed to activate artifact' });\n  }\n}\n```\n\n5. Implement artifact listing API endpoint:\n```typescript\n// src/pages/api/artifacts/index.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { prisma } from '@/lib/prisma';\nimport { getServerSession } from 'next-auth';\nimport { authOptions } from '@/pages/api/auth/[...nextauth]';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'GET') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  const session = await getServerSession(req, res, authOptions);\n  if (!session) {\n    return res.status(401).json({ error: 'Unauthorized' });\n  }\n\n  try {\n    // Get all discovered artifacts for this empire\n    const artifacts = await prisma.artifacts.findMany({\n      where: {\n        discovery_status: { not: 'undiscovered' },\n        artifact_activations: {\n          some: { empire_id: session.user.empireId }\n        }\n      },\n      include: {\n        artifact_activations: {\n          where: { empire_id: session.user.empireId },\n          orderBy: { activation_time: 'desc' },\n          take: 1\n        }\n      }\n    });\n\n    return res.status(200).json({ \n      artifacts: artifacts.map(a => ({\n        id: a.id,\n        name: a.name,\n        description: a.description,\n        status: a.discovery_status,\n        effectType: a.effect_type,\n        lastActivation: a.artifact_activations[0] || null\n      }))\n    });\n  } catch (error) {\n    console.error('Error fetching artifacts:', error);\n    return res.status(500).json({ error: 'Failed to fetch artifacts' });\n  }\n}\n```\n\n6. Integration with simulation engine:\n   - Add an artifactsReducer to the simulation engine pipeline\n   - Ensure artifact effects are applied during simulation steps\n   - Implement time-based decay for artifact effects\n   - Add artifact effects to the KPI calculations\n\n7. Implement safety caps and audit logging:\n   - Ensure all artifact effects are bounded within predefined limits\n   - Log all artifact interactions with detailed parameters\n   - Create an admin endpoint for reviewing artifact activation logs\n   - Implement circuit breakers to disable artifacts if unexpected behavior is detected",
        "testStrategy": "1. Unit test the artifact generation system:\n   - Test with multiple seeds to verify deterministic placement\n   - Verify that the same seed always produces the same artifacts\n   - Check that artifact effects are within expected bounds\n   - Test edge cases for seed values\n\n2. Test the artifact discovery endpoint:\n   - Verify that undiscovered artifacts can be found at their locations\n   - Test that the endpoint correctly updates artifact status\n   - Verify that the endpoint returns appropriate error responses for invalid requests\n   - Test that artifacts cannot be discovered twice\n\n3. Test the artifact activation endpoint:\n   - Verify that activation requires sufficient research level\n   - Test that stabilizers correctly modify the effect calculation\n   - Verify that effects are bounded within the specified limits\n   - Test the safety logging system captures all relevant parameters\n   - Verify that activation status is correctly updated\n\n4. Test the artifacts listing endpoint:\n   - Verify that only discovered artifacts are returned\n   - Test filtering by different statuses\n   - Verify that artifact details are correctly formatted\n   - Test pagination and sorting options\n\n5. Integration tests:\n   - Test the full artifact lifecycle: generation → discovery → activation → effect application\n   - Verify that artifact effects are correctly applied in the simulation engine\n   - Test that artifact effects respect the bounded deterministic requirements\n   - Verify that the KPI calculations correctly incorporate artifact effects\n\n6. Safety and audit tests:\n   - Verify that all artifact interactions are properly logged\n   - Test the admin audit log review functionality\n   - Verify that circuit breakers correctly trigger on unexpected behavior\n   - Test that artifact effects cannot exceed maximum allowed values\n   - Verify that the system is resilient to malformed activation requests",
        "status": "pending",
        "dependencies": [
          1,
          2,
          13
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Database Schema for Artifacts System",
            "description": "Implement the database schema for artifacts and artifact activations to store all necessary data for the ancient artifacts system.",
            "dependencies": [],
            "details": "Create a migration file to add the artifacts and artifact_activations tables to the database. The artifacts table should store information about each artifact including its name, description, location, discovery status, effect type, effect magnitude, effect bounds, and a seed for deterministic generation. The artifact_activations table should track each activation event with details about the empire, research level, stabilizer usage, applied effect, and safety logs.",
            "status": "pending",
            "testStrategy": "Test the database schema by creating test artifacts and activations, verifying constraints work correctly, and ensuring relationships between tables function as expected. Test edge cases for the discovery_status check constraint."
          },
          {
            "id": 2,
            "title": "Implement Seeded Artifact Generation System",
            "description": "Create a deterministic artifact generation function that uses a seed to place artifacts in exploration locations with bounded effect ranges.",
            "dependencies": [
              "14.1"
            ],
            "details": "Develop a utility function that takes a seed value and generates artifacts with deterministic properties. The function should place artifacts in exploration locations based on the seed, determine effect types (production boosts, research acceleration, resource generation, etc.), and set bounded effect ranges. Ensure that the same seed always produces the same artifacts with the same properties. Store the generated artifacts in the database.",
            "status": "pending",
            "testStrategy": "Test with multiple seeds to verify deterministic placement. Verify that the same seed always produces the same artifacts. Check that artifact effects are within expected bounds. Test edge cases for seed values."
          },
          {
            "id": 3,
            "title": "Implement Artifact Discovery API Endpoint",
            "description": "Create an API endpoint that allows players to discover artifacts at exploration locations and updates their discovery status.",
            "dependencies": [
              "14.1",
              "14.2"
            ],
            "details": "Implement the POST /api/artifacts/discover endpoint that accepts a locationId and checks if there's an undiscovered artifact at that location. If found, update its status to 'discovered' and return basic information about the artifact to the client. Include proper authentication, error handling, and validation.",
            "status": "pending",
            "testStrategy": "Test the endpoint with valid and invalid location IDs. Verify authentication requirements. Ensure the discovery status is correctly updated in the database. Test error handling for cases where no artifact exists at the location."
          },
          {
            "id": 4,
            "title": "Implement Artifact Activation API Endpoint",
            "description": "Create an API endpoint that allows players to activate discovered artifacts using research levels and optional stabilizers.",
            "dependencies": [
              "14.3"
            ],
            "details": "Implement the POST /api/artifacts/activate endpoint that processes artifact activation requests. The endpoint should verify the artifact's current status, check the empire's research level (minimum level 3), calculate effects based on the artifact's seed, research level, and stabilizer usage, generate comprehensive safety logs, and update the artifact's status to 'activated' or 'stabilized'. Include proper validation and error handling.",
            "status": "pending",
            "testStrategy": "Test activation with different research levels and with/without stabilizers. Verify effect calculations are deterministic based on the seed. Test error cases including insufficient research level and invalid artifact states. Verify safety logs are properly generated."
          },
          {
            "id": 5,
            "title": "Implement Artifact Listing API Endpoint",
            "description": "Create an API endpoint that retrieves all discovered artifacts for the current empire with their status and activation history.",
            "dependencies": [
              "14.3"
            ],
            "details": "Implement the GET /api/artifacts endpoint that returns a list of all artifacts discovered by the current empire. Include information about each artifact's status, effect type, and last activation details. Filter out undiscovered artifacts and ensure proper authentication.",
            "status": "pending",
            "testStrategy": "Test the endpoint returns only artifacts discovered by the current empire. Verify the correct activation history is included. Test with empires that have no discovered artifacts. Ensure authentication requirements are enforced."
          },
          {
            "id": 6,
            "title": "Integrate Artifacts with Simulation Engine",
            "description": "Add artifact effects to the simulation engine and implement safety mechanisms for artifact interactions.",
            "dependencies": [
              "14.4"
            ],
            "details": "Create an artifactsReducer for the simulation engine pipeline that applies artifact effects during simulation steps. Implement time-based decay for artifact effects. Add artifact effects to KPI calculations. Implement safety caps to ensure all artifact effects are bounded within predefined limits. Create comprehensive audit logging for all artifact interactions and implement circuit breakers to disable artifacts if unexpected behavior is detected. Add an admin endpoint for reviewing artifact activation logs.",
            "status": "pending",
            "testStrategy": "Test that artifact effects are correctly applied in the simulation. Verify that safety caps prevent excessive effects. Test the audit logging system captures all relevant details. Verify that circuit breakers trigger appropriately for anomalous behavior. Test time-based decay of artifact effects."
          }
        ]
      },
      {
        "id": 15,
        "title": "Implement Technology Tree System",
        "description": "Create a deterministic technology tree system with directed acyclic graph structure, research state machine, and API endpoints for retrieving the tech tree, initiating research, and checking research state.",
        "details": "Implement a comprehensive technology tree system with the following components:\n\n1. Database schema for technology tree:\n```sql\nCREATE TABLE IF NOT EXISTS technologies (\n  id SERIAL PRIMARY KEY,\n  name VARCHAR(255) NOT NULL,\n  description TEXT NOT NULL,\n  category VARCHAR(50) NOT NULL CHECK (category IN ('history', 'fiction', 'hybrid')),\n  tier INTEGER NOT NULL,\n  research_cost INTEGER NOT NULL,\n  research_time INTEGER NOT NULL,\n  effects JSONB NOT NULL,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS technology_prerequisites (\n  id SERIAL PRIMARY KEY,\n  technology_id INTEGER NOT NULL REFERENCES technologies(id),\n  prerequisite_id INTEGER NOT NULL REFERENCES technologies(id),\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  UNIQUE(technology_id, prerequisite_id)\n);\n\nCREATE TABLE IF NOT EXISTS empire_research (\n  id SERIAL PRIMARY KEY,\n  empire_id INTEGER NOT NULL REFERENCES empires(id),\n  technology_id INTEGER NOT NULL REFERENCES technologies(id),\n  status VARCHAR(50) NOT NULL CHECK (status IN ('not_started', 'in_progress', 'completed')),\n  progress INTEGER NOT NULL DEFAULT 0,\n  started_at TIMESTAMP WITH TIME ZONE,\n  completed_at TIMESTAMP WITH TIME ZONE,\n  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n  UNIQUE(empire_id, technology_id)\n);\n```\n\n2. Technology DAG implementation:\n   - Create a TechnologyGraph class that manages the directed acyclic graph structure\n   - Implement methods to validate the graph (no cycles, proper prerequisites)\n   - Ensure deterministic generation of the tech tree based on a seed\n   - Implement methods to check if a technology is available for research\n\n```typescript\n// src/server/models/TechnologyGraph.ts\nimport { seedrandom } from 'seedrandom';\n\nexport class TechnologyGraph {\n  private nodes: Map<string, Technology>;\n  private edges: Map<string, string[]>;\n  \n  constructor(seed: string) {\n    this.nodes = new Map();\n    this.edges = new Map();\n    this.generateGraph(seed);\n  }\n  \n  private generateGraph(seed: string): void {\n    const rng = seedrandom(seed);\n    // Generate deterministic technology tree based on seed\n    // ...\n  }\n  \n  public isAvailableForResearch(technologyId: string, completedTechs: string[]): boolean {\n    // Check if all prerequisites are completed\n    const prerequisites = this.edges.get(technologyId) || [];\n    return prerequisites.every(prereqId => completedTechs.includes(prereqId));\n  }\n  \n  public validateGraph(): boolean {\n    // Check for cycles and other validation\n    // ...\n    return true;\n  }\n}\n```\n\n3. Research state machine:\n   - Implement a state machine for research progress (not_started → in_progress → completed)\n   - Create functions to update research progress based on empire resources and time\n   - Ensure research costs and times are respected\n   - Implement bounded effects for completed technologies\n\n```typescript\n// src/server/models/ResearchManager.ts\nexport class ResearchManager {\n  public async startResearch(empireId: number, technologyId: number): Promise<boolean> {\n    // Check prerequisites\n    // Update database\n    // Return success/failure\n  }\n  \n  public async updateResearchProgress(empireId: number): Promise<void> {\n    // Calculate progress based on time and resources\n    // Update state if research is completed\n  }\n  \n  public async applyTechnologyEffects(empireId: number, technologyId: number): Promise<void> {\n    // Apply bounded effects to empire stats\n  }\n}\n```\n\n4. API endpoints implementation:\n   - GET /tech/tree: Return the full technology tree with nodes and edges\n   - POST /tech/research: Start researching a specific technology\n   - GET /tech/state: Get the current research state for an empire\n\n```typescript\n// src/pages/api/tech/tree.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { prisma } from '@/server/db';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'GET') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n  \n  try {\n    const technologies = await prisma.technologies.findMany();\n    const prerequisites = await prisma.technology_prerequisites.findMany();\n    \n    return res.status(200).json({\n      nodes: technologies,\n      edges: prerequisites\n    });\n  } catch (error) {\n    console.error('Error fetching technology tree:', error);\n    return res.status(500).json({ error: 'Failed to fetch technology tree' });\n  }\n}\n\n// src/pages/api/tech/research.ts\nimport { NextApiRequest, NextApiResponse } from 'next';\nimport { ResearchManager } from '@/server/models/ResearchManager';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  if (req.method !== 'POST') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n  \n  const { empireId, technologyId } = req.body;\n  \n  if (!empireId || !technologyId) {\n    return res.status(400).json({ error: 'Missing required fields' });\n  }\n  \n  try {\n    const researchManager = new ResearchManager();\n    const success = await researchManager.startResearch(empireId, technologyId);\n    \n    if (success) {\n      return res.status(200).json({ message: 'Research started successfully' });\n    } else {\n      return res.status(400).json({ error: 'Cannot research this technology yet' });\n    }\n  } catch (error) {\n    console.error('Error starting research:', error);\n    return res.status(500).json({ error: 'Failed to start research' });\n  }\n}\n\n// src/pages/api/tech/state.ts\n// Similar implementation for getting research state\n```\n\n5. Integration with simulation engine:\n   - Update the simulation engine to process research progress on each tick\n   - Apply technology effects when research is completed\n   - Ensure deterministic behavior with the same seed",
        "testStrategy": "1. Unit test the technology DAG implementation:\n   - Test graph validation to ensure no cycles are allowed\n   - Verify that prerequisites are correctly enforced\n   - Test with multiple seeds to ensure deterministic generation\n   - Verify that the same seed always produces the same technology tree\n\n2. Test the research state machine:\n   - Verify transitions between states (not_started → in_progress → completed)\n   - Test edge cases like attempting to research unavailable technologies\n   - Verify that research progress is calculated correctly\n   - Test that research completion triggers the appropriate effects\n\n3. API endpoint testing:\n   - Test GET /tech/tree to verify it returns the complete technology tree\n   - Test POST /tech/research with valid and invalid inputs\n   - Verify authentication and authorization for research actions\n   - Test GET /tech/state to ensure it returns the correct research state\n\n4. Integration tests:\n   - Verify that technology effects are properly applied when research completes\n   - Test the interaction between the technology system and other game systems\n   - Ensure that research progress is correctly updated during simulation ticks\n\n5. Determinism tests:\n   - Run multiple simulations with the same seed and verify identical outcomes\n   - Test technology unlock rules with various empire states\n   - Verify that technology effects are bounded within specified caps",
        "status": "pending",
        "dependencies": [
          1,
          2,
          9
        ],
        "priority": "high",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-08-14T08:17:06.033Z",
      "updated": "2025-08-14T20:26:09.660Z",
      "description": "Unified Sprint 11: Simulation Advanced & Consistency",
      "copiedFrom": {
        "tag": "sprint-a-sim-engine",
        "date": "2025-08-14T08:17:06.033Z"
      }
    }
  },
  "sprint-12-performance": {
    "tasks": [
      {
        "id": 12,
        "title": "Implement Performance Optimization for 50-Player Sessions",
        "description": "Optimize system performance to support 50 concurrent players with acceptable response times and stability.",
        "details": "Implement the following optimizations:\n\n1. Action Batching:\n- Group similar actions for efficient processing\n- Prioritize critical real-time updates\n- Optimize WebSocket message frequency\n\n2. Database Optimization:\n- Index tuning for common queries\n- Connection pooling configuration\n- Query optimization for high-volume operations\n\n3. Caching Strategy:\n- Implement multi-level caching\n- Cache invalidation policies\n- Distributed cache for session data\n\n4. Load Testing Framework:\n- Simulate 50-player sessions\n- Measure response times and resource usage\n- Identify and resolve bottlenecks\n\n5. Monitoring System:\n- Real-time performance metrics\n- Alerting for degraded performance\n- Diagnostic tools for issue resolution\n\nImplement horizontal scaling for key services. Optimize network communication patterns for reduced latency.",
        "testStrategy": "Load tests with simulated 50-player sessions. Performance profiling to identify bottlenecks. Verification that GM summary median is less than 4.5s at 50 participants as specified in requirements. Stability testing for voice communication across teams.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Action Batching System",
            "description": "Develop a system to group similar actions for efficient processing, prioritize critical real-time updates, and optimize WebSocket message frequency.",
            "dependencies": [],
            "details": "Create a batching mechanism that groups similar player actions to reduce processing overhead. Implement priority queues for critical real-time updates. Optimize WebSocket communication by reducing message frequency through intelligent bundling. Include configuration parameters for batch size and timing thresholds. Develop fallback mechanisms for high-priority actions that cannot be delayed.",
            "status": "pending",
            "testStrategy": "Measure message throughput with and without batching. Verify critical actions are processed with appropriate priority. Test with simulated high-frequency actions from 50 concurrent players."
          },
          {
            "id": 2,
            "title": "Optimize Database Performance",
            "description": "Tune database indexes for common queries, configure connection pooling, and optimize queries for high-volume operations.",
            "dependencies": [
              "12.1"
            ],
            "details": "Analyze query patterns and create appropriate indexes for frequently accessed data. Configure connection pooling parameters for optimal resource utilization. Rewrite high-volume queries to minimize execution time and resource consumption. Implement query caching where appropriate. Consider database sharding strategies for horizontal scaling of player data.",
            "status": "pending",
            "testStrategy": "Benchmark query performance before and after optimization. Test connection pool under simulated load of 50 concurrent players. Verify query execution plans are optimal for common operations."
          },
          {
            "id": 3,
            "title": "Implement Multi-level Caching Strategy",
            "description": "Design and implement a multi-level caching system with appropriate invalidation policies and distributed cache for session data.",
            "dependencies": [
              "12.2"
            ],
            "details": "Implement in-memory caching for frequently accessed data. Set up distributed cache using Redis or similar technology for session data. Define cache invalidation policies based on data update patterns. Create cache warming mechanisms for predictable data access. Implement cache hit/miss metrics for performance monitoring.",
            "status": "pending",
            "testStrategy": "Measure system performance with and without caching enabled. Test cache invalidation correctness under various update scenarios. Verify distributed cache consistency across multiple server instances."
          },
          {
            "id": 4,
            "title": "Develop Load Testing Framework",
            "description": "Create a framework to simulate 50-player sessions, measure response times and resource usage, and identify performance bottlenecks.",
            "dependencies": [
              "12.1",
              "12.2",
              "12.3"
            ],
            "details": "Develop automated load testing scripts that simulate realistic player behavior. Implement metrics collection for response times, CPU/memory usage, and network throughput. Create visualization tools for performance data analysis. Design tests for specific scenarios like combat, inventory management, and social interactions. Include gradual scaling tests from 10 to 50 players to identify scaling issues.",
            "status": "pending",
            "testStrategy": "Run load tests with increasing player counts to identify scaling limits. Verify GM summary median is less than 4.5s at 50 participants. Test stability of voice communication across teams under load."
          },
          {
            "id": 5,
            "title": "Implement Performance Monitoring System",
            "description": "Set up real-time performance metrics, alerting for degraded performance, and diagnostic tools for issue resolution.",
            "dependencies": [
              "12.4"
            ],
            "details": "Integrate APM (Application Performance Monitoring) tools to track system performance in real-time. Configure alerting thresholds for key metrics like response time, error rates, and resource utilization. Develop custom dashboards for visualizing performance data. Implement logging enhancements for easier troubleshooting. Create automated reports for performance trends over time.",
            "status": "pending",
            "testStrategy": "Verify alerts trigger appropriately when performance degrades. Test diagnostic tools by introducing controlled performance issues. Confirm monitoring system can handle the additional load without significant performance impact."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-14T08:17:17.748Z",
      "updated": "2025-08-14T08:17:17.748Z",
      "description": "Unified Sprint 12: Performance @50 (Hardening)",
      "copiedFrom": {
        "tag": "feature-live-ops",
        "date": "2025-08-14T08:17:17.748Z"
      }
    }
  },
  "sprint-3-policies": {
    "tasks": [
      {
        "id": 1,
        "title": "Set up Project Structure and Environment for Policy Drafting Copilot",
        "description": "Create the initial project structure, configure the development environment, and establish the foundational architecture for the Policy Drafting Copilot application.",
        "details": "This task involves setting up the core project structure and development environment for the Policy Drafting Copilot application. The implementation should include:\n\n1. Initialize a new project repository with appropriate version control\n2. Set up the development environment with necessary dependencies and tools\n3. Create the basic directory structure:\n   - `/src` - Source code\n   - `/tests` - Test files\n   - `/docs` - Documentation\n   - `/examples` - Example usage\n   - `/api` - API integration code\n\n4. Configure build tools and package management\n5. Set up linting and code formatting tools\n6. Create initial configuration files for the application\n7. Establish the basic architecture for the application:\n   - Define the core modules (NL parser, bill text generator, fiscal note generator, modifier proposal)\n   - Create placeholder files for API integration with `/api/policies`\n   - Set up the validation framework for caps/decay/backfire rules\n\n8. Create a README.md with project overview, setup instructions, and contribution guidelines\n9. Set up continuous integration pipeline for automated testing\n10. Document the architecture decisions and technical approach",
        "testStrategy": "To verify the correct implementation of this task:\n\n1. Ensure all directories and files are created according to the specified structure\n2. Verify that the development environment can be set up by a new developer by following the README instructions\n3. Run a basic smoke test to confirm the environment is working:\n   - Execute build commands\n   - Run linting tools\n   - Execute any placeholder tests\n   \n4. Verify that the continuous integration pipeline is properly configured:\n   - Push a test commit to trigger the CI pipeline\n   - Confirm that the pipeline runs successfully\n   \n5. Review the architecture documentation to ensure it aligns with the requirements\n6. Validate that placeholder modules for all required components exist\n7. Ensure the project can be built without errors\n8. Verify that the API integration structure is in place\n9. Check that the validation framework structure is established\n10. Have another team member attempt to clone and set up the project to verify documentation completeness",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Implement AI Constitutional Court Validator",
        "description": "Develop a validator component that reviews proposed policies against constitutional constraints defined by government archetypes, providing deterministic accept/reject decisions with rationales.",
        "details": "The AI Constitutional Court Validator implementation should include:\n\n1. Create a validator service module in the project structure:\n   - `/src/services/constitutional-validator.js`\n   - `/src/models/validation-result.js`\n\n2. Define interfaces for the validator:\n   - Input: Policy proposal object with metadata\n   - Output: Validation result with accept/reject decision and detailed rationale\n\n3. Implement the core validation logic:\n   - Load constitutional constraints from government archetype definitions\n   - Parse policy proposals into analyzable components\n   - Apply rule-based validation against constitutional constraints\n   - Generate comprehensive rationale for decisions with reference to specific constraints\n\n4. Create deterministic decision engine:\n   - Ensure consistent results for identical inputs\n   - Implement weighted scoring system for partial compliance scenarios\n   - Define clear thresholds for acceptance/rejection\n\n5. Develop integration with policy activation endpoint:\n   - Create HTTP client for policy activation API\n   - Implement conditional activation based on validation results\n   - Add logging and error handling for activation attempts\n\n6. Add configuration options:\n   - Validation strictness levels\n   - Custom rule weighting\n   - Override capabilities with appropriate authorization\n\n7. Document the validator API and integration points with examples",
        "testStrategy": "The validation component should be thoroughly tested using:\n\n1. Unit tests:\n   - Test validation logic with various policy inputs\n   - Verify correct constraint application for each government archetype\n   - Ensure deterministic results with identical inputs\n   - Test edge cases (empty policies, malformed inputs)\n\n2. Integration tests:\n   - Verify correct integration with policy activation endpoint\n   - Test end-to-end flow from policy submission to validation to activation/rejection\n   - Validate proper error handling and logging\n\n3. Rule coverage tests:\n   - Create test suite that exercises each constitutional constraint\n   - Verify both positive (compliant) and negative (non-compliant) test cases\n   - Measure and report on rule coverage metrics\n\n4. Performance tests:\n   - Benchmark validation speed for various policy sizes\n   - Test system under load with concurrent validation requests\n\n5. Manual validation:\n   - Review sample rationales for clarity and correctness\n   - Verify that explanations reference appropriate constitutional constraints",
        "status": "pending",
        "dependencies": [
          1
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Implement Persona Advisors System",
        "description": "Develop a diegetic persona advisors system with persistent style and memory, bounded by constitutional powers, that connects to the validator to produce capped policy proposals.",
        "details": "The Persona Advisors implementation should include:\n\n1. Create the persona advisors module structure:\n   - `/src/services/persona-advisors.js`\n   - `/src/models/persona.js`\n   - `/src/models/proposal.js`\n\n2. Implement core persona functionality:\n   - Define persona class with persistent memory and style attributes\n   - Implement natural language only output constraints\n   - Create seeding mechanism linked to snapshot hash for reproducibility\n   - Build connection interface to the constitutional validator\n\n3. Develop persona bounds enforcement:\n   - Implement constitutional power boundaries\n   - Create middleware to ensure all outputs conform to persona limitations\n   - Design capping mechanism for proposal generation\n\n4. Integrate with validator component:\n   - Create adapter between persona output and validator input\n   - Implement feedback loop for rejected proposals\n   - Build proposal refinement based on validator rationale\n\n5. Implement persona state management:\n   - Design persistence layer for persona memory\n   - Create serialization/deserialization for persona state\n   - Implement state rollback capabilities for testing\n\n6. Create persona seeding system:\n   - Develop deterministic initialization from snapshot hash\n   - Implement persona template library\n   - Build persona configuration interface",
        "testStrategy": "The Persona Advisors system should be thoroughly tested using:\n\n1. Unit tests:\n   - Test persona initialization with various seed hashes\n   - Verify persistence of style and memory across sessions\n   - Ensure all outputs are natural language only\n   - Test constitutional bounds enforcement\n   - Verify connection to validator produces expected results\n\n2. Integration tests:\n   - Test end-to-end flow from persona advice to validated proposals\n   - Verify proposal capping mechanisms work as expected\n   - Test interaction between personas and validator component\n   - Ensure proper handling of rejected proposals\n\n3. Replayability tests:\n   - Verify identical inputs and seeds produce identical personas\n   - Test state serialization and restoration\n   - Ensure deterministic behavior with controlled inputs\n\n4. Boundary tests:\n   - Test persona behavior at constitutional power limits\n   - Verify graceful handling of edge cases\n   - Ensure proper error handling for invalid inputs\n\n5. Performance tests:\n   - Measure memory usage during extended persona sessions\n   - Test response time for proposal generation\n   - Verify scalability with multiple concurrent personas",
        "status": "pending",
        "dependencies": [
          1,
          2
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Implement Legislative Bodies MVP with Bill Pipeline",
        "description": "Develop a configurable legislative system with a complete bill pipeline supporting unicameral/bicameral configurations, voting logic, and coalition discipline, with deterministic bill text canonicalization and required API endpoints.",
        "details": "The Legislative Bodies MVP implementation should include:\n\n1. Create the legislative system module structure:\n   - `/src/services/legislature.js`\n   - `/src/models/bill.js`\n   - `/src/models/legislature-config.js`\n   - `/src/models/vote.js`\n   - `/src/controllers/legislature-controller.js`\n\n2. Implement the bill pipeline stages:\n   - Draft: Initial bill creation with metadata and text\n   - Committee: Review process with configurable committee structure\n   - Floor: Full chamber voting with quorum requirements\n   - Conference (for bicameral): Reconciliation between chambers\n   - Final: Consolidated bill version\n   - Sign/Veto: Executive action\n   - Override: Legislative override of executive veto\n\n3. Develop configuration system for legislature:\n   - Unicameral vs. bicameral structure\n   - Customizable thresholds for passage at each stage\n   - Quorum requirements\n   - Coalition discipline parameters (voting bloc behavior)\n\n4. Implement deterministic bill text canonicalization:\n   - Create a standardized format for bill text\n   - Implement hash-based verification of bill content\n   - Ensure identical semantic content always produces identical canonical form\n   - Handle amendments and changes while maintaining traceability\n\n5. Create required API endpoints:\n   - `POST /gov/legislature/bill` - Create new bill\n   - `POST /gov/legislature/vote` - Record votes on bills\n   - `POST /gov/legislature/advance` - Move bill to next stage in pipeline\n\n6. Integrate with existing components:\n   - Connect with constitutional validator for bill compliance checks\n   - Interface with persona advisors for bill sponsorship and voting behavior\n\n7. Implement deterministic outcome logic:\n   - Ensure identical inputs always produce identical legislative outcomes\n   - Add capability to cap/limit extreme legislative outcomes\n   - Create reproducible voting patterns based on seed values",
        "testStrategy": "The Legislative Bodies MVP should be thoroughly tested using:\n\n1. Unit tests:\n   - Test each pipeline stage transition with various inputs\n   - Verify correct application of voting thresholds and quorum requirements\n   - Test unicameral and bicameral configurations separately\n   - Ensure coalition discipline logic works as expected\n   - Verify deterministic canonicalization with identical and similar bill texts\n   - Test all API endpoints with valid and invalid inputs\n\n2. Integration tests:\n   - Test complete bill lifecycle from draft to final disposition\n   - Verify interaction with constitutional validator\n   - Test integration with persona advisors for voting behavior\n   - Ensure proper state management across pipeline stages\n\n3. Determinism tests:\n   - Run identical scenarios multiple times to verify consistent outcomes\n   - Test with different random seeds to ensure reproducibility\n   - Verify that capping mechanisms properly limit extreme outcomes\n\n4. Performance tests:\n   - Measure throughput for large numbers of bills and votes\n   - Test canonicalization performance with large bill texts\n   - Verify system handles complex bicameral negotiations efficiently\n\n5. API contract tests:\n   - Verify all endpoints conform to OpenAPI specifications\n   - Test response formats and error handling\n   - Ensure proper authentication and authorization",
        "status": "pending",
        "dependencies": [
          1,
          2
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Legislative System Module Structure",
            "description": "Set up the foundational file structure for the legislative system, including service, models, and controller files with basic interfaces defined.",
            "dependencies": [],
            "details": "Create the following files with basic structure and exports:\n1. `/src/services/legislature.js`: Define core service functions for managing the legislative process\n2. `/src/models/bill.js`: Create Bill class with properties for stages, text, metadata, and voting history\n3. `/src/models/legislature-config.js`: Define configuration schema for unicameral/bicameral settings\n4. `/src/models/vote.js`: Create Vote class with member, position, and timestamp\n5. `/src/controllers/legislature-controller.js`: Set up API route handlers for bill operations",
            "status": "pending",
            "testStrategy": "Verify file structure is correctly created. Write unit tests for basic model instantiation and property access. Test service module imports and exports."
          },
          {
            "id": 2,
            "title": "Implement Bill Pipeline Stages and Workflow",
            "description": "Develop the core bill pipeline functionality with all required stages from draft to override, including state transitions and validation logic.",
            "dependencies": [
              "4.1"
            ],
            "details": "In `/src/services/legislature.js`, implement:\n1. Define enum for bill stages (DRAFT, COMMITTEE, FLOOR, CONFERENCE, FINAL, SIGN_VETO, OVERRIDE)\n2. Create stage transition functions with validation rules\n3. Implement committee review process with configurable structure\n4. Build floor voting mechanism with quorum validation\n5. Add conference reconciliation for bicameral legislatures\n6. Create executive action (sign/veto) processing\n7. Implement veto override logic with appropriate thresholds",
            "status": "pending",
            "testStrategy": "Test each pipeline stage transition with various inputs. Verify correct stage progression and rejection of invalid transitions. Test edge cases like failed votes and vetoes."
          },
          {
            "id": 3,
            "title": "Develop Legislature Configuration System",
            "description": "Create a flexible configuration system that supports both unicameral and bicameral structures with customizable voting thresholds, quorum requirements, and coalition discipline parameters.",
            "dependencies": [
              "4.1"
            ],
            "details": "In `/src/models/legislature-config.js`:\n1. Implement configuration schema with structure type (unicameral/bicameral)\n2. Add customizable passage thresholds for each pipeline stage\n3. Create quorum requirement settings for different vote types\n4. Implement coalition discipline parameters to control voting bloc behavior\n5. Add validation functions to ensure configuration consistency\n6. Create default configurations for common legislature types\n7. Build configuration loading and application functions",
            "status": "pending",
            "testStrategy": "Test configuration validation with valid and invalid inputs. Verify that unicameral and bicameral configurations produce correct behavior. Test coalition discipline parameters with various voting scenarios."
          },
          {
            "id": 4,
            "title": "Implement Bill Text Canonicalization",
            "description": "Create a system for deterministic bill text canonicalization that ensures identical semantic content always produces the same canonical form, with support for amendments and change tracking.",
            "dependencies": [
              "4.1"
            ],
            "details": "In `/src/models/bill.js` and `/src/services/legislature.js`:\n1. Define standardized format for bill text with sections, clauses, and metadata\n2. Implement text normalization functions (whitespace, punctuation, capitalization)\n3. Create hash-based verification system for bill content integrity\n4. Build amendment tracking system that preserves change history\n5. Implement semantic comparison functions to identify identical content\n6. Create functions to generate canonical text representation\n7. Add versioning system for bill revisions",
            "status": "pending",
            "testStrategy": "Test canonicalization with various text inputs to verify identical semantic content produces identical canonical forms. Test amendment application and tracking. Verify hash consistency across equivalent bills with different formatting."
          },
          {
            "id": 5,
            "title": "Create API Endpoints for Legislative Operations",
            "description": "Implement the required API endpoints for bill creation, voting, and pipeline advancement, with proper request validation and response formatting.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.4"
            ],
            "details": "In `/src/controllers/legislature-controller.js`:\n1. Implement `POST /gov/legislature/bill` endpoint for bill creation\n   - Validate bill text and metadata\n   - Apply canonicalization\n   - Store in appropriate data structure\n2. Create `POST /gov/legislature/vote` endpoint for recording votes\n   - Validate voter eligibility and quorum requirements\n   - Process coalition discipline effects\n   - Update bill status based on voting outcome\n3. Build `POST /gov/legislature/advance` endpoint for pipeline progression\n   - Validate current stage and requirements for advancement\n   - Apply stage-specific processing logic\n   - Update bill status and history",
            "status": "pending",
            "testStrategy": "Test API endpoints with valid and invalid requests. Verify correct response codes and formats. Test authentication and authorization if applicable. Ensure endpoints correctly interact with the legislature service."
          },
          {
            "id": 6,
            "title": "Integrate with Existing Components and Implement Deterministic Outcomes",
            "description": "Connect the legislative system with constitutional validator and persona advisors, while ensuring deterministic outcomes for identical inputs with capability to limit extreme results.",
            "dependencies": [
              "4.2",
              "4.3",
              "4.5"
            ],
            "details": "1. Connect with constitutional validator:\n   - Import validator service in legislature service\n   - Add validation checks at appropriate pipeline stages\n   - Handle validation failures appropriately\n2. Interface with persona advisors:\n   - Create functions for bill sponsorship assignment\n   - Implement voting behavior based on persona profiles\n   - Add bill recommendation system\n3. Implement deterministic outcome logic:\n   - Use seed values for reproducible voting patterns\n   - Create deterministic random number generator for voting decisions\n   - Implement caps/limits for extreme legislative outcomes\n   - Add logging for outcome traceability\n4. Create comprehensive integration tests",
            "status": "pending",
            "testStrategy": "Test integration with validator using mock constitutional constraints. Verify persona advisor integration with various persona types. Test deterministic outcomes by running identical scenarios with same seeds and verifying consistent results. Test outcome limiting functionality with extreme inputs."
          }
        ]
      },
      {
        "id": 5,
        "title": "UI Spec: Policy Console & Legislature Interface",
        "description": "Define the UI specifications for the Policy Console and Legislature interfaces, including the policy editor/effects panel, advisor proposals, bills table with stage chips, and detail drawer components.",
        "details": "The UI specification for the Policy Console and Legislature interfaces should include:\n\n1. Policy Console Components:\n   - Policy Editor Panel:\n     - Create a rich text editor component for policy drafting\n     - Implement syntax highlighting for policy language\n     - Add version history tracking UI elements\n     - Design save/publish controls with appropriate validation states\n   - Effects Panel:\n     - Develop visualization components for policy impact metrics\n     - Create collapsible sections for different impact categories\n     - Implement tooltips for explaining complex metrics\n     - Design comparison view for before/after policy changes\n   - Advisor Proposals Section:\n     - Design card-based UI for advisor proposals\n     - Implement filtering and sorting controls\n     - Create acceptance/rejection interaction flows\n     - Add persona avatar and styling consistent with advisor personalities\n\n2. Legislature Interface:\n   - Bills Table:\n     - Design responsive table with sortable columns\n     - Implement stage chips with distinct visual states (Draft, Committee, Floor, Passed, Failed)\n     - Create pagination and search functionality\n     - Add quick-action buttons for common operations\n   - Detail Drawer:\n     - Design expandable drawer for bill details\n     - Create tabbed interface for bill text, voting history, and amendments\n     - Implement comment/annotation UI elements\n     - Add voting controls for appropriate user roles\n\n3. Component Contracts:\n   - Define clear component interfaces with required props and events\n   - Document state management approach for each component\n   - Specify accessibility requirements (ARIA roles, keyboard navigation)\n   - Create component hierarchy diagram showing relationships\n\n4. Test IDs:\n   - Define consistent test-id naming convention\n   - Document required test-ids for all interactive elements\n   - Create a test-id registry to prevent duplicates\n   - Specify data-testid attributes for automated testing\n\n5. Design Integration:\n   - Link to design assets in `/design/ui_visual_design.md`\n   - Document color schemes, typography, and spacing guidelines\n   - Specify responsive breakpoints and behavior\n   - Define animation and transition specifications\n\n6. Implementation Guidelines:\n   - Recommend component library usage where appropriate\n   - Specify state management patterns for complex interactions\n   - Document accessibility compliance requirements\n   - Define performance expectations and optimization strategies",
        "testStrategy": "The UI specification should be thoroughly tested using:\n\n1. Design Review:\n   - Conduct a formal review with designers to ensure alignment with visual design documents\n   - Verify that all components match the style guide specifications\n   - Confirm that responsive behaviors are clearly defined\n   - Validate that all interaction states are documented\n\n2. Developer Review:\n   - Have frontend developers review component contracts for completeness\n   - Verify that all required props, events, and behaviors are specified\n   - Ensure test-id conventions are clear and comprehensive\n   - Confirm that state management approaches are well-defined\n\n3. Prototype Testing:\n   - Create low-fidelity prototypes of key interfaces\n   - Test user flows through critical paths\n   - Verify that all user stories can be completed with the specified components\n   - Document any usability concerns for refinement\n\n4. Accessibility Audit:\n   - Review specifications against WCAG 2.1 AA standards\n   - Verify that keyboard navigation paths are defined\n   - Ensure color contrast requirements are specified\n   - Confirm that screen reader considerations are documented\n\n5. Implementation Validation:\n   - Create a checklist of UI specification requirements\n   - Verify each component against the specification during implementation\n   - Test all interactive elements with defined test-ids\n   - Validate responsive behavior across device sizes\n\n6. User Testing Plan:\n   - Define specific user testing scenarios for the implemented UI\n   - Create task completion criteria for each major interface\n   - Specify metrics for measuring UI effectiveness\n   - Document approach for collecting and incorporating user feedback",
        "status": "pending",
        "dependencies": [
          1,
          3,
          4
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Implement Lobbying & Disclosures System",
        "description": "Develop a lobbying and disclosures system that tracks entities, sectors, and budgets, with transparency mechanisms and bounded influence effects on agenda and scheduling.",
        "details": "The Lobbying & Disclosures system implementation should include:\n\n1. Create the module structure:\n   - `/src/services/lobbying-service.js`\n   - `/src/models/lobby-entity.js`\n   - `/src/models/lobby-disclosure.js`\n   - `/src/models/lobby-contribution.js`\n   - `/src/controllers/lobbying-controller.js`\n\n2. Implement the entity registry:\n   - Create database schema for lobbying entities with fields for name, type, sector, and budget\n   - Implement validation rules for entity registration (required fields, budget ranges)\n   - Add support for entity relationships (parent/subsidiary connections)\n   - Build indexing for efficient sector-based queries\n\n3. Develop the disclosure system:\n   - Implement disclosure records with timestamps, entities, targets, and amounts\n   - Create aggregation functions for reporting total influence by entity/sector\n   - Add transparency mechanisms that expose disclosures publicly\n   - Implement backfire effects when influence exceeds thresholds\n\n4. Build bounded influence effects:\n   - Connect lobbying activities to agenda-setting in legislative bodies\n   - Implement configurable bias coefficients for scheduling based on contributions\n   - Create transparency triggers that increase visibility when influence exceeds thresholds\n   - Add backfire mechanics that reduce effectiveness when transparency triggers\n\n5. Implement required API endpoints:\n   - `POST /lobby/register`: Register a new lobbying entity\n   - `POST /lobby/disclose`: Record a new lobbying disclosure\n   - `POST /lobby/contribute`: Process a lobbying contribution\n   - `GET /lobby/disclosures`: Retrieve lobbying disclosures with filtering options\n\n6. Connect to existing systems:\n   - Integrate with the legislative system for influence effects\n   - Connect to the validator to ensure lobbying activities respect constitutional constraints\n   - Add hooks for persona advisors to reference lobbying data in proposals",
        "testStrategy": "The Lobbying & Disclosures system should be thoroughly tested using:\n\n1. Unit tests:\n   - Test entity registration with valid and invalid inputs\n   - Verify disclosure recording with various parameters\n   - Test contribution processing with different amounts and targets\n   - Ensure proper validation of all API inputs\n   - Verify correct calculation of influence metrics\n\n2. Integration tests:\n   - Test the connection between lobbying and legislative scheduling\n   - Verify that transparency triggers activate at appropriate thresholds\n   - Test backfire mechanics under various influence scenarios\n   - Ensure proper integration with the constitutional validator\n\n3. API tests:\n   - Test all endpoints with valid and invalid requests\n   - Verify proper error handling and status codes\n   - Test authentication and authorization requirements\n   - Ensure correct data is returned from GET requests\n\n4. Determinism tests:\n   - Verify that identical lobbying patterns produce identical influence effects\n   - Test that the system produces consistent results across multiple runs\n   - Ensure that transparency and backfire effects are deterministic\n\n5. Performance tests:\n   - Test system performance with large numbers of entities and disclosures\n   - Verify efficient querying of disclosure data\n   - Ensure the system can handle concurrent registration and disclosure requests",
        "status": "pending",
        "dependencies": [
          1,
          2,
          4
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Module Structure and Database Schemas",
            "description": "Set up the foundational file structure for the lobbying system and implement the database schemas for all required models.",
            "dependencies": [],
            "details": "Create the following files with their basic structure:\n- `/src/services/lobbying-service.js`: Core service with methods for entity registration, disclosure recording, and contribution processing\n- `/src/models/lobby-entity.js`: Schema with fields for name, type, sector, budget, and parent/subsidiary relationships\n- `/src/models/lobby-disclosure.js`: Schema with fields for timestamp, entity reference, target, amount, and purpose\n- `/src/models/lobby-contribution.js`: Schema with fields for entity, recipient, amount, date, and purpose\n- `/src/controllers/lobbying-controller.js`: Controller with route handlers for API endpoints\n\nImplement Mongoose schemas with proper validation rules for each model, including required fields, data types, and relationship references.",
            "status": "pending",
            "testStrategy": "Write unit tests for each model to verify schema validation works correctly. Test with valid and invalid inputs to ensure proper error handling."
          },
          {
            "id": 2,
            "title": "Implement Entity Registry and Validation",
            "description": "Build the entity registration system with validation rules, relationship tracking, and sector-based indexing.",
            "dependencies": [
              "6.1"
            ],
            "details": "In the lobbying service, implement:\n- Entity registration function that validates and stores new lobbying entities\n- Validation rules for required fields (name, type, sector)\n- Budget range validation (min/max thresholds)\n- Parent/subsidiary relationship tracking with circular reference prevention\n- Indexing for efficient sector-based queries\n- Methods to retrieve entities by ID, name, sector, or budget range\n- Update and deactivation functions for entity management\n\nAdd corresponding controller methods in lobbying-controller.js to expose the entity registration API.",
            "status": "pending",
            "testStrategy": "Test entity registration with valid and invalid inputs. Verify parent/subsidiary relationships are correctly established and queried. Test sector-based indexing performance with large datasets."
          },
          {
            "id": 3,
            "title": "Develop Disclosure System with Aggregation",
            "description": "Implement the disclosure recording system with aggregation functions and transparency mechanisms.",
            "dependencies": [
              "6.1",
              "6.2"
            ],
            "details": "In the lobbying service, implement:\n- Disclosure recording function that validates and stores lobbying activities\n- Contribution processing with amount validation and target verification\n- Aggregation functions to calculate total influence by entity, sector, or target\n- Time-based aggregation for reporting (daily, weekly, monthly, yearly)\n- Transparency triggers that flag high-value or frequent disclosures\n- Public exposure mechanisms that make disclosures available through API\n- Backfire effect calculation when influence exceeds configurable thresholds\n\nAdd corresponding controller methods for disclosure recording and retrieval.",
            "status": "pending",
            "testStrategy": "Test disclosure recording with various parameters. Verify aggregation functions correctly sum values across different dimensions. Test transparency triggers with threshold values."
          },
          {
            "id": 4,
            "title": "Build Bounded Influence Effects System",
            "description": "Implement the system that connects lobbying activities to agenda-setting with configurable bias coefficients and transparency triggers.",
            "dependencies": [
              "6.3"
            ],
            "details": "Develop the influence effects system that:\n- Connects to the legislative system (from Task 4) via a well-defined interface\n- Implements configurable bias coefficients that affect bill scheduling based on contributions\n- Creates a weighted influence calculator based on contribution amounts and entity sectors\n- Implements transparency triggers that increase visibility when influence exceeds thresholds\n- Adds backfire mechanics that reduce effectiveness when transparency is triggered\n- Provides methods to query current influence levels on specific legislative items\n- Includes decay functions for influence over time\n\nEnsure all influence effects respect constitutional constraints by connecting to the validator.",
            "status": "pending",
            "testStrategy": "Test influence calculations with various contribution scenarios. Verify bias coefficients correctly affect scheduling. Test transparency triggers and backfire mechanics with threshold values."
          },
          {
            "id": 5,
            "title": "Implement API Endpoints and Documentation",
            "description": "Create all required API endpoints for the lobbying system with proper request validation, error handling, and documentation.",
            "dependencies": [
              "6.2",
              "6.3",
              "6.4"
            ],
            "details": "Implement the following API endpoints in the lobbying controller:\n- `POST /lobby/register`: Register a new lobbying entity with validation\n- `POST /lobby/disclose`: Record a new lobbying disclosure with entity verification\n- `POST /lobby/contribute`: Process a lobbying contribution with amount validation\n- `GET /lobby/disclosures`: Retrieve lobbying disclosures with filtering options\n- `GET /lobby/entities`: Retrieve lobbying entities with filtering by sector/budget\n- `GET /lobby/influence`: Get aggregated influence data by entity/sector\n- `GET /lobby/transparency`: Get public transparency reports\n\nAdd request validation, error handling, and response formatting for all endpoints. Create API documentation using Swagger/OpenAPI.",
            "status": "pending",
            "testStrategy": "Test all API endpoints with valid and invalid requests. Verify proper error responses for invalid inputs. Test filtering and pagination for GET endpoints."
          },
          {
            "id": 6,
            "title": "Integrate with Existing Systems",
            "description": "Connect the lobbying system to existing legislative and validator systems, and implement hooks for persona advisors.",
            "dependencies": [
              "6.4",
              "6.5"
            ],
            "details": "Integrate the lobbying system with:\n- Legislative system: Connect influence effects to agenda-setting and scheduling mechanisms\n- Validator system: Ensure lobbying activities respect constitutional constraints\n- Persona advisors: Add hooks for advisors to reference lobbying data in proposals\n\nImplement:\n- Event listeners for legislative actions that might trigger lobbying disclosures\n- Validation hooks that check lobbying influence against constitutional limits\n- Data access methods for persona advisors to query lobbying information\n- Notification system for transparency triggers\n- Reporting interfaces for system-wide lobbying activity\n\nEnsure all integrations use well-defined interfaces with proper error handling and fallback mechanisms.",
            "status": "pending",
            "testStrategy": "Test integration points with mock objects representing the legislative and validator systems. Verify proper data flow between systems. Test error handling when dependent systems fail."
          }
        ]
      },
      {
        "id": 7,
        "title": "Implement Succession & Continuity State Machine",
        "description": "Develop a state machine and game setup options for leader removal scenarios (deposed, conquered, term expiry) with deterministic successor outcomes based on government archetypes.",
        "details": "The Succession & Continuity implementation should include:\n\n1. Create the module structure:\n   - `/src/services/succession-service.js`\n   - `/src/models/succession-event.js`\n   - `/src/models/successor.js`\n   - `/src/controllers/succession-controller.js`\n\n2. Implement the state machine for leader transitions:\n   - Define state transitions for all removal scenarios:\n     - Deposition (internal power struggle)\n     - Conquest (external takeover)\n     - Term expiry (normal democratic transition)\n   - Create event handlers for each transition type\n   - Implement validation rules to ensure transitions follow archetype rules\n\n3. Develop government archetype-specific succession rules:\n   - Democracy: implement term limits, election scheduling, interim leadership\n   - Autocracy: implement power struggles, coup mechanics, dynasty succession\n   - Oligarchy: implement council rotation, factional balance calculations\n   - Technocracy: implement merit-based succession formulas\n   - Theocracy: implement divine selection processes\n\n4. Create Game Setup configuration options:\n   - Allow customization of succession rules during game initialization\n   - Implement presets for common historical succession patterns\n   - Create UI configuration hooks for succession rule modification\n\n5. Implement required API endpoints:\n   - `GET /gov/succession/options`: Return available succession options based on current government\n   - `POST /gov/succession/apply`: Apply a succession event with specified parameters\n\n6. Ensure deterministic outcomes:\n   - Implement seeded random generation for any probabilistic elements\n   - Create comprehensive logging of succession event chains\n   - Build replay capability to verify deterministic behavior\n\n7. Integrate with existing government systems:\n   - Connect to constitutional validator for succession legality checks\n   - Update legislative bodies when leadership changes\n   - Trigger appropriate UI notifications and state updates",
        "testStrategy": "The Succession & Continuity system should be thoroughly tested using:\n\n1. Unit tests:\n   - Test each state transition type with various inputs\n   - Verify deterministic outcomes with identical inputs and seeds\n   - Test succession rules for each government archetype\n   - Ensure proper validation of illegal succession attempts\n   - Verify correct API responses for all endpoints\n\n2. Integration tests:\n   - Test interaction with constitutional validator\n   - Verify legislative body updates after succession events\n   - Test game setup configuration persistence\n   - Ensure proper event logging and replay functionality\n\n3. Scenario tests:\n   - Create test scenarios for each removal case:\n     - Democratic term expiry with peaceful transition\n     - Autocratic deposition with power struggle\n     - Conquest with regime change\n     - Mixed scenarios with multiple transitions\n   - Verify that outcomes match expected successor determination\n\n4. Performance tests:\n   - Measure response time for succession calculations\n   - Test with large numbers of potential successors\n   - Verify system stability during rapid succession events\n\n5. API tests:\n   - Test GET /gov/succession/options returns correct options based on government type\n   - Verify POST /gov/succession/apply correctly processes valid succession events\n   - Test error handling for invalid succession attempts\n   - Ensure proper authentication and authorization checks",
        "status": "pending",
        "dependencies": [
          1,
          2,
          4
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Module Structure and Base Models",
            "description": "Set up the foundational file structure and define the core models needed for the succession system.",
            "dependencies": [],
            "details": "Create the following files with their basic structure:\n1. `/src/services/succession-service.js`: Initialize with methods for handling succession events and state transitions.\n2. `/src/models/succession-event.js`: Define the model for succession events with properties for event type, timestamp, cause, affected leaders, and outcome.\n3. `/src/models/successor.js`: Create a model for potential successors with properties for candidate ID, legitimacy score, support metrics, and succession path.\n4. `/src/controllers/succession-controller.js`: Implement basic controller with route handlers for the required API endpoints.",
            "status": "pending",
            "testStrategy": "Write unit tests for each model to verify proper initialization and property validation. Test the basic service methods with mock data to ensure they're properly structured."
          },
          {
            "id": 2,
            "title": "Implement State Machine for Leader Transitions",
            "description": "Develop the core state machine that handles different types of leader removal scenarios and manages the transition process.",
            "dependencies": [
              "7.1"
            ],
            "details": "In the succession-service.js file:\n1. Define state transition functions for each removal scenario:\n   - `handleDeposition(currentLeader, cause)`: Handle internal power struggles\n   - `handleConquest(currentLeader, conqueror)`: Process external takeovers\n   - `handleTermExpiry(currentLeader)`: Manage normal democratic transitions\n2. Implement a main `processTransition(eventType, params)` method that routes to the appropriate handler\n3. Create validation rules in each handler to ensure transitions follow the rules of the current government archetype\n4. Implement event logging for each transition to ensure deterministic replay capability",
            "status": "pending",
            "testStrategy": "Create unit tests for each transition type with various input parameters. Verify that identical inputs produce identical outcomes. Test edge cases like contested successions or invalid transition attempts."
          },
          {
            "id": 3,
            "title": "Develop Government Archetype-Specific Succession Rules",
            "description": "Implement the succession rule sets for each government archetype, ensuring that leader transitions follow historically accurate and logically consistent patterns.",
            "dependencies": [
              "7.2"
            ],
            "details": "Create a rules engine in succession-service.js that implements:\n1. Democracy rules: Term limits, election scheduling, interim leadership during transitions\n2. Autocracy rules: Power struggles, coup mechanics, dynasty succession calculations\n3. Oligarchy rules: Council rotation logic, factional balance calculations\n4. Technocracy rules: Merit-based succession formulas using leader statistics\n5. Theocracy rules: Divine selection processes and religious hierarchy succession\n\nEach rule set should export a `determineSuccessor(currentState, event)` function that returns a deterministic successor based on the government type and event context.",
            "status": "pending",
            "testStrategy": "Test each government archetype's succession rules independently with various scenarios. Verify that edge cases (like tied votes in democracies or contested succession in autocracies) are handled consistently. Ensure that succession follows the expected patterns for each government type."
          },
          {
            "id": 4,
            "title": "Create Game Setup Configuration Options",
            "description": "Develop the configuration system that allows customization of succession rules during game initialization and provides preset historical patterns.",
            "dependencies": [
              "7.3"
            ],
            "details": "1. Create a `/src/config/succession-presets.js` file with historical succession pattern presets\n2. Implement a configuration schema in `/src/models/succession-config.js` that defines all customizable succession parameters\n3. Add methods to succession-service.js to load and apply configuration options:\n   - `loadPreset(presetName)`: Load a predefined succession configuration\n   - `applyCustomConfig(configOptions)`: Apply custom succession rules\n4. Create UI configuration hooks in the controller that expose configuration options to the frontend\n5. Implement validation to ensure configurations maintain game balance",
            "status": "pending",
            "testStrategy": "Test loading of each preset configuration and verify it produces the expected succession behavior. Test applying custom configurations with both valid and invalid parameters. Verify that UI hooks correctly expose the configuration options."
          },
          {
            "id": 5,
            "title": "Implement Required API Endpoints",
            "description": "Develop the API endpoints needed for the succession system to interact with the rest of the application.",
            "dependencies": [
              "7.1",
              "7.2",
              "7.3",
              "7.4"
            ],
            "details": "In succession-controller.js, implement the following endpoints:\n1. `GET /gov/succession/options`: Return available succession options based on current government type\n   - Query parameters: governmentType, currentLeaderId\n   - Response: JSON object with available succession mechanisms\n2. `POST /gov/succession/apply`: Apply a succession event with specified parameters\n   - Request body: eventType, cause, parameters\n   - Response: Succession event outcome with new leader information\n3. `GET /gov/succession/history`: Retrieve succession history for the current game\n4. `GET /gov/succession/forecast`: Calculate potential successors based on current state",
            "status": "pending",
            "testStrategy": "Create integration tests for each API endpoint with various request parameters. Test authentication and authorization requirements. Verify that responses match expected formats and contain all required information."
          },
          {
            "id": 6,
            "title": "Integrate with Existing Government Systems",
            "description": "Connect the succession system with other government components to ensure cohesive state management and proper event propagation.",
            "dependencies": [
              "7.5"
            ],
            "details": "1. Connect to the constitutional validator:\n   - Import the validator service in succession-service.js\n   - Add validation calls before finalizing succession events\n   - Handle validation failures appropriately\n2. Update legislative bodies when leadership changes:\n   - Implement hooks in succession-service.js that trigger legislative updates\n   - Handle special cases like dissolved parliaments or emergency sessions\n3. Implement UI notification system:\n   - Create event emitters for succession events\n   - Define notification templates for different succession types\n4. Ensure proper state synchronization:\n   - Implement database transactions for atomic succession events\n   - Create rollback mechanisms for failed transitions",
            "status": "pending",
            "testStrategy": "Develop integration tests that verify proper interaction between the succession system and other government components. Test scenarios like constitutional crises, contested successions, and normal transitions to ensure all systems remain synchronized."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-14T08:55:11.204Z",
      "updated": "2025-08-14T09:44:59.239Z",
      "description": "Unified Sprint 3: Policies & Advisors (copilot, constitutional court, personas)"
    }
  }
}